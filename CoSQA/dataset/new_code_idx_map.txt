{
 "def writeBoolean ( self , n ) : t = TYPE_BOOL_TRUE if n is False : t = TYPE_BOOL_FALSE self . stream . write ( t ) ": 0,
 "def paste ( xsel = False ) : selection = \" primary \" if xsel else \" clipboard \" try : return subprocess . Popen ( [ \" xclip \" , \" -selection \" , selection , \" -o \" ] , stdout = subprocess . PIPE ) . communicate ( ) [0] . decode ( \" utf-8 \" ) except OSError as why : raise XclipNotFound": 1,
 "def _format_json ( data , theme ) : output = json . dumps ( data , indent = 2 , sort_keys = True ) if pygments and sys . stdout . isatty ( ) : style = get_style_by_name ( theme ) formatter = Terminal256Formatter ( style = style ) return pygments . highlight ( output , JsonLexer ( ) , formatter ) return output": 2,
 "def create_path ( path ) : import os if not os . path . exists ( path ) : os . makedirs ( path ) ": 3,
 "def _vector_or_scalar ( x , type = ' row ' ) : if isinstance ( x , ( list , tuple ) ) : x = np . array ( x ) if isinstance ( x , np . ndarray ) : assert x . ndim = = 1 if type = = ' column ' : x = x[ : , None] return x": 4,
 "def experiment_property ( prop ) : exp = experiment ( session ) p = getattr ( exp , prop ) return success_response ( field = prop , data = p , request_type = prop ) ": 5,
 "def data_from_file ( file ) : fp = wave . open ( file , ' r ' ) data = fp . readframes ( fp . getnframes ( ) ) channels = fp . getnchannels ( ) freq = fp . getframerate ( ) bits = fp . getsampwidth ( ) # Unpack bytes -- warning currently only tested with 16 bit wavefiles . 32 # bit not supported . data = struct . unpack ( ( ' %sh ' % fp . getnframes ( ) ) * channels , data ) # Only use first channel channel1 = [] n = 0 for d in data : if n % channels = = 0 : channel1 . append ( d ) n + = 1 fp . close ( ) return ( channel1 , freq , bits ) ": 6,
 "def source_range ( start , end , nr_var_dict ) : return OrderedDict ( ( k , e-s ) for k , ( s , e ) in source_range_tuple ( start , end , nr_var_dict ) . iteritems ( ) ) ": 7,
 "def timespan ( start_time ) : timespan = datetime . datetime . now ( ) - start_time timespan_ms = timespan . total_seconds ( ) * 1000 return timespan_ms": 8,
 "def _convert_to_array ( array_like , dtype ) : if isinstance ( array_like , bytes ) : return np . frombuffer ( array_like , dtype = dtype ) return np . asarray ( array_like , dtype = dtype ) ": 9,
 "def get_uniques ( l ) : result = [] for i in l : if i not in result : result . append ( i ) return result": 10,
 "def interp ( x , xp , *args , **kwargs ) : return interpolate_1d ( x , xp , *args , **kwargs ) ": 11,
 "def _array2cstr ( arr ) : out = StringIO ( ) np . save ( out , arr ) return b64encode ( out . getvalue ( ) ) ": 12,
 "def percentile ( values , k ) : if not values : return None values . sort ( ) index = ( len ( values ) * ( float ( k ) / 100 ) ) - 1 return values[int ( math . ceil ( index ) ) ]": 13,
 "def _string_hash ( s ) : h = 5381 for c in s : h = h * 33 + ord ( c ) return h": 14,
 "def transform_from_rot_trans ( R , t ) : R = R . reshape ( 3 , 3 ) t = t . reshape ( 3 , 1 ) return np . vstack ( ( np . hstack ( [R , t] ) , [0 , 0 , 0 , 1] ) ) ": 15,
 "def _encode_bool ( name , value , dummy0 , dummy1 ) : return b \" \\x08 \" + name + ( value and b \" \\x01 \" or b \" \\x00 \" ) ": 16,
 "def transform_to_3d ( points , normal , z = 0 ) : d = np . cross ( normal , ( 0 , 0 , 1 ) ) M = rotation_matrix ( d ) transformed_points = M . dot ( points . T ) . T + z return transformed_points": 17,
 "def _not ( condition = None , **kwargs ) : result = True if condition is not None : result = not run ( condition , **kwargs ) return result": 18,
 "def HttpResponse403 ( request , template = KEY_AUTH_403_TEMPLATE , content = KEY_AUTH_403_CONTENT , content_type = KEY_AUTH_403_CONTENT_TYPE ) : return AccessFailedResponse ( request , template , content , content_type , status = 403 ) ": 19,
 "def items ( self , section_name ) : return [ ( k , v ) for k , v in super ( GitConfigParser , self ) . items ( section_name ) if k ! = ' __name__ ' ]": 20,
 "def mag ( z ) : if isinstance ( z[0] , np . ndarray ) : return np . array ( list ( map ( np . linalg . norm , z ) ) ) else : return np . linalg . norm ( z ) ": 21,
 "def config_parser_to_dict ( config_parser ) : response = {} for section in config_parser . sections ( ) : for option in config_parser . options ( section ) : response . setdefault ( section , {} ) [option] = config_parser . get ( section , option ) return response": 22,
 "def __add__ ( self , other ) : return self . _handle_type ( other ) ( self . value + other . value ) ": 23,
 "def connect_mysql ( host , port , user , password , database ) : return pymysql . connect ( host = host , port = port , user = user , passwd = password , db = database ) ": 24,
 "def get_column ( self , X , column ) : if isinstance ( X , pd . DataFrame ) : return X[column] . values return X[ : , column]": 25,
 "def connect ( url , username , password ) : bb_session = stashy . connect ( url , username , password ) logger . info ( ' Connected to : %s as %s ' , url , username ) return bb_session": 26,
 "def add_blank_row ( self , label ) : col_labels = self . df . columns blank_item = pd . Series ( {} , index = col_labels , name = label ) # use . loc to add in place ( append won ' t do that ) self . df . loc[blank_item . name] = blank_item return self . df": 27,
 "def teardown ( self ) : while self . _http_clients : self . _http_clients . pop ( ) . close ( ) if self . created : self . halt ( ) ": 28,
 "def dumped ( text , level , indent = 2 ) : return indented ( \" {\\n%s\\n} \" % indented ( text , level + 1 , indent ) or \" None \" , level , indent ) + \" \\n \" ": 29,
 "def context ( self ) : parent = _ACTION_CONTEXT . set ( self ) try : yield self finally : _ACTION_CONTEXT . reset ( parent ) ": 30,
 "def pformat ( object , indent = 1 , width = 80 , depth = None ) : return PrettyPrinter ( indent = indent , width = width , depth = depth ) . pformat ( object ) ": 31,
 "def replace_sys_args ( new_args ) : # Replace sys . argv arguments # for module import old_args = sys . argv sys . argv = new_args try : yield finally : sys . argv = old_args": 32,
 "def serialize ( obj ) : if isinstance ( obj , list ) : return [serialize ( o ) for o in obj] return GenericSerializer ( ModelProviderImpl ( ) ) . serialize ( obj ) ": 33,
 "def advance_one_line ( self ) : current_line = self . _current_token . line_number while current_line = = self . _current_token . line_number : self . _current_token = ConfigParser . Token ( *next ( self . _token_generator ) ) ": 34,
 "def generate_swagger_html ( swagger_static_root , swagger_json_url ) : tmpl = _get_template ( \" swagger . html \" ) return tmpl . render ( swagger_root = swagger_static_root , swagger_json_url = swagger_json_url ) ": 35,
 "def do_next ( self , args ) : self . _do_print_from_last_cmd = True self . _interp . step_over ( ) return True": 36,
 "def __add__ ( self , other ) : assert self . matrix . shape[1] = = other . matrix . shape[1] return LabeledMatrix ( np . concatenate ( [self . matrix , other . matrix] , axis = 0 ) , self . labels ) ": 37,
 "def get_line_flux ( line_wave , wave , flux , **kwargs ) : return np . interp ( line_wave , wave , flux , **kwargs ) ": 38,
 "def send ( message , request_context = None , binary = False ) : if binary : return uwsgi . websocket_send_binary ( message , request_context ) return uwsgi . websocket_send ( message , request_context ) ": 39,
 "def get_number ( s , cast = int ) : import string d = \" \" . join ( x for x in str ( s ) if x in string . digits ) return cast ( d ) ": 40,
 "def get_hline ( ) : return Window ( width = LayoutDimension . exact ( 1 ) , height = LayoutDimension . exact ( 1 ) , content = FillControl ( ' - ' , token = Token . Line ) ) ": 41,
 "def parse_cookies_str ( cookies ) : cookie_dict = {} for record in cookies . split ( \" ; \" ) : key , value = record . strip ( ) . split ( \" = \" , 1 ) cookie_dict[key] = value return cookie_dict": 42,
 "def to_snake_case ( name ) : s1 = FIRST_CAP_REGEX . sub ( r ' \\1_\\2 ' , name ) return ALL_CAP_REGEX . sub ( r ' \\1_\\2 ' , s1 ) . lower ( ) ": 43,
 "def populate_obj ( obj , attrs ) : for k , v in attrs . iteritems ( ) : setattr ( obj , k , v ) ": 44,
 "def wordfreq ( text , is_filename = False ) : if is_filename : with open ( text ) as f : text = f . read ( ) freqs = {} for word in text . split ( ) : lword = word . lower ( ) freqs[lword] = freqs . get ( lword , 0 ) + 1 return freqs": 45,
 "def copyFile ( input , output , replace = None ) : _found = findFile ( output ) if not _found or ( _found and replace ) : shutil . copy2 ( input , output ) ": 46,
 "def push ( h , x ) : h . push ( x ) up ( h , h . size ( ) -1 ) ": 47,
 "def yank ( event ) : event . current_buffer . paste_clipboard_data ( event . cli . clipboard . get_data ( ) , count = event . arg , paste_mode = PasteMode . EMACS ) ": 48,
 "def filter_contour ( imageFile , opFile ) : im = Image . open ( imageFile ) im1 = im . filter ( ImageFilter . CONTOUR ) im1 . save ( opFile ) ": 49,
 "def count ( lines ) : words = [w for l in lines for w in l . strip ( ) . split ( ) ] return Counter ( words ) ": 50,
 "def dictapply ( d , fn ) : for k , v in d . items ( ) : if isinstance ( v , dict ) : v = dictapply ( v , fn ) else : d[k] = fn ( v ) return d": 51,
 "def count_replica ( self , partition ) : return sum ( 1 for b in partition . replicas if b in self . brokers ) ": 52,
 "def visit_Name ( self , node ) : return self . add ( node , self . result[node . id] ) ": 53,
 "def mkdir ( dir , enter ) : if not os . path . exists ( dir ) : os . makedirs ( dir ) ": 54,
 "def qrot ( vector , quaternion ) : t = 2 * np . cross ( quaternion[1 : ] , vector ) v_rot = vector + quaternion[0] * t + np . cross ( quaternion[1 : ] , t ) return v_rot": 55,
 "def _numpy_char_to_bytes ( arr ) : # based on : http : //stackoverflow . com/a/10984878/809705 arr = np . array ( arr , copy = False , order = ' C ' ) dtype = ' S ' + str ( arr . shape[-1] ) return arr . view ( dtype ) . reshape ( arr . shape[ : -1] ) ": 56,
 "def csv_to_dicts ( file , header = None ) : with open ( file ) as csvfile : return [row for row in csv . DictReader ( csvfile , fieldnames = header ) ]": 57,
 "def get_tri_area ( pts ) : a , b , c = pts[0] , pts[1] , pts[2] v1 = np . array ( b ) - np . array ( a ) v2 = np . array ( c ) - np . array ( a ) area_tri = abs ( sp . linalg . norm ( sp . cross ( v1 , v2 ) ) / 2 ) return area_tri": 58,
 "def one_hot ( x , size , dtype = np . float32 ) : return np . array ( x[ . . . , np . newaxis] = = np . arange ( size ) , dtype ) ": 59,
 "def round_to_int ( number , precision ) : precision = int ( precision ) rounded = ( int ( number ) + precision / 2 ) // precision * precision return rounded": 60,
 "def create_object ( cls , members ) : obj = cls . __new__ ( cls ) obj . __dict__ = members return obj": 61,
 "def to_unicode_repr ( _letter ) : # Python 2-3 compatible return u \" u ' \" + u \" \" . join ( [ u \" \\\\u%04x \" %ord ( l ) for l in _letter ] ) + u \" ' \" ": 62,
 "def string_input ( prompt = ' ' ) : v = sys . version[0] if v = = ' 3 ' : return input ( prompt ) else : return raw_input ( prompt ) ": 63,
 "def cfloat64_array_to_numpy ( cptr , length ) : if isinstance ( cptr , ctypes . POINTER ( ctypes . c_double ) ) : return np . fromiter ( cptr , dtype = np . float64 , count = length ) else : raise RuntimeError ( ' Expected double pointer ' ) ": 64,
 "def yn_prompt ( msg , default = True ) : ret = custom_prompt ( msg , [ \" y \" , \" n \" ] , \" y \" if default else \" n \" ) if ret = = \" y \" : return True return False": 65,
 "def _display ( self , layout ) : print ( file = self . out ) TextWriter ( ) . format ( layout , self . out ) ": 66,
 "def assert_list ( self , putative_list , expected_type = string_types , key_arg = None ) : return assert_list ( putative_list , expected_type , key_arg = key_arg , raise_type = lambda msg : TargetDefinitionException ( self , msg ) ) ": 67,
 "def _xxrange ( self , start , end , step_count ) : _step = ( end - start ) / float ( step_count ) return ( start + ( i * _step ) for i in xrange ( int ( step_count ) ) ) ": 68,
 "def assert_exactly_one_true ( bool_list ) : assert isinstance ( bool_list , list ) counter = 0 for item in bool_list : if item : counter + = 1 return counter = = 1": 69,
 "def _get_random_id ( ) : symbols = string . ascii_uppercase + string . ascii_lowercase + string . digits return ' ' . join ( random . choice ( symbols ) for _ in range ( 15 ) ) ": 70,
 "async def list ( source ) : result = [] async with streamcontext ( source ) as streamer : async for item in streamer : result . append ( item ) yield result": 71,
 "def _attrprint ( d , delimiter = ' , ' ) : return delimiter . join ( ( ' \" %s \" = \" %s \" ' % item ) for item in sorted ( d . items ( ) ) ) ": 72,
 "def get_next_scheduled_time ( cron_string ) : itr = croniter . croniter ( cron_string , datetime . utcnow ( ) ) return itr . get_next ( datetime ) ": 73,
 "def exit ( exit_code = 0 ) : r core . processExitHooks ( ) if state . isExitHooked and not hasattr ( sys , ' exitfunc ' ) : # The function is called from the exit hook sys . stderr . flush ( ) sys . stdout . flush ( ) os . _exit ( exit_code ) # pylint : disable = W0212 sys . exit ( exit_code ) ": 74,
 "def dot_product ( self , other ) : return self . x * other . x + self . y * other . y": 75,
 "def reloader_thread ( softexit = False ) : while RUN_RELOADER : if code_changed ( ) : # force reload if softexit : sys . exit ( 3 ) else : os . _exit ( 3 ) time . sleep ( 1 ) ": 76,
 "def list_to_csv ( value ) : if isinstance ( value , ( list , tuple , set ) ) : value = \" , \" . join ( value ) return value": 77,
 "def average ( iterator ) : count = 0 total = 0 for num in iterator : count + = 1 total + = num return float ( total ) /count": 78,
 "def cint32_array_to_numpy ( cptr , length ) : if isinstance ( cptr , ctypes . POINTER ( ctypes . c_int32 ) ) : return np . fromiter ( cptr , dtype = np . int32 , count = length ) else : raise RuntimeError ( ' Expected int pointer ' ) ": 79,
 "def _aws_get_instance_by_tag ( region , name , tag , raw ) : client = boto3 . session . Session ( ) . client ( ' ec2 ' , region ) matching_reservations = client . describe_instances ( Filters = [{ ' Name ' : tag , ' Values ' : [name]}] ) . get ( ' Reservations ' , [] ) instances = [] [[instances . append ( _aws_instance_from_dict ( region , instance , raw ) ) # pylint : disable = expression-not-assigned for instance in reservation . get ( ' Instances ' ) ] for reservation in matching_reservations if reservation] return instances": 80,
 "def loganalytics_data_plane_client ( cli_ctx , _ ) : from . vendored_sdks . loganalytics import LogAnalyticsDataClient from azure . cli . core . _profile import Profile profile = Profile ( cli_ctx = cli_ctx ) cred , _ , _ = profile . get_login_credentials ( resource = \" https : //api . loganalytics . io \" ) return LogAnalyticsDataClient ( cred ) ": 81,
 "def cfloat32_array_to_numpy ( cptr , length ) : if isinstance ( cptr , ctypes . POINTER ( ctypes . c_float ) ) : return np . fromiter ( cptr , dtype = np . float32 , count = length ) else : raise RuntimeError ( ' Expected float pointer ' ) ": 82,
 "def underscore ( text ) : return UNDERSCORE[1] . sub ( r ' \\1_\\2 ' , UNDERSCORE[0] . sub ( r ' \\1_\\2 ' , text ) ) . lower ( ) ": 83,
 "def cint8_array_to_numpy ( cptr , length ) : if isinstance ( cptr , ctypes . POINTER ( ctypes . c_int8 ) ) : return np . fromiter ( cptr , dtype = np . int8 , count = length ) else : raise RuntimeError ( ' Expected int pointer ' ) ": 84,
 "def get_stoplist ( language ) : file_path = os . path . join ( \" stoplists \" , \" %s . txt \" % language ) try : stopwords = pkgutil . get_data ( \" justext \" , file_path ) except IOError : raise ValueError ( \" Stoplist for language ' %s ' is missing . \" \" Please use function ' get_stoplists ' for complete list of stoplists \" \" and feel free to contribute by your own stoplist . \" % language ) return frozenset ( w . decode ( \" utf8 \" ) . lower ( ) for w in stopwords . splitlines ( ) ) ": 85,
 "def add_str ( window , line_num , str ) : try : window . addstr ( line_num , 0 , str ) except curses . error : pass": 86,
 "def relative_path ( path ) : return os . path . join ( os . path . dirname ( __file__ ) , path ) ": 87,
 "def dictfetchall ( cursor ) : desc = cursor . description return [dict ( zip ( [col[0] for col in desc] , row ) ) for row in cursor . fetchall ( ) ]": 88,
 "def xmltreefromfile ( filename ) : try : return ElementTree . parse ( filename , ElementTree . XMLParser ( collect_ids = False ) ) except TypeError : return ElementTree . parse ( filename , ElementTree . XMLParser ( ) ) ": 89,
 "def _dictfetchall ( self , cursor ) : columns = [col[0] for col in cursor . description] return [ dict ( zip ( columns , row ) ) for row in cursor . fetchall ( ) ]": 90,
 "def beta_pdf ( x , a , b ) : bc = 1 / beta ( a , b ) fc = x ** ( a - 1 ) sc = ( 1 - x ) ** ( b - 1 ) return bc * fc * sc": 91,
 "def filter_out ( queryset , setting_name ) : kwargs = helpers . get_settings ( ) . get ( setting_name , {} ) . get ( ' FILTER_OUT ' , {} ) queryset = queryset . exclude ( **kwargs ) return queryset": 92,
 "def intToBin ( i ) : # divide in two parts ( bytes ) i1 = i % 256 i2 = int ( i / 256 ) # make string ( little endian ) return i . to_bytes ( 2 , byteorder = ' little ' ) ": 93,
 "def listlike ( obj ) : return hasattr ( obj , \" __iter__ \" ) \\ and not issubclass ( type ( obj ) , str ) \\ and not issubclass ( type ( obj ) , unicode ) ": 94,
 "def table_top_abs ( self ) : table_height = np . array ( [0 , 0 , self . table_full_size[2]] ) return string_to_array ( self . floor . get ( \" pos \" ) ) + table_height": 95,
 "def pdf ( x , mu , std ) : return ( 1 . 0 / ( std * sqrt ( 2 * pi ) ) ) * np . exp ( - ( x - mu ) ** 2 / ( 2 * std ** 2 ) ) ": 96,
 "def bytes_to_c_array ( data ) : chars = [ \" ' {} ' \" . format ( encode_escape ( i ) ) for i in decode_escape ( data ) ] return ' , ' . join ( chars ) + ' , 0 ' ": 97,
 "def gray2bgr ( img ) : img = img[ . . . , None] if img . ndim = = 2 else img out_img = cv2 . cvtColor ( img , cv2 . COLOR_GRAY2BGR ) return out_img": 98,
 "def mean_date ( dt_list ) : dt_list_sort = sorted ( dt_list ) dt_list_sort_rel = [dt - dt_list_sort[0] for dt in dt_list_sort] avg_timedelta = sum ( dt_list_sort_rel , timedelta ( ) ) /len ( dt_list_sort_rel ) return dt_list_sort[0] + avg_timedelta": 99,
 "def rotate_img ( im , deg , mode = cv2 . BORDER_CONSTANT , interpolation = cv2 . INTER_AREA ) : r , c , *_ = im . shape M = cv2 . getRotationMatrix2D ( ( c//2 , r//2 ) , deg , 1 ) return cv2 . warpAffine ( im , M , ( c , r ) , borderMode = mode , flags = cv2 . WARP_FILL_OUTLIERS+interpolation ) ": 100,
 "def similarity ( self , other ) : if self . magnitude = = 0 or other . magnitude = = 0 : return 0 return self . dot ( other ) / self . magnitude": 101,
 "def _calculate_distance ( latlon1 , latlon2 ) : lat1 , lon1 = latlon1 lat2 , lon2 = latlon2 dlon = lon2 - lon1 dlat = lat2 - lat1 R = 6371 # radius of the earth in kilometers a = np . sin ( dlat / 2 ) **2 + np . cos ( lat1 ) * np . cos ( lat2 ) * ( np . sin ( dlon / 2 ) ) **2 c = 2 * np . pi * R * np . arctan2 ( np . sqrt ( a ) , np . sqrt ( 1 - a ) ) / 180 return c": 102,
 "def screen_cv2 ( self ) : pil_image = self . screen . convert ( ' RGB ' ) cv2_image = np . array ( pil_image ) pil_image . close ( ) # Convert RGB to BGR cv2_image = cv2_image[ : , : , : : -1] return cv2_image": 103,
 "def direct2dDistance ( self , point ) : if not isinstance ( point , MapPoint ) : return 0 . 0 return ( ( self . x-point . x ) **2 + ( self . y-point . y ) **2 ) ** ( 0 . 5 ) # simple distance formula": 104,
 "def _model_unique ( ins ) : unique = [] for t in ins . tables : for c in t . constraints : if isinstance ( c , UniqueConstraint ) : unique . append ( tuple ( col . key for col in c . columns ) ) return unique": 105,
 "def horz_dpi ( self ) : pHYs = self . _chunks . pHYs if pHYs is None : return 72 return self . _dpi ( pHYs . units_specifier , pHYs . horz_px_per_unit ) ": 106,
 "def parse ( self , s ) : return datetime . datetime . strptime ( s , self . date_format ) . date ( ) ": 107,
 "def estimate_complexity ( self , x , y , z , n ) : num_calculations = x * y * z * n run_time = num_calculations / 100000 # a 2014 PC does about 100k calcs in a second ( guess based on prior logs ) return self . show_time_as_short_string ( run_time ) ": 108,
 "def weekly ( date = datetime . date . today ( ) ) : return date - datetime . timedelta ( days = date . weekday ( ) ) ": 109,
 "def inh ( table ) : t = [] for i in table : t . append ( np . ndarray . tolist ( np . arcsinh ( i ) ) ) return t": 110,
 "def daterange ( start , end , delta = timedelta ( days = 1 ) , lower = Interval . CLOSED , upper = Interval . OPEN ) : date_interval = Interval ( lower = lower , lower_value = start , upper_value = end , upper = upper ) current = start if start in date_interval else start + delta while current in date_interval : yield current current = current + delta": 111,
 "async def _thread_coro ( self , *args ) : return await self . _loop . run_in_executor ( self . _executor , self . _function , *args ) ": 112,
 "def start_of_month ( val ) : if type ( val ) = = date : val = datetime . fromordinal ( val . toordinal ( ) ) return start_of_day ( val ) . replace ( day = 1 ) ": 113,
 "def check_output ( args , env = None , sp = subprocess ) : log . debug ( ' calling %s with env %s ' , args , env ) output = sp . check_output ( args = args , env = env ) log . debug ( ' output : %r ' , output ) return output": 114,
 "def datetime_to_ms ( dt ) : seconds = calendar . timegm ( dt . utctimetuple ( ) ) return seconds * 1000 + int ( dt . microsecond / 1000 ) ": 115,
 "def retry_on_signal ( function ) : while True : try : return function ( ) except EnvironmentError , e : if e . errno ! = errno . EINTR : raise": 116,
 "def datetime_to_timezone ( date , tz = \" UTC \" ) : if not date . tzinfo : date = date . replace ( tzinfo = timezone ( get_timezone ( ) ) ) return date . astimezone ( timezone ( tz ) ) ": 117,
 "def test ( *args ) : subprocess . call ( [ \" py . test-2 . 7 \" ] + list ( args ) ) subprocess . call ( [ \" py . test-3 . 4 \" ] + list ( args ) ) ": 118,
 "def ToDatetime ( self ) : return datetime . utcfromtimestamp ( self . seconds + self . nanos / float ( _NANOS_PER_SECOND ) ) ": 119,
 "def sortable_title ( instance ) : title = plone_sortable_title ( instance ) if safe_callable ( title ) : title = title ( ) return title . lower ( ) ": 120,
 "def localize ( dt ) : if dt . tzinfo is UTC : return ( dt + LOCAL_UTC_OFFSET ) . replace ( tzinfo = None ) # No TZ info so not going to assume anything , return as-is . return dt": 121,
 "def percent_cb ( name , complete , total ) : logger . debug ( \" {} : {} transferred out of {} \" . format ( name , sizeof_fmt ( complete ) , sizeof_fmt ( total ) ) ) progress . update_target ( name , complete , total ) ": 122,
 "def now ( self ) : \t\t\t\tif self . use_utc : \t\t\treturn datetime . datetime . utcnow ( ) \t\telse : \t\t\treturn datetime . datetime . now ( ) ": 123,
 "def to_pascal_case ( s ) : return re . sub ( r ' ( ?!^ ) _ ( [a-zA-Z] ) ' , lambda m : m . group ( 1 ) . upper ( ) , s . capitalize ( ) ) ": 124,
 "def _convert_date_to_dict ( field_date ) : return {DAY : field_date . day , MONTH : field_date . month , YEAR : field_date . year}": 125,
 "def convert_array ( array ) : out = io . BytesIO ( array ) out . seek ( 0 ) return np . load ( out ) ": 126,
 "def parse_timestamp ( timestamp ) : dt = dateutil . parser . parse ( timestamp ) return dt . astimezone ( dateutil . tz . tzutc ( ) ) ": 127,
 "def add_to_js ( self , name , var ) : frame = self . page ( ) . mainFrame ( ) frame . addToJavaScriptWindowObject ( name , var ) ": 128,
 "def fromtimestamp ( cls , timestamp ) : d = cls . utcfromtimestamp ( timestamp ) return d . astimezone ( localtz ( ) ) ": 129,
 "def print_latex ( o ) : if can_print_latex ( o ) : s = latex ( o , mode = ' plain ' ) s = s . replace ( ' \\\\dag ' , ' \\\\dagger ' ) s = s . strip ( ' $ ' ) return ' $$%s$$ ' % s # Fallback to the string printer return None": 130,
 "def datetime64_to_datetime ( dt ) : dt64 = np . datetime64 ( dt ) ts = ( dt64 - np . datetime64 ( ' 1970-01-01T00 : 00 : 00 ' ) ) / np . timedelta64 ( 1 , ' s ' ) return datetime . datetime . utcfromtimestamp ( ts ) ": 131,
 "def batch_tensor ( self , name ) : if name in self . transition_tensors : return tensor_util . merge_first_two_dims ( self . transition_tensors[name] ) else : return self . rollout_tensors[name]": 132,
 "def isInteractive ( ) : if sys . stdout . isatty ( ) and os . name ! = ' nt ' : # Hopefully everything but ms supports ' \\r ' try : import threading except ImportError : return False else : return True else : return False": 133,
 "def create_symlink ( source , link_name ) : os_symlink = getattr ( os , \" symlink \" , None ) if isinstance ( os_symlink , collections . Callable ) : os_symlink ( source , link_name ) else : import ctypes csl = ctypes . windll . kernel32 . CreateSymbolicLinkW csl . argtypes = ( ctypes . c_wchar_p , ctypes . c_wchar_p , ctypes . c_uint32 ) csl . restype = ctypes . c_ubyte flags = 1 if os . path . isdir ( source ) else 0 if csl ( link_name , source , flags ) = = 0 : raise ctypes . WinError ( ) ": 134,
 "def export ( defn ) : globals ( ) [defn . __name__] = defn __all__ . append ( defn . __name__ ) return defn": 135,
 "def parse ( source , remove_comments = True , **kw ) : return ElementTree . parse ( source , SourceLineParser ( ) , **kw ) ": 136,
 "def decorator ( func ) : r def wrapper ( __decorated__ = None , *Args , **KwArgs ) : if __decorated__ is None : # the decorator has some optional arguments . return lambda _func : func ( _func , *Args , **KwArgs ) else : return func ( __decorated__ , *Args , **KwArgs ) return wrap ( wrapper , func ) ": 137,
 "def show_image ( self , key ) : data = self . model . get_data ( ) data[key] . show ( ) ": 138,
 "def get_default_args ( func ) : args , varargs , keywords , defaults = getargspec_no_self ( func ) return dict ( zip ( args[-len ( defaults ) : ] , defaults ) ) ": 139,
 "def _interval_to_bound_points ( array ) : array_boundaries = np . array ( [x . left for x in array] ) array_boundaries = np . concatenate ( ( array_boundaries , np . array ( [array[-1] . right] ) ) ) return array_boundaries": 140,
 "def closing_plugin ( self , cancelable = False ) : self . dialog_manager . close_all ( ) self . shell . exit_interpreter ( ) return True": 141,
 "def test ( ) : from spyder . utils . qthelpers import qapplication app = qapplication ( ) dlg = ProjectDialog ( None ) dlg . show ( ) sys . exit ( app . exec_ ( ) ) ": 142,
 "def del_label ( self , name ) : labels_tag = self . root[0] labels_tag . remove ( self . _find_label ( name ) ) ": 143,
 "def mixedcase ( path ) : words = path . split ( ' _ ' ) return words[0] + ' ' . join ( word . title ( ) for word in words[1 : ] ) ": 144,
 "def delete_all_eggs ( self ) : path_to_delete = os . path . join ( self . egg_directory , \" lib \" , \" python \" ) if os . path . exists ( path_to_delete ) : shutil . rmtree ( path_to_delete ) ": 145,
 "def get_system_cpu_times ( ) : user , nice , system , idle = _psutil_osx . get_system_cpu_times ( ) return _cputimes_ntuple ( user , nice , system , idle ) ": 146,
 "def remove ( self , document_id , namespace , timestamp ) : self . solr . delete ( id = u ( document_id ) , commit = ( self . auto_commit_interval = = 0 ) ) ": 147,
 "def update_hash_from_str ( hsh , str_input ) : byte_input = str ( str_input ) . encode ( \" UTF-8 \" ) hsh . update ( byte_input ) ": 148,
 "def make_regex ( separator ) : return re . compile ( r ' ( ? : ' + re . escape ( separator ) + r ' ) ? ( ( ? : [^ ' + re . escape ( separator ) + r ' \\\\]|\\\\ . ) + ) ' ) ": 149,
 "def dictify ( a_named_tuple ) : return dict ( ( s , getattr ( a_named_tuple , s ) ) for s in a_named_tuple . _fields ) ": 150,
 "def _py2_and_3_joiner ( sep , joinable ) : if ISPY3 : sep = bytes ( sep , DEFAULT_ENCODING ) joined = sep . join ( joinable ) return joined . decode ( DEFAULT_ENCODING ) if ISPY3 else joined": 151,
 "def c_str ( string ) : if not isinstance ( string , str ) : string = string . decode ( ' ascii ' ) return ctypes . c_char_p ( string . encode ( ' utf-8 ' ) ) ": 152,
 "def endline_semicolon_check ( self , original , loc , tokens ) : return self . check_strict ( \" semicolon at end of line \" , original , loc , tokens ) ": 153,
 "def _datetime_to_date ( arg ) : _arg = parse ( arg ) if isinstance ( _arg , datetime . datetime ) : _arg = _arg . date ( ) return _arg": 154,
 "def get ( self ) : with self . _mutex : entry = self . _queue . pop ( ) del self . _block_map[entry[2]] return entry[2]": 155,
 "def center_text ( text , width = 80 ) : centered = [] for line in text . splitlines ( ) : centered . append ( line . center ( width ) ) return \" \\n \" . join ( centered ) ": 156,
 "def from_json ( cls , json_str ) : d = json . loads ( json_str ) return cls . from_dict ( d ) ": 157,
 "def update ( kernel = False ) : manager = MANAGER cmds = { ' yum -y --color = never ' : {False : ' --exclude = kernel* update ' , True : ' update ' }} cmd = cmds[manager][kernel] run_as_root ( \" % ( manager ) s % ( cmd ) s \" % locals ( ) ) ": 158,
 "def guess_encoding ( text , default = DEFAULT_ENCODING ) : result = chardet . detect ( text ) return normalize_result ( result , default = default ) ": 159,
 "def commajoin_as_strings ( iterable ) : return _ ( u ' , ' ) . join ( ( six . text_type ( i ) for i in iterable ) ) ": 160,
 "def supports_color ( ) : unsupported_platform = ( sys . platform in ( ' win32 ' , ' Pocket PC ' ) ) # isatty is not always implemented , # 6223 . is_a_tty = hasattr ( sys . stdout , ' isatty ' ) and sys . stdout . isatty ( ) if unsupported_platform or not is_a_tty : return False return True": 161,
 "def seconds_to_hms ( seconds ) : hours = int ( seconds / 3600 . 0 ) minutes = int ( ( seconds / 60 . 0 ) % 60 . 0 ) secs = float ( seconds % 60 . 0 ) return \" {0 : 02d} : {1 : 02d} : {2 : 02 . 6f} \" . format ( hours , minutes , secs ) ": 162,
 "def __contains__ ( self , key ) : k = self . _real_key ( key ) return k in self . _data": 163,
 "def get_truetype ( value ) : if value in [ \" true \" , \" True \" , \" y \" , \" Y \" , \" yes \" ] : return True if value in [ \" false \" , \" False \" , \" n \" , \" N \" , \" no \" ] : return False if value . isdigit ( ) : return int ( value ) return str ( value ) ": 164,
 "def Serializable ( o ) : if isinstance ( o , ( str , dict , int ) ) : return o else : try : json . dumps ( o ) return o except Exception : LOG . debug ( \" Got a non-serilizeable object : %s \" % o ) return o . __repr__ ( ) ": 165,
 "def timed_rotating_file_handler ( name , logname , filename , when = ' h ' , interval = 1 , backupCount = 0 , encoding = None , delay = False , utc = False ) : return wrap_log_handler ( logging . handlers . TimedRotatingFileHandler ( filename , when = when , interval = interval , backupCount = backupCount , encoding = encoding , delay = delay , utc = utc ) ) ": 166,
 "def is_identifier ( string ) : matched = PYTHON_IDENTIFIER_RE . match ( string ) return bool ( matched ) and not keyword . iskeyword ( string ) ": 167,
 "def uniform_iterator ( sequence ) : if isinstance ( sequence , abc . Mapping ) : return six . iteritems ( sequence ) else : return enumerate ( sequence ) ": 168,
 "def _guess_type ( val ) : if isinstance ( val , bool ) : return \" choice \" elif isinstance ( val , int ) : return \" number \" elif isinstance ( val , float ) : return \" number \" elif isinstance ( val , str ) : return \" text \" elif hasattr ( val , ' read ' ) : return \" file \" else : return \" text \" ": 169,
 "def _to_corrected_pandas_type ( dt ) : import numpy as np if type ( dt ) = = ByteType : return np . int8 elif type ( dt ) = = ShortType : return np . int16 elif type ( dt ) = = IntegerType : return np . int32 elif type ( dt ) = = FloatType : return np . float32 else : return None": 170,
 "def _platform_is_windows ( platform = sys . platform ) : matched = platform in ( ' cygwin ' , ' win32 ' , ' win64 ' ) if matched : error_msg = \" Windows isn ' t supported yet \" raise OSError ( error_msg ) return matched": 171,
 "def _xls2col_widths ( self , worksheet , tab ) : for col in xrange ( worksheet . ncols ) : try : xls_width = worksheet . colinfo_map[col] . width pys_width = self . xls_width2pys_width ( xls_width ) self . code_array . col_widths[col , tab] = pys_width except KeyError : pass": 172,
 "def keys_to_snake_case ( camel_case_dict ) : return dict ( ( to_snake_case ( key ) , value ) for ( key , value ) in camel_case_dict . items ( ) ) ": 173,
 "def _bytes_to_json ( value ) : if isinstance ( value , bytes ) : value = base64 . standard_b64encode ( value ) . decode ( \" ascii \" ) return value": 174,
 "def dict_hash ( dct ) : dct_s = json . dumps ( dct , sort_keys = True ) try : m = md5 ( dct_s ) except TypeError : m = md5 ( dct_s . encode ( ) ) return m . hexdigest ( ) ": 175,
 "def int_to_date ( date ) : year = date // 10**4 month = date % 10**4 // 10**2 day = date % 10**2 return datetime . date ( year , month , day ) ": 176,
 "def filter_dict ( d , keys ) : return {k : v for k , v in d . items ( ) if k in keys}": 177,
 "def hasattrs ( object , *names ) : for name in names : if not hasattr ( object , name ) : return False return True": 178,
 "def dict_update_newkeys ( dict_ , dict2 ) : for key , val in six . iteritems ( dict2 ) : if key not in dict_ : dict_[key] = val": 179,
 "def numpy_aware_eq ( a , b ) : if isinstance ( a , np . ndarray ) or isinstance ( b , np . ndarray ) : return np . array_equal ( a , b ) if ( ( isinstance ( a , Iterable ) and isinstance ( b , Iterable ) ) and not isinstance ( a , str ) and not isinstance ( b , str ) ) : if len ( a ) ! = len ( b ) : return False return all ( numpy_aware_eq ( x , y ) for x , y in zip ( a , b ) ) return a = = b": 180,
 "def update ( self , other_dict ) : for key , value in iter_multi_items ( other_dict ) : MultiDict . add ( self , key , value ) ": 181,
 "def _internet_on ( address ) : try : urllib2 . urlopen ( address , timeout = 1 ) return True except urllib2 . URLError as err : return False": 182,
 "def _defaultdict ( dct , fallback = _illegal_character ) : out = defaultdict ( lambda : fallback ) for k , v in six . iteritems ( dct ) : out[k] = v return out": 183,
 "def is_json_file ( filename , show_warnings = False ) : try : config_dict = load_config ( filename , file_type = \" json \" ) is_json = True except : is_json = False return ( is_json ) ": 184,
 "def _remove_dict_keys_with_value ( dict_ , val ) : return {k : v for k , v in dict_ . items ( ) if v is not val}": 185,
 "def post_commit_hook ( argv ) : _ , stdout , _ = run ( \" git log -1 --format = %B HEAD \" ) message = \" \\n \" . join ( stdout ) options = { \" allow_empty \" : True} if not _check_message ( message , options ) : click . echo ( \" Commit message errors ( fix with ' git commit --amend ' ) . \" , file = sys . stderr ) return 1 # it should not fail with exit return 0": 186,
 "def setdefaults ( dct , defaults ) : for key in defaults : dct . setdefault ( key , defaults[key] ) return dct": 187,
 "def is_image_file_valid ( file_path_name ) : # Image . verify is only implemented for PNG images , and it only verifies # the CRC checksum in the image . The only way to check from within # Pillow is to load the image in a try/except and check the error . If # as much info as possible is from the image is needed , # ``ImageFile . LOAD_TRUNCATED_IMAGES = True`` needs to bet set and it # will attempt to parse as much as possible . try : with Image . open ( file_path_name ) as image : image . load ( ) except IOError : return False return True": 188,
 "def dict_to_html_attrs ( dict_ ) : res = ' ' . join ( ' %s = \" %s \" ' % ( k , v ) for k , v in dict_ . items ( ) ) return res": 189,
 "def is_binary ( filename ) : with open ( filename , ' rb ' ) as fp : data = fp . read ( 1024 ) if not data : return False if b ' \\0 ' in data : return True return False": 190,
 "def dict_to_querystring ( dictionary ) : s = u \" \" for d in dictionary . keys ( ) : s = unicode . format ( u \" {0}{1} = {2}& \" , s , d , dictionary[d] ) return s[ : -1]": 191,
 "def _check_elements_equal ( lst ) : assert isinstance ( lst , list ) , \" Input value must be a list . \" return not lst or lst . count ( lst[0] ) = = len ( lst ) ": 192,
 "def nonull_dict ( self ) : return {k : v for k , v in six . iteritems ( self . dict ) if v and k ! = ' _codes ' }": 193,
 "def is_element_present ( driver , selector , by = By . CSS_SELECTOR ) : try : driver . find_element ( by = by , value = selector ) return True except Exception : return False": 194,
 "def updateFromKwargs ( self , properties , kwargs , collector , **unused ) : properties[self . name] = self . getFromKwargs ( kwargs ) ": 195,
 "def is_callable ( *p ) : import symbols return all ( isinstance ( x , symbols . FUNCTION ) for x in p ) ": 196,
 "async def disconnect ( self ) : if not self . connected : return self . writer . close ( ) self . reader = None self . writer = None": 197,
 "def is_dataframe ( obj ) : try : # This is the best method of type checking from pandas import DataFrame return isinstance ( obj , DataFrame ) except ImportError : # Pandas is not a dependency , so this is scary return obj . __class__ . __name__ = = \" DataFrame \" ": 198,
 "def test ( ) : import unittest tests = unittest . TestLoader ( ) . discover ( ' tests ' ) unittest . TextTestRunner ( verbosity = 2 ) . run ( tests ) ": 199,
 "def is_datetime_like ( dtype ) : return ( np . issubdtype ( dtype , np . datetime64 ) or np . issubdtype ( dtype , np . timedelta64 ) ) ": 200,
 "def serialize_json_string ( self , value ) : # Check if the value might be a json string if not isinstance ( value , six . string_types ) : return value # Make sure it starts with a brace if not value . startswith ( ' { ' ) or value . startswith ( ' [ ' ) : return value # Try to load the string try : return json . loads ( value ) except : return value": 201,
 "def is_defined ( self , objtxt , force_import = False ) : return self . interpreter . is_defined ( objtxt , force_import ) ": 202,
 "def group_exists ( groupname ) : try : grp . getgrnam ( groupname ) group_exists = True except KeyError : group_exists = False return group_exists": 203,
 "def sync ( self , recursive = False ) : self . syncTree ( recursive = recursive ) self . syncView ( recursive = recursive ) ": 204,
 "def is_same_shape ( self , other_im , check_channels = False ) : if self . height = = other_im . height and self . width = = other_im . width : if check_channels and self . channels ! = other_im . channels : return False return True return False": 205,
 "def get_distance_between_two_points ( self , one , two ) : dx = one . x - two . x dy = one . y - two . y return math . sqrt ( dx * dx + dy * dy ) ": 206,
 "def post_process ( self ) : self . image . putdata ( self . pixels ) self . image = self . image . transpose ( Image . ROTATE_90 ) ": 207,
 "def _not_none ( items ) : if not isinstance ( items , ( tuple , list ) ) : items = ( items , ) return all ( item is not _none for item in items ) ": 208,
 "def delete_all_from_db ( ) : # The models . CASCADE property is set on all ForeignKey fields , so tables can # be deleted in any order without breaking constraints . for model in django . apps . apps . get_models ( ) : model . objects . all ( ) . delete ( ) ": 209,
 "def is_complex ( dtype ) : dtype = tf . as_dtype ( dtype ) if hasattr ( dtype , ' is_complex ' ) : return dtype . is_complex return np . issubdtype ( np . dtype ( dtype ) , np . complex ) ": 210,
 "def delete ( build_folder ) : if _meta_ . del_build in [ \" on \" , \" ON \" ] and os . path . exists ( build_folder ) : shutil . rmtree ( build_folder ) ": 211,
 "def _stdin_ready_posix ( ) : infds , outfds , erfds = select . select ( [sys . stdin] , [] , [] , 0 ) return bool ( infds ) ": 212,
 "def json_response ( data , status = 200 ) : from django . http import JsonResponse return JsonResponse ( data = data , status = status , safe = isinstance ( data , dict ) ) ": 213,
 "def _is_path ( s ) : if isinstance ( s , string_types ) : try : return op . exists ( s ) except ( OSError , ValueError ) : return False else : return False": 214,
 "def see_doc ( obj_with_doc ) : def decorator ( fn ) : fn . __doc__ = obj_with_doc . __doc__ return fn return decorator": 215,
 "def isToneCal ( self ) : return self . ui . calTypeCmbbx . currentIndex ( ) = = self . ui . calTypeCmbbx . count ( ) -1": 216,
 "def hmsToDeg ( h , m , s ) : return h * degPerHMSHour + m * degPerHMSMin + s * degPerHMSSec": 217,
 "def is_date ( thing ) : # known date types date_types = ( datetime . datetime , datetime . date , DateTime ) return isinstance ( thing , date_types ) ": 218,
 "def prepare ( doc ) : doc . caption_found = False doc . plot_found = False doc . listings_counter = 0": 219,
 "def validate ( key ) : if not isinstance ( key , ( str , bytes ) ) : raise KeyError ( ' Key must be of type str or bytes , found type {} ' . format ( type ( key ) ) ) ": 220,
 "def _normal_prompt ( self ) : sys . stdout . write ( self . __get_ps1 ( ) ) sys . stdout . flush ( ) return safe_input ( ) ": 221,
 "def maxDepth ( self , currentDepth = 0 ) : if not any ( ( self . left , self . right ) ) : return currentDepth result = 0 for child in ( self . left , self . right ) : if child : result = max ( result , child . maxDepth ( currentDepth + 1 ) ) return result": 222,
 "def from_rectangle ( box ) : x = box . left + box . width * random . uniform ( 0 , 1 ) y = box . bottom + box . height * random . uniform ( 0 , 1 ) return Vector ( x , y ) ": 223,
 "def launched ( ) : if not PREFIX : return False return os . path . realpath ( sys . prefix ) = = os . path . realpath ( PREFIX ) ": 224,
 "def hline ( self , x , y , width , color ) : self . rect ( x , y , width , 1 , color , fill = True ) ": 225,
 "def is_sequence ( obj ) : return isinstance ( obj , Sequence ) and not ( isinstance ( obj , str ) or BinaryClass . is_valid_type ( obj ) ) ": 226,
 "def isnamedtuple ( obj ) : return isinstance ( obj , tuple ) \\ and hasattr ( obj , \" _fields \" ) \\ and hasattr ( obj , \" _asdict \" ) \\ and callable ( obj . _asdict ) ": 227,
 "def starts_with_prefix_in_list ( text , prefixes ) : for prefix in prefixes : if text . startswith ( prefix ) : return True return False": 228,
 "def print_yaml ( o ) : print ( yaml . dump ( o , default_flow_style = False , indent = 4 , encoding = ' utf-8 ' ) ) ": 229,
 "def issuperset ( self , other ) : self . _binary_sanity_check ( other ) return set . issuperset ( self , other ) ": 230,
 "def deserialize_ndarray_npy ( d ) : with io . BytesIO ( ) as f : f . write ( json . loads ( d[ ' npy ' ] ) . encode ( ' latin-1 ' ) ) f . seek ( 0 ) return np . load ( f ) ": 231,
 "def check ( text ) : err = \" misc . currency \" msg = u \" Incorrect use of symbols in {} . \" symbols = [ \" \\$[\\d]* ? ( ? : dollars|usd|us dollars ) \" ] return existence_check ( text , symbols , err , msg ) ": 232,
 "def required_header ( header ) : if header in IGNORE_HEADERS : return False if header . startswith ( ' HTTP_ ' ) or header = = ' CONTENT_TYPE ' : return True return False": 233,
 "def _map_table_name ( self , model_names ) : for model in model_names : if isinstance ( model , tuple ) : model = model[0] try : model_cls = getattr ( self . models , model ) self . table_to_class[class_mapper ( model_cls ) . tables[0] . name] = model except AttributeError : pass": 234,
 "def service_available ( service_name ) : try : subprocess . check_output ( [ ' service ' , service_name , ' status ' ] , stderr = subprocess . STDOUT ) . decode ( ' UTF-8 ' ) except subprocess . CalledProcessError as e : return b ' unrecognized service ' not in e . output else : return True": 235,
 "def keys ( self ) : all_keys = [k . decode ( ' utf-8 ' ) for k , v in self . rdb . hgetall ( self . session_hash ) . items ( ) ] return all_keys": 236,
 "def _valid_other_type ( x , types ) : return all ( any ( isinstance ( el , t ) for t in types ) for el in np . ravel ( x ) ) ": 237,
 "def escape_tex ( value ) : newval = value for pattern , replacement in LATEX_SUBS : newval = pattern . sub ( replacement , newval ) return newval": 238,
 "def _pip_exists ( self ) : return os . path . isfile ( os . path . join ( self . path , ' bin ' , ' pip ' ) ) ": 239,
 "def update_index ( index ) : logger . info ( \" Updating search index : ' %s ' \" , index ) client = get_client ( ) responses = [] for model in get_index_models ( index ) : logger . info ( \" Updating search index model : ' %s ' \" , model . search_doc_type ) objects = model . objects . get_search_queryset ( index ) . iterator ( ) actions = bulk_actions ( objects , index = index , action = \" index \" ) response = helpers . bulk ( client , actions , chunk_size = get_setting ( \" chunk_size \" ) ) responses . append ( response ) return responses": 240,
 "def hidden_cursor ( self ) : self . stream . write ( self . hide_cursor ) try : yield finally : self . stream . write ( self . normal_cursor ) ": 241,
 "def copy ( doc , dest , src ) : return Target ( doc ) . copy ( dest , src ) . document": 242,
 "def is_string ( val ) : try : basestring except NameError : return isinstance ( val , str ) return isinstance ( val , basestring ) ": 243,
 "def read_from_file ( file_path , encoding = \" utf-8 \" ) : with codecs . open ( file_path , \" r \" , encoding ) as f : return f . read ( ) ": 244,
 "def _is_root ( ) : import os import ctypes try : return os . geteuid ( ) = = 0 except AttributeError : return ctypes . windll . shell32 . IsUserAnAdmin ( ) ! = 0 return False": 245,
 "def describe_enum_value ( enum_value ) : enum_value_descriptor = EnumValueDescriptor ( ) enum_value_descriptor . name = six . text_type ( enum_value . name ) enum_value_descriptor . number = enum_value . number return enum_value_descriptor": 246,
 "def user_in_all_groups ( user , groups ) : return user_is_superuser ( user ) or all ( user_in_group ( user , group ) for group in groups ) ": 247,
 "def items ( self ) : return [ ( value_descriptor . name , value_descriptor . number ) for value_descriptor in self . _enum_type . values]": 248,
 "def n_choose_k ( n , k ) : return int ( reduce ( MUL , ( Fraction ( n-i , i+1 ) for i in range ( k ) ) , 1 ) ) ": 249,
 "def items ( cls ) : return [ cls . PRECIPITATION , cls . WIND , cls . TEMPERATURE , cls . PRESSURE ]": 250,
 "def revnet_164_cifar ( ) : hparams = revnet_cifar_base ( ) hparams . bottleneck = True hparams . num_channels = [16 , 32 , 64] hparams . num_layers_per_block = [8 , 8 , 8] return hparams": 251,
 "def mtf_image_transformer_cifar_mp_4x ( ) : hparams = mtf_image_transformer_base_cifar ( ) hparams . mesh_shape = \" model : 4;batch : 8 \" hparams . layout = \" batch : batch;d_ff : model;heads : model \" hparams . batch_size = 32 hparams . num_heads = 8 hparams . d_ff = 8192 return hparams": 252,
 "def image_set_aspect ( aspect = 1 . 0 , axes = \" gca \" ) : if axes is \" gca \" : axes = _pylab . gca ( ) e = axes . get_images ( ) [0] . get_extent ( ) axes . set_aspect ( abs ( ( e[1]-e[0] ) / ( e[3]-e[2] ) ) /aspect ) ": 253,
 "def Flush ( self ) : while self . _age : node = self . _age . PopLeft ( ) self . KillObject ( node . data ) self . _hash = dict ( ) ": 254,
 "def _propagate_mean ( mean , linop , dist ) : return linop . matmul ( mean ) + dist . mean ( ) [ . . . , tf . newaxis]": 255,
 "def invalidate_cache ( cpu , address , size ) : cache = cpu . instruction_cache for offset in range ( size ) : if address + offset in cache : del cache[address + offset]": 256,
 "def convertToBool ( ) : if not OPTIONS . strictBool . value : return [] REQUIRES . add ( ' strictbool . asm ' ) result = [] result . append ( ' pop af ' ) result . append ( ' call __NORMALIZE_BOOLEAN ' ) result . append ( ' push af ' ) return result": 257,
 "def normalize ( x , min_value , max_value ) : x = ( x - min_value ) / ( max_value - min_value ) return clip ( x , 0 , 1 ) ": 258,
 "def prepare_for_reraise ( error , exc_info = None ) : if not hasattr ( error , \" _type_ \" ) : if exc_info is None : exc_info = sys . exc_info ( ) error . _type_ = exc_info[0] error . _traceback = exc_info[2] return error": 259,
 "def close_all_but_this ( self ) : self . close_all_right ( ) for i in range ( 0 , self . get_stack_count ( ) -1 ) : self . close_file ( 0 ) ": 260,
 "def eval_in_system_namespace ( self , exec_str ) : ns = self . cmd_namespace try : return eval ( exec_str , ns ) except Exception as e : self . logger . warning ( ' Could not execute %s , gave error %s ' , exec_str , e ) return None": 261,
 "def _close_socket ( self ) : try : self . socket . shutdown ( socket . SHUT_RDWR ) except ( OSError , socket . error ) : pass self . socket . close ( ) ": 262,
 "def exec_function ( ast , globals_map ) : locals_map = globals_map exec ast in globals_map , locals_map return locals_map": 263,
 "def cleanup ( self , app ) : if hasattr ( self . database . obj , ' close_all ' ) : self . database . close_all ( ) ": 264,
 "def get_unicode_str ( obj ) : if isinstance ( obj , six . text_type ) : return obj if isinstance ( obj , six . binary_type ) : return obj . decode ( \" utf-8 \" , errors = \" ignore \" ) return six . text_type ( obj ) ": 265,
 "def exp_fit_fun ( x , a , tau , c ) : # pylint : disable = invalid-name return a * np . exp ( -x / tau ) + c": 266,
 "def _findNearest ( arr , value ) : arr = np . array ( arr ) # find nearest value in array idx = ( abs ( arr-value ) ) . argmin ( ) return arr[idx]": 267,
 "def gauss_pdf ( x , mu , sigma ) : return 1 / np . sqrt ( 2 * np . pi ) / sigma * np . exp ( - ( x - mu ) ** 2 / 2 . / sigma ** 2 ) ": 268,
 "def remove_examples_all ( ) : d = examples_all_dir ( ) if d . exists ( ) : log . debug ( ' remove %s ' , d ) d . rmtree ( ) else : log . debug ( ' nothing to remove : %s ' , d ) ": 269,
 "def resources ( self ) : return [self . pdf . getPage ( i ) for i in range ( self . pdf . getNumPages ( ) ) ]": 270,
 "def cli_command_quit ( self , msg ) : if self . state = = State . RUNNING and self . sprocess and self . sprocess . proc : self . sprocess . proc . kill ( ) else : sys . exit ( 0 ) ": 271,
 "def dot ( self , w ) : return sum ( [x * y for x , y in zip ( self , w ) ] ) ": 272,
 "def printc ( cls , txt , color = colors . red ) : print ( cls . color_txt ( txt , color ) ) ": 273,
 "def need_update ( a , b ) : a = listify ( a ) b = listify ( b ) return any ( ( not op . exists ( x ) ) for x in b ) or \\ all ( ( os . stat ( x ) . st_size = = 0 for x in b ) ) or \\ any ( is_newer_file ( x , y ) for x in a for y in b ) ": 274,
 "def lengths ( self ) : return ( np . array ( [ math . sqrt ( sum ( row**2 ) ) for row in self . matrix ] ) ) ": 275,
 "def random_str ( size = 10 ) : return ' ' . join ( random . choice ( string . ascii_lowercase ) for _ in range ( size ) ) ": 276,
 "def get_table_columns ( dbconn , tablename ) : cur = dbconn . cursor ( ) cur . execute ( \" PRAGMA table_info ( ' %s ' ) ; \" % tablename ) info = cur . fetchall ( ) cols = [ ( i[1] , i[2] ) for i in info] return cols": 277,
 "def remove_duplicates ( lst ) : dset = set ( ) return [l for l in lst if l not in dset and not dset . add ( l ) ]": 278,
 "def _on_select ( self , *args ) : if callable ( self . __callback ) : self . __callback ( self . selection ) ": 279,
 "def fft_spectrum ( frames , fft_points = 512 ) : SPECTRUM_VECTOR = np . fft . rfft ( frames , n = fft_points , axis = -1 , norm = None ) return np . absolute ( SPECTRUM_VECTOR ) ": 280,
 "def isetdiff_flags ( list1 , list2 ) : set2 = set ( list2 ) return ( item not in set2 for item in list1 ) ": 281,
 "def guess_file_type ( kind , filepath = None , youtube_id = None , web_url = None , encoding = None ) : if youtube_id : return FileTypes . YOUTUBE_VIDEO_FILE elif web_url : return FileTypes . WEB_VIDEO_FILE elif encoding : return FileTypes . BASE64_FILE else : ext = os . path . splitext ( filepath ) [1][1 : ] . lower ( ) if kind in FILE_TYPE_MAPPING and ext in FILE_TYPE_MAPPING[kind] : return FILE_TYPE_MAPPING[kind][ext] return None": 282,
 "def is_same_dict ( d1 , d2 ) : for k , v in d1 . items ( ) : if isinstance ( v , dict ) : is_same_dict ( v , d2[k] ) else : assert d1[k] = = d2[k] for k , v in d2 . items ( ) : if isinstance ( v , dict ) : is_same_dict ( v , d1[k] ) else : assert d1[k] = = d2[k]": 283,
 "def file_writelines_flush_sync ( path , lines ) : fp = open ( path , ' w ' ) try : fp . writelines ( lines ) flush_sync_file_object ( fp ) finally : fp . close ( ) ": 284,
 "def make_kind_check ( python_types , numpy_kind ) : def check ( value ) : if hasattr ( value , ' dtype ' ) : return value . dtype . kind = = numpy_kind return isinstance ( value , python_types ) return check": 285,
 "def file_empty ( fp ) : # for python 2 we need to use a homemade peek ( ) if six . PY2 : contents = fp . read ( ) fp . seek ( 0 ) return not bool ( contents ) else : return not fp . peek ( ) ": 286,
 "def all_equal ( arg1 , arg2 ) : if all ( hasattr ( el , ' _infinitely_iterable ' ) for el in [arg1 , arg2] ) : return arg1 = = arg2 try : return all ( a1 = = a2 for a1 , a2 in zip ( arg1 , arg2 ) ) except TypeError : return arg1 = = arg2": 287,
 "def get_file_size ( filename ) : if os . path . isfile ( filename ) : return convert_size ( os . path . getsize ( filename ) ) return None": 288,
 "def _check_for_int ( x ) : try : y = int ( x ) except ( OverflowError , ValueError ) : pass else : # There is no way in AMF0 to distinguish between integers and floats if x = = x and y = = x : return y return x": 289,
 "def fill_form ( form , data ) : for ( key , value ) in data . items ( ) : if hasattr ( form , key ) : if isinstance ( value , dict ) : fill_form ( getattr ( form , key ) , value ) else : getattr ( form , key ) . data = value return form": 290,
 "def check_clang_apply_replacements_binary ( args ) : try : subprocess . check_call ( [args . clang_apply_replacements_binary , ' --version ' ] ) except : print ( ' Unable to run clang-apply-replacements . Is clang-apply-replacements ' ' binary correctly specified? ' , file = sys . stderr ) traceback . print_exc ( ) sys . exit ( 1 ) ": 291,
 "def _maybe_fill ( arr , fill_value = np . nan ) : if _isna_compat ( arr , fill_value ) : arr . fill ( fill_value ) return arr": 292,
 "def extract_alzip ( archive , compression , cmd , verbosity , interactive , outdir ) : return [cmd , ' -d ' , outdir , archive]": 293,
 "def get_lons_from_cartesian ( x__ , y__ ) : return rad2deg ( arccos ( x__ / sqrt ( x__ ** 2 + y__ ** 2 ) ) ) * sign ( y__ ) ": 294,
 "def filter_ ( stream_spec , filter_name , *args , **kwargs ) : return filter ( stream_spec , filter_name , *args , **kwargs ) ": 295,
 "def find_lt ( a , x ) : i = bs . bisect_left ( a , x ) if i : return i - 1 raise ValueError": 296,
 "def get_stationary_distribution ( self ) : # The stationary distribution is proportional to the left-eigenvector # associated with the largest eigenvalue ( i . e . , 1 ) of the transition # matrix . check_is_fitted ( self , \" transmat_ \" ) eigvals , eigvecs = np . linalg . eig ( self . transmat_ . T ) eigvec = np . real_if_close ( eigvecs[ : , np . argmax ( eigvals ) ] ) return eigvec / eigvec . sum ( ) ": 297,
 "def apply_fit ( xy , coeffs ) : x_new = coeffs[0][2] + coeffs[0][0]*xy[ : , 0] + coeffs[0][1]*xy[ : , 1] y_new = coeffs[1][2] + coeffs[1][0]*xy[ : , 0] + coeffs[1][1]*xy[ : , 1] return x_new , y_new": 298,
 "def _tf_squared_euclidean ( X , Y ) : return tf . reduce_sum ( tf . pow ( tf . subtract ( X , Y ) , 2 ) , axis = 1 ) ": 299,
 "def euclidean ( x , y ) : result = 0 . 0 for i in range ( x . shape[0] ) : result + = ( x[i] - y[i] ) ** 2 return np . sqrt ( result ) ": 300,
 "def create_table_from_fits ( fitsfile , hduname , colnames = None ) : if colnames is None : return Table . read ( fitsfile , hduname ) cols = [] with fits . open ( fitsfile , memmap = True ) as h : for k in colnames : data = h[hduname] . data . field ( k ) cols + = [Column ( name = k , data = data ) ] return Table ( cols ) ": 301,
 "def _gcd_array ( X ) : greatest_common_divisor = 0 . 0 for x in X : greatest_common_divisor = _gcd ( greatest_common_divisor , x ) return greatest_common_divisor": 302,
 "def lint ( args ) : application = get_current_application ( ) if not args : args = [application . name , ' tests ' ] args = [ ' flake8 ' ] + list ( args ) run . main ( args , standalone_mode = False ) ": 303,
 "def torecarray ( *args , **kwargs ) : import numpy as np return toarray ( *args , **kwargs ) . view ( np . recarray ) ": 304,
 "def _type_bool ( label , default = False ) : return label , abstractSearch . nothing , abstractRender . boolen , default": 305,
 "def join_cols ( cols ) : return \" , \" . join ( [i for i in cols] ) if isinstance ( cols , ( list , tuple , set ) ) else cols": 306,
 "def parse_form ( self , req , name , field ) : return core . get_value ( req . POST , name , field ) ": 307,
 "def type_converter ( text ) : if text . isdigit ( ) : return int ( text ) , int try : return float ( text ) , float except ValueError : return text , STRING_TYPE": 308,
 "def cors_header ( func ) : @wraps ( func ) def wrapper ( self , request , *args , **kwargs ) : res = func ( self , request , *args , **kwargs ) request . setHeader ( ' Access-Control-Allow-Origin ' , ' * ' ) request . setHeader ( ' Access-Control-Allow-Headers ' , ' Content-Type , Access-Control-Allow-Headers , Authorization , X-Requested-With ' ) return res return wrapper": 309,
 "def handleFlaskPostRequest ( flaskRequest , endpoint ) : if flaskRequest . method = = \" POST \" : return handleHttpPost ( flaskRequest , endpoint ) elif flaskRequest . method = = \" OPTIONS \" : return handleHttpOptions ( ) else : raise exceptions . MethodNotAllowedException ( ) ": 310,
 "def python_mime ( fn ) : @wraps ( fn ) def python_mime_decorator ( *args , **kwargs ) : response . content_type = \" text/x-python \" return fn ( *args , **kwargs ) return python_mime_decorator": 311,
 "def _spawn_kafka_consumer_thread ( self ) : self . logger . debug ( \" Spawn kafka consumer thread \" \" \" ) self . _consumer_thread = Thread ( target = self . _consumer_loop ) self . _consumer_thread . setDaemon ( True ) self . _consumer_thread . start ( ) ": 312,
 "def flatpages_link_list ( request ) : from django . contrib . flatpages . models import FlatPage link_list = [ ( page . title , page . url ) for page in FlatPage . objects . all ( ) ] return render_to_link_list ( link_list ) ": 313,
 "def values ( self ) : lower = float ( self . lowerSpnbx . value ( ) ) upper = float ( self . upperSpnbx . value ( ) ) return ( lower , upper ) ": 314,
 "def sqlmany ( self , stringname , *args ) : if hasattr ( self , ' alchemist ' ) : return getattr ( self . alchemist . many , stringname ) ( *args ) s = self . strings[stringname] return self . connection . cursor ( ) . executemany ( s , args ) ": 315,
 "def convolve_gaussian_2d ( image , gaussian_kernel_1d ) : result = scipy . ndimage . filters . correlate1d ( image , gaussian_kernel_1d , axis = 0 ) result = scipy . ndimage . filters . correlate1d ( result , gaussian_kernel_1d , axis = 1 ) return result": 316,
 "def render_template_string ( source , **context ) : ctx = _app_ctx_stack . top ctx . app . update_template_context ( context ) return _render ( ctx . app . jinja_env . from_string ( source ) , context , ctx . app ) ": 317,
 "def asynchronous ( function , event ) : thread = Thread ( target = synchronous , args = ( function , event ) ) thread . daemon = True thread . start ( ) ": 318,
 "def default_static_path ( ) : fdir = os . path . dirname ( __file__ ) return os . path . abspath ( os . path . join ( fdir , ' . . /assets/ ' ) ) ": 319,
 "def count_list ( the_list ) : count = the_list . count result = [ ( item , count ( item ) ) for item in set ( the_list ) ] result . sort ( ) return result": 320,
 "def round_to_float ( number , precision ) : rounded = Decimal ( str ( floor ( ( number + precision / 2 ) // precision ) ) ) * Decimal ( str ( precision ) ) return float ( rounded ) ": 321,
 "def _calc_overlap_count ( markers1 : dict , markers2 : dict , ) : overlaps = np . zeros ( ( len ( markers1 ) , len ( markers2 ) ) ) j = 0 for marker_group in markers1 : tmp = [len ( markers2[i] . intersection ( markers1[marker_group] ) ) for i in markers2 . keys ( ) ] overlaps[j , : ] = tmp j + = 1 return overlaps": 322,
 "def intround ( value ) : return int ( decimal . Decimal . from_float ( value ) . to_integral_value ( decimal . ROUND_HALF_EVEN ) ) ": 323,
 "def focusInEvent ( self , event ) : self . focus_changed . emit ( ) return super ( PageControlWidget , self ) . focusInEvent ( event ) ": 324,
 "def _accumulate ( sequence , func ) : iterator = iter ( sequence ) total = next ( iterator ) yield total for element in iterator : total = func ( total , element ) yield total": 325,
 "def iter_finds ( regex_obj , s ) : if isinstance ( regex_obj , str ) : for m in re . finditer ( regex_obj , s ) : yield m . group ( ) else : for m in regex_obj . finditer ( s ) : yield m . group ( ) ": 326,
 "def a2s ( a ) : s = np . zeros ( ( 6 , ) , ' f ' ) # make the a matrix for i in range ( 3 ) : s[i] = a[i][i] s[3] = a[0][1] s[4] = a[1][2] s[5] = a[0][2] return s": 327,
 "def concat ( cls , iterables ) : def generator ( ) : for it in iterables : for element in it : yield element return cls ( generator ( ) ) ": 328,
 "def format_result ( input ) : items = list ( iteritems ( input ) ) return OrderedDict ( sorted ( items , key = lambda x : x[0] ) ) ": 329,
 "def bulk_query ( self , query , *multiparams ) : with self . get_connection ( ) as conn : conn . bulk_query ( query , *multiparams ) ": 330,
 "def Trie ( S ) : T = None for w in S : T = add ( T , w ) return T": 331,
 "def __set__ ( self , instance , value ) : self . map[id ( instance ) ] = ( weakref . ref ( instance ) , value ) ": 332,
 "def recarray ( self ) : return numpy . rec . fromrecords ( self . records , names = self . names ) ": 333,
 "def go_to_background ( ) : try : if os . fork ( ) : sys . exit ( ) except OSError as errmsg : LOGGER . error ( ' Fork failed : {0} ' . format ( errmsg ) ) sys . exit ( ' Fork failed ' ) ": 334,
 "def generate_unique_host_id ( ) : host = \" . \" . join ( reversed ( socket . gethostname ( ) . split ( \" . \" ) ) ) pid = os . getpid ( ) return \" %s . %d \" % ( host , pid ) ": 335,
 "def compress ( self , data_list ) : data = {} if data_list : return dict ( ( f . name , data_list[i] ) for i , f in enumerate ( self . form ) ) return data": 336,
 "def init_db ( ) : db . drop_all ( ) db . configure_mappers ( ) db . create_all ( ) db . session . commit ( ) ": 337,
 "def safe_format ( s , **kwargs ) : return string . Formatter ( ) . vformat ( s , ( ) , defaultdict ( str , **kwargs ) ) ": 338,
 "def _init_unique_sets ( self ) : ks = dict ( ) for t in self . _unique_checks : key = t[0] ks[key] = set ( ) # empty set return ks": 339,
 "def straight_line_show ( title , length = 100 , linestyle = \" = \" , pad = 0 ) : print ( StrTemplate . straight_line ( title = title , length = length , linestyle = linestyle , pad = pad ) ) ": 340,
 "def make_executable ( script_path ) : status = os . stat ( script_path ) os . chmod ( script_path , status . st_mode | stat . S_IEXEC ) ": 341,
 "def make_html_code ( self , lines ) : line = code_header + ' \\n ' for l in lines : line = line + html_quote ( l ) + ' \\n ' return line + code_footer": 342,
 "def cross_product_matrix ( vec ) : return np . array ( [[0 , -vec[2] , vec[1]] , [vec[2] , 0 , -vec[0]] , [-vec[1] , vec[0] , 0]] ) ": 343,
 "def index_nearest ( value , array ) : a = ( array-value ) **2 return index ( a . min ( ) , a ) ": 344,
 "def main ( args = sys . argv ) : parser = create_optparser ( args[0] ) return cli ( parser . parse_args ( args[1 : ] ) ) ": 345,
 "def free ( self ) : if self . _ptr is None : return Gauged . array_free ( self . ptr ) FloatArray . ALLOCATIONS - = 1 self . _ptr = None": 346,
 "def from_points ( cls , list_of_lists ) : result = [] for l in list_of_lists : curve = [] for point in l : curve . append ( ( point . lon , point . lat ) ) result . append ( curve ) return Polygon ( result ) ": 347,
 "def connect ( ) : ftp_class = ftplib . FTP if not SSL else ftplib . FTP_TLS ftp = ftp_class ( timeout = TIMEOUT ) ftp . connect ( HOST , PORT ) ftp . login ( USER , PASSWORD ) if SSL : ftp . prot_p ( ) # secure data connection return ftp": 348,
 "def tmpfile ( prefix , direc ) : return tempfile . mktemp ( prefix = prefix , suffix = ' . pdb ' , dir = direc ) ": 349,
 "def connect ( host , port , username , password ) : # Instantiate ftplib client session = ftplib . FTP ( ) # Connect to host without auth session . connect ( host , port ) # Authenticate connection session . login ( username , password ) return session": 350,
 "def unique_list ( lst ) : uniq = [] for item in lst : if item not in uniq : uniq . append ( item ) return uniq": 351,
 "def All ( sequence ) : return bool ( reduce ( lambda x , y : x and y , sequence , True ) ) ": 352,
 "def zero_state ( self , batch_size ) : return torch . zeros ( batch_size , self . state_dim , dtype = torch . float32 ) ": 353,
 "def _fullname ( o ) : return o . __module__ + \" . \" + o . __name__ if o . __module__ else o . __name__": 354,
 "def create_index ( config ) : filename = pathlib . Path ( config . cache_path ) / \" index . json \" index = { \" version \" : __version__} with open ( filename , \" w \" ) as out : out . write ( json . dumps ( index , indent = 2 ) ) ": 355,
 "def issorted ( list_ , op = operator . le ) : return all ( op ( list_[ix] , list_[ix + 1] ) for ix in range ( len ( list_ ) - 1 ) ) ": 356,
 "def is_valid ( number ) : n = str ( number ) if not n . isdigit ( ) : return False return int ( n[-1] ) = = get_check_digit ( n[ : -1] ) ": 357,
 "def us2mc ( string ) : return re . sub ( r ' _ ( [a-z] ) ' , lambda m : ( m . group ( 1 ) . upper ( ) ) , string ) ": 358,
 "def csv2yaml ( in_file , out_file = None ) : if out_file is None : out_file = \" %s . yaml \" % os . path . splitext ( in_file ) [0] barcode_ids = _generate_barcode_ids ( _read_input_csv ( in_file ) ) lanes = _organize_lanes ( _read_input_csv ( in_file ) , barcode_ids ) with open ( out_file , \" w \" ) as out_handle : out_handle . write ( yaml . safe_dump ( lanes , default_flow_style = False ) ) return out_file": 359,
 "def get_average_length_of_string ( strings ) : if not strings : return 0 return sum ( len ( word ) for word in strings ) / len ( strings ) ": 360,
 "def cumsum ( inlist ) : newlist = copy . deepcopy ( inlist ) for i in range ( 1 , len ( newlist ) ) : newlist[i] = newlist[i] + newlist[i - 1] return newlist": 361,
 "def good ( txt ) : print ( \" %s # %s%s%s \" % ( PR_GOOD_CC , get_time_stamp ( ) , txt , PR_NC ) ) sys . stdout . flush ( ) ": 362,
 "def move_to ( self , ypos , xpos ) : # the screen ' s co-ordinates are 1 based , but the command is 0 based xpos - = 1 ypos - = 1 self . exec_command ( \" MoveCursor ( {0} , {1} ) \" . format ( ypos , xpos ) . encode ( \" ascii \" ) ) ": 363,
 "def dict_from_object ( obj : object ) : # If object is a dict instance , no need to convert . return ( obj if isinstance ( obj , dict ) else {attr : getattr ( obj , attr ) for attr in dir ( obj ) if not attr . startswith ( ' _ ' ) } ) ": 364,
 "def ensure_hbounds ( self ) : self . cursor . x = min ( max ( 0 , self . cursor . x ) , self . columns - 1 ) ": 365,
 "def strip_spaces ( s ) : return u \" \" . join ( [c for c in s . split ( u ' ' ) if c] ) ": 366,
 "def scatter ( self , *args , **kwargs ) : cls = _make_class ( ScatterVisual , _default_marker = kwargs . pop ( ' marker ' , None ) , ) return self . _add_item ( cls , *args , **kwargs ) ": 367,
 "def download_file_from_bucket ( self , bucket , file_path , key ) : with open ( file_path , ' wb ' ) as data : self . __s3 . download_fileobj ( bucket , key , data ) return file_path": 368,
 "def imdecode ( image_path ) : import os assert os . path . exists ( image_path ) , image_path + ' not found ' im = cv2 . imread ( image_path ) return im": 369,
 "def ex ( self , cmd ) : with self . builtin_trap : exec cmd in self . user_global_ns , self . user_ns": 370,
 "def isbinary ( *args ) : return all ( map ( lambda c : isnumber ( c ) or isbool ( c ) , args ) ) ": 371,
 "def split ( s ) : l = [_split ( x ) for x in _SPLIT_RE . split ( s ) ] return [item for sublist in l for item in sublist]": 372,
 "def dt2jd ( dt ) : a = ( 14 - dt . month ) //12 y = dt . year + 4800 - a m = dt . month + 12*a - 3 return dt . day + ( ( 153*m + 2 ) //5 ) + 365*y + y//4 - y//100 + y//400 - 32045": 373,
 "def smooth_gaussian ( image , sigma = 1 ) : return scipy . ndimage . filters . gaussian_filter ( image , sigma = sigma , mode = \" nearest \" ) ": 374,
 "def _time_to_json ( value ) : if isinstance ( value , datetime . time ) : value = value . isoformat ( ) return value": 375,
 "def EvalGaussianPdf ( x , mu , sigma ) : return scipy . stats . norm . pdf ( x , mu , sigma ) ": 376,
 "def convert_timestamp ( timestamp ) : datetime = dt . datetime . utcfromtimestamp ( timestamp/1000 . ) return np . datetime64 ( datetime . replace ( tzinfo = None ) ) ": 377,
 "def _make_cmd_list ( cmd_list ) : cmd = ' ' for i in cmd_list : cmd = cmd + ' \" ' + i + ' \" , ' cmd = cmd[ : -1] return cmd": 378,
 "def accuracy ( self ) : sub_observed = np . array ( [self . observed . metadata[i] for i in self . observed . arr] ) return float ( ( self . model_predictions ( ) = = sub_observed ) . sum ( ) ) / self . data_size": 379,
 "def cli ( yamlfile , format , context ) : print ( JSONLDGenerator ( yamlfile , format ) . serialize ( context = context ) ) ": 380,
 "def double_sha256 ( data ) : return bytes_as_revhex ( hashlib . sha256 ( hashlib . sha256 ( data ) . digest ( ) ) . digest ( ) ) ": 381,
 "def get_cantons ( self ) : return sorted ( list ( set ( [ location . canton for location in self . get_locations ( ) . values ( ) ] ) ) ) ": 382,
 "def get_method_name ( method ) : name = get_object_name ( method ) if name . startswith ( \" __ \" ) and not name . endswith ( \" __ \" ) : name = \" _{0}{1} \" . format ( get_object_name ( method . im_class ) , name ) return name": 383,
 "def _add_default_arguments ( parser ) : parser . add_argument ( ' -c ' , ' --config ' , action = ' store ' , dest = ' config ' , help = ' Path to the configuration file ' ) parser . add_argument ( ' -f ' , ' --foreground ' , action = ' store_true ' , dest = ' foreground ' , help = ' Run the application interactively ' ) ": 384,
 "def get_methods ( *objs ) : return set ( attr for obj in objs for attr in dir ( obj ) if not attr . startswith ( ' _ ' ) and callable ( getattr ( obj , attr ) ) ) ": 385,
 "def computeDelaunayTriangulation ( points ) : siteList = SiteList ( points ) context = Context ( ) context . triangulate = True voronoi ( siteList , context ) return context . triangles": 386,
 "def get_keys_from_class ( cc ) : return [prop . name for prop in cc . properties . values ( ) \\ if ' key ' in prop . qualifiers]": 387,
 "def rm ( venv_name ) : inenv = InenvManager ( ) venv = inenv . get_venv ( venv_name ) click . confirm ( \" Delete dir {} \" . format ( venv . path ) ) shutil . rmtree ( venv . path ) ": 388,
 "def columns ( self ) : res = [col[ ' name ' ] for col in self . column_definitions] res . extend ( [col[ ' name ' ] for col in self . foreign_key_definitions] ) return res": 389,
 "def remove_non_magic_cols ( self ) : for table_name in self . tables : table = self . tables[table_name] table . remove_non_magic_cols_from_table ( ) ": 390,
 "def get_obj ( ref ) : oid = int ( ref ) return server . id2ref . get ( oid ) or server . id2obj[oid]": 391,
 "def _split_comma_separated ( string ) : return set ( text . strip ( ) for text in string . split ( ' , ' ) if text . strip ( ) ) ": 392,
 "def angle ( x0 , y0 , x1 , y1 ) : return degrees ( atan2 ( y1-y0 , x1-x0 ) ) ": 393,
 "def delete_duplicates ( seq ) : seen = set ( ) seen_add = seen . add return [x for x in seq if not ( x in seen or seen_add ( x ) ) ]": 394,
 "def guess_extension ( amimetype , normalize = False ) : ext = _mimes . guess_extension ( amimetype ) if ext and normalize : # Normalize some common magic mis-interpreation ext = { ' . asc ' : ' . txt ' , ' . obj ' : ' . bin ' } . get ( ext , ext ) from invenio . legacy . bibdocfile . api_normalizer import normalize_format return normalize_format ( ext ) return ext": 395,
 "def reset ( ) : shutil . rmtree ( session[ ' img_input_dir ' ] ) shutil . rmtree ( session[ ' img_output_dir ' ] ) session . clear ( ) return jsonify ( ok = ' true ' ) ": 396,
 "def boolean ( value ) : if isinstance ( value , bool ) : return value if value = = \" \" : return False return strtobool ( value ) ": 397,
 "def detokenize ( s ) : print ( s ) s = re . sub ( \" \\s+ ( [; : , \\ . \\?!] ) \" , \" \\\\1 \" , s ) s = re . sub ( \" \\s+ ( n ' t ) \" , \" \\\\1 \" , s ) return s": 398,
 "def get_colors ( img ) : w , h = img . size return [color[ : 3] for count , color in img . convert ( ' RGB ' ) . getcolors ( w * h ) ]": 399,
 "def pop ( h ) : n = h . size ( ) - 1 h . swap ( 0 , n ) down ( h , 0 , n ) return h . pop ( ) ": 400,
 "def memory ( ) : mem_info = dict ( ) for k , v in psutil . virtual_memory ( ) . _asdict ( ) . items ( ) : mem_info[k] = int ( v ) return mem_info": 401,
 "def check_precomputed_distance_matrix ( X ) : tmp = X . copy ( ) tmp[np . isinf ( tmp ) ] = 1 check_array ( tmp ) ": 402,
 "def calculate_month ( birth_date ) : year = int ( birth_date . strftime ( ' %Y ' ) ) month = int ( birth_date . strftime ( ' %m ' ) ) + ( ( int ( year / 100 ) - 14 ) % 5 ) * 20 return month": 403,
 "def linedelimited ( inlist , delimiter ) : outstr = ' ' for item in inlist : if type ( item ) ! = StringType : item = str ( item ) outstr = outstr + item + delimiter outstr = outstr[0 : -1] return outstr": 404,
 "def get_month_start_end_day ( ) : t = date . today ( ) n = mdays[t . month] return ( date ( t . year , t . month , 1 ) , date ( t . year , t . month , n ) ) ": 405,
 "def dequeue ( self , block = True ) : return self . queue . get ( block , self . queue_get_timeout ) ": 406,
 "def return_value ( self , *args , **kwargs ) : self . _called ( ) return self . _return_value ( *args , **kwargs ) ": 407,
 "def get_best_encoding ( stream ) : rv = getattr ( stream , ' encoding ' , None ) or sys . getdefaultencoding ( ) if is_ascii_encoding ( rv ) : return ' utf-8 ' return rv": 408,
 "def relpath ( self ) : cwd = self . __class__ ( os . getcwdu ( ) ) return cwd . relpathto ( self ) ": 409,
 "def we_are_in_lyon ( ) : import socket try : hostname = socket . gethostname ( ) ip = socket . gethostbyname ( hostname ) except socket . gaierror : return False return ip . startswith ( \" 134 . 158 . \" ) ": 410,
 "def skip_connection_distance ( a , b ) : if a[2] ! = b[2] : return 1 . 0 len_a = abs ( a[1] - a[0] ) len_b = abs ( b[1] - b[0] ) return ( abs ( a[0] - b[0] ) + abs ( len_a - len_b ) ) / ( max ( a[0] , b[0] ) + max ( len_a , len_b ) ) ": 411,
 "def eqstr ( a , b ) : return bool ( libspice . eqstr_c ( stypes . stringToCharP ( a ) , stypes . stringToCharP ( b ) ) ) ": 412,
 "def get_by ( self , name ) : return next ( ( item for item in self if item . name = = name ) , None ) ": 413,
 "def validate ( self , *args , **kwargs ) : # pylint : disable = arguments-differ return super ( ParameterValidator , self ) . _validate ( *args , **kwargs ) ": 414,
 "def get_parent_dir ( name ) : parent_dir = os . path . dirname ( os . path . dirname ( name ) ) if parent_dir : return parent_dir return os . path . abspath ( ' . ' ) ": 415,
 "def me ( self ) : return self . guild . me if self . guild is not None else self . bot . user": 416,
 "def get_size_in_bytes ( self , handle ) : fpath = self . _fpath_from_handle ( handle ) return os . stat ( fpath ) . st_size": 417,
 "def show_guestbook ( ) : cursor = flask . g . db . execute ( ' SELECT name , message FROM entry ORDER BY id DESC; ' ) entries = [{ ' name ' : row[0] , ' message ' : row[1]} for row in cursor . fetchall ( ) ] return jinja2 . Template ( LAYOUT ) . render ( entries = entries ) ": 418,
 "def get_month_start ( day = None ) : day = add_timezone ( day or datetime . date . today ( ) ) return day . replace ( day = 1 ) ": 419,
 "def rank ( idx , dim ) : idxm = multi_index ( idx , dim ) out = 0 while idxm[-1 : ] = = ( 0 , ) : out + = 1 idxm = idxm[ : -1] return out": 420,
 "def get_last_commit ( git_path = None ) : if git_path is None : git_path = GIT_PATH line = get_last_commit_line ( git_path ) revision_id = line . split ( ) [1] return revision_id": 421,
 "def csvpretty ( csvfile : csvfile = sys . stdin ) : shellish . tabulate ( csv . reader ( csvfile ) ) ": 422,
 "def array_dim ( arr ) : dim = [] while True : try : dim . append ( len ( arr ) ) arr = arr[0] except TypeError : return dim": 423,
 "def _split_str ( s , n ) : length = len ( s ) return [s[i : i + n] for i in range ( 0 , length , n ) ]": 424,
 "def qsize ( self ) : self . mutex . acquire ( ) n = self . _qsize ( ) self . mutex . release ( ) return n": 425,
 "def is_static ( self , filename ) : if self . staticpaths is None : # We ' re not using static file support return False for path in self . staticpaths : if filename . startswith ( path ) : return True return False": 426,
 "def serve_static ( request , path , insecure = False , **kwargs ) : # Follow the same logic Django uses for determining access to the # static-serving view . if not django_settings . DEBUG and not insecure : raise ImproperlyConfigured ( \" The staticfiles view can only be used in \" \" debug mode or if the --insecure \" \" option of ' runserver ' is used \" ) if not settings . PIPELINE_ENABLED and settings . PIPELINE_COLLECTOR_ENABLED : # Collect only the requested file , in order to serve the result as # fast as possible . This won ' t interfere with the template tags in any # way , as those will still cause Django to collect all media . default_collector . collect ( request , files = [path] ) return serve ( request , path , document_root = django_settings . STATIC_ROOT , **kwargs ) ": 427,
 "def go_to_new_line ( self ) : self . stdkey_end ( False , False ) self . insert_text ( self . get_line_separator ( ) ) ": 428,
 "def get_font_list ( ) : font_map = pangocairo . cairo_font_map_get_default ( ) font_list = [f . get_name ( ) for f in font_map . list_families ( ) ] font_list . sort ( ) return font_list": 429,
 "def has_parent ( self , term ) : for parent in self . parents : if parent . item_id = = term or parent . has_parent ( term ) : return True return False": 430,
 "def unique_list_dicts ( dlist , key ) : return list ( dict ( ( val[key] , val ) for val in dlist ) . values ( ) ) ": 431,
 "def _get_local_ip ( ) : return set ( [x[4][0] for x in socket . getaddrinfo ( socket . gethostname ( ) , 80 , socket . AF_INET ) ] ) . pop ( ) ": 432,
 "def get_public_members ( obj ) : return {attr : getattr ( obj , attr ) for attr in dir ( obj ) if not attr . startswith ( \" _ \" ) and not hasattr ( getattr ( obj , attr ) , ' __call__ ' ) }": 433,
 "def timer ( ) : if sys . platform = = \" win32 \" : default_timer = time . clock else : default_timer = time . time return default_timer ( ) ": 434,
 "def last_day ( year = _year , month = _month ) : last_day = calendar . monthrange ( year , month ) [1] return datetime . date ( year = year , month = month , day = last_day ) ": 435,
 "def unit_tangent ( self , t ) : dseg = self . derivative ( t ) return dseg/abs ( dseg ) ": 436,
 "def get_obj_cols ( df ) : obj_cols = [] for idx , dt in enumerate ( df . dtypes ) : if dt = = ' object ' or is_category ( dt ) : obj_cols . append ( df . columns . values[idx] ) return obj_cols": 437,
 "def match_aspect_to_viewport ( self ) : viewport = self . viewport self . aspect = float ( viewport . width ) / viewport . height": 438,
 "def get_property_by_name ( pif , name ) : return next ( ( x for x in pif . properties if x . name = = name ) , None ) ": 439,
 "def _uniquify ( _list ) : seen = set ( ) result = [] for x in _list : if x not in seen : result . append ( x ) seen . add ( x ) return result": 440,
 "def fmt_duration ( secs ) : return ' ' . join ( fmt . human_duration ( secs , 0 , precision = 2 , short = True ) . strip ( ) . split ( ) ) ": 441,
 "def get_module_path ( modname ) : return osp . abspath ( osp . dirname ( sys . modules[modname] . __file__ ) ) ": 442,
 "def np_hash ( a ) : if a is None : return hash ( None ) # Ensure that hashes are equal whatever the ordering in memory ( C or # Fortran ) a = np . ascontiguousarray ( a ) # Compute the digest and return a decimal int return int ( hashlib . sha1 ( a . view ( a . dtype ) ) . hexdigest ( ) , 16 ) ": 443,
 "def get ( s , delimiter = ' ' , format = \" diacritical \" ) : return delimiter . join ( _pinyin_generator ( u ( s ) , format = format ) ) ": 444,
 "def center_eigenvalue_diff ( mat ) : N = len ( mat ) evals = np . sort ( la . eigvals ( mat ) ) diff = np . abs ( evals[N/2] - evals[N/2-1] ) return diff": 445,
 "def get_file_size ( fileobj ) : currpos = fileobj . tell ( ) fileobj . seek ( 0 , 2 ) total_size = fileobj . tell ( ) fileobj . seek ( currpos ) return total_size": 446,
 "def array_bytes ( array ) : return np . product ( array . shape ) *np . dtype ( array . dtype ) . itemsize": 447,
 "def clear_es ( ) : # TODO : should receive a catalog slug . ESHypermap . es . indices . delete ( ESHypermap . index_name , ignore = [400 , 404] ) LOGGER . debug ( ' Elasticsearch : Index cleared ' ) ": 448,
 "def get_idx_rect ( index_list ) : rows , cols = list ( zip ( *[ ( i . row ( ) , i . column ( ) ) for i in index_list] ) ) return ( min ( rows ) , max ( rows ) , min ( cols ) , max ( cols ) ) ": 449,
 "def _get_node_parent ( self , age , pos ) : return self . nodes[age][int ( pos / self . comp ) ]": 450,
 "def __repr__ ( self ) : strings = [] for currItem in self : strings . append ( \" %s \" % currItem ) return \" ( %s ) \" % ( \" , \" . join ( strings ) ) ": 451,
 "def dedup_list ( l ) : dedup = set ( ) return [ x for x in l if not ( x in dedup or dedup . add ( x ) ) ]": 452,
 "def tf2 ( ) : # Import the `tf` compat API from this file and check if it ' s already TF 2 . 0 . if tf . __version__ . startswith ( ' 2 . ' ) : return tf elif hasattr ( tf , ' compat ' ) and hasattr ( tf . compat , ' v2 ' ) : # As a fallback , try `tensorflow . compat . v2` if it ' s defined . return tf . compat . v2 raise ImportError ( ' cannot import tensorflow 2 . 0 API ' ) ": 453,
 "def split_addresses ( email_string_list ) : return [f for f in [s . strip ( ) for s in email_string_list . split ( \" , \" ) ] if f]": 454,
 "def size ( ) : try : assert os ! = ' nt ' and sys . stdout . isatty ( ) rows , columns = os . popen ( ' stty size ' , ' r ' ) . read ( ) . split ( ) except ( AssertionError , AttributeError , ValueError ) : # in case of failure , use dimensions of a full screen 13 \" laptop rows , columns = DEFAULT_HEIGHT , DEFAULT_WIDTH return int ( rows ) , int ( columns ) ": 455,
 "def get_list_index ( lst , index_or_name ) : if isinstance ( index_or_name , six . integer_types ) : return index_or_name return lst . index ( index_or_name ) ": 456,
 "def write_enum ( fo , datum , schema ) : index = schema[ ' symbols ' ] . index ( datum ) write_int ( fo , index ) ": 457,
 "def get_bottomrect_idx ( self , pos ) : for i , r in enumerate ( self . link_bottom_rects ) : if r . Contains ( pos ) : return i return -1": 458,
 "def _dt_to_epoch ( dt ) : try : epoch = dt . timestamp ( ) except AttributeError : # py2 epoch = ( dt - datetime ( 1970 , 1 , 1 ) ) . total_seconds ( ) return epoch": 459,
 "def plot_epsilon_residuals ( self ) : fig = plt . figure ( ) ax = fig . add_subplot ( 111 ) ax . scatter ( range ( self . epsilon . size ) , self . epsilon , c = ' k ' , marker = ' * ' ) ax . axhline ( y = 0 . 0 ) plt . show ( ) ": 460,
 "def _get_column_types ( self , data ) : columns = list ( zip_longest ( *data ) ) return [self . _get_column_type ( column ) for column in columns]": 461,
 "def forceupdate ( self , *args , **kw ) : self . _update ( False , self . _ON_DUP_OVERWRITE , *args , **kw ) ": 462,
 "def get_nt_system_uid ( ) : try : import _winreg as winreg except ImportError : import winreg lm = winreg . ConnectRegistry ( None , winreg . HKEY_LOCAL_MACHINE ) try : key = winreg . OpenKey ( lm , r \" Software\\Microsoft\\Cryptography \" ) try : return winreg . QueryValueEx ( key , \" MachineGuid \" ) [0] finally : key . Close ( ) finally : lm . Close ( ) ": 463,
 "def _escape ( s ) : e = s e = e . replace ( ' \\\\ ' , ' \\\\\\\\ ' ) e = e . replace ( ' \\n ' , ' \\\\n ' ) e = e . replace ( ' \\r ' , ' \\\\r ' ) e = e . replace ( \" ' \" , \" \\\\ ' \" ) e = e . replace ( ' \" ' , ' \\\\ \" ' ) return e": 464,
 "def get_element_with_id ( self , id ) : # Should we maintain a hashmap of ids to make this more efficient? Probably overkill . # TODO : Elements can contain nested elements ( captions , footnotes , table cells , etc . ) return next ( ( el for el in self . elements if el . id = = id ) , None ) ": 465,
 "def vector_distance ( a , b ) : a = np . array ( a ) b = np . array ( b ) return np . linalg . norm ( a - b ) ": 466,
 "def url ( self ) : with switch_window ( self . _browser , self . name ) : return self . _browser . url": 467,
 "def euclidean ( c1 , c2 ) : diffs = ( ( i - j ) for i , j in zip ( c1 , c2 ) ) return sum ( x * x for x in diffs ) ": 468,
 "def get_free_memory_win ( ) : stat = MEMORYSTATUSEX ( ) ctypes . windll . kernel32 . GlobalMemoryStatusEx ( ctypes . byref ( stat ) ) return int ( stat . ullAvailPhys / 1024 / 1024 ) ": 469,
 "def xpathEvalExpression ( self , str ) : ret = libxml2mod . xmlXPathEvalExpression ( str , self . _o ) if ret is None : raise xpathError ( ' xmlXPathEvalExpression ( ) failed ' ) return xpathObjectRet ( ret ) ": 470,
 "def EnumValueName ( self , enum , value ) : return self . enum_types_by_name[enum] . values_by_number[value] . name": 471,
 "def is_in ( self , point_x , point_y ) : point_array = array ( ( ( point_x , point_y ) , ) ) vertices = array ( self . points ) winding = self . inside_rule = = \" winding \" result = points_in_polygon ( point_array , vertices , winding ) return result[0]": 472,
 "def extent_count ( self ) : self . open ( ) count = lvm_vg_get_extent_count ( self . handle ) self . close ( ) return count": 473,
 "def title ( self ) : with switch_window ( self . _browser , self . name ) : return self . _browser . title": 474,
 "def visit_BoolOp ( self , node ) : return sum ( ( self . visit ( value ) for value in node . values ) , [] ) ": 475,
 "def __get_xml_text ( root ) : txt = \" \" for e in root . childNodes : if ( e . nodeType = = e . TEXT_NODE ) : txt + = e . data return txt": 476,
 "def runcode ( code ) : \t\tfor line in code : \t\tprint ( ' # ' +line ) \t\texec ( line , globals ( ) ) \tprint ( ' # return ans ' ) \treturn ans": 477,
 "def fetch_event ( urls ) : rs = ( grequests . get ( u ) for u in urls ) return [content . json ( ) for content in grequests . map ( rs ) ]": 478,
 "def get_order ( self , codes ) : return sorted ( codes , key = lambda e : [self . ev2idx . get ( e ) ] ) ": 479,
 "def equal ( list1 , list2 ) : return [item1 = = item2 for item1 , item2 in broadcast_zip ( list1 , list2 ) ]": 480,
 "def select ( self , cmd , *args , **kwargs ) : self . cursor . execute ( cmd , *args , **kwargs ) return self . cursor . fetchall ( ) ": 481,
 "def go_to_parent_directory ( self ) : self . chdir ( osp . abspath ( osp . join ( getcwd_or_home ( ) , os . pardir ) ) ) ": 482,
 "def _convert_to_float_if_possible ( s ) : try : ret = float ( s ) except ( ValueError , TypeError ) : ret = s return ret": 483,
 "def _top ( self ) : # Goto top of the list self . top . body . focus_position = 2 if self . compact is False else 0 self . top . keypress ( self . size , \" \" ) ": 484,
 "def to_gtp ( coord ) : if coord is None : return ' pass ' y , x = coord return ' {}{} ' . format ( _GTP_COLUMNS[x] , go . N - y ) ": 485,
 "def nb_to_python ( nb_path ) : exporter = python . PythonExporter ( ) output , resources = exporter . from_filename ( nb_path ) return output": 486,
 "def searchlast ( self , n = 10 ) : solutions = deque ( [] , n ) for solution in self : solutions . append ( solution ) return solutions": 487,
 "def to_json ( df , state_index , color_index , fills ) : records = {} for i , row in df . iterrows ( ) : records[row[state_index]] = { \" fillKey \" : row[color_index] } return { \" data \" : records , \" fills \" : fills }": 488,
 "def _text_to_graphiz ( self , text ) : dot = Source ( text , format = ' svg ' ) return dot . pipe ( ) . decode ( ' utf-8 ' ) ": 489,
 "def _round_half_hour ( record ) : k = record . datetime + timedelta ( minutes = - ( record . datetime . minute % 30 ) ) return datetime ( k . year , k . month , k . day , k . hour , k . minute , 0 ) ": 490,
 "def get_X0 ( X ) : if pandas_available and isinstance ( X , pd . DataFrame ) : assert len ( X ) = = 1 x = np . array ( X . iloc[0] ) else : x , = X return x": 491,
 "def threads_init ( gtk = True ) : # enable X11 multithreading x11 . XInitThreads ( ) if gtk : from gtk . gdk import threads_init threads_init ( ) ": 492,
 "def security ( self ) : return {k : v for i in self . pdf . resolvedObjects . items ( ) for k , v in i[1] . items ( ) }": 493,
 "def enable_gtk3 ( self , app = None ) : from pydev_ipython . inputhookgtk3 import create_inputhook_gtk3 self . set_inputhook ( create_inputhook_gtk3 ( self . _stdin_file ) ) self . _current_gui = GUI_GTK": 494,
 "def dot ( a , b ) : b = numpy . asarray ( b ) return numpy . dot ( a , b . reshape ( b . shape[0] , -1 ) ) . reshape ( a . shape[ : -1] + b . shape[1 : ] ) ": 495,
 "def __gzip ( filename ) : \t\t\t\tzipname = filename + ' . gz ' \t\tfile_pointer = open ( filename , ' rb ' ) \t\tzip_pointer = gzip . open ( zipname , ' wb ' ) \t\tzip_pointer . writelines ( file_pointer ) \t\tfile_pointer . close ( ) \t\tzip_pointer . close ( ) \t\treturn zipname": 496,
 "def create_h5py_with_large_cache ( filename , cache_size_mb ) : # h5py does not allow to control the cache size from the high level # we employ the workaround # sources : # http : //stackoverflow . com/questions/14653259/how-to-set-cache-settings-while-using-h5py-high-level-interface # https : //groups . google . com/forum/ # !msg/h5py/RVx1ZB6LpE4/KH57vq5yw2AJ propfaid = h5py . h5p . create ( h5py . h5p . FILE_ACCESS ) settings = list ( propfaid . get_cache ( ) ) settings[2] = 1024 * 1024 * cache_size_mb propfaid . set_cache ( *settings ) fid = h5py . h5f . create ( filename , flags = h5py . h5f . ACC_EXCL , fapl = propfaid ) fin = h5py . File ( fid ) return fin": 497,
 "def rfft2d_freqs ( h , w ) : fy = np . fft . fftfreq ( h ) [ : , None] # when we have an odd input dimension we need to keep one additional # frequency and later cut off 1 pixel if w % 2 = = 1 : fx = np . fft . fftfreq ( w ) [ : w // 2 + 2] else : fx = np . fft . fftfreq ( w ) [ : w // 2 + 1] return np . sqrt ( fx * fx + fy * fy ) ": 498,
 "def md5_hash_file ( fh ) : md5 = hashlib . md5 ( ) while True : data = fh . read ( 8192 ) if not data : break md5 . update ( data ) return md5 . hexdigest ( ) ": 499,
 "def software_fibonacci ( n ) : a , b = 0 , 1 for i in range ( n ) : a , b = b , a + b return a": 500,
 "def h5ToDict ( h5 , readH5pyDataset = True ) : h = h5py . File ( h5 , \" r \" ) ret = unwrapArray ( h , recursive = True , readH5pyDataset = readH5pyDataset ) if readH5pyDataset : h . close ( ) return ret": 501,
 "def current_zipfile ( ) : if zipfile . is_zipfile ( sys . argv[0] ) : fd = open ( sys . argv[0] , \" rb \" ) return zipfile . ZipFile ( fd ) ": 502,
 "def __unixify ( self , s ) : return os . path . normpath ( s ) . replace ( os . sep , \" / \" ) ": 503,
 "def __init__ ( self , encoding = ' utf-8 ' ) : super ( StdinInputReader , self ) . __init__ ( sys . stdin , encoding = encoding ) ": 504,
 "def _add_hash ( source ) : source = ' \\n ' . join ( ' # ' + line . rstrip ( ) for line in source . splitlines ( ) ) return source": 505,
 "def apply ( f , obj , *args , **kwargs ) : return vectorize ( f ) ( obj , *args , **kwargs ) ": 506,
 "def drop_empty ( rows ) : return zip ( *[col for col in zip ( *rows ) if bool ( filter ( bool , col[1 : ] ) ) ] ) ": 507,
 "def heappush_max ( heap , item ) : heap . append ( item ) _siftdown_max ( heap , 0 , len ( heap ) - 1 ) ": 508,
 "def _heappush_max ( heap , item ) : heap . append ( item ) heapq . _siftdown_max ( heap , 0 , len ( heap ) - 1 ) ": 509,
 "def _remove_keywords ( d ) : return { k : v for k , v in iteritems ( d ) if k not in RESERVED }": 510,
 "def _heapify_max ( x ) : n = len ( x ) for i in reversed ( range ( n//2 ) ) : _siftup_max ( x , i ) ": 511,
 "def uniq ( seq ) : seen = set ( ) return [x for x in seq if str ( x ) not in seen and not seen . add ( str ( x ) ) ]": 512,
 "def replace_all ( filepath , searchExp , replaceExp ) : for line in fileinput . input ( filepath , inplace = 1 ) : if searchExp in line : line = line . replace ( searchExp , replaceExp ) sys . stdout . write ( line ) ": 513,
 "def __call__ ( self , kind : Optional[str] = None , **kwargs ) : return plot ( self . histogram , kind = kind , **kwargs ) ": 514,
 "def ci ( a , which = 95 , axis = None ) : p = 50 - which / 2 , 50 + which / 2 return percentiles ( a , p , axis ) ": 515,
 "def dtype ( self ) : try : return self . data . dtype except AttributeError : return numpy . dtype ( ' %s%d ' % ( self . _sample_type , self . _sample_bytes ) ) ": 516,
 "def tuple_search ( t , i , v ) : for e in t : if e[i] = = v : return e return None": 517,
 "def from_pairs_to_array_values ( pairs ) : result = {} for pair in pairs : result[pair[0]] = concat ( prop_or ( [] , pair[0] , result ) , [pair[1]] ) return result": 518,
 "def area ( x , y ) : # http : //stackoverflow . com/questions/24467972/calculate-area-of-polygon-given-x-y-coordinates return 0 . 5 * np . abs ( np . dot ( x , np . roll ( y , 1 ) ) - np . dot ( y , np . roll ( x , 1 ) ) ) ": 519,
 "def _getSuperFunc ( self , s , func ) : return getattr ( super ( self . cls ( ) , s ) , func . __name__ ) ": 520,
 "def val_to_bin ( edges , x ) : ibin = np . digitize ( np . array ( x , ndmin = 1 ) , edges ) - 1 return ibin": 521,
 "def compare ( dicts ) : common_members = {} common_keys = reduce ( lambda x , y : x & y , map ( dict . keys , dicts ) ) for k in common_keys : common_members[k] = list ( reduce ( lambda x , y : x & y , [set ( d[k] ) for d in dicts] ) ) return common_members": 522,
 "def _get_compiled_ext ( ) : for ext , mode , typ in imp . get_suffixes ( ) : if typ = = imp . PY_COMPILED : return ext": 523,
 "def list_add_capitalize ( l ) : nl = [] for i in l : nl . append ( i ) if hasattr ( i , \" capitalize \" ) : nl . append ( i . capitalize ( ) ) return list ( set ( nl ) ) ": 524,
 "def to_camel_case ( text ) : split = text . split ( ' _ ' ) return split[0] + \" \" . join ( x . title ( ) for x in split[1 : ] ) ": 525,
 "def median ( lst ) : # : http : //stackoverflow . com/a/24101534 sortedLst = sorted ( lst ) lstLen = len ( lst ) index = ( lstLen - 1 ) // 2 if ( lstLen % 2 ) : return sortedLst[index] else : return ( sortedLst[index] + sortedLst[index + 1] ) /2 . 0": 526,
 "def _IsRetryable ( error ) : if not isinstance ( error , MySQLdb . OperationalError ) : return False if not error . args : return False code = error . args[0] return code in _RETRYABLE_ERRORS": 527,
 "def pid_exists ( pid ) : try : os . kill ( pid , 0 ) except OSError as exc : return exc . errno = = errno . EPERM else : return True": 528,
 "def getPrimeFactors ( n ) : lo = [1] n2 = n // 2 k = 2 for k in range ( 2 , n2 + 1 ) : if ( n // k ) *k = = n : lo . append ( k ) return lo + [n , ]": 529,
 "def _isstring ( dtype ) : return dtype . type = = numpy . unicode_ or dtype . type = = numpy . string_": 530,
 "def _is_override ( meta , method ) : from taipan . objective . modifiers import _OverriddenMethod return isinstance ( method , _OverriddenMethod ) ": 531,
 "def should_skip_logging ( func ) : disabled = strtobool ( request . headers . get ( \" x-request-nolog \" , \" false \" ) ) return disabled or getattr ( func , SKIP_LOGGING , False ) ": 532,
 "def calc_cR ( Q2 , sigma ) : return Q2 * np . exp ( np . sum ( np . log ( sigma**2 ) ) /sigma . shape[0] ) ": 533,
 "def is_builtin_type ( tp ) : return hasattr ( __builtins__ , tp . __name__ ) and tp is getattr ( __builtins__ , tp . __name__ ) ": 534,
 "def forget_coords ( self ) : self . w . ntotal . set_text ( ' 0 ' ) self . coords_dict . clear ( ) self . redo ( ) ": 535,
 "def flat_list ( lst ) : if isinstance ( lst , list ) : for item in lst : for i in flat_list ( item ) : yield i else : yield lst": 536,
 "def safe_exit ( output ) : try : sys . stdout . write ( output ) sys . stdout . flush ( ) except IOError : pass": 537,
 "def imflip ( img , direction = ' horizontal ' ) : assert direction in [ ' horizontal ' , ' vertical ' ] if direction = = ' horizontal ' : return np . flip ( img , axis = 1 ) else : return np . flip ( img , axis = 0 ) ": 538,
 "def get_order ( self ) : return [dict ( reverse = r[0] , key = r[1] ) for r in self . get_model ( ) ]": 539,
 "def hflip ( img ) : if not _is_pil_image ( img ) : raise TypeError ( ' img should be PIL Image . Got {} ' . format ( type ( img ) ) ) return img . transpose ( Image . FLIP_LEFT_RIGHT ) ": 540,
 "def get_document_frequency ( self , term ) : if term not in self . _terms : raise IndexError ( TERM_DOES_NOT_EXIST ) else : return len ( self . _terms[term] ) ": 541,
 "def destroy ( self ) : if self . widget : self . set_active ( False ) super ( AndroidBarcodeView , self ) . destroy ( ) ": 542,
 "def one_for_all ( self , deps ) : requires , dependencies = [] , [] deps . reverse ( ) # Inverting the list brings the # dependencies in order to be installed . requires = Utils ( ) . dimensional_list ( deps ) dependencies = Utils ( ) . remove_dbs ( requires ) return dependencies": 543,
 "def trigger_fullscreen_action ( self , fullscreen ) : action = self . action_group . get_action ( ' fullscreen ' ) action . set_active ( fullscreen ) ": 544,
 "def download_json ( local_filename , url , clobber = False ) : with open ( local_filename , ' w ' ) as json_file : json_file . write ( json . dumps ( requests . get ( url ) . json ( ) , sort_keys = True , indent = 2 , separators = ( ' , ' , ' : ' ) ) ) ": 545,
 "def is_password_valid ( password ) : pattern = re . compile ( r \" ^ . {4 , 75}$ \" ) return bool ( pattern . match ( password ) ) ": 546,
 "def drag_and_drop ( self , droppable ) : self . scroll_to ( ) ActionChains ( self . parent . driver ) . drag_and_drop ( self . _element , droppable . _element ) . perform ( ) ": 547,
 "def url_encode ( url ) : if isinstance ( url , text_type ) : url = url . encode ( ' utf8 ' ) return quote ( url , ' : /%?& = ' ) ": 548,
 "def ExecuteRaw ( self , position , command ) : self . EnsureGdbPosition ( position[0] , None , None ) return gdb . execute ( command , to_string = True ) ": 549,
 "def finish ( ) : out . warn ( \" Interrupted! \" ) for t in threads : t . stop ( ) jobs . clear ( ) out . warn ( \" Waiting for download threads to finish . \" ) ": 550,
 "def rlognormal ( mu , tau , size = None ) : return np . random . lognormal ( mu , np . sqrt ( 1 . / tau ) , size ) ": 551,
 "def calculate_boundingbox ( lng , lat , miles ) : latChange = change_in_latitude ( miles ) latSouth = lat - latChange latNorth = lat + latChange lngChange = change_in_longitude ( lat , miles ) lngWest = lng + lngChange lngEast = lng - lngChange return ( lngWest , latSouth , lngEast , latNorth ) ": 552,
 "def uniqueID ( size = 6 , chars = string . ascii_uppercase + string . digits ) : return ' ' . join ( random . choice ( chars ) for x in xrange ( size ) ) ": 553,
 "def toBase64 ( s ) : if isinstance ( s , str ) : s = s . encode ( \" utf-8 \" ) return binascii . b2a_base64 ( s ) [ : -1]": 554,
 "def _generate_key_map ( entity_list , key , entity_class ) : key_map = {} for obj in entity_list : key_map[obj[key]] = entity_class ( **obj ) return key_map": 555,
 "def intersect ( d1 , d2 ) : return dict ( ( k , d1[k] ) for k in d1 if k in d2 and d1[k] = = d2[k] ) ": 556,
 "def _rndPointDisposition ( dx , dy ) : x = int ( random . uniform ( -dx , dx ) ) y = int ( random . uniform ( -dy , dy ) ) return ( x , y ) ": 557,
 "def sine_wave ( frequency ) : xs = tf . reshape ( tf . range ( _samples ( ) , dtype = tf . float32 ) , [1 , _samples ( ) , 1] ) ts = xs / FLAGS . sample_rate return tf . sin ( 2 * math . pi * frequency * ts ) ": 558,
 "def bitsToString ( arr ) : s = array ( ' c ' , ' . ' *len ( arr ) ) for i in xrange ( len ( arr ) ) : if arr[i] = = 1 : s[i] = ' * ' return s": 559,
 "def find_nearest_index ( arr , value ) : arr = np . array ( arr ) index = ( abs ( arr-value ) ) . argmin ( ) return index": 560,
 "def make_file_read_only ( file_path ) : old_permissions = os . stat ( file_path ) . st_mode os . chmod ( file_path , old_permissions & ~WRITE_PERMISSIONS ) ": 561,
 "def copy ( self ) : result = NocaseDict ( ) result . _data = self . _data . copy ( ) # pylint : disable = protected-access return result": 562,
 "def longest_run ( da , dim = ' time ' ) : d = rle ( da , dim = dim ) rl_long = d . max ( dim = dim ) return rl_long": 563,
 "def fopenat ( base_fd , path ) : return os . fdopen ( openat ( base_fd , path , os . O_RDONLY ) , ' rb ' ) ": 564,
 "def vars_class ( cls ) : return dict ( chain . from_iterable ( vars ( cls ) . items ( ) for cls in reversed ( cls . __mro__ ) ) ) ": 565,
 "def flatten ( l , types = ( list , float ) ) : l = [item if isinstance ( item , types ) else [item] for item in l] return [item for sublist in l for item in sublist]": 566,
 "def _ensure_element ( tup , elem ) : try : return tup , tup . index ( elem ) except ValueError : return tuple ( chain ( tup , ( elem , ) ) ) , len ( tup ) ": 567,
 "def bitdepth ( self ) : if hasattr ( self . mgfile . info , ' bits_per_sample ' ) : return self . mgfile . info . bits_per_sample return 0": 568,
 "def to_python ( self , value ) : if value is None : return value if isinstance ( value , self . enum ) : return value return self . enum[value]": 569,
 "def force_iterable ( f ) : def wrapper ( *args , **kwargs ) : r = f ( *args , **kwargs ) if hasattr ( r , ' __iter__ ' ) : return r else : return [r] return wrapper": 570,
 "def _read_date_from_string ( str1 ) : full_date = [int ( x ) for x in str1 . split ( ' / ' ) ] return datetime . date ( full_date[0] , full_date[1] , full_date[2] ) ": 571,
 "def wr_row_mergeall ( self , worksheet , txtstr , fmt , row_idx ) : hdridxval = len ( self . hdrs ) - 1 worksheet . merge_range ( row_idx , 0 , row_idx , hdridxval , txtstr , fmt ) return row_idx + 1": 572,
 "def dates_in_range ( start_date , end_date ) : return [ start_date + timedelta ( n ) for n in range ( int ( ( end_date - start_date ) . days ) ) ]": 573,
 "def unique ( input_list ) : output = [] for item in input_list : if item not in output : output . append ( item ) return output": 574,
 "def sort_fn_list ( fn_list ) : dt_list = get_dt_list ( fn_list ) fn_list_sort = [fn for ( dt , fn ) in sorted ( zip ( dt_list , fn_list ) ) ] return fn_list_sort": 575,
 "def fast_distinct ( self ) : return self . model . objects . filter ( pk__in = self . values_list ( ' pk ' , flat = True ) ) ": 576,
 "def Proxy ( f ) : def Wrapped ( self , *args ) : return getattr ( self , f ) ( *args ) return Wrapped": 577,
 "def metres2latlon ( mx , my , origin_shift = 2 * pi * 6378137 / 2 . 0 ) : lon = ( mx / origin_shift ) * 180 . 0 lat = ( my / origin_shift ) * 180 . 0 lat = 180 / pi * ( 2 * atan ( exp ( lat * pi / 180 . 0 ) ) - pi / 2 . 0 ) return lat , lon": 578,
 "def next ( self ) : # File-like object . result = self . readline ( ) if result = = self . _empty_buffer : raise StopIteration return result": 579,
 "def _factor_generator ( n ) : p = prime_factors ( n ) factors = {} for p1 in p : try : factors[p1] + = 1 except KeyError : factors[p1] = 1 return factors": 580,
 "def unique ( seq ) : cleaned = [] for each in seq : if each not in cleaned : cleaned . append ( each ) return cleaned": 581,
 "def get_md5_for_file ( file ) : md5 = hashlib . md5 ( ) while True : data = file . read ( md5 . block_size ) if not data : break md5 . update ( data ) return md5 . hexdigest ( ) ": 582,
 "def _rank ( self , ranking , n ) : return nlargest ( n , ranking , key = ranking . get ) ": 583,
 "def drop_indexes ( self ) : LOG . warning ( \" Dropping all indexe \" ) for collection_name in INDEXES : LOG . warning ( \" Dropping all indexes for collection name %s \" , collection_name ) self . db[collection_name] . drop_indexes ( ) ": 584,
 "def last ( self ) : # End of file self . __file . seek ( 0 , 2 ) # Get the last struct data = self . get ( self . length - 1 ) return data": 585,
 "def debug_src ( src , pm = False , globs = None ) : testsrc = script_from_examples ( src ) debug_script ( testsrc , pm , globs ) ": 586,
 "def get_last_row ( dbconn , tablename , n = 1 , uuid = None ) : return fetch ( dbconn , tablename , n , uuid , end = True ) ": 587,
 "def save ( self , fname : str ) : with open ( fname , \" wb \" ) as fp : pickle . dump ( self , fp ) ": 588,
 "def display_len ( text ) : text = unicodedata . normalize ( ' NFD ' , text ) return sum ( char_width ( char ) for char in text ) ": 589,
 "def isString ( s ) : try : return isinstance ( s , unicode ) or isinstance ( s , basestring ) except NameError : return isinstance ( s , str ) ": 590,
 "def rel_path ( filename ) : return os . path . join ( os . getcwd ( ) , os . path . dirname ( __file__ ) , filename ) ": 591,
 "def const_rand ( size , seed = 23980 ) : old_seed = np . random . seed ( ) np . random . seed ( seed ) out = np . random . rand ( size ) np . random . seed ( old_seed ) return out": 592,
 "def get_action_methods ( self ) : return [ ( name , getattr ( self , name ) ) for name , _ in Action . get_command_types ( ) ]": 593,
 "def start ( ) : global app bottle . run ( app , host = conf . WebHost , port = conf . WebPort , debug = conf . WebAutoReload , reloader = conf . WebAutoReload , quiet = conf . WebQuiet ) ": 594,
 "async def sysinfo ( dev : Device ) : click . echo ( await dev . get_system_info ( ) ) click . echo ( await dev . get_interface_information ( ) ) ": 595,
 "def count_ ( self ) : try : num = len ( self . df . index ) except Exception as e : self . err ( e , \" Can not count data \" ) return return num": 596,
 "def post_object_async ( self , path , **kwds ) : return self . do_request_async ( self . api_url + path , ' POST ' , **kwds ) ": 597,
 "def findfirst ( f , coll ) : result = list ( dropwhile ( f , coll ) ) return result[0] if result else None": 598,
 "def start ( self ) : self . _process = threading . Thread ( target = self . _background_runner ) self . _process . start ( ) ": 599,
 "def return_letters_from_string ( text ) : out = \" \" for letter in text : if letter . isalpha ( ) : out + = letter return out": 600,
 "def parse_querystring ( self , req , name , field ) : return core . get_value ( req . args , name , field ) ": 601,
 "def inject_into_urllib3 ( ) : util . ssl_ . SSLContext = SecureTransportContext util . HAS_SNI = HAS_SNI util . ssl_ . HAS_SNI = HAS_SNI util . IS_SECURETRANSPORT = True util . ssl_ . IS_SECURETRANSPORT = True": 602,
 "def strip_spaces ( x ) : x = x . replace ( b ' ' , b ' ' ) x = x . replace ( b ' \\t ' , b ' ' ) return x": 603,
 "def argsort_indices ( a , axis = -1 ) : a = np . asarray ( a ) ind = list ( np . ix_ ( *[np . arange ( d ) for d in a . shape] ) ) ind[axis] = a . argsort ( axis ) return tuple ( ind ) ": 604,
 "def file_or_default ( path , default , function = None ) : try : result = file_get_contents ( path ) if function ! = None : return function ( result ) return result except IOError as e : if e . errno = = errno . ENOENT : return default raise": 605,
 "def this_quarter ( ) : since = TODAY + delta ( day = 1 ) while since . month % 3 ! = 0 : since - = delta ( months = 1 ) until = since + delta ( months = 3 ) return Date ( since ) , Date ( until ) ": 606,
 "def strToBool ( val ) : if isinstance ( val , str ) : val = val . lower ( ) return val in [ ' true ' , ' on ' , ' yes ' , True]": 607,
 "def clear_list_value ( self , value ) : # Don ' t go any further : this value is empty . if not value : return self . empty_value # Clean empty items if wanted if self . clean_empty : value = [v for v in value if v] return value or self . empty_value": 608,
 "def call_out ( command ) : # start external command process p = subprocess . Popen ( command , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) # get outputs out , _ = p . communicate ( ) return p . returncode , out . strip ( ) ": 609,
 "def run ( self , value ) : if self . pass_ and not value . strip ( ) : return True if not value : return False return True": 610,
 "def _string_width ( self , s ) : s = str ( s ) w = 0 for i in s : w + = self . character_widths[i] return w * self . font_size / 1000 . 0": 611,
 "def find_le ( a , x ) : i = bs . bisect_right ( a , x ) if i : return i - 1 raise ValueError": 612,
 "def crop_box ( im , box = False , **kwargs ) : if box : im = im . crop ( box ) return im": 613,
 "def datatype ( dbtype , description , cursor ) : dt = cursor . db . introspection . get_field_type ( dbtype , description ) if type ( dt ) is tuple : return dt[0] else : return dt": 614,
 "def normalize ( im , invert = False , scale = None , dtype = np . float64 ) : if dtype not in {np . float16 , np . float32 , np . float64} : raise ValueError ( ' dtype must be numpy . float16 , float32 , or float64 . ' ) out = im . astype ( ' float ' ) . copy ( ) scale = scale or ( 0 . 0 , 255 . 0 ) l , u = ( float ( i ) for i in scale ) out = ( out - l ) / ( u - l ) if invert : out = -out + ( out . max ( ) + out . min ( ) ) return out . astype ( dtype ) ": 615,
 "def end_index ( self ) : paginator = self . paginator # Special case for the last page because there can be orphans . if self . number = = paginator . num_pages : return paginator . count return ( self . number - 1 ) * paginator . per_page + paginator . first_page": 616,
 "def filtered_image ( self , im ) : q = np . fft . fftn ( im ) for k , v in self . filters : q[k] - = v return np . real ( np . fft . ifftn ( q ) ) ": 617,
 "def get_buffer ( self , data_np , header , format , output = None ) : if not have_pil : raise Exception ( \" Install PIL to use this method \" ) image = PILimage . fromarray ( data_np ) buf = output if buf is None : buf = BytesIO ( ) image . save ( buf , format ) return buf": 618,
 "def uint32_to_uint8 ( cls , img ) : return np . flipud ( img . view ( dtype = np . uint8 ) . reshape ( img . shape + ( 4 , ) ) ) ": 619,
 "def get_user_by_id ( self , id ) : return self . db_adapter . get_object ( self . UserClass , id = id ) ": 620,
 "def reduce_fn ( x ) : values = x . values if pd and isinstance ( x , pd . Series ) else x for v in values : if not is_nan ( v ) : return v return np . NaN": 621,
 "def _EnforceProcessMemoryLimit ( self , memory_limit ) : # Resource is not supported on Windows . if resource : if memory_limit is None : memory_limit = 4 * 1024 * 1024 * 1024 elif memory_limit = = 0 : memory_limit = resource . RLIM_INFINITY resource . setrlimit ( resource . RLIMIT_DATA , ( memory_limit , memory_limit ) ) ": 622,
 "def check_many ( self , domains ) : return dict ( ( item . domain , item . status ) for item in self . check_domain_request ( domains ) ) ": 623,
 "def end_block ( self ) : self . current_indent - = 1 # If we did not add a new line automatically yet , now it ' s the time! if not self . auto_added_line : self . writeln ( ) self . auto_added_line = True": 624,
 "def get_weights_from_kmodel ( kmodel ) : layers_with_weights = [layer for layer in kmodel . layers if layer . weights] bweights = [] for klayer in layers_with_weights : # bws would be [weights , bias] or [weights] bws = WeightsConverter . get_bigdl_weights_from_klayer ( klayer ) for w in bws : bweights . append ( w ) return bweights": 625,
 "def MultiArgMax ( x ) : m = x . max ( ) return ( i for i , v in enumerate ( x ) if v = = m ) ": 626,
 "def __init__ ( self , find , subcon ) : Subconstruct . __init__ ( self , subcon ) self . find = find": 627,
 "def value ( self ) : if self . _prop . fget is None : raise AttributeError ( ' Unable to read attribute ' ) return self . _prop . fget ( self . _obj ) ": 628,
 "def prepend_line ( filepath , line ) : with open ( filepath ) as f : lines = f . readlines ( ) lines . insert ( 0 , line ) with open ( filepath , ' w ' ) as f : f . writelines ( lines ) ": 629,
 "def find_coord_vars ( ncds ) : coord_vars = [] for d in ncds . dimensions : if d in ncds . variables and ncds . variables[d] . dimensions = = ( d , ) : coord_vars . append ( ncds . variables[d] ) return coord_vars": 630,
 "def get_func_posargs_name ( f ) : sigparams = inspect . signature ( f ) . parameters for p in sigparams : if sigparams[p] . kind = = inspect . Parameter . VAR_POSITIONAL : return sigparams[p] . name return None": 631,
 "def check_git ( ) : try : with open ( os . devnull , \" wb \" ) as devnull : subprocess . check_call ( [ \" git \" , \" --version \" ] , stdout = devnull , stderr = devnull ) except : raise RuntimeError ( \" Please make sure git is installed and on your path . \" ) ": 632,
 "def as_list ( self ) : return [self . name , self . value , [x . as_list for x in self . children]]": 633,
 "def positive_integer ( anon , obj , field , val ) : return anon . faker . positive_integer ( field = field ) ": 634,
 "def method ( func ) : attr = abc . abstractmethod ( func ) attr . __imethod__ = True return attr": 635,
 "def get_lines ( handle , line ) : for i , l in enumerate ( handle ) : if i = = line : return l": 636,
 "def is_int ( value ) : if isinstance ( value , bool ) : return False try : int ( value ) return True except ( ValueError , TypeError ) : return False": 637,
 "def norm ( x , mu , sigma = 1 . 0 ) : return stats . norm ( loc = mu , scale = sigma ) . pdf ( x ) ": 638,
 "def add_noise ( Y , sigma ) : return Y + np . random . normal ( 0 , sigma , Y . shape ) ": 639,
 "def spline_interpolate_by_datetime ( datetime_axis , y_axis , datetime_new_axis ) : numeric_datetime_axis = [ totimestamp ( a_datetime ) for a_datetime in datetime_axis ] numeric_datetime_new_axis = [ totimestamp ( a_datetime ) for a_datetime in datetime_new_axis ] return spline_interpolate ( numeric_datetime_axis , y_axis , numeric_datetime_new_axis ) ": 640,
 "def _load_data ( filepath ) : with h5py . File ( filepath , \" r \" ) as h5dataset : image_array = np . array ( h5dataset[ \" images \" ] ) # The ' label ' data set in the hdf5 file actually contains the float values # and not the class labels . values_array = np . array ( h5dataset[ \" labels \" ] ) return image_array , values_array": 641,
 "def invertDictMapping ( d ) : inv_map = {} for k , v in d . items ( ) : inv_map[v] = inv_map . get ( v , [] ) inv_map[v] . append ( k ) return inv_map": 642,
 "def chunk_list ( l , n ) : return [l[i : i + n] for i in range ( 0 , len ( l ) , n ) ]": 643,
 "def is_valid_ip ( ip_address ) : valid = True try : socket . inet_aton ( ip_address . strip ( ) ) except : valid = False return valid": 644,
 "def main ( idle ) : while True : LOG . debug ( \" Sleeping for {0} seconds . \" . format ( idle ) ) time . sleep ( idle ) ": 645,
 "def unique ( _list ) : ret = [] for item in _list : if item not in ret : ret . append ( item ) return ret": 646,
 "def is_a_sequence ( var , allow_none = False ) : return isinstance ( var , ( list , tuple ) ) or ( var is None and allow_none ) ": 647,
 "def isin ( elems , line ) : found = False for e in elems : if e in line . lower ( ) : found = True break return found": 648,
 "def _notnull ( expr ) : if isinstance ( expr , SequenceExpr ) : return NotNull ( _input = expr , _data_type = types . boolean ) elif isinstance ( expr , Scalar ) : return NotNull ( _input = expr , _value_type = types . boolean ) ": 649,
 "def conv_dict ( self ) : return dict ( integer = self . integer , real = self . real , no_type = self . no_type ) ": 650,
 "def _writable_dir ( path ) : return os . path . isdir ( path ) and os . access ( path , os . W_OK ) ": 651,
 "def make_qs ( n , m = None ) : try : import sympy except ImportError : raise ImportError ( \" This function requires sympy . Please install it . \" ) if m is None : syms = sympy . symbols ( \" \" . join ( f \" q{i} \" for i in range ( n ) ) ) if isinstance ( syms , tuple ) : return syms else : return ( syms , ) syms = sympy . symbols ( \" \" . join ( f \" q{i} \" for i in range ( n , m ) ) ) if isinstance ( syms , tuple ) : return syms else : return ( syms , ) ": 652,
 "def isdir ( path , **kwargs ) : import os . path return os . path . isdir ( path , **kwargs ) ": 653,
 "def batch ( items , size ) : return [items[x : x + size] for x in xrange ( 0 , len ( items ) , size ) ]": 654,
 "def is_float_array ( l ) : r if isinstance ( l , np . ndarray ) : if l . dtype . kind = = ' f ' : return True return False": 655,
 "def myreplace ( astr , thefind , thereplace ) : alist = astr . split ( thefind ) new_s = alist . split ( thereplace ) return new_s": 656,
 "def is_iter_non_string ( obj ) : if isinstance ( obj , list ) or isinstance ( obj , tuple ) : return True return False": 657,
 "def round_to_x_digits ( number , digits ) : return round ( number * math . pow ( 10 , digits ) ) / math . pow ( 10 , digits ) ": 658,
 "def __next__ ( self ) : res = self . _head self . _fill ( ) if res is None : raise StopIteration ( ) return res": 659,
 "def as_tuple ( self , value ) : if isinstance ( value , list ) : value = tuple ( value ) return value": 660,
 "def __reversed__ ( self ) : _dict = self . _dict return iter ( ( key , _dict[key] ) for key in reversed ( self . _list ) ) ": 661,
 "def register_modele ( self , modele : Modele ) : self . lemmatiseur . _modeles[modele . gr ( ) ] = modele": 662,
 "def split_every ( n , iterable ) : items = iter ( iterable ) return itertools . takewhile ( bool , ( list ( itertools . islice ( items , n ) ) for _ in itertools . count ( ) ) ) ": 663,
 "def flatten ( l ) : return sum ( map ( flatten , l ) , [] ) \\ if isinstance ( l , list ) or isinstance ( l , tuple ) else [l]": 664,
 "def directory_files ( path ) : for entry in os . scandir ( path ) : if not entry . name . startswith ( ' . ' ) and entry . is_file ( ) : yield entry . name": 665,
 "def read_array ( path , mmap_mode = None ) : file_ext = op . splitext ( path ) [1] if file_ext = = ' . npy ' : return np . load ( path , mmap_mode = mmap_mode ) raise NotImplementedError ( \" The file extension `{}` \" . format ( file_ext ) + \" is not currently supported . \" ) ": 666,
 "def group_by ( iterable , key_func ) : groups = ( list ( sub ) for key , sub in groupby ( iterable , key_func ) ) return zip ( groups , groups ) ": 667,
 "def get_python ( ) : if sys . platform = = ' win32 ' : python = path . join ( VE_ROOT , ' Scripts ' , ' python . exe ' ) else : python = path . join ( VE_ROOT , ' bin ' , ' python ' ) return python": 668,
 "def render_template ( template_name , **context ) : tmpl = jinja_env . get_template ( template_name ) context[ \" url_for \" ] = url_for return Response ( tmpl . render ( context ) , mimetype = \" text/html \" ) ": 669,
 "def selectnone ( table , field , complement = False ) : return select ( table , field , lambda v : v is None , complement = complement ) ": 670,
 "def _join ( verb ) : data = pd . merge ( verb . x , verb . y , **verb . kwargs ) # Preserve x groups if isinstance ( verb . x , GroupedDataFrame ) : data . plydata_groups = list ( verb . x . plydata_groups ) return data": 671,
 "def stn ( s , length , encoding , errors ) : s = s . encode ( encoding , errors ) return s[ : length] + ( length - len ( s ) ) * NUL": 672,
 "def join_images ( img_files , out_file ) : images = [PIL . Image . open ( f ) for f in img_files] joined = PIL . Image . new ( ' RGB ' , ( sum ( i . size[0] for i in images ) , max ( i . size[1] for i in images ) ) ) left = 0 for img in images : joined . paste ( im = img , box = ( left , 0 ) ) left = left + img . size[0] joined . save ( out_file ) ": 673,
 "def _dict ( content ) : if _has_pandas : data = _data_frame ( content ) . to_dict ( orient = ' records ' ) else : response = loads ( content ) key = [x for x in response . keys ( ) if x in c . response_data][0] data = response[key] return data": 674,
 "def get_join_cols ( by_entry ) : left_cols = [] right_cols = [] for col in by_entry : if isinstance ( col , str ) : left_cols . append ( col ) right_cols . append ( col ) else : left_cols . append ( col[0] ) right_cols . append ( col[1] ) return left_cols , right_cols": 675,
 "def IPYTHON_MAIN ( ) : import pkg_resources runner_frame = inspect . getouterframes ( inspect . currentframe ( ) ) [-2] return ( getattr ( runner_frame , \" function \" , None ) = = pkg_resources . load_entry_point ( \" ipython \" , \" console_scripts \" , \" ipython \" ) . __name__ ) ": 676,
 "def flatten_dict_join_keys ( dct , join_symbol = \" \" ) : return dict ( flatten_dict ( dct , join = lambda a , b : a+join_symbol+b ) ) ": 677,
 "def hash_iterable ( it ) : \t\thash_value = hash ( type ( it ) ) \tfor value in it : \t\thash_value = hash ( ( hash_value , value ) ) \treturn hash_value": 678,
 "def _to_diagonally_dominant ( mat ) : mat + = np . diag ( np . sum ( mat ! = 0 , axis = 1 ) + 0 . 01 ) return mat": 679,
 "def traverse_setter ( obj , attribute , value ) : obj . traverse ( lambda x : setattr ( x , attribute , value ) ) ": 680,
 "def read_key ( self , key , bucket_name = None ) : obj = self . get_key ( key , bucket_name ) return obj . get ( ) [ ' Body ' ] . read ( ) . decode ( ' utf-8 ' ) ": 681,
 "def dump_json ( obj ) : return simplejson . dumps ( obj , ignore_nan = True , default = json_util . default ) ": 682,
 "def get_property ( self , filename ) : with open ( self . filepath ( filename ) ) as f : return f . read ( ) . strip ( ) ": 683,
 "def pretty_dict_str ( d , indent = 2 ) : b = StringIO ( ) write_pretty_dict_str ( b , d , indent = indent ) return b . getvalue ( ) ": 684,
 "def help_for_command ( command ) : help_text = pydoc . text . document ( command ) # remove backspaces return re . subn ( ' . \\\\x08 ' , ' ' , help_text ) [0]": 685,
 "def save ( self , fname ) : with open ( fname , ' wb ' ) as f : json . dump ( self , f ) ": 686,
 "def validate ( raw_schema , target = None , **kwargs ) : schema = schema_validator ( raw_schema , **kwargs ) if target is not None : validate_object ( target , schema = schema , **kwargs ) ": 687,
 "def build_output ( self , fout ) : fout . write ( ' \\n ' . join ( [s for s in self . out] ) ) ": 688,
 "def json_serial ( obj ) : if isinstance ( obj , LegipyModel ) : return obj . to_json ( ) elif isinstance ( obj , ( datetime . date , datetime . datetime ) ) : return obj . isoformat ( ) raise TypeError ( \" Type {0} not serializable \" . format ( repr ( type ( obj ) ) ) ) ": 689,
 "def generic_add ( a , b ) : logger . debug ( ' Called generic_add ( {} , {} ) ' . format ( a , b ) ) return a + b": 690,
 "def _unjsonify ( x , isattributes = False ) : if isattributes : obj = json . loads ( x ) return dict_class ( obj ) return json . loads ( x ) ": 691,
 "def get_absolute_path ( *args ) : directory = os . path . dirname ( os . path . abspath ( __file__ ) ) return os . path . join ( directory , *args ) ": 692,
 "def graphql_queries_to_json ( *queries ) : rtn = {} for i , query in enumerate ( queries ) : rtn[ \" q{} \" . format ( i ) ] = query . value return json . dumps ( rtn ) ": 693,
 "def synthesize ( self , duration ) : sr = self . samplerate . samples_per_second seconds = duration / Seconds ( 1 ) samples = np . random . uniform ( low = -1 . , high = 1 . , size = int ( sr * seconds ) ) return AudioSamples ( samples , self . samplerate ) ": 694,
 "def _clean_dict ( target_dict , whitelist = None ) : assert isinstance ( target_dict , dict ) return { ustr ( k ) . strip ( ) : ustr ( v ) . strip ( ) for k , v in target_dict . items ( ) if v not in ( None , Ellipsis , [] , ( ) , \" \" ) and ( not whitelist or k in whitelist ) }": 695,
 "def calculate_embedding ( self , batch_image_bytes ) : return self . tf_session . run ( self . embedding , feed_dict = {self . input_jpeg : batch_image_bytes} ) ": 696,
 "def timeout_thread_handler ( timeout , stop_event ) : stop_happened = stop_event . wait ( timeout ) if stop_happened is False : print ( \" Killing program due to %f second timeout \" % timeout ) os . _exit ( 2 ) ": 697,
 "def copy_no_perm ( src , dst ) : shutil . copy ( src , dst ) perm = os . stat ( dst ) . st_mode shutil . copystat ( src , dst ) os . chmod ( dst , perm ) ": 698,
 "def iter_with_last ( iterable ) : # Ensure it ' s an iterator and get the first field iterable = iter ( iterable ) prev = next ( iterable ) for item in iterable : # Lag by one item so I know I ' m not at the end yield False , prev prev = item # Last item yield True , prev": 699,
 "def store_data ( data ) : with open ( url_json_path ) as json_file : try : json_file_data = load ( json_file ) json_file_data . update ( data ) except ( AttributeError , JSONDecodeError ) : json_file_data = data with open ( url_json_path , ' w ' ) as json_file : dump ( json_file_data , json_file , indent = 4 , sort_keys = True ) ": 700,
 "def filename_addstring ( filename , text ) : fn , ext = os . path . splitext ( filename ) return fn + text + ext": 701,
 "def pop ( self ) : if not self . empty ( ) : val = self . stack[-1] del self . stack[-1] return val": 702,
 "def interpolate_logscale_single ( start , end , coefficient ) : return np . exp ( np . log ( start ) + ( np . log ( end ) - np . log ( start ) ) * coefficient ) ": 703,
 "def get_last_modified_timestamp ( self ) : cmd = \" find . -print0 | xargs -0 stat -f ' %T@ %p ' | sort -n | tail -1 | cut -f2- -d ' ' \" ps = subprocess . Popen ( cmd , shell = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) output = ps . communicate ( ) [0] print output": 704,
 "def _stdin_ ( p ) : _v = sys . version[0] return input ( p ) if _v is ' 3 ' else raw_input ( p ) ": 705,
 "def get_list_dimensions ( _list ) : if isinstance ( _list , list ) or isinstance ( _list , tuple ) : return [len ( _list ) ] + get_list_dimensions ( _list[0] ) return []": 706,
 "def sort_filenames ( filenames ) : basenames = [os . path . basename ( x ) for x in filenames] indexes = [i[0] for i in sorted ( enumerate ( basenames ) , key = lambda x : x[1] ) ] return [filenames[x] for x in indexes]": 707,
 "def levenshtein_distance_metric ( a , b ) : return ( levenshtein_distance ( a , b ) / ( 2 . 0 * max ( len ( a ) , len ( b ) , 1 ) ) ) ": 708,
 "def wait_until_exit ( self ) : if self . _timeout is None : raise Exception ( \" Thread will never exit . Use stop or specify timeout when starting it! \" ) self . _thread . join ( ) self . stop ( ) ": 709,
 "def timed ( log = sys . stderr , limit = 2 . 0 ) : return lambda func : timeit ( func , log , limit ) ": 710,
 "def dict_jsonp ( param ) : if not isinstance ( param , dict ) : param = dict ( param ) return jsonp ( param ) ": 711,
 "def txt_line_iterator ( path ) : with tf . gfile . Open ( path ) as f : for line in f : yield line . strip ( ) ": 712,
 "def get_size ( objects ) : res = 0 for o in objects : try : res + = _getsizeof ( o ) except AttributeError : print ( \" IGNORING : type = %s; o = %s \" % ( str ( type ( o ) ) , str ( o ) ) ) return res": 713,
 "def distinct ( xs ) : # don ' t use collections . OrderedDict because we do support Python 2 . 6 seen = set ( ) return [x for x in xs if x not in seen and not seen . add ( x ) ]": 714,
 "def stderr ( a ) : return np . nanstd ( a ) / np . sqrt ( sum ( np . isfinite ( a ) ) ) ": 715,
 "def get_table_names ( connection ) : \t\tcursor = connection . cursor ( ) \tcursor . execute ( \" SELECT name FROM sqlite_master WHERE type = = ' table ' \" ) \treturn [name for ( name , ) in cursor]": 716,
 "def time ( func , *args , **kwargs ) : start_time = time_module . time ( ) func ( *args , **kwargs ) end_time = time_module . time ( ) return end_time - start_time": 717,
 "def camel_case_from_underscores ( string ) : components = string . split ( ' _ ' ) string = ' ' for component in components : string + = component[0] . upper ( ) + component[1 : ] return string": 718,
 "def list_get ( l , idx , default = None ) : try : if l[idx] : return l[idx] else : return default except IndexError : return default": 719,
 "def classnameify ( s ) : return ' ' . join ( w if w in ACRONYMS else w . title ( ) for w in s . split ( ' _ ' ) ) ": 720,
 "def dedupe_list ( l ) : result = [] for el in l : if el not in result : result . append ( el ) return result": 721,
 "def force_to_string ( unknown ) : result = ' ' if type ( unknown ) is str : result = unknown if type ( unknown ) is int : result = str ( unknown ) if type ( unknown ) is float : result = str ( unknown ) if type ( unknown ) is dict : result = Dict2String ( unknown ) if type ( unknown ) is list : result = List2String ( unknown ) return result": 722,
 "def nan_pixels ( self ) : nan_px = np . where ( np . isnan ( np . sum ( self . raw_data , axis = 2 ) ) ) nan_px = np . c_[nan_px[0] , nan_px[1]] return nan_px": 723,
 "def clean_error ( err ) : if err : decoded = err . decode ( ' utf-8 ' ) try : return decoded . split ( ' \\r\\n ' ) [-2] except Exception : return decoded return ' There was an error . ' ": 724,
 "def downcaseTokens ( s , l , t ) : return [ tt . lower ( ) for tt in map ( _ustr , t ) ]": 725,
 "def arr_to_vector ( arr ) : dim = array_dim ( arr ) tmp_arr = [] for n in range ( len ( dim ) - 1 ) : for inner in arr : for i in inner : tmp_arr . append ( i ) arr = tmp_arr tmp_arr = [] return arr": 726,
 "def get_all_attributes ( klass_or_instance ) : pairs = list ( ) for attr , value in inspect . getmembers ( klass_or_instance , lambda x : not inspect . isroutine ( x ) ) : if not ( attr . startswith ( \" __ \" ) or attr . endswith ( \" __ \" ) ) : pairs . append ( ( attr , value ) ) return pairs": 727,
 "def session_to_epoch ( timestamp ) : utc_timetuple = datetime . strptime ( timestamp , SYNERGY_SESSION_PATTERN ) . replace ( tzinfo = None ) . utctimetuple ( ) return calendar . timegm ( utc_timetuple ) ": 728,
 "def zero_pixels ( self ) : zero_px = np . where ( np . sum ( self . raw_data , axis = 2 ) = = 0 ) zero_px = np . c_[zero_px[0] , zero_px[1]] return zero_px": 729,
 "def end_table_header ( self ) : r if self . header : msg = \" Table already has a header \" raise TableError ( msg ) self . header = True self . append ( Command ( r ' endhead ' ) ) ": 730,
 "def raise_os_error ( _errno , path = None ) : msg = \" %s : ' %s ' \" % ( strerror ( _errno ) , path ) if path else strerror ( _errno ) raise OSError ( _errno , msg ) ": 731,
 "def get_mnist ( data_type = \" train \" , location = \" /tmp/mnist \" ) : X , Y = mnist . read_data_sets ( location , data_type ) return X , Y + 1": 732,
 "def _multiline_width ( multiline_s , line_width_fn = len ) : return max ( map ( line_width_fn , re . split ( \" [\\r\\n] \" , multiline_s ) ) ) ": 733,
 "def col_rename ( df , col_name , new_col_name ) : col_list = list ( df . columns ) for index , value in enumerate ( col_list ) : if value = = col_name : col_list[index] = new_col_name break df . columns = col_list": 734,
 "def _include_yaml ( loader , node ) : return load_yaml ( os . path . join ( os . path . dirname ( loader . name ) , node . value ) ) ": 735,
 "def comma_converter ( float_string ) : trans_table = maketrans ( b ' , ' , b ' . ' ) return float ( float_string . translate ( trans_table ) ) ": 736,
 "def datetime_local_to_utc ( local ) : timestamp = time . mktime ( local . timetuple ( ) ) return datetime . datetime . utcfromtimestamp ( timestamp ) ": 737,
 "def to_identifier ( s ) : if s . startswith ( ' GPS ' ) : s = ' Gps ' + s[3 : ] return ' ' . join ( [i . capitalize ( ) for i in s . split ( ' _ ' ) ] ) if ' _ ' in s else s": 738,
 "def lock ( self , block = True ) : \t\t\t\tself . _locked = True\t\treturn self . _lock . acquire ( block ) ": 739,
 "def _validate_pos ( df ) : assert isinstance ( df , pd . DataFrame ) assert [ \" seqname \" , \" position \" , \" strand \" ] = = df . columns . tolist ( ) assert df . position . dtype = = np . dtype ( \" int64 \" ) assert df . strand . dtype = = np . dtype ( \" O \" ) assert df . seqname . dtype = = np . dtype ( \" O \" ) return df": 740,
 "def lognorm ( x , mu , sigma = 1 . 0 ) : return stats . lognorm ( sigma , scale = mu ) . pdf ( x ) ": 741,
 "def autoconvert ( string ) : for fn in ( boolify , int , float ) : try : return fn ( string ) except ValueError : pass return string": 742,
 "def to_distribution_values ( self , values ) : with warnings . catch_warnings ( ) : warnings . simplefilter ( \" ignore \" ) # avoid RuntimeWarning : divide by zero encountered in log return numpy . log ( values ) ": 743,
 "def find_console_handler ( logger ) : for handler in logger . handlers : if ( isinstance ( handler , logging . StreamHandler ) and handler . stream = = sys . stderr ) : return handler": 744,
 "def unicode_is_ascii ( u_string ) : assert isinstance ( u_string , str ) try : u_string . encode ( ' ascii ' ) return True except UnicodeEncodeError : return False": 745,
 "def clog ( color ) : logger = log ( color ) return lambda msg : logger ( centralize ( msg ) . rstrip ( ) ) ": 746,
 "def is_defined ( self , obj , force_import = False ) : from spyder_kernels . utils . dochelpers import isdefined ns = self . _get_current_namespace ( with_magics = True ) return isdefined ( obj , force_import = force_import , namespace = ns ) ": 747,
 "def format ( self , record , *args , **kwargs ) : return logging . Formatter . format ( self , record , *args , **kwargs ) . replace ( ' \\n ' , ' \\n ' + ' ' * 8 ) ": 748,
 "def is_delimiter ( line ) : return bool ( line ) and line[0] in punctuation and line[0]*len ( line ) = = line": 749,
 "def load_config ( filename = \" logging . ini \" , *args , **kwargs ) : logging . config . fileConfig ( filename , *args , **kwargs ) ": 750,
 "def is_parameter ( self ) : return ( isinstance ( self . scope , CodeFunction ) and self in self . scope . parameters ) ": 751,
 "def print_log ( value_color = \" \" , value_noncolor = \" \" ) : HEADER = ' \\033[92m ' ENDC = ' \\033[0m ' print ( HEADER + value_color + ENDC + str ( value_noncolor ) ) ": 752,
 "def is_seq ( obj ) : if not hasattr ( obj , ' __iter__ ' ) : return False if isinstance ( obj , basestring ) : return False return True": 753,
 "def logger ( message , level = 10 ) : logging . getLogger ( __name__ ) . log ( level , str ( message ) ) ": 754,
 "def is_listish ( obj ) : if isinstance ( obj , ( list , tuple , set ) ) : return True return is_sequence ( obj ) ": 755,
 "def isin ( value , values ) : for i , v in enumerate ( value ) : if v not in np . array ( values ) [ : , i] : return False return True": 756,
 "def is_non_empty_string ( input_string ) : try : if not input_string . strip ( ) : raise ValueError ( ) except AttributeError as error : raise TypeError ( error ) return True": 757,
 "def get_naive ( dt ) : if not dt . tzinfo : return dt if hasattr ( dt , \" asdatetime \" ) : return dt . asdatetime ( ) return dt . replace ( tzinfo = None ) ": 758,
 "def _match_literal ( self , a , b = None ) : return a . lower ( ) = = b if not self . case_sensitive else a = = b": 759,
 "def make_symmetric ( dict ) : for key , value in list ( dict . items ( ) ) : dict[value] = key return dict": 760,
 "def isnumber ( *args ) : return all ( map ( lambda c : isinstance ( c , int ) or isinstance ( c , float ) , args ) ) ": 761,
 "def relpath ( path ) : return os . path . normpath ( os . path . join ( os . path . abspath ( os . path . dirname ( __file__ ) ) , path ) ) ": 762,
 "def cudaDriverGetVersion ( ) : version = ctypes . c_int ( ) status = _libcudart . cudaDriverGetVersion ( ctypes . byref ( version ) ) cudaCheckStatus ( status ) return version . value": 763,
 "def israw ( self , **kwargs ) : if self . raw is None : info = self . _container_info ( ) self . raw = self . stdout . isatty ( ) and info[ ' Config ' ][ ' Tty ' ] return self . raw": 764,
 "def html ( header_rows ) : name = ' table%d ' % next ( tablecounter ) return HtmlTable ( [map ( str , row ) for row in header_rows] , name ) . render ( ) ": 765,
 "def isSquare ( matrix ) : try : try : dim1 , dim2 = matrix . shape except AttributeError : dim1 , dim2 = _np . array ( matrix ) . shape except ValueError : return False if dim1 = = dim2 : return True return False": 766,
 "def ver_to_tuple ( value ) : return tuple ( int ( _f ) for _f in re . split ( r ' \\D+ ' , value ) if _f ) ": 767,
 "def is_type ( value ) : if isinstance ( value , type ) : return issubclass ( value , Type ) return isinstance ( value , Type ) ": 768,
 "def _strvar ( a , prec = ' { : G} ' ) : r return ' ' . join ( [prec . format ( i ) for i in np . atleast_1d ( a ) ] ) ": 769,
 "def check_filename ( filename ) : if not isinstance ( filename , str ) : raise TypeError ( \" filename must be a string \" ) if regex . path . linux . filename . search ( filename ) : return True return False": 770,
 "def GeneratePassphrase ( length = 20 ) : valid_chars = \" abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ \" valid_chars + = \" 0123456789 , -_&$ # \" return \" \" . join ( random . choice ( valid_chars ) for i in range ( length ) ) ": 771,
 "def is_float ( value ) : return isinstance ( value , float ) or isinstance ( value , int ) or isinstance ( value , np . float64 ) , float ( value ) ": 772,
 "def _sub_patterns ( patterns , text ) : for pattern , repl in patterns : text = re . sub ( pattern , repl , text ) return text": 773,
 "def on_source_directory_chooser_clicked ( self ) : title = self . tr ( ' Set the source directory for script and scenario ' ) self . choose_directory ( self . source_directory , title ) ": 774,
 "def from_json_list ( cls , api_client , data ) : return [cls . from_json ( api_client , item ) for item in data]": 775,
 "def clean_all ( self , args ) : self . clean_dists ( args ) self . clean_builds ( args ) self . clean_download_cache ( args ) ": 776,
 "def _merge_maps ( m1 , m2 ) : return type ( m1 ) ( chain ( m1 . items ( ) , m2 . items ( ) ) ) ": 777,
 "def strip ( notebook ) : for cell in notebook . cells : if cell . cell_type = = ' code ' : cell . outputs = [] cell . execution_count = None": 778,
 "def find_whole_word ( w ) : return re . compile ( r ' \\b ( {0} ) \\b ' . format ( w ) , flags = re . IGNORECASE ) . search": 779,
 "def __delitem__ ( self , resource ) : self . __caches[type ( resource ) ] . pop ( resource . get_cache_internal_key ( ) , None ) ": 780,
 "def autozoom ( self , n = None ) : if n = = None : for p in self . plot_widgets : p . autoRange ( ) else : self . plot_widgets[n] . autoRange ( ) return self": 781,
 "def color_to_hex ( color ) : if color is None or colorConverter . to_rgba ( color ) [3] = = 0 : return ' none ' else : rgb = colorConverter . to_rgb ( color ) return ' # {0 : 02X}{1 : 02X}{2 : 02X} ' . format ( * ( int ( 255 * c ) for c in rgb ) ) ": 782,
 "def erase_lines ( n = 1 ) : for _ in range ( n ) : print ( codes . cursor[ \" up \" ] , end = \" \" ) print ( codes . cursor[ \" eol \" ] , end = \" \" ) ": 783,
 "def horizontal_line ( ax , scale , i , **kwargs ) : p1 = ( 0 , i , scale - i ) p2 = ( scale - i , i , 0 ) line ( ax , p1 , p2 , **kwargs ) ": 784,
 "def terminate ( self ) : for t in self . _threads : t . quit ( ) self . _thread = [] self . _workers = []": 785,
 "def raise_figure_window ( f = 0 ) : if _fun . is_a_number ( f ) : f = _pylab . figure ( f ) f . canvas . manager . window . raise_ ( ) ": 786,
 "def linregress ( x , y , return_stats = False ) : a1 , a0 , r_value , p_value , stderr = scipy . stats . linregress ( x , y ) retval = a1 , a0 if return_stats : retval + = r_value , p_value , stderr return retval": 787,
 "def clear_matplotlib_ticks ( self , axis = \" both \" ) : ax = self . get_axes ( ) plotting . clear_matplotlib_ticks ( ax = ax , axis = axis ) ": 788,
 "def get_latex_table ( self , parameters = None , transpose = False , caption = None , label = \" tab : model_params \" , hlines = True , blank_fill = \" -- \" ) : # pragma : no cover if parameters is None : parameters = self . parent . _all_parameters for p in parameters : assert isinstance ( p , str ) , \\ \" Generating a LaTeX table requires all parameters have labels \" num_parameters = len ( parameters ) num_chains = len ( self . parent . chains ) fit_values = self . get_summary ( squeeze = False ) if label is None : label = \" \" if caption is None : caption = \" \" end_text = \" \\\\\\\\ \\n \" if transpose : column_text = \" c \" * ( num_chains + 1 ) else : column_text = \" c \" * ( num_parameters + 1 ) center_text = \" \" hline_text = \" \\\\hline\\n \" if hlines : center_text + = hline_text + \" \\t\\t \" if transpose : center_text + = \" & \" . join ( [ \" Parameter \" ] + [c . name for c in self . parent . chains] ) + end_text if hlines : center_text + = \" \\t\\t \" + hline_text for p in parameters : arr = [ \" \\t\\t \" + p] for chain_res in fit_values : if p in chain_res : arr . append ( self . get_parameter_text ( *chain_res[p] , wrap = True ) ) else : arr . append ( blank_fill ) center_text + = \" & \" . join ( arr ) + end_text else : center_text + = \" & \" . join ( [ \" Model \" ] + parameters ) + end_text if hlines : center_text + = \" \\t\\t \" + hline_text for name , chain_res in zip ( [c . name for c in self . parent . chains] , fit_values ) : arr = [ \" \\t\\t \" + name] for p in parameters : if p in chain_res : arr . append ( self . get_parameter_text ( *chain_res[p] , wrap = True ) ) else : arr . append ( blank_fill ) center_text + = \" & \" . join ( arr ) + end_text if hlines : center_text + = \" \\t\\t \" + hline_text final_text = get_latex_table_frame ( caption , label ) % ( column_text , center_text ) return final_text": 789,
 "def set_ylimits ( self , row , column , min = None , max = None ) : subplot = self . get_subplot_at ( row , column ) subplot . set_ylimits ( min , max ) ": 790,
 "def _norm ( self , x ) : return tf . sqrt ( tf . reduce_sum ( tf . square ( x ) , keepdims = True , axis = -1 ) + 1e-7 ) ": 791,
 "def show ( self , imgs , ax = None ) : ax = ax or plt . gca ( ) if type ( imgs ) is not list : imgs = [imgs] for i , img in enumerate ( imgs ) : ax . imshow ( img , cmap = plt . get_cmap ( \" plasma \" ) ) ax . axis ( \" off \" ) ": 792,
 "def cross_join ( df1 , df2 ) : if len ( df1 ) = = 0 : return df2 if len ( df2 ) = = 0 : return df1 # Add as lists so that the new index keeps the items in # the order that they are added together all_columns = pd . Index ( list ( df1 . columns ) + list ( df2 . columns ) ) df1[ ' key ' ] = 1 df2[ ' key ' ] = 1 return pd . merge ( df1 , df2 , on = ' key ' ) . loc[ : , all_columns]": 793,
 "def downsample ( array , k ) : length = array . shape[0] indices = random . sample ( xrange ( length ) , k ) return array[indices]": 794,
 "def cmp_contents ( filename1 , filename2 ) : with open_readable ( filename1 , ' rb ' ) as fobj : contents1 = fobj . read ( ) with open_readable ( filename2 , ' rb ' ) as fobj : contents2 = fobj . read ( ) return contents1 = = contents2": 795,
 "def _digits ( minval , maxval ) : if minval = = maxval : return 3 else : return min ( 10 , max ( 2 , int ( 1 + abs ( np . log10 ( maxval - minval ) ) ) ) ) ": 796,
 "def compare ( a , b ) : s = 0 for i in range ( len ( a ) ) : s = s+abs ( a[i]-b[i] ) return s": 797,
 "def compare ( left , right ) : with open_zip ( left ) as l : with open_zip ( right ) as r : return compare_zips ( l , r ) ": 798,
 "def coverage ( ) : # Note : coverage options are controlled by . coveragerc file install ( ) test_setup ( ) sh ( \" %s -m coverage run %s \" % ( PYTHON , TEST_SCRIPT ) ) sh ( \" %s -m coverage report \" % PYTHON ) sh ( \" %s -m coverage html \" % PYTHON ) sh ( \" %s -m webbrowser -t htmlcov/index . html \" % PYTHON ) ": 799,
 "def m ( name = ' ' , **kwargs ) : with Reflect . context ( **kwargs ) as r : kwargs[ \" name \" ] = name instance = M_CLASS ( r , stream , **kwargs ) instance ( ) ": 800,
 "def cpp_prog_builder ( build_context , target ) : yprint ( build_context . conf , ' Build CppProg ' , target ) workspace_dir = build_context . get_workspace ( ' CppProg ' , target . name ) build_cpp ( build_context , target , target . compiler_config , workspace_dir ) ": 801,
 "def dictmerge ( x , y ) : z = x . copy ( ) z . update ( y ) return z": 802,
 "def merge ( self , other ) : Stats . merge ( self , other ) self . changes + = other . changes": 803,
 "def _message_to_string ( message , data = None ) : if data is None : data = _json_from_message ( message ) return \" Message {} from {} to {} : {} \" . format ( message . namespace , message . source_id , message . destination_id , data ) ": 804,
 "def fn_min ( self , a , axis = None ) : return numpy . nanmin ( self . _to_ndarray ( a ) , axis = axis ) ": 805,
 "def min_values ( args ) : return Interval ( min ( x . low for x in args ) , min ( x . high for x in args ) ) ": 806,
 "def makedirs ( path , mode = 0o777 , exist_ok = False ) : os . makedirs ( path , mode , exist_ok ) ": 807,
 "def _from_dict ( cls , _dict ) : args = {} if ' collections ' in _dict : args[ ' collections ' ] = [ Collection . _from_dict ( x ) for x in ( _dict . get ( ' collections ' ) ) ] return cls ( **args ) ": 808,
 "def most_common ( items ) : counts = {} for i in items : counts . setdefault ( i , 0 ) counts[i] + = 1 return max ( six . iteritems ( counts ) , key = operator . itemgetter ( 1 ) ) ": 809,
 "def find_one ( cls , *args , **kwargs ) : database , collection = cls . _collection_key . split ( ' . ' ) return current ( ) [database][collection] . find_one ( *args , **kwargs ) ": 810,
 "def indentsize ( line ) : expline = string . expandtabs ( line ) return len ( expline ) - len ( string . lstrip ( expline ) ) ": 811,
 "def mostCommonItem ( lst ) : # This elegant solution from : http : //stackoverflow . com/a/1518632/1760218 lst = [l for l in lst if l] if lst : return max ( set ( lst ) , key = lst . count ) else : return None": 812,
 "def make_env_key ( app_name , key ) : key = key . replace ( ' - ' , ' _ ' ) . replace ( ' ' , ' _ ' ) return str ( \" _ \" . join ( ( x . upper ( ) for x in ( app_name , key ) ) ) ) ": 813,
 "def _go_to_line ( editor , line ) : b = editor . application . current_buffer b . cursor_position = b . document . translate_row_col_to_index ( max ( 0 , int ( line ) - 1 ) , 0 ) ": 814,
 "def touch ( ) : from . models import Bucket bucket = Bucket . create ( ) db . session . commit ( ) click . secho ( str ( bucket ) , fg = ' green ' ) ": 815,
 "def align_file_position ( f , size ) : align = ( size - 1 ) - ( f . tell ( ) % size ) f . seek ( align , 1 ) ": 816,
 "def format_header_cell ( val ) : return re . sub ( ' _ ' , ' ' , re . sub ( r ' ( _Px_ ) ' , ' ( ' , re . sub ( r ' ( _xP_ ) ' , ' ) ' , str ( val ) ) ) ) ": 817,
 "def go_to_line ( self , line ) : cursor = self . textCursor ( ) cursor . setPosition ( self . document ( ) . findBlockByNumber ( line - 1 ) . position ( ) ) self . setTextCursor ( cursor ) return True": 818,
 "def copy ( self ) : return self . __class__ ( self . _key , self . _load , self . _iteritems ( ) ) ": 819,
 "def singleton ( class_ ) : instances = {} def get_instance ( *args , **kwargs ) : if class_ not in instances : instances[class_] = class_ ( *args , **kwargs ) return instances[class_] return get_instance": 820,
 "def list_string_to_dict ( string ) : dictionary = {} for idx , c in enumerate ( string ) : dictionary . update ( {c : idx} ) return dictionary": 821,
 "def _match_space_at_line ( line ) : regex = re . compile ( r \" ^{0}$ \" . format ( _MDL_COMMENT ) ) return regex . match ( line ) ": 822,
 "def _comment ( string ) : lines = [line . strip ( ) for line in string . splitlines ( ) ] return \" # \" + ( \" %s # \" % linesep ) . join ( lines ) ": 823,
 "def count_generator ( generator , memory_efficient = True ) : if memory_efficient : counter = 0 for _ in generator : counter + = 1 return counter else : return len ( list ( generator ) ) ": 824,
 "def export_context ( cls , context ) : \t\t\t\tif context is None : \t\t\treturn\t\tresult = [ ( x . context_name ( ) , x . context_value ( ) ) for x in context]\t\tresult . reverse ( ) \t\treturn tuple ( result ) ": 825,
 "def generate_matrices ( dim = 40 ) : positive = numpy . random . uniform ( -1 , 1 , ( dim , dim ) ) negative = positive + numpy . random . normal ( 0 , 1 , ( dim , dim ) ) return positive , negative": 826,
 "def qr ( self , text ) : qr_code = qrcode . QRCode ( version = 4 , box_size = 4 , border = 1 ) qr_code . add_data ( text ) qr_code . make ( fit = True ) qr_img = qr_code . make_image ( ) im = qr_img . _img . convert ( \" RGB \" ) # Convert the RGB image in printable image self . _convert_image ( im ) ": 827,
 "def compute ( args ) : x , y , params = args return x , y , mandelbrot ( x , y , params ) ": 828,
 "def clear_global ( self ) : vname = self . varname logger . debug ( f ' global clearning {vname} ' ) if vname in globals ( ) : logger . debug ( ' removing global instance var : {} ' . format ( vname ) ) del globals ( ) [vname]": 829,
 "def get ( self ) : if self . closed : raise PoolClosed ( ) while self . _getcount not in self . _cache : counter , result = self . outq . get ( ) self . _cache[counter] = result result , succeeded = self . _cache . pop ( self . _getcount ) self . _getcount + = 1 if not succeeded : klass , exc , tb = result raise klass , exc , tb return result": 830,
 "def _release ( self ) : del self . funcs del self . variables del self . variable_values del self . satisfied": 831,
 "def compute_capture ( args ) : x , y , w , h , params = args return x , y , mandelbrot_capture ( x , y , w , h , params ) ": 832,
 "def __delitem__ ( self , key ) : del self . _variables[key] self . _coord_names . discard ( key ) ": 833,
 "def remove_columns ( self , data , columns ) : for column in columns : if column in data . columns : data = data . drop ( column , axis = 1 ) return data": 834,
 "def _synced ( method , self , args , kwargs ) : with self . _lock : return method ( *args , **kwargs ) ": 835,
 "def _delete_local ( self , filename ) : if os . path . exists ( filename ) : os . remove ( filename ) ": 836,
 "def remove_elements ( target , indices ) : copied = list ( target ) for index in reversed ( indices ) : del copied[index] return copied": 837,
 "def get_window ( self ) : x = self while not x . _parent = = None and \\ not isinstance ( x . _parent , Window ) : x = x . _parent return x . _parent": 838,
 "def remove_bad ( string ) : remove = [ ' : ' , ' , ' , ' ( ' , ' ) ' , ' ' , ' | ' , ' ; ' , ' \\ ' ' ] for c in remove : string = string . replace ( c , ' _ ' ) return string": 839,
 "def restore_scrollbar_position ( self ) : scrollbar_pos = self . get_option ( ' scrollbar_position ' , None ) if scrollbar_pos is not None : self . explorer . treewidget . set_scrollbar_position ( scrollbar_pos ) ": 840,
 "def rm_empty_indices ( *args ) : rm_inds = args[0] if not rm_inds : return args[1 : ] keep_inds = [i for i in range ( len ( args[1] ) ) if i not in rm_inds] return [[a[i] for i in keep_inds] for a in args[1 : ]]": 841,
 "def deprecate ( func ) : @wraps ( func ) def wrapper ( *args , **kwargs ) : warn ( \" Deprecated , this will be removed in the future \" , DeprecationWarning ) return func ( *args , **kwargs ) wrapper . __doc__ = \" Deprecated . \\n \" + ( wrapper . __doc__ or \" \" ) return wrapper": 842,
 "def remove_node ( self , node ) : if _debug : Network . _debug ( \" remove_node %r \" , node ) self . nodes . remove ( node ) node . lan = None": 843,
 "def wordify ( text ) : stopset = set ( nltk . corpus . stopwords . words ( ' english ' ) ) tokens = nltk . WordPunctTokenizer ( ) . tokenize ( text ) return [w for w in tokens if w not in stopset]": 844,
 "def is_admin ( self ) : return self . role = = self . roles . administrator . value and self . state = = State . approved": 845,
 "def start_connect ( self ) : Log . debug ( \" In start_connect ( ) of %s \" % self . _get_classname ( ) ) # TODO : specify buffer size , exception handling self . create_socket ( socket . AF_INET , socket . SOCK_STREAM ) # when ready , handle_connect is called self . _connecting = True self . connect ( self . endpoint ) ": 846,
 "def contains_empty ( features ) : if not features : return True for feature in features : if feature . shape[0] = = 0 : return True return False": 847,
 "def _api_type ( self , value ) : if isinstance ( value , six . string_types ) : return ' string ' elif isinstance ( value , six . integer_types ) : return ' integer ' elif type ( value ) is datetime . datetime : return ' date ' ": 848,
 "def denorm ( self , arr ) : if type ( arr ) is not np . ndarray : arr = to_np ( arr ) if len ( arr . shape ) = = 3 : arr = arr[None] return self . transform . denorm ( np . rollaxis ( arr , 1 , 4 ) ) ": 849,
 "def is_seq ( obj ) : return ( not is_str ( obj ) and not is_dict ( obj ) and ( hasattr ( obj , \" __getitem__ \" ) or hasattr ( obj , \" __iter__ \" ) ) ) ": 850,
 "def isTestCaseDisabled ( test_case_class , method_name ) : test_method = getattr ( test_case_class , method_name ) return getattr ( test_method , \" __test__ \" , ' not nose ' ) is False": 851,
 "def _histplot_bins ( column , bins = 100 ) : col_min = np . min ( column ) col_max = np . max ( column ) return range ( col_min , col_max + 2 , max ( ( col_max - col_min ) // bins , 1 ) ) ": 852,
 "def path_for_import ( name ) : return os . path . dirname ( os . path . abspath ( import_module ( name ) . __file__ ) ) ": 853,
 "def as_float_array ( a ) : return np . asarray ( a , dtype = np . quaternion ) . view ( ( np . double , 4 ) ) ": 854,
 "def tokenize ( string ) : for match in TOKENS_REGEX . finditer ( string ) : yield Token ( match . lastgroup , match . group ( ) . strip ( ) , match . span ( ) ) ": 855,
 "def A ( *a ) : return np . array ( a[0] ) if len ( a ) = = 1 else [np . array ( o ) for o in a]": 856,
 "def chunked ( l , n ) : return [l[i : i + n] for i in range ( 0 , len ( l ) , n ) ]": 857,
 "def contains_all ( self , array ) : dtype = getattr ( array , ' dtype ' , None ) if dtype is None : dtype = np . result_type ( *array ) return is_real_dtype ( dtype ) ": 858,
 "def quit ( self ) : self . script . LOG . warn ( \" Abort due to user choice! \" ) sys . exit ( self . QUIT_RC ) ": 859,
 "def print_images ( self , *printable_images ) : printable_image = reduce ( lambda x , y : x . append ( y ) , list ( printable_images ) ) self . print_image ( printable_image ) ": 860,
 "def ma ( self ) : a = self . array return numpy . ma . MaskedArray ( a , mask = numpy . logical_not ( numpy . isfinite ( a ) ) ) ": 861,
 "def _divide ( self , x1 , x2 , out ) : self . tspace . _divide ( x1 . tensor , x2 . tensor , out . tensor ) ": 862,
 "def _to_json ( self ) : return dict ( ( ( k , v ) for k , v in self . __dict__ . iteritems ( ) if k ! = ' server ' ) ) ": 863,
 "def _user_yes_no_query ( self , question ) : sys . stdout . write ( ' %s [y/n]\\n ' % question ) while True : try : return strtobool ( raw_input ( ) . lower ( ) ) except ValueError : sys . stdout . write ( ' Please respond with \\ ' y\\ ' or \\ ' n\\ ' . \\n ' ) ": 864,
 "def json_datetime_serial ( obj ) : if isinstance ( obj , ( datetime , date ) ) : serial = obj . isoformat ( ) return serial if ObjectId is not None and isinstance ( obj , ObjectId ) : # TODO : try to use bson . json_util instead return str ( obj ) raise TypeError ( \" Type not serializable \" ) ": 865,
 "def to_one_hot ( dataY ) : nc = 1 + np . max ( dataY ) onehot = [np . zeros ( nc , dtype = np . int8 ) for _ in dataY] for i , j in enumerate ( dataY ) : onehot[i][j] = 1 return onehot": 866,
 "def matrix_at_check ( self , original , loc , tokens ) : return self . check_py ( \" 35 \" , \" matrix multiplication \" , original , loc , tokens ) ": 867,
 "def glob_by_extensions ( directory , extensions ) : directorycheck ( directory ) files = [] xt = files . extend for ex in extensions : xt ( glob . glob ( ' {0}/* . {1} ' . format ( directory , ex ) ) ) return files": 868,
 "def is_equal_strings_ignore_case ( first , second ) : if first and second : return first . upper ( ) = = second . upper ( ) else : return not ( first or second ) ": 869,
 "def _fix_up ( self , cls , code_name ) : self . _code_name = code_name if self . _name is None : self . _name = code_name": 870,
 "def dot_v3 ( v , w ) : return sum ( [x * y for x , y in zip ( v , w ) ] ) ": 871,
 "def read_img ( path ) : img = cv2 . resize ( cv2 . imread ( path , 0 ) , ( 80 , 30 ) ) . astype ( np . float32 ) / 255 img = np . expand_dims ( img . transpose ( 1 , 0 ) , 0 ) return img": 872,
 "def file_to_str ( fname ) : data = None # rU = read with Universal line terminator with open ( fname , ' rU ' ) as fd : data = fd . read ( ) return data": 873,
 "def _download_py3 ( link , path , __hdr__ ) : try : req = urllib . request . Request ( link , headers = __hdr__ ) u = urllib . request . urlopen ( req ) except Exception as e : raise Exception ( ' Download failed with the error : \\n{} ' . format ( e ) ) with open ( path , ' wb ' ) as outf : for l in u : outf . write ( l ) u . close ( ) ": 874,
 "def to_dotfile ( self ) : domain = self . get_domain ( ) filename = \" %s . dot \" % ( self . __class__ . __name__ ) nx . write_dot ( domain , filename ) return filename": 875,
 "def _openpyxl_read_xl ( xl_path : str ) : try : wb = load_workbook ( filename = xl_path , read_only = True ) except : raise else : return wb": 876,
 "def _drop_str_columns ( df ) : str_columns = filter ( lambda pair : pair[1] . char = = ' S ' , df . _gather_dtypes ( ) . items ( ) ) str_column_names = list ( map ( lambda pair : pair[0] , str_columns ) ) return df . drop ( str_column_names ) ": 877,
 "def upcaseTokens ( s , l , t ) : return [ tt . upper ( ) for tt in map ( _ustr , t ) ]": 878,
 "def C_dict2array ( C ) : return np . hstack ( [np . asarray ( C[k] ) . ravel ( ) for k in C_keys] ) ": 879,
 "def normalize_path ( path ) : return os . path . normcase ( os . path . realpath ( os . path . expanduser ( path ) ) ) ": 880,
 "def haversine ( x ) : y = . 5*x y = np . sin ( y ) return y*y": 881,
 "def __get_float ( section , name ) : try : return float ( section[name] ) except ( ValueError , TypeError , KeyError ) : return float ( 0 ) ": 882,
 "def write_color ( string , name , style = ' normal ' , when = ' auto ' ) : write ( color ( string , name , style , when ) ) ": 883,
 "def close ( self ) : os . close ( self . in_d ) os . close ( self . out_d ) ": 884,
 "def extract_keywords_from_text ( self , text ) : sentences = nltk . tokenize . sent_tokenize ( text ) self . extract_keywords_from_sentences ( sentences ) ": 885,
 "def deserialize_date ( string ) : try : from dateutil . parser import parse return parse ( string ) . date ( ) except ImportError : return string": 886,
 "def get_soup ( page = ' ' ) : content = requests . get ( ' %s/%s ' % ( BASE_URL , page ) ) . text return BeautifulSoup ( content ) ": 887,
 "def parse_date ( s ) : if isinstance ( s , ( datetime . datetime , datetime . date ) ) : return s try : from dateutil . parser import parse except ImportError : parse = lambda d : datetime . datetime . strptime ( d , \" %Y-%m-%d \" ) return parse ( s ) ": 888,
 "def clean_dataframe ( df ) : df = df . fillna ( method = ' ffill ' ) df = df . fillna ( 0 . 0 ) return df": 889,
 "def fsliceafter ( astr , sub ) : findex = astr . find ( sub ) return astr[findex + len ( sub ) : ]": 890,
 "def map_wrap ( f ) : @functools . wraps ( f ) def wrapper ( *args , **kwargs ) : return f ( *args , **kwargs ) return wrapper": 891,
 "def list_formatter ( handler , item , value ) : return u ' , ' . join ( str ( v ) for v in value ) ": 892,
 "def debug ( self , text ) : \t\t\t\tself . logger . debug ( \" {}{} \" . format ( self . message_prefix , text ) ) ": 893,
 "def safe_int_conv ( number ) : try : return int ( np . array ( number ) . astype ( int , casting = ' safe ' ) ) except TypeError : raise ValueError ( ' cannot safely convert {} to integer ' . format ( number ) ) ": 894,
 "def quote ( self , s ) : if six . PY2 : from pipes import quote else : from shlex import quote return quote ( s ) ": 895,
 "def translate_fourier ( image , dx ) : N = image . shape[0] f = 2*np . pi*np . fft . fftfreq ( N ) kx , ky , kz = np . meshgrid ( * ( f , ) *3 , indexing = ' ij ' ) kv = np . array ( [kx , ky , kz] ) . T q = np . fft . fftn ( image ) *np . exp ( -1 . j* ( kv*dx ) . sum ( axis = -1 ) ) . T return np . real ( np . fft . ifftn ( q ) ) ": 896,
 "def perform_pca ( A ) : # First subtract the mean M = ( A-numpy . mean ( A . T , axis = 1 ) ) . T # Get eigenvectors and values of covariance matrix return numpy . linalg . eig ( numpy . cov ( M ) ) ": 897,
 "def main_func ( args = None ) : # we have to initialize a gui even if we dont need one right now . # as soon as you call maya . standalone . initialize ( ) , a QApplication # with type Tty is created . This is the type for conosle apps . # Because i have not found a way to replace that , we just init the gui . guimain . init_gui ( ) main . init ( ) launcher = Launcher ( ) parsed , unknown = launcher . parse_args ( args ) parsed . func ( parsed , unknown ) ": 898,
 "def debug_on_error ( type , value , tb ) : traceback . print_exc ( type , value , tb ) print ( ) pdb . pm ( ) ": 899,
 "def set_trace ( ) : # https : //github . com/nose-devs/nose/blob/master/nose/tools/nontrivial . py pdb . Pdb ( stdout = sys . __stdout__ ) . set_trace ( sys . _getframe ( ) . f_back ) ": 900,
 "def _remove_duplicates ( objects ) : seen , uniq = set ( ) , [] for obj in objects : obj_id = id ( obj ) if obj_id in seen : continue seen . add ( obj_id ) uniq . append ( obj ) return uniq": 901,
 "def to_camel_case ( snake_case_string ) : parts = snake_case_string . lstrip ( ' _ ' ) . split ( ' _ ' ) return parts[0] + ' ' . join ( [i . title ( ) for i in parts[1 : ]] ) ": 902,
 "def dimensions ( self ) : size = self . pdf . getPage ( 0 ) . mediaBox return { ' w ' : float ( size[2] ) , ' h ' : float ( size[3] ) }": 903,
 "def do_history ( self , line ) : self . _split_args ( line , 0 , 0 ) for idx , item in enumerate ( self . _history ) : d1_cli . impl . util . print_info ( \" {0 : 3d} {1} \" . format ( idx , item ) ) ": 904,
 "def quote ( s , unsafe = ' / ' ) : res = s . replace ( ' % ' , ' %25 ' ) for c in unsafe : res = res . replace ( c , ' % ' + ( hex ( ord ( c ) ) . upper ( ) ) [2 : ] ) return res": 905,
 "def linearRegressionAnalysis ( series ) : n = safeLen ( series ) sumI = sum ( [i for i , v in enumerate ( series ) if v is not None] ) sumV = sum ( [v for i , v in enumerate ( series ) if v is not None] ) sumII = sum ( [i * i for i , v in enumerate ( series ) if v is not None] ) sumIV = sum ( [i * v for i , v in enumerate ( series ) if v is not None] ) denominator = float ( n * sumII - sumI * sumI ) if denominator = = 0 : return None else : factor = ( n * sumIV - sumI * sumV ) / denominator / series . step offset = sumII * sumV - sumIV * sumI offset = offset / denominator - factor * series . start return factor , offset": 906,
 "def from_bytes ( cls , b ) : \t\t\t\tim = cls ( ) \t\tim . chunks = list ( parse_chunks ( b ) ) \t\tim . init ( ) \t\treturn im": 907,
 "def less_strict_bool ( x ) : if x is None : return False elif x is True or x is False : return x else : return strict_bool ( x ) ": 908,
 "def _get_token ( self , oauth_request , token_type = ' access ' ) : token_field = oauth_request . get_parameter ( ' oauth_token ' ) token = self . data_store . lookup_token ( token_type , token_field ) if not token : raise OAuthError ( ' Invalid %s token : %s ' % ( token_type , token_field ) ) return token": 909,
 "def pause ( self ) : mixer . music . pause ( ) self . pause_time = self . get_time ( ) self . paused = True": 910,
 "def draw_image ( self , ax , image ) : self . renderer . draw_image ( imdata = utils . image_to_base64 ( image ) , extent = image . get_extent ( ) , coordinates = \" data \" , style = { \" alpha \" : image . get_alpha ( ) , \" zorder \" : image . get_zorder ( ) } , mplobj = image ) ": 911,
 "def cart2pol ( x , y ) : theta = np . arctan2 ( y , x ) rho = np . hypot ( x , y ) return theta , rho": 912,
 "def get_column_keys_and_names ( table ) : ins = inspect ( table ) return ( ( k , c . name ) for k , c in ins . mapper . c . items ( ) ) ": 913,
 "def asyncStarCmap ( asyncCallable , iterable ) : results = [] yield coopStar ( asyncCallable , results . append , iterable ) returnValue ( results ) ": 914,
 "def _psutil_kill_pid ( pid ) : try : parent = Process ( pid ) for child in parent . children ( recursive = True ) : child . kill ( ) parent . kill ( ) except NoSuchProcess : return": 915,
 "def paint_cube ( self , x , y ) : # get the color color = self . next_color ( ) # calculate the position cube_pos = [x , y , x + self . cube_size , y + self . cube_size] # draw the cube draw = ImageDraw . Draw ( im = self . image ) draw . rectangle ( xy = cube_pos , fill = color ) ": 916,
 "def onchange ( self , value ) : log . debug ( ' combo box . selected %s ' % value ) self . select_by_value ( value ) return ( value , ) ": 917,
 "def p_postfix_expr ( self , p ) : if len ( p ) = = 2 : p[0] = p[1] else : p[0] = ast . UnaryOp ( op = p[2] , value = p[1] , postfix = True ) ": 918,
 "def phantomjs_retrieve ( url , data = None ) : range_limit ( ) print \" pGET \" , url process = subprocess . Popen ( [ ' phantomjs ' , PHANTOM_SCRIPT , url] , stdout = subprocess . PIPE ) out = process . communicate ( ) process . wait ( ) response = out[0] . decode ( ' utf-8 ' , ' ignore ' ) status = response[ : 2] body = response[3 : ] # After the ' ok ' part . if status = = ' ok ' : return 200 , body else : return 404 , body": 919,
 "def pprint_for_ordereddict ( ) : od_saved = OrderedDict . __repr__ try : OrderedDict . __repr__ = dict . __repr__ yield finally : OrderedDict . __repr__ = od_saved": 920,
 "def getTypeStr ( _type ) : r if isinstance ( _type , CustomType ) : return str ( _type ) if hasattr ( _type , ' __name__ ' ) : return _type . __name__ return ' ' ": 921,
 "def iget_list_column_slice ( list_ , start = None , stop = None , stride = None ) : if isinstance ( start , slice ) : slice_ = start else : slice_ = slice ( start , stop , stride ) return ( row[slice_] for row in list_ ) ": 922,
 "def pformat ( o , indent = 1 , width = 80 , depth = None ) : return PrettyPrinter ( indent = indent , width = width , depth = depth ) . pformat ( o ) ": 923,
 "def print_trace ( self ) : traceback . print_exc ( ) for tb in self . tracebacks : print tb , print ' ' ": 924,
 "def py ( self , output ) : import pprint pprint . pprint ( output , stream = self . outfile ) ": 925,
 "def pretty ( obj , verbose = False , max_width = 79 , newline = ' \\n ' ) : stream = StringIO ( ) printer = RepresentationPrinter ( stream , verbose , max_width , newline ) printer . pretty ( obj ) printer . flush ( ) return stream . getvalue ( ) ": 926,
 "def file_length ( file_obj ) : file_obj . seek ( 0 , 2 ) length = file_obj . tell ( ) file_obj . seek ( 0 ) return length": 927,
 "def prnt ( self ) : print ( \" = = = = \\n\\n%s object key : \\033[32m%s\\033[0m \" % ( self . __class__ . __name__ , self . key ) ) pprnt ( self . _data or self . clean_value ( ) ) ": 928,
 "def timestamp_to_microseconds ( timestamp ) : timestamp_str = datetime . datetime . strptime ( timestamp , ISO_DATETIME_REGEX ) epoch_time_secs = calendar . timegm ( timestamp_str . timetuple ( ) ) epoch_time_mus = epoch_time_secs * 1e6 + timestamp_str . microsecond return epoch_time_mus": 929,
 "def stdout_display ( ) : if sys . version_info[0] = = 2 : yield SmartBuffer ( sys . stdout ) else : yield SmartBuffer ( sys . stdout . buffer ) ": 930,
 "def start ( self , timeout = None ) : assert super ( PyrosBase , self ) . start ( timeout = timeout ) # Because we currently use this to setup connection return self . name": 931,
 "def filter_regex ( names , regex ) : return tuple ( name for name in names if regex . search ( name ) is not None ) ": 932,
 "def line_count ( fn ) : with open ( fn ) as f : for i , l in enumerate ( f ) : pass return i + 1": 933,
 "def load ( self ) : self . _list = self . _source . load ( ) self . _list_iter = itertools . cycle ( self . _list ) ": 934,
 "def _get_points ( self ) : return tuple ( [self . _getitem__points ( i ) for i in range ( self . _len__points ( ) ) ] ) ": 935,
 "def format_pylint_disables ( error_names , tag = True ) : tag_str = \" lint-amnesty , \" if tag else \" \" if error_names : return u \" # {tag}pylint : disable = {disabled} \" . format ( disabled = \" , \" . join ( sorted ( error_names ) ) , tag = tag_str , ) else : return \" \" ": 936,
 "def qrandom ( n ) : import quantumrandom return np . concatenate ( [ quantumrandom . get_data ( data_type = ' uint16 ' , array_length = 1024 ) for i in range ( int ( np . ceil ( n/1024 . 0 ) ) ) ] ) [ : n]": 937,
 "def clear_table ( dbconn , table_name ) : cur = dbconn . cursor ( ) cur . execute ( \" DELETE FROM ' {name} ' \" . format ( name = table_name ) ) dbconn . commit ( ) ": 938,
 "def lowstrip ( term ) : term = re . sub ( ' \\s+ ' , ' ' , term ) term = term . lower ( ) return term": 939,
 "def chmod ( self , mode ) : self . sftp . _log ( DEBUG , ' chmod ( %s , %r ) ' % ( hexlify ( self . handle ) , mode ) ) attr = SFTPAttributes ( ) attr . st_mode = mode self . sftp . _request ( CMD_FSETSTAT , self . handle , attr ) ": 940,
 "def region_from_segment ( image , segment ) : x , y , w , h = segment return image[y : y + h , x : x + w]": 941,
 "def test ( ctx , all = False , verbose = False ) : cmd = ' tox ' if all else ' py . test ' if verbose : cmd + = ' -v ' return ctx . run ( cmd , pty = True ) . return_code": 942,
 "def set_value ( self , value ) : if value : self . setCheckState ( Qt . Checked ) else : self . setCheckState ( Qt . Unchecked ) ": 943,
 "def show_xticklabels ( self , row , column ) : subplot = self . get_subplot_at ( row , column ) subplot . show_xticklabels ( ) ": 944,
 "def resizeEvent ( self , event ) : if not self . isMaximized ( ) and not self . fullscreen_flag : self . window_size = self . size ( ) QMainWindow . resizeEvent ( self , event ) # To be used by the tour to be able to resize self . sig_resized . emit ( event ) ": 945,
 "def PrintSummaryTable ( self ) : print ( \" \" \" As of {0 : s} the repository contains : | **File paths covered** | **{1 : d}** || : ------------------ | ------ : || **Registry keys covered** | **{2 : d}** || **Total artifacts** | **{3 : d}** | \" \" \" . format ( time . strftime ( ' %Y-%m-%d ' ) , self . path_count , self . reg_key_count , self . total_count ) ) ": 946,
 "def state ( self ) : ev = self . _query_waiters . request ( self . __do_query_state ) ev . wait ( 1 . 0 ) return self . _state": 947,
 "def refresh_swagger ( self ) : try : os . remove ( self . _get_swagger_filename ( self . swagger_url ) ) except EnvironmentError as e : logger . warn ( os . strerror ( e . errno ) ) else : self . __init__ ( ) ": 948,
 "def full ( self ) : if not self . size : return False return len ( self . pq ) = = ( self . size + self . removed_count ) ": 949,
 "def get_tablenames ( cur ) : cur . execute ( \" SELECT name FROM sqlite_master WHERE type = ' table ' \" ) tablename_list_ = cur . fetchall ( ) tablename_list = [str ( tablename[0] ) for tablename in tablename_list_ ] return tablename_list": 950,
 "def get_file_name ( url ) : return os . path . basename ( urllib . parse . urlparse ( url ) . path ) or ' unknown_name ' ": 951,
 "def _quit ( self , *args ) : self . logger . warn ( ' Bye! ' ) sys . exit ( self . exit ( ) ) ": 952,
 "def sorted_index ( values , x ) : i = bisect_left ( values , x ) j = bisect_right ( values , x ) return values[i : j] . index ( x ) + i": 953,
 "def prepare ( self ) : super ( RabbitMQRequestHandler , self ) . prepare ( ) if self . _rabbitmq_is_closed : self . _connect_to_rabbitmq ( ) ": 954,
 "def rnormal ( mu , tau , size = None ) : return np . random . normal ( mu , 1 . / np . sqrt ( tau ) , size ) ": 955,
 "def _num_cpus_darwin ( ) : p = subprocess . Popen ( [ ' sysctl ' , ' -n ' , ' hw . ncpu ' ] , stdout = subprocess . PIPE ) return p . stdout . read ( ) ": 956,
 "def endless_permutations ( N , random_state = None ) : generator = check_random_state ( random_state ) while True : batch_inds = generator . permutation ( N ) for b in batch_inds : yield b": 957,
 "def newest_file ( file_iterable ) : return max ( file_iterable , key = lambda fname : os . path . getmtime ( fname ) ) ": 958,
 "def timeit ( output ) : b = time . time ( ) yield print output , ' time used : % . 3fs ' % ( time . time ( ) -b ) ": 959,
 "def read_string ( buff , byteorder = ' big ' ) : length = read_numeric ( USHORT , buff , byteorder ) return buff . read ( length ) . decode ( ' utf-8 ' ) ": 960,
 "def add_to_toolbar ( self , toolbar , widget ) : actions = widget . toolbar_actions if actions is not None : add_actions ( toolbar , actions ) ": 961,
 "def load_data ( filename ) : data = pandas . read_csv ( filename , header = None , delimiter = ' \\t ' , skiprows = 9 ) return data . as_matrix ( ) ": 962,
 "def get_system_uid ( ) : try : if os . name = = ' nt ' : return get_nt_system_uid ( ) if sys . platform = = ' darwin ' : return get_osx_system_uid ( ) except Exception : return get_mac_uid ( ) else : return get_mac_uid ( ) ": 963,
 "def lines ( input ) : for raw_line in input : line = raw_line . strip ( ) if line and not line . startswith ( ' # ' ) : yield strip_comments ( line ) ": 964,
 "def get_user_name ( ) : if sys . platform = = ' win32 ' : # user = os . getenv ( ' USERPROFILE ' ) user = os . getenv ( ' USERNAME ' ) else : user = os . getenv ( ' LOGNAME ' ) return user": 965,
 "def getlines ( filename , module_globals = None ) : if filename in cache : return cache[filename][2] try : return updatecache ( filename , module_globals ) except MemoryError : clearcache ( ) return []": 966,
 "def compute_y ( self , coefficients , num_x ) : y_vals = [] for x in range ( 1 , num_x + 1 ) : y = sum ( [c * x ** i for i , c in enumerate ( coefficients[ : : -1] ) ] ) y_vals . append ( y ) return y_vals": 967,
 "def _readuntil ( f , end = _TYPE_END ) : \t\tbuf = bytearray ( ) \tbyte = f . read ( 1 ) \twhile byte ! = end : \t\tif byte = = b ' ' : \t\t\traise ValueError ( ' File ended unexpectedly . Expected end byte {} . ' . format ( end ) ) \t\tbuf + = byte\t\tbyte = f . read ( 1 ) \treturn buf": 968,
 "def _add_pos1 ( token ) : result = token . copy ( ) result[ ' pos1 ' ] = _POSMAP[token[ ' pos ' ] . split ( \" ( \" ) [0]] return result": 969,
 "def read_string_from_file ( path , encoding = \" utf8 \" ) : with codecs . open ( path , \" rb \" , encoding = encoding ) as f : value = f . read ( ) return value": 970,
 "def getfirstline ( file , default ) : with open ( file , ' rb ' ) as fh : content = fh . readlines ( ) if len ( content ) = = 1 : return content[0] . decode ( ' utf-8 ' ) . strip ( ' \\n ' ) return default": 971,
 "def page_guiref ( arg_s = None ) : from IPython . core import page page . page ( gui_reference , auto_html = True ) ": 972,
 "def _read_stdin ( ) : line = sys . stdin . readline ( ) while line : yield line line = sys . stdin . readline ( ) ": 973,
 "def save_excel ( self , fd ) : from pylon . io . excel import ExcelWriter ExcelWriter ( self ) . write ( fd ) ": 974,
 "async def async_input ( prompt ) : print ( prompt , end = ' ' , flush = True ) return ( await loop . run_in_executor ( None , sys . stdin . readline ) ) . rstrip ( ) ": 975,
 "def set_font_size ( self , size ) : if self . font . font_size = = size : pass else : self . font . _set_size ( size ) ": 976,
 "def open_json ( file_name ) : with open ( file_name , \" r \" ) as json_data : data = json . load ( json_data ) return data": 977,
 "def is_read_only ( object ) : try : attribute = \" _trace__read__ \" setattr ( object , attribute , True ) delattr ( object , attribute ) return False except ( TypeError , AttributeError ) : return True": 978,
 "def draw_header ( self , stream , header ) : stream . writeln ( ' = ' * ( len ( header ) + 4 ) ) stream . writeln ( ' | ' + header + ' | ' ) stream . writeln ( ' = ' * ( len ( header ) + 4 ) ) stream . writeln ( ) ": 979,
 "def url_read_text ( url , verbose = True ) : r data = url_read ( url , verbose ) text = data . decode ( ' utf8 ' ) return text": 980,
 "def get_xy_grids ( ds , stride = 1 , getval = False ) : gt = ds . GetGeoTransform ( ) # stride = stride_m/gt[1] pX = np . arange ( 0 , ds . RasterXSize , stride ) pY = np . arange ( 0 , ds . RasterYSize , stride ) psamp = np . meshgrid ( pX , pY ) mX , mY = pixelToMap ( psamp[0] , psamp[1] , gt ) return mX , mY": 981,
 "def _parse_config ( config_file_path ) : config_file = open ( config_file_path , ' r ' ) config = yaml . load ( config_file ) config_file . close ( ) return config": 982,
 "def json_iter ( path ) : with open ( path , ' r ' ) as f : for line in f . readlines ( ) : yield json . loads ( line ) ": 983,
 "def mouse_move_event ( self , event ) : self . example . mouse_position_event ( event . x ( ) , event . y ( ) ) ": 984,
 "def exit ( self ) : self . pubsub . unsubscribe ( ) self . client . connection_pool . disconnect ( ) logger . info ( \" Connection to Redis closed \" ) ": 985,
 "def get_var_type ( self , name ) : name = create_string_buffer ( name ) type_ = create_string_buffer ( MAXSTRLEN ) self . library . get_var_type . argtypes = [c_char_p , c_char_p] self . library . get_var_type ( name , type_ ) return type_ . value": 986,
 "def acquire_node ( self , node ) : try : return node . set ( self . resource , self . lock_key , nx = True , px = self . ttl ) except ( redis . exceptions . ConnectionError , redis . exceptions . TimeoutError ) : return False": 987,
 "def java_version ( ) : result = subprocess . check_output ( [c . JAVA , ' -version ' ] , stderr = subprocess . STDOUT ) first_line = result . splitlines ( ) [0] return first_line . decode ( ) ": 988,
 "def expireat ( self , key , when ) : expire_time = datetime . fromtimestamp ( when ) key = self . _encode ( key ) if key in self . redis : self . timeouts[key] = expire_time return True return False": 989,
 "def init_checks_registry ( ) : mod = inspect . getmodule ( register_check ) for ( name , function ) in inspect . getmembers ( mod , inspect . isfunction ) : register_check ( function ) ": 990,
 "def find_root ( self ) : cmd = self while cmd . parent : cmd = cmd . parent return cmd": 991,
 "def _load_texture ( file_name , resolver ) : file_data = resolver . get ( file_name ) image = PIL . Image . open ( util . wrap_as_stream ( file_data ) ) return image": 992,
 "def _tuple_repr ( data ) : if len ( data ) = = 1 : return \" ( %s , ) \" % rpr ( data[0] ) else : return \" ( %s ) \" % \" , \" . join ( [rpr ( x ) for x in data] ) ": 993,
 "def Load ( file ) : with open ( file , ' rb ' ) as file : model = dill . load ( file ) return model": 994,
 "def make_bintree ( levels ) : G = nx . DiGraph ( ) root = ' 0 ' G . add_node ( root ) add_children ( G , root , levels , 2 ) return G": 995,
 "def is_valid_regex ( string ) : try : re . compile ( string ) is_valid = True except re . error : is_valid = False return is_valid": 996,
 "def _makes_clone ( _func , *args , **kw ) : self = args[0] . _clone ( ) _func ( self , *args[1 : ] , **kw ) return self": 997,
 "def validate_multiindex ( self , obj ) : levels = [l if l is not None else \" level_{0} \" . format ( i ) for i , l in enumerate ( obj . index . names ) ] try : return obj . reset_index ( ) , levels except ValueError : raise ValueError ( \" duplicate names/columns in the multi-index when \" \" storing as a table \" ) ": 998,
 "def alert ( text = ' ' , title = ' ' , button = OK_TEXT , root = None , timeout = None ) : assert TKINTER_IMPORT_SUCCEEDED , ' Tkinter is required for pymsgbox ' return _buttonbox ( msg = text , title = title , choices = [str ( button ) ] , root = root , timeout = timeout ) ": 999,
 "def cmd_reindex ( ) : db = connect ( args . database ) for idx in args . indexes : pg_reindex ( db , idx ) ": 1000,
 "def update_redirect ( self ) : page_history = Stack ( session . get ( \" page_history \" , [] ) ) page_history . push ( request . url ) session[ \" page_history \" ] = page_history . to_json ( ) ": 1001,
 "def filter_dict_by_key ( d , keys ) : return {k : v for k , v in d . items ( ) if k in keys}": 1002,
 "def sent2features ( sentence , template ) : return [word2features ( sentence , i , template ) for i in range ( len ( sentence ) ) ]": 1003,
 "def handle_whitespace ( text ) : r text = re_retab . sub ( sub_retab , text ) text = re_whitespace . sub ( ' ' , text ) . strip ( ) return text": 1004,
 "def get_table ( ports ) : table = PrettyTable ( [ \" Name \" , \" Port \" , \" Protocol \" , \" Description \" ] ) table . align[ \" Name \" ] = \" l \" table . align[ \" Description \" ] = \" l \" table . padding_width = 1 for port in ports : table . add_row ( port ) return table": 1005,
 "def _remove_blank ( l ) : ret = [] for i , _ in enumerate ( l ) : if l[i] = = 0 : break ret . append ( l[i] ) return ret": 1006,
 "def auto ( ) : \t\ttry : \t\tStyle . enabled = False\t\tStyle . enabled = sys . stdout . isatty ( ) \texcept ( AttributeError , TypeError ) : \t\tpass": 1007,
 "def Fsphere ( q , R ) : return 4 * np . pi / q ** 3 * ( np . sin ( q * R ) - q * R * np . cos ( q * R ) ) ": 1008,
 "def figsize ( x = 8 , y = 7 . , aspect = 1 . ) : # update rcparams with adjusted figsize params mpl . rcParams . update ( { ' figure . figsize ' : ( x*aspect , y ) } ) ": 1009,
 "def vowels ( self ) : return IPAString ( ipa_chars = [c for c in self . ipa_chars if c . is_vowel] ) ": 1010,
 "def prune ( self , n ) : if self . minimize : self . data = self . data[ : n] else : self . data = self . data[-1 * n : ]": 1011,
 "def submitbutton ( self , request , tag ) : return tags . input ( type = ' submit ' , name = ' __submit__ ' , value = self . _getDescription ( ) ) ": 1012,
 "def rrmdir ( directory ) : for root , dirs , files in os . walk ( directory , topdown = False ) : for name in files : os . remove ( os . path . join ( root , name ) ) for name in dirs : os . rmdir ( os . path . join ( root , name ) ) os . rmdir ( directory ) ": 1013,
 "def flatten_list ( l ) : return list ( chain . from_iterable ( repeat ( x , 1 ) if isinstance ( x , str ) else x for x in l ) ) ": 1014,
 "def rm_keys_from_dict ( d , keys ) : # Loop for each key given for key in keys : # Is the key in the dictionary? if key in d : try : d . pop ( key , None ) except KeyError : # Not concerned with an error . Keep going . pass return d": 1015,
 "def create_ellipse ( width , height , angle ) : angle = angle / 180 . 0 * np . pi thetas = np . linspace ( 0 , 2*np . pi , 200 ) a = width / 2 . 0 b = height / 2 . 0 x = a*np . cos ( thetas ) *np . cos ( angle ) - b*np . sin ( thetas ) *np . sin ( angle ) y = a*np . cos ( thetas ) *np . sin ( angle ) + b*np . sin ( thetas ) *np . cos ( angle ) z = np . zeros ( thetas . shape ) return np . vstack ( ( x , y , z ) ) . T": 1016,
 "def purge_dict ( idict ) : odict = {} for key , val in idict . items ( ) : if is_null ( val ) : continue odict[key] = val return odict": 1017,
 "def set_color ( self , fg = None , bg = None , intensify = False , target = sys . stdout ) : raise NotImplementedError": 1018,
 "def pop ( self , index = -1 ) : \t\t\t\tvalue = self . _list . pop ( index ) \t\tdel self . _dict[value]\t\treturn value": 1019,
 "def selecttrue ( table , field , complement = False ) : return select ( table , field , lambda v : bool ( v ) , complement = complement ) ": 1020,
 "def unaccentuate ( s ) : return \" \" . join ( c for c in unicodedata . normalize ( \" NFKD \" , s ) if not unicodedata . combining ( c ) ) ": 1021,
 "def subn_filter ( s , find , replace , count = 0 ) : return re . gsub ( find , replace , count , s ) ": 1022,
 "def multi_replace ( instr , search_list = [] , repl_list = None ) : repl_list = [ ' ' ] * len ( search_list ) if repl_list is None else repl_list for ser , repl in zip ( search_list , repl_list ) : instr = instr . replace ( ser , repl ) return instr": 1023,
 "def configure_relation ( graph , ns , mappings ) : convention = RelationConvention ( graph ) convention . configure ( ns , mappings ) ": 1024,
 "def _replace_nan ( a , val ) : mask = isnull ( a ) return where_method ( val , mask , a ) , mask": 1025,
 "def cprint ( string , fg = None , bg = None , end = ' \\n ' , target = sys . stdout ) : _color_manager . set_color ( fg , bg ) target . write ( string + end ) target . flush ( ) # Needed for Python 3 . x _color_manager . set_defaults ( ) ": 1026,
 "def http_request_json ( *args , **kwargs ) : ret , status = http_request ( *args , **kwargs ) return json . loads ( ret ) , status": 1027,
 "def stdoutwriteline ( *args ) : s = \" \" for i in args : s + = str ( i ) + \" \" s = s . strip ( ) sys . stdout . write ( str ( s ) + \" \\n \" ) sys . stdout . flush ( ) return s": 1028,
 "def copy_user_agent_from_driver ( self ) : selenium_user_agent = self . driver . execute_script ( \" return navigator . userAgent; \" ) self . headers . update ( { \" user-agent \" : selenium_user_agent} ) ": 1029,
 "def _show ( self , message , indent = 0 , enable_verbose = True ) : # pragma : no cover if enable_verbose : print ( \" \" * indent + message ) ": 1030,
 "def save_session_to_file ( self , sessionfile ) : pickle . dump ( requests . utils . dict_from_cookiejar ( self . _session . cookies ) , sessionfile ) ": 1031,
 "def is_http_running_on ( port ) : try : conn = httplib . HTTPConnection ( ' 127 . 0 . 0 . 1 : ' + str ( port ) ) conn . connect ( ) conn . close ( ) return True except Exception : return False": 1032,
 "def download ( url , encoding = ' utf-8 ' ) : import requests response = requests . get ( url ) response . encoding = encoding return response . text": 1033,
 "def clear ( self ) : self . axes . cla ( ) self . conf . ntrace = 0 self . conf . xlabel = ' ' self . conf . ylabel = ' ' self . conf . title = ' ' ": 1034,
 "def __init__ ( self , pos , cell , motion , cellmotion ) : self . pos = pos self . cell = cell \" \" \" ( x , y ) position of the mouse snapped to a cell on the root console . type : ( int , int ) \" \" \" self . motion = motion \" \" \" ( x , y ) motion of the mouse on the screen . type : ( int , int ) \" \" \" self . cellmotion = cellmotion \" \" \" ( x , y ) mostion of the mouse moving over cells on the root console . type : ( int , int ) \" \" \" ": 1035,
 "def resize ( self , size ) : \t\t\t\tif size is not None : \t\t\tself . __value = int ( WBinArray ( self . __value ) [ : size] ) \t\tself . __size = size": 1036,
 "def print_out ( self , *lst ) : self . print2file ( self . stdout , True , True , *lst ) ": 1037,
 "def raise_for_not_ok_status ( response ) : if response . code ! = OK : raise HTTPError ( ' Non-200 response code ( %s ) for url : %s ' % ( response . code , uridecode ( response . request . absoluteURI ) ) ) return response": 1038,
 "def disable_busy_cursor ( ) : while QgsApplication . instance ( ) . overrideCursor ( ) is not None and \\ QgsApplication . instance ( ) . overrideCursor ( ) . shape ( ) = = \\ QtCore . Qt . WaitCursor : QgsApplication . instance ( ) . restoreOverrideCursor ( ) ": 1039,
 "async def json_or_text ( response ) : text = await response . text ( ) if response . headers[ ' Content-Type ' ] = = ' application/json; charset = utf-8 ' : return json . loads ( text ) return text": 1040,
 "def get_auth ( ) : import getpass user = input ( \" User Name : \" ) # noqa pswd = getpass . getpass ( ' Password : ' ) return Github ( user , pswd ) ": 1041,
 "def http ( self , *args , **kwargs ) : kwargs[ ' api ' ] = self . api return http ( *args , **kwargs ) ": 1042,
 "def ILIKE ( pattern ) : return P ( lambda x : fnmatch . fnmatch ( x . lower ( ) , pattern . lower ( ) ) ) ": 1043,
 "def documentation ( self ) : newclient = self . __class__ ( self . session , self . root_url ) return newclient . get_raw ( ' / ' ) ": 1044,
 "def _add_indent ( string , indent ) : lines = string . split ( \" \\n \" ) first , lines = lines[0] , lines[1 : ] lines = [ \" {indent}{s} \" . format ( indent = \" \" * indent , s = s ) for s in lines] lines = [first] + lines return \" \\n \" . join ( lines ) ": 1045,
 "def get_key_goids ( self , goids ) : go2obj = self . go2obj return set ( go2obj[go] . id for go in goids ) ": 1046,
 "def requests_post ( url , data = None , json = None , **kwargs ) : return requests_request ( ' post ' , url , data = data , json = json , **kwargs ) ": 1047,
 "def find_start_point ( self ) : for i , row in enumerate ( self . data ) : for j , _ in enumerate ( row ) : if self . data[i , j] ! = 0 : # or not np . isfinite ( self . data[i , j] ) : return i , j": 1048,
 "def uniquify_list ( L ) : return [e for i , e in enumerate ( L ) if L . index ( e ) = = i]": 1049,
 "def norm_vec ( vector ) : assert len ( vector ) = = 3 v = np . array ( vector ) return v/np . sqrt ( np . sum ( v**2 ) ) ": 1050,
 "def get_file_string ( filepath ) : with open ( os . path . abspath ( filepath ) ) as f : return f . read ( ) ": 1051,
 "def _get_sql ( filename ) : with open ( os . path . join ( SQL_DIR , filename ) , ' r ' ) as f : return f . read ( ) ": 1052,
 "def out_shape_from_array ( arr ) : arr = np . asarray ( arr ) if arr . ndim = = 1 : return arr . shape else : return ( arr . shape[1] , ) ": 1053,
 "def parse_s3_url ( url ) : bucket = ' ' path = ' ' if url : result = urlparse ( url ) bucket = result . netloc path = result . path . strip ( ' / ' ) return bucket , path": 1054,
 "def pickle_load ( fname ) : assert type ( fname ) is str and os . path . exists ( fname ) print ( \" loaded \" , fname ) return pickle . load ( open ( fname , \" rb \" ) ) ": 1055,
 "def get_key_by_value ( dictionary , search_value ) : for key , value in dictionary . iteritems ( ) : if value = = search_value : return ugettext ( key ) ": 1056,
 "def plot_dist_normal ( s , mu , sigma ) : import matplotlib . pyplot as plt count , bins , ignored = plt . hist ( s , 30 , normed = True ) plt . plot ( bins , 1/ ( sigma * np . sqrt ( 2 * np . pi ) ) \\ * np . exp ( - ( bins - mu ) **2 / ( 2 * sigma**2 ) ) , \\ linewidth = 2 , color = ' r ' ) plt . show ( ) ": 1057,
 "def _pdf_at_peak ( self ) : return ( self . peak - self . low ) / ( self . high - self . low ) ": 1058,
 "def _dict_to_proto ( py_dict , proto ) : dict_json_str = json . dumps ( py_dict ) return json_format . Parse ( dict_json_str , proto ) ": 1059,
 "def round_to_n ( x , n ) : return round ( x , -int ( np . floor ( np . log10 ( x ) ) ) + ( n - 1 ) ) ": 1060,
 "def trigger ( self , target : str , trigger : str , parameters : Dict[str , Any] = {} ) : \t\t\t\tpass": 1061,
 "def get_rounded ( self , digits ) : result = self . copy ( ) result . round ( digits ) return result": 1062,
 "def open_with_encoding ( filename , encoding , mode = ' r ' ) : return io . open ( filename , mode = mode , encoding = encoding , newline = ' ' ) ": 1063,
 "def call_and_exit ( self , cmd , shell = True ) : sys . exit ( subprocess . call ( cmd , shell = shell ) ) ": 1064,
 "def merge ( left , right , how = ' inner ' , key = None , left_key = None , right_key = None , left_as = ' left ' , right_as = ' right ' ) : return join ( left , right , how , key , left_key , right_key , join_fn = make_union_join ( left_as , right_as ) ) ": 1065,
 "async def result_processor ( tasks ) : output = {} for task in tasks : num , res = await task output[num] = res return output": 1066,
 "def add_text ( text , x = 0 . 01 , y = 0 . 01 , axes = \" gca \" , draw = True , **kwargs ) : if axes = = \" gca \" : axes = _pylab . gca ( ) axes . text ( x , y , text , transform = axes . transAxes , **kwargs ) if draw : _pylab . draw ( ) ": 1067,
 "def safe_quotes ( text , escape_single_quotes = False ) : if isinstance ( text , str ) : safe_text = text . replace ( ' \" ' , \" &quot; \" ) if escape_single_quotes : safe_text = safe_text . replace ( \" ' \" , \" & # 92; ' \" ) return safe_text . replace ( ' True ' , ' true ' ) return text": 1068,
 "def make_post_request ( self , url , auth , json_payload ) : response = requests . post ( url , auth = auth , json = json_payload ) return response . json ( ) ": 1069,
 "def fig2x ( figure , format ) : # Save svg to file like object svg_io io = StringIO ( ) figure . savefig ( io , format = format ) # Rewind the file like object io . seek ( 0 ) data = io . getvalue ( ) io . close ( ) return data": 1070,
 "def error ( *args ) : if sys . stdin . isatty ( ) : print ( ' ERROR : ' , *args , file = sys . stderr ) else : notify_error ( *args ) ": 1071,
 "def close ( *args , **kwargs ) : r _ , plt , _ = _import_plt ( ) plt . close ( *args , **kwargs ) ": 1072,
 "def head ( filename , n = 10 ) : with freader ( filename ) as fr : for _ in range ( n ) : print ( fr . readline ( ) . strip ( ) ) ": 1073,
 "def format_exc ( limit = None ) : try : etype , value , tb = sys . exc_info ( ) return ' ' . join ( traceback . format_exception ( etype , value , tb , limit ) ) finally : etype = value = tb = None": 1074,
 "def conv1x1 ( in_planes , out_planes , stride = 1 ) : return nn . Conv2d ( in_planes , out_planes , kernel_size = 1 , stride = stride , bias = False ) ": 1075,
 "def _get_name ( self , key ) : if key in self . display_names : return self . display_names[key] return key . capitalize ( ) ": 1076,
 "def scipy_sparse_to_spmatrix ( A ) : coo = A . tocoo ( ) SP = spmatrix ( coo . data . tolist ( ) , coo . row . tolist ( ) , coo . col . tolist ( ) , size = A . shape ) return SP": 1077,
 "def _screen ( self , s , newline = False ) : if self . verbose : if newline : print ( s ) else : print ( s , end = ' ' ) ": 1078,
 "def _stdout_raw ( self , s ) : print ( s , end = ' ' , file = sys . stdout ) sys . stdout . flush ( ) ": 1079,
 "def write_wav ( path , samples , sr = 16000 ) : max_value = np . abs ( np . iinfo ( np . int16 ) . min ) data = ( samples * max_value ) . astype ( np . int16 ) scipy . io . wavfile . write ( path , sr , data ) ": 1080,
 "def string_to_identity ( identity_str ) : m = _identity_regexp . match ( identity_str ) result = m . groupdict ( ) log . debug ( ' parsed identity : %s ' , result ) return {k : v for k , v in result . items ( ) if v}": 1081,
 "def mouse_out ( self ) : self . scroll_to ( ) ActionChains ( self . parent . driver ) . move_by_offset ( 0 , 0 ) . click ( ) . perform ( ) ": 1082,
 "def _set_scroll_v ( self , *args ) : self . _canvas_categories . yview ( *args ) self . _canvas_scroll . yview ( *args ) ": 1083,
 "def bash ( filename ) : sys . stdout . flush ( ) subprocess . call ( \" bash {} \" . format ( filename ) , shell = True ) ": 1084,
 "def stdin_readable ( ) : if not WINDOWS : try : return bool ( select ( [sys . stdin] , [] , [] , 0 ) [0] ) except Exception : logger . log_exc ( ) try : return not sys . stdin . isatty ( ) except Exception : logger . log_exc ( ) return False": 1085,
 "def execute_in_background ( self ) : # http : //stackoverflow . com/questions/1605520 args = shlex . split ( self . cmd ) p = Popen ( args ) return p . pid": 1086,
 "def ratio_and_percentage ( current , total , time_remaining ) : return \" {} / {} ( {}% completed ) \" . format ( current , total , int ( current / total * 100 ) ) ": 1087,
 "def ask_dir ( self ) : \t\t\t\targs [ ' directory ' ] = askdirectory ( **self . dir_opt ) \t\tself . dir_text . set ( args [ ' directory ' ] ) ": 1088,
 "def numpy ( self ) : # load GDCM ' s image reading functionality image_reader = gdcm . ImageReader ( ) image_reader . SetFileName ( self . fname ) if not image_reader . Read ( ) : raise IOError ( \" Could not read DICOM image \" ) pixel_array = self . _gdcm_to_numpy ( image_reader . GetImage ( ) ) return pixel_array": 1089,
 "def selectgt ( table , field , value , complement = False ) : value = Comparable ( value ) return selectop ( table , field , value , operator . gt , complement = complement ) ": 1090,
 "def read_utf8 ( fh , byteorder , dtype , count , offsetsize ) : return fh . read ( count ) . decode ( ' utf-8 ' ) ": 1091,
 "def selectnotnone ( table , field , complement = False ) : return select ( table , field , lambda v : v is not None , complement = complement ) ": 1092,
 "def ReadManyFromPath ( filepath ) : with io . open ( filepath , mode = \" r \" , encoding = \" utf-8 \" ) as filedesc : return ReadManyFromFile ( filedesc ) ": 1093,
 "def find_first_number ( ll ) : for nr , entry in enumerate ( ll ) : try : float ( entry ) except ( ValueError , TypeError ) as e : pass else : return nr return None": 1094,
 "def filter_by_ids ( original_list , ids_to_filter ) : if not ids_to_filter : return original_list return [i for i in original_list if i[ ' id ' ] in ids_to_filter]": 1095,
 "def load_yaml ( filepath ) : with open ( filepath ) as f : txt = f . read ( ) return yaml . load ( txt ) ": 1096,
 "def __init__ ( self ) : super ( AttributeContainerIdentifier , self ) . __init__ ( ) self . _identifier = id ( self ) ": 1097,
 "async def readline ( self ) : future = asyncio . Future ( ) data_available = False while True : if not data_available : if not self . my_serial . inWaiting ( ) : await asyncio . sleep ( self . sleep_tune ) else : data_available = True data = self . my_serial . readline ( ) future . set_result ( data ) else : if not future . done ( ) : await asyncio . sleep ( self . sleep_tune ) else : return future . result ( ) ": 1098,
 "def _trim ( image ) : background = PIL . Image . new ( image . mode , image . size , image . getpixel ( ( 0 , 0 ) ) ) diff = PIL . ImageChops . difference ( image , background ) diff = PIL . ImageChops . add ( diff , diff , 2 . 0 , -100 ) bbox = diff . getbbox ( ) if bbox : image = image . crop ( bbox ) return image": 1099,
 "def remove_series ( self , series ) : if len ( self . all_series ( ) ) = = 1 : raise ValueError ( \" Cannot remove last series from %s \" % str ( self ) ) self . _all_series . remove ( series ) series . _chart = None": 1100,
 "def del_Unnamed ( df ) : cols_del = [c for c in df . columns if ' Unnamed ' in c] return df . drop ( cols_del , axis = 1 ) ": 1101,
 "def get_header ( request , header_service ) : service = request . META . get ( ' HTTP_{} ' . format ( header_service ) , b ' ' ) if isinstance ( service , str ) : # Work around django test client oddness service = service . encode ( HTTP_HEADER_ENCODING ) return service": 1102,
 "def _removeTags ( tags , objects ) : for t in tags : for o in objects : o . tags . remove ( t ) return True": 1103,
 "def fix_datagrepper_message ( message ) : if not ( ' source_name ' in message and ' source_version ' in message ) : return message # Don ' t mutate the original message message = message . copy ( ) del message[ ' source_name ' ] del message[ ' source_version ' ] # datanommer adds the headers field to the message in all cases . # This is a huge problem because if the signature was generated with a ' headers ' # key set and we delete it here , messages will fail validation , but if we don ' t # messages will fail validation if they didn ' t have a ' headers ' key set . # # There ' s no way to know whether or not the headers field was part of the signed # message or not . Generally , the problem is datanommer is mutating messages . if ' headers ' in message and not message[ ' headers ' ] : del message[ ' headers ' ] if ' timestamp ' in message : message[ ' timestamp ' ] = int ( message[ ' timestamp ' ] ) return message": 1104,
 "def set_time ( filename , mod_time ) : \t\tlog . debug ( ' Setting modified time to %s ' , mod_time ) \tmtime = calendar . timegm ( mod_time . utctimetuple ( ) ) \t # utctimetuple discards microseconds , so restore it ( for consistency ) \tmtime + = mod_time . microsecond / 1000000\tatime = os . stat ( filename ) . st_atime\tos . utime ( filename , ( atime , mtime ) ) ": 1105,
 "def get_var ( name , factory = None ) : if name not in _VARS and factory is not None : _VARS[name] = factory ( ) return _VARS . get ( name ) ": 1106,
 "def turn ( self ) : first = self . _data . pop ( 0 ) self . _data . append ( first ) ": 1107,
 "def clean_axis ( axis ) : axis . get_xaxis ( ) . set_ticks ( [] ) axis . get_yaxis ( ) . set_ticks ( [] ) for spine in list ( axis . spines . values ( ) ) : spine . set_visible ( False ) ": 1108,
 "def set_log_level ( logger_name : str , log_level : str , propagate : bool = False ) : log = logging . getLogger ( logger_name ) log . propagate = propagate log . setLevel ( log_level ) ": 1109,
 "def split_comma_argument ( comma_sep_str ) : terms = [] for term in comma_sep_str . split ( ' , ' ) : if term : terms . append ( term ) return terms": 1110,
 "def set_pivot_keys ( self , foreign_key , other_key ) : self . __foreign_key = foreign_key self . __other_key = other_key return self": 1111,
 "def mock_add_spec ( self , spec , spec_set = False ) : self . _mock_add_spec ( spec , spec_set ) self . _mock_set_magics ( ) ": 1112,
 "def fmt_subst ( regex , subst ) : return lambda text : re . sub ( regex , subst , text ) if text else text": 1113,
 "def discard ( self , element ) : try : i = int ( element ) set . discard ( self , i ) except ValueError : pass": 1114,
 "def median ( self ) : mu = self . mean ( ) ret_val = math . exp ( mu ) if math . isnan ( ret_val ) : ret_val = float ( \" inf \" ) return ret_val": 1115,
 "def load_file ( self , filename ) : with open ( filename , ' r ' ) as sourcefile : self . set_string ( sourcefile . read ( ) ) ": 1116,
 "def normalise_string ( string ) : string = ( string . strip ( ) ) . lower ( ) return re . sub ( r ' \\W+ ' , ' _ ' , string ) ": 1117,
 "def to_utc ( self , dt ) : if dt . tzinfo is None : return dt . replace ( tzinfo = self . utc ) return dt . astimezone ( self . utc ) ": 1118,
 "def dashrepl ( value ) : patt = re . compile ( r ' \\W ' , re . UNICODE ) return re . sub ( patt , ' - ' , value ) ": 1119,
 "def im2mat ( I ) : return I . reshape ( ( I . shape[0] * I . shape[1] , I . shape[2] ) ) ": 1120,
 "def check_str ( obj ) : if isinstance ( obj , str ) : return obj if isinstance ( obj , float ) : return str ( int ( obj ) ) else : return str ( obj ) ": 1121,
 "async def restart ( request ) : def wait_and_restart ( ) : log . info ( ' Restarting server ' ) sleep ( 1 ) os . system ( ' kill 1 ' ) Thread ( target = wait_and_restart ) . start ( ) return web . json_response ( { \" message \" : \" restarting \" } ) ": 1122,
 "def get_jsonparsed_data ( url ) : response = urlopen ( url ) data = response . read ( ) . decode ( ' utf-8 ' ) return json . loads ( data ) ": 1123,
 "def feed_eof ( self ) : self . _incoming . write_eof ( ) ssldata , appdata = self . feed_ssldata ( b ' ' ) assert appdata = = [] or appdata = = [b ' ' ]": 1124,
 "def bounds_to_poly ( bounds ) : x0 , y0 , x1 , y1 = bounds return Polygon ( [ ( x0 , y0 ) , ( x1 , y0 ) , ( x1 , y1 ) , ( x0 , y1 ) ] ) ": 1125,
 "def reset ( self ) : \t\t\t\tself . __iterator , self . __saved = itertools . tee ( self . __saved ) ": 1126,
 "def format_exc ( *exc_info ) : typ , exc , tb = exc_info or sys . exc_info ( ) error = traceback . format_exception ( typ , exc , tb ) return \" \" . join ( error ) ": 1127,
 "def _saferound ( value , decimal_places ) : try : f = float ( value ) except ValueError : return ' ' format = ' %% . %df ' % decimal_places return format % f": 1128,
 "def _shuffle ( data , idx ) : shuffle_data = [] for idx_k , idx_v in data : shuffle_data . append ( ( idx_k , mx . ndarray . array ( idx_v . asnumpy ( ) [idx] , idx_v . context ) ) ) return shuffle_data": 1129,
 "def lowPass ( self , *args ) : return Signal ( self . _butter ( self . samples , ' low ' , *args ) , fs = self . fs ) ": 1130,
 "def begin_stream_loop ( stream , poll_interval ) : while should_continue ( ) : try : stream . start_polling ( poll_interval ) except Exception as e : # Infinite restart logger . error ( \" Exception while polling . Restarting in 1 second . \" , exc_info = True ) time . sleep ( 1 ) ": 1131,
 "def readTuple ( self , line , n = 3 ) : numbers = [num for num in line . split ( ' ' ) if num] return [float ( num ) for num in numbers[1 : n + 1]]": 1132,
 "def stub_main ( ) : from google . apputils import run_script_module import butcher . main run_script_module . RunScriptModule ( butcher . main ) ": 1133,
 "def _nbytes ( buf ) : if isinstance ( buf , memoryview ) : if PY3 : # py3 introduces nbytes attribute return buf . nbytes else : # compute nbytes on py2 size = buf . itemsize for dim in buf . shape : size * = dim return size else : # not a memoryview , raw bytes/ py2 buffer return len ( buf ) ": 1134,
 "def save ( variable , filename ) : fileObj = open ( filename , ' wb ' ) pickle . dump ( variable , fileObj ) fileObj . close ( ) ": 1135,
 "def _skip_frame ( self ) : for line in self . _f : if line = = ' ITEM : ATOMS\\n ' : break for i in range ( self . num_atoms ) : next ( self . _f ) ": 1136,
 "def skip ( self , n ) : try : self . _iter_object . skip ( n ) except AttributeError : for i in range ( 0 , n ) : self . next ( ) ": 1137,
 "def write_fits ( self , fitsfile ) : tab = self . create_table ( ) hdu_data = fits . table_to_hdu ( tab ) hdus = [fits . PrimaryHDU ( ) , hdu_data] fits_utils . write_hdus ( hdus , fitsfile ) ": 1138,
 "def getbyteslice ( self , start , end ) : c = self . _rawarray[start : end] return c": 1139,
 "def pickle_save ( thing , fname ) : pickle . dump ( thing , open ( fname , \" wb \" ) , pickle . HIGHEST_PROTOCOL ) return thing": 1140,
 "def is_full_slice ( obj , l ) : return ( isinstance ( obj , slice ) and obj . start = = 0 and obj . stop = = l and obj . step is None ) ": 1141,
 "def resize_image ( self , data , size ) : from machina . core . compat import PILImage as Image image = Image . open ( BytesIO ( data ) ) # Resize! image . thumbnail ( size , Image . ANTIALIAS ) string = BytesIO ( ) image . save ( string , format = ' PNG ' ) return string . getvalue ( ) ": 1142,
 "def stop ( self , dummy_signum = None , dummy_frame = None ) : logging . info ( ' Shutting down . . . ' ) self . socket . close ( ) sys . exit ( 0 ) ": 1143,
 "def stop ( self ) : with self . synclock : if self . syncthread is not None : self . syncthread . cancel ( ) self . syncthread = None": 1144,
 "def symlink_remove ( link ) : # https : //stackoverflow . com/q/26554135/6400719 if os . path . isdir ( path2str ( link ) ) and is_windows : # this should only be on Py2 . 7 and windows os . rmdir ( path2str ( link ) ) else : os . unlink ( path2str ( link ) ) ": 1145,
 "def split_strings_in_list_retain_spaces ( orig_list ) : temp_list = list ( ) for line in orig_list : line_split = __re . split ( r ' ( \\s+ ) ' , line ) temp_list . append ( line_split ) return temp_list": 1146,
 "def transcript_sort_key ( transcript ) : return ( -len ( transcript . protein_sequence ) , -len ( transcript . sequence ) , transcript . name ) ": 1147,
 "def getdefaultencoding ( ) : enc = get_stream_enc ( sys . stdin ) if not enc or enc = = ' ascii ' : try : # There are reports of getpreferredencoding raising errors # in some cases , which may well be fixed , but let ' s be conservative here . enc = locale . getpreferredencoding ( ) except Exception : pass return enc or sys . getdefaultencoding ( ) ": 1148,
 "def _config_win32_domain ( self , domain ) : # we call str ( ) on domain to convert it from unicode to ascii self . domain = dns . name . from_text ( str ( domain ) ) ": 1149,
 "def _dict_values_sorted_by_key ( dictionary ) : # This should be a yield from instead . for _ , value in sorted ( dictionary . iteritems ( ) , key = operator . itemgetter ( 0 ) ) : yield value": 1150,
 "def get_neg_infinity ( dtype ) : if issubclass ( dtype . type , ( np . floating , np . integer ) ) : return -np . inf if issubclass ( dtype . type , np . complexfloating ) : return -np . inf - 1j * np . inf return NINF": 1151,
 "def chmod_add_excute ( filename ) : st = os . stat ( filename ) os . chmod ( filename , st . st_mode | stat . S_IEXEC ) ": 1152,
 "def _removeStopwords ( text_list ) : output_list = [] for word in text_list : if word . lower ( ) not in _stopwords : output_list . append ( word ) return output_list": 1153,
 "def GetPythonLibraryDirectoryPath ( ) : path = sysconfig . get_python_lib ( True ) _ , _ , path = path . rpartition ( sysconfig . PREFIX ) if path . startswith ( os . sep ) : path = path[1 : ] return path": 1154,
 "def lspearmanr ( x , y ) : TINY = 1e-30 if len ( x ) ! = len ( y ) : raise ValueError ( ' Input values not paired in spearmanr . Aborting . ' ) n = len ( x ) rankx = rankdata ( x ) ranky = rankdata ( y ) dsq = sumdiffsquared ( rankx , ranky ) rs = 1 - 6*dsq / float ( n* ( n**2-1 ) ) t = rs * math . sqrt ( ( n-2 ) / ( ( rs+1 . 0 ) * ( 1 . 0-rs ) ) ) df = n-2 probrs = betai ( 0 . 5*df , 0 . 5 , df/ ( df+t*t ) ) # t already a float # probability values for rs are from part 2 of the spearman function in # Numerical Recipies , p . 510 . They are close to tables , but not exact . ( ? ) return rs , probrs": 1155,
 "def _python_rpath ( self ) : # Windows virtualenv installation installs pip to the [Ss]cripts # folder . Here ' s a simple check to support : if sys . platform = = ' win32 ' : return os . path . join ( ' Scripts ' , ' python . exe ' ) return os . path . join ( ' bin ' , ' python ' ) ": 1156,
 "def setValue ( self , p_float ) : p_float = p_float * 100 super ( PercentageSpinBox , self ) . setValue ( p_float ) ": 1157,
 "def expand_args ( cmd_args ) : if isinstance ( cmd_args , ( tuple , list ) ) : args_list = list ( cmd_args ) else : args_list = shlex . split ( cmd_args ) return args_list": 1158,
 "def datetime_from_timestamp ( timestamp , content ) : return set_date_tzinfo ( datetime . fromtimestamp ( timestamp ) , tz_name = content . settings . get ( ' TIMEZONE ' , None ) ) ": 1159,
 "def split_on ( s , sep = \" \" ) : pattern = ' ' ' ( ( ? : [^%s \" ' ]| \" [^ \" ]* \" | ' [^ ' ]* ' ) + ) ' ' ' % sep return [_strip_speechmarks ( t ) for t in re . split ( pattern , s ) [1 : : 2]]": 1160,
 "def SetValue ( self , row , col , value ) : self . dataframe . iloc[row , col] = value": 1161,
 "def extract_args ( argv ) : string = \" \" . join ( argv ) string = string . split ( ' - ' ) program = string[0] arguments = [s . split ( ) for s in string[1 : ]] return arguments": 1162,
 "def move_to ( x , y ) : _make_cnc_request ( \" coord/{0}/{1} \" . format ( x , y ) ) state[ ' turtle ' ] . goto ( x , y ) ": 1163,
 "def stopwatch_now ( ) : if six . PY2 : now = time . time ( ) else : now = time . monotonic ( ) return now": 1164,
 "def case_us2mc ( x ) : return re . sub ( r ' _ ( [a-z] ) ' , lambda m : ( m . group ( 1 ) . upper ( ) ) , x ) ": 1165,
 "def file_found ( filename , force ) : if os . path . exists ( filename ) and not force : logger . info ( \" Found %s; skipping . . . \" %filename ) return True else : return False": 1166,
 "def restart ( self , reset = False ) : # Get start path to use in restart script spyder_start_directory = get_module_path ( ' spyder ' ) restart_script = osp . join ( spyder_start_directory , ' app ' , ' restart . py ' ) # Get any initial argument passed when spyder was started # Note : Variables defined in bootstrap . py and spyder/app/start . py env = os . environ . copy ( ) bootstrap_args = env . pop ( ' SPYDER_BOOTSTRAP_ARGS ' , None ) spyder_args = env . pop ( ' SPYDER_ARGS ' ) # Get current process and python running spyder pid = os . getpid ( ) python = sys . executable # Check if started with bootstrap . py if bootstrap_args is not None : spyder_args = bootstrap_args is_bootstrap = True else : is_bootstrap = False # Pass variables as environment variables ( str ) to restarter subprocess env[ ' SPYDER_ARGS ' ] = spyder_args env[ ' SPYDER_PID ' ] = str ( pid ) env[ ' SPYDER_IS_BOOTSTRAP ' ] = str ( is_bootstrap ) env[ ' SPYDER_RESET ' ] = str ( reset ) if DEV : if os . name = = ' nt ' : env[ ' PYTHONPATH ' ] = ' ; ' . join ( sys . path ) else : env[ ' PYTHONPATH ' ] = ' : ' . join ( sys . path ) # Build the command and popen arguments depending on the OS if os . name = = ' nt ' : # Hide flashing command prompt startupinfo = subprocess . STARTUPINFO ( ) startupinfo . dwFlags | = subprocess . STARTF_USESHOWWINDOW shell = False else : startupinfo = None shell = True command = ' \" {0} \" \" {1} \" ' command = command . format ( python , restart_script ) try : if self . closing ( True ) : subprocess . Popen ( command , shell = shell , env = env , startupinfo = startupinfo ) self . console . quit ( ) except Exception as error : # If there is an error with subprocess , Spyder should not quit and # the error can be inspected in the internal console print ( error ) # spyder : test-skip print ( command ) ": 1167,
 "def MatrixSolve ( a , rhs , adj ) : return np . linalg . solve ( a if not adj else _adjoint ( a ) , rhs ) , ": 1168,
 "def _bindingsToDict ( self , bindings ) : myDict = {} for key , val in bindings . iteritems ( ) : myDict[key . toPython ( ) . replace ( ' ? ' , ' ' ) ] = val . toPython ( ) return myDict": 1169,
 "def createdb ( ) : manager . db . engine . echo = True manager . db . create_all ( ) set_alembic_revision ( ) ": 1170,
 "def algo_exp ( x , m , t , b ) : return m*np . exp ( -t*x ) +b": 1171,
 "def sort_dict ( d , key = None , reverse = False ) : kv_items = [kv for kv in d . items ( ) ] # Sort kv_items according to key . if key is None : kv_items . sort ( key = lambda t : t[1] , reverse = reverse ) else : kv_items . sort ( key = key , reverse = reverse ) # Build ordered dict . return collections . OrderedDict ( kv_items ) ": 1172,
 "def commit ( self , session = None ) : if self . __cleared : return if self . _parent : # nested transaction self . _commit_parent ( ) else : self . _commit_repository ( ) self . _clear ( ) ": 1173,
 "def arglexsort ( arrays ) : dtypes = ' , ' . join ( array . dtype . str for array in arrays ) recarray = np . empty ( len ( arrays[0] ) , dtype = dtypes ) for i , array in enumerate ( arrays ) : recarray[ ' f%s ' % i] = array return recarray . argsort ( ) ": 1174,
 "def __init__ ( self ) : super ( Sqlite3DatabaseFile , self ) . __init__ ( ) self . _connection = None self . _cursor = None self . filename = None self . read_only = None": 1175,
 "def _shutdown_transport ( self ) : if self . sock is not None : try : unwrap = self . sock . unwrap except AttributeError : return try : self . sock = unwrap ( ) except ValueError : # Failure within SSL might mean unwrap exists but socket is not # deemed wrapped pass": 1176,
 "def sort_nicely ( l ) : convert = lambda text : int ( text ) if text . isdigit ( ) else text alphanum_key = lambda key : [convert ( c ) for c in re . split ( ' ( [0-9]+ ) ' , key ) ] l . sort ( key = alphanum_key ) ": 1177,
 "def weighted_std ( values , weights ) : average = np . average ( values , weights = weights ) variance = np . average ( ( values-average ) **2 , weights = weights ) return np . sqrt ( variance ) ": 1178,
 "def _std ( self , x ) : return np . nanstd ( x . values , ddof = self . _ddof ) ": 1179,
 "def sort_data ( data , cols ) : return data . sort_values ( cols ) [cols + [ ' value ' ]] . reset_index ( drop = True ) ": 1180,
 "def get_function_class ( function_name ) : if function_name in _known_functions : return _known_functions[function_name] else : raise UnknownFunction ( \" Function %s is not known . Known functions are : %s \" % ( function_name , \" , \" . join ( _known_functions . keys ( ) ) ) ) ": 1181,
 "def safe_call ( cls , method , *args ) : return cls . call ( method , *args , safe = True ) ": 1182,
 "def text_width ( string , font_name , font_size ) : return stringWidth ( string , fontName = font_name , fontSize = font_size ) ": 1183,
 "def is_static ( *p ) : return all ( is_CONST ( x ) or is_number ( x ) or is_const ( x ) for x in p ) ": 1184,
 "def incidence ( boundary ) : return GroupBy ( boundary ) . split ( np . arange ( boundary . size ) // boundary . shape[1] ) ": 1185,
 "def _update_staticmethod ( self , oldsm , newsm ) : # While we can ' t modify the staticmethod object itself ( it has no # mutable attributes ) , we *can* extract the underlying function # ( by calling __get__ ( ) , which returns it ) and update it in-place . # We don ' t have the class available to pass to __get__ ( ) but any # object except None will do . self . _update ( None , None , oldsm . __get__ ( 0 ) , newsm . __get__ ( 0 ) ) ": 1186,
 "def column_stack_2d ( data ) : return list ( list ( itt . chain . from_iterable ( _ ) ) for _ in zip ( *data ) ) ": 1187,
 "def disconnect ( self ) : if self . _connected : self . _connected = False self . _conn . disconnect ( ) ": 1188,
 "def _configure_logger ( ) : if not app . debug : _configure_logger_for_production ( logging . getLogger ( ) ) elif not app . testing : _configure_logger_for_debugging ( logging . getLogger ( ) ) ": 1189,
 "def _StopStatusUpdateThread ( self ) : self . _status_update_active = False if self . _status_update_thread . isAlive ( ) : self . _status_update_thread . join ( ) self . _status_update_thread = None": 1190,
 "def to_binary ( s , encoding = ' utf8 ' ) : if PY3 : # pragma : no cover return s if isinstance ( s , binary_type ) else binary_type ( s , encoding = encoding ) return binary_type ( s ) ": 1191,
 "def stop_button_click_handler ( self ) : self . stop_button . setDisabled ( True ) # Interrupt computations or stop debugging if not self . shellwidget . _reading : self . interrupt_kernel ( ) else : self . shellwidget . write_to_stdin ( ' exit ' ) ": 1192,
 "def md5_string ( s ) : m = hashlib . md5 ( ) m . update ( s ) return str ( m . hexdigest ( ) ) ": 1193,
 "def disown ( cmd ) : subprocess . Popen ( cmd , stdout = subprocess . DEVNULL , stderr = subprocess . DEVNULL ) ": 1194,
 "def _validate_date_str ( str_ ) : if not str_ : return None # Convert to datetime so we can validate it ' s a real date that exists then # convert it back to the string . try : date = datetime . strptime ( str_ , DATE_FMT ) except ValueError : msg = ' Invalid date format , should be YYYY-MM-DD ' raise argparse . ArgumentTypeError ( msg ) return date . strftime ( DATE_FMT ) ": 1195,
 "def magnitude ( X ) : r = np . real ( X ) i = np . imag ( X ) return np . sqrt ( r * r + i * i ) ;": 1196,
 "def loads ( s , model = None , parser = None ) : with StringIO ( s ) as f : return load ( f , model = model , parser = parser ) ": 1197,
 "def _serialize_json ( obj , fp ) : json . dump ( obj , fp , indent = 4 , default = serialize ) ": 1198,
 "def is_valid_url ( url ) : pieces = urlparse ( url ) return all ( [pieces . scheme , pieces . netloc] ) ": 1199,
 "def bytesize ( arr ) : byte_size = np . prod ( arr . shape ) * np . dtype ( arr . dtype ) . itemsize return byte_size": 1200,
 "def format_float ( value ) : # not used string = \" { : g} \" . format ( value ) . replace ( \" e+ \" , \" e \" ) string = re . sub ( \" e ( -? ) 0* ( \\d+ ) \" , r \" e\\1\\2 \" , string ) return string": 1201,
 "def random_int ( maximum_value ) : \t\tif maximum_value = = 0 : \t\treturn 0\telif maximum_value = = 1 : \t\treturn random_bits ( 1 ) \tbits = math . floor ( math . log2 ( maximum_value ) ) \tresult = random_bits ( bits ) + random_int ( maximum_value - ( ( 2 ** bits ) - 1 ) ) \treturn result": 1202,
 "def covstr ( s ) : try : ret = int ( s ) except ValueError : ret = float ( s ) return ret": 1203,
 "def _system_parameters ( **kwargs ) : return {key : value for key , value in kwargs . items ( ) if ( value is not None or value = = {} ) }": 1204,
 "def _from_bytes ( bytes , byteorder = \" big \" , signed = False ) : return int . from_bytes ( bytes , byteorder = byteorder , signed = signed ) ": 1205,
 "def lcumsum ( inlist ) : newlist = copy . deepcopy ( inlist ) for i in range ( 1 , len ( newlist ) ) : newlist[i] = newlist[i] + newlist[i-1] return newlist": 1206,
 "def is_hex_string ( string ) : pattern = re . compile ( r ' [A-Fa-f0-9]+ ' ) if isinstance ( string , six . binary_type ) : string = str ( string ) return pattern . match ( string ) is not None": 1207,
 "def local_accuracy ( X_train , y_train , X_test , y_test , attr_test , model_generator , metric , trained_model ) : X_train , X_test = to_array ( X_train , X_test ) # how many features to mask assert X_train . shape[1] = = X_test . shape[1] # keep nkeep top features and re-train the model for each test explanation yp_test = trained_model . predict ( X_test ) return metric ( yp_test , strip_list ( attr_test ) . sum ( 1 ) ) ": 1208,
 "def doc_to_html ( doc , doc_format = \" ROBOT \" ) : from robot . libdocpkg . htmlwriter import DocToHtml return DocToHtml ( doc_format ) ( doc ) ": 1209,
 "def replace ( scope , strings , source , dest ) : return [s . replace ( source[0] , dest[0] ) for s in strings]": 1210,
 "def parse_datetime ( dt_str ) : date_format = \" %Y-%m-%dT%H : %M : %S %z \" dt_str = dt_str . replace ( \" Z \" , \" +0000 \" ) return datetime . datetime . strptime ( dt_str , date_format ) ": 1211,
 "def pack_triples_numpy ( triples ) : if len ( triples ) = = 0 : return np . array ( [] , dtype = np . int64 ) return np . stack ( list ( map ( _transform_triple_numpy , triples ) ) , axis = 0 ) ": 1212,
 "def str2bytes ( x ) : if type ( x ) is bytes : return x elif type ( x ) is str : return bytes ( [ ord ( i ) for i in x ] ) else : return str2bytes ( str ( x ) ) ": 1213,
 "def visit_Str ( self , node ) : self . result[node] = self . builder . NamedType ( pytype_to_ctype ( str ) ) ": 1214,
 "def string_list_to_array ( l ) : result = javabridge . get_env ( ) . make_object_array ( len ( l ) , javabridge . get_env ( ) . find_class ( \" java/lang/String \" ) ) for i in range ( len ( l ) ) : javabridge . get_env ( ) . set_object_array_element ( result , i , javabridge . get_env ( ) . new_string_utf ( l[i] ) ) return result": 1215,
 "def coerce ( self , value ) : if isinstance ( value , dict ) : value = [value] if not isiterable_notstring ( value ) : value = [value] return [coerce_single_instance ( self . lookup_field , v ) for v in value]": 1216,
 "def drop_bad_characters ( text ) : # Strip all non-ascii and non-printable characters text = ' ' . join ( [c for c in text if c in ALLOWED_CHARS] ) return text": 1217,
 "def removeFromRegistery ( obj ) : \t\t\tif isRabaObject ( obj ) : \t\t_unregisterRabaObjectInstance ( obj ) \telif isRabaList ( obj ) : \t\t_unregisterRabaListInstance ( obj ) ": 1218,
 "def filter_none ( list_of_points ) : remove_elementnone = filter ( lambda p : p is not None , list_of_points ) remove_sublistnone = filter ( lambda p : not contains_none ( p ) , remove_elementnone ) return list ( remove_sublistnone ) ": 1219,
 "def _unzip_handle ( handle ) : if isinstance ( handle , basestring ) : handle = _gzip_open_filename ( handle ) else : handle = _gzip_open_handle ( handle ) return handle": 1220,
 "def _update_texttuple ( self , x , y , s , cs , d ) : pos = ( x , y , cs ) for i , ( old_x , old_y , old_s , old_cs , old_d ) in enumerate ( self . value ) : if ( old_x , old_y , old_cs ) = = pos : self . value[i] = ( old_x , old_y , s , old_cs , d ) return raise ValueError ( \" No text tuple found at {0}! \" . format ( pos ) ) ": 1221,
 "def authenticate ( self , transport , account_name , password = None ) : Authenticator . authenticate ( self , transport , account_name , password ) if password = = None : return self . pre_auth ( transport , account_name ) else : return self . auth ( transport , account_name , password ) ": 1222,
 "def _wait_for_response ( self ) : \t\t\t\twhile not self . server . response_code : \t\t\ttime . sleep ( 2 ) \t\ttime . sleep ( 5 ) \t\tself . server . shutdown ( ) ": 1223,
 "def copy_and_update ( dictionary , update ) : newdict = dictionary . copy ( ) newdict . update ( update ) return newdict": 1224,
 "def _do_auto_predict ( machine , X , *args ) : if auto_predict and hasattr ( machine , \" predict \" ) : return machine . predict ( X ) ": 1225,
 "def row_to_dict ( row ) : o = {} for colname in row . colnames : if isinstance ( row[colname] , np . string_ ) and row[colname] . dtype . kind in [ ' S ' , ' U ' ] : o[colname] = str ( row[colname] ) else : o[colname] = row[colname] return o": 1226,
 "def color_string ( color , string ) : if not color_available : return string return color + string + colorama . Fore . RESET": 1227,
 "def execute ( self , env , args ) : # start the task if env . task . start ( args . task_name ) : env . io . success ( u ' Task Loaded . ' ) ": 1228,
 "def create_tmpfile ( self , content ) : # Not using a context manager to avoid unneccessary identation in test code tmpfile , tmpfilepath = tempfile . mkstemp ( ) self . tmpfiles . append ( tmpfilepath ) with os . fdopen ( tmpfile , \" w \" ) as f : f . write ( content ) return tmpfilepath": 1229,
 "def aandb ( a , b ) : return matrix ( np . logical_and ( a , b ) . astype ( ' float ' ) , a . size ) ": 1230,
 "def json_template ( data , template_name , template_context ) : html = render_to_string ( template_name , template_context ) data = data or {} data[ ' html ' ] = html return HttpResponse ( json_encode ( data ) , content_type = ' application/json ' ) ": 1231,
 "def find ( self , *args , **kwargs ) : return Cursor ( self , *args , wrap = self . document_class , **kwargs ) ": 1232,
 "def unfolding ( tens , i ) : return reshape ( tens . full ( ) , ( np . prod ( tens . n[0 : ( i+1 ) ] ) , -1 ) ) ": 1233,
 "def members ( self , uid = \" * \" , objects = False ) : entries = self . search ( uid = ' * ' ) if objects : return self . memberObjects ( entries ) result = [] for entry in entries : result . append ( entry[1] ) return result": 1234,
 "def flatten_all_but_last ( a ) : ret = tf . reshape ( a , [-1 , tf . shape ( a ) [-1]] ) if not tf . executing_eagerly ( ) : ret . set_shape ( [None] + a . get_shape ( ) . as_list ( ) [-1 : ] ) return ret": 1235,
 "def list_move_to_front ( l , value = ' other ' ) : l = list ( l ) if value in l : l . remove ( value ) l . insert ( 0 , value ) return l": 1236,
 "def afx_small ( ) : hparams = transformer . transformer_tpu ( ) hparams . filter_size = 1024 hparams . num_heads = 4 hparams . num_hidden_layers = 3 hparams . batch_size = 512 return hparams": 1237,
 "def get_span_char_width ( span , column_widths ) : start_column = span[0][1] column_count = get_span_column_count ( span ) total_width = 0 for i in range ( start_column , start_column + column_count ) : total_width + = column_widths[i] total_width + = column_count - 1 return total_width": 1238,
 "def has_attribute ( module_name , attribute_name ) : init_file = ' %s/__init__ . py ' % module_name return any ( [attribute_name in init_line for init_line in open ( init_file ) . readlines ( ) ] ) ": 1239,
 "def sort_genomic_ranges ( rngs ) : return sorted ( rngs , key = lambda x : ( x . chr , x . start , x . end ) ) ": 1240,
 "def is_square_matrix ( mat ) : mat = np . array ( mat ) if mat . ndim ! = 2 : return False shape = mat . shape return shape[0] = = shape[1]": 1241,
 "def save_session ( self , sid , session , namespace = None ) : return self . server . save_session ( sid , session , namespace = namespace or self . namespace ) ": 1242,
 "def is_connected ( self ) : try : return self . socket is not None and self . socket . getsockname ( ) [1] ! = 0 and BaseTransport . is_connected ( self ) except socket . error : return False": 1243,
 "def show ( config ) : with open ( config , ' r ' ) : main . show ( yaml . load ( open ( config ) ) ) ": 1244,
 "def _validate_type_scalar ( self , value ) : if isinstance ( value , _int_types + ( _str_type , float , date , datetime , bool ) ) : return True": 1245,
 "def encode_dataset ( dataset , vocabulary ) : def encode ( features ) : return {k : vocabulary . encode_tf ( v ) for k , v in features . items ( ) } return dataset . map ( encode , num_parallel_calls = tf . data . experimental . AUTOTUNE ) ": 1246,
 "def generate_write_yaml_to_file ( file_name ) : def write_yaml ( config ) : with open ( file_name , ' w+ ' ) as fh : fh . write ( yaml . dump ( config ) ) return write_yaml": 1247,
 "def Stop ( self ) : self . _Close ( ) if self . _rpc_thread . isAlive ( ) : self . _rpc_thread . join ( ) self . _rpc_thread = None": 1248,
 "def is_valid_ipv6 ( ip_str ) : try : socket . inet_pton ( socket . AF_INET6 , ip_str ) except socket . error : return False return True": 1249,
 "def flush ( ) : try : sys . stdout . flush ( ) sys . stderr . flush ( ) except ( AttributeError , ValueError , IOError ) : pass # unsupported try : libc . fflush ( None ) except ( AttributeError , ValueError , IOError ) : pass": 1250,
 "def get_list_representation ( self ) : if self . is_list : return self . list_or_slice else : return self[list ( range ( self . num_examples ) ) ]": 1251,
 "def join ( self ) : \t\t\t\tself . inputfeeder_thread . join ( ) \t\tself . pool . join ( ) \t\tself . resulttracker_thread . join ( ) \t\tself . failuretracker_thread . join ( ) ": 1252,
 "def write_tsv_line_from_list ( linelist , outfp ) : line = ' \\t ' . join ( linelist ) outfp . write ( line ) outfp . write ( ' \\n ' ) ": 1253,
 "def _make_sentence ( txt ) : # Make sure first letter is capitalized txt = txt . strip ( ' ' ) txt = txt[0] . upper ( ) + txt[1 : ] + ' . ' return txt": 1254,
 "def make_directory ( path ) : if not os . path . exists ( path ) : # concurrent writes that try to create the same dir can fail try : os . makedirs ( path ) except OSError as e : if e . errno = = errno . EEXIST : pass else : raise e": 1255,
 "def csv_matrix_print ( classes , table ) : result = \" \" classes . sort ( ) for i in classes : for j in classes : result + = str ( table[i][j] ) + \" , \" result = result[ : -1] + \" \\n \" return result[ : -1]": 1256,
 "def quaternion_to_rotation_matrix ( quaternion ) : c , x , y , z = quaternion return np . array ( [ [c*c + x*x - y*y - z*z , 2*x*y - 2*c*z , 2*x*z + 2*c*y ] , [2*x*y + 2*c*z , c*c - x*x + y*y - z*z , 2*y*z - 2*c*x ] , [2*x*z - 2*c*y , 2*y*z + 2*c*x , c*c - x*x - y*y + z*z] ] , float ) ": 1257,
 "def write_file ( filename , content ) : print ' Generating {0} ' . format ( filename ) with open ( filename , ' wb ' ) as out_f : out_f . write ( content ) ": 1258,
 "def ms_to_datetime ( ms ) : dt = datetime . datetime . utcfromtimestamp ( ms / 1000 ) return dt . replace ( microsecond = ( ms % 1000 ) * 1000 ) . replace ( tzinfo = pytz . utc ) ": 1259,
 "def retry_test ( func ) : success = False ex = Exception ( \" Unknown \" ) for i in six . moves . range ( 3 ) : try : result = func ( ) except Exception as e : time . sleep ( 1 ) ex = e else : success = True break if not success : raise ex assert success return result": 1260,
 "def get_own_ip ( ) : sock = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM ) try : sock . connect ( ( \" 8 . 8 . 8 . 8 \" , 80 ) ) except socket . gaierror : ip_ = \" 127 . 0 . 0 . 1 \" else : ip_ = sock . getsockname ( ) [0] finally : sock . close ( ) return ip_": 1261,
 "def make_aware ( dt ) : return dt if dt . tzinfo else dt . replace ( tzinfo = timezone . utc ) ": 1262,
 "def timestamp_to_datetime ( timestamp ) : from datetime import datetime , timedelta obj = datetime . fromtimestamp ( timestamp[0] ) return obj + timedelta ( microseconds = int ( timestamp[1] ) ) ": 1263,
 "def yview ( self , *args ) : self . after_idle ( self . __updateWnds ) ttk . Treeview . yview ( self , *args ) ": 1264,
 "def is_gzipped_fastq ( file_name ) : _ , ext = os . path . splitext ( file_name ) return file_name . endswith ( \" . fastq . gz \" ) or file_name . endswith ( \" . fq . gz \" ) ": 1265,
 "def get_pg_connection ( host , user , port , password , database , ssl = {} ) : return psycopg2 . connect ( host = host , user = user , port = port , password = password , dbname = database , sslmode = ssl . get ( ' sslmode ' , None ) , sslcert = ssl . get ( ' sslcert ' , None ) , sslkey = ssl . get ( ' sslkey ' , None ) , sslrootcert = ssl . get ( ' sslrootcert ' , None ) , ) ": 1266,
 "def defvalkey ( js , key , default = None , take_none = True ) : if js is None : return default if key not in js : return default if js[key] is None and not take_none : return default return js[key]": 1267,
 "def get_python_dict ( scala_map ) : python_dict = {} keys = get_python_list ( scala_map . keys ( ) . toList ( ) ) for key in keys : python_dict[key] = scala_map . apply ( key ) return python_dict": 1268,
 "def resize_image_to_fit_width ( image , dest_w ) : scale_factor = dest_w / image . size[0] dest_h = image . size[1] * scale_factor scaled_image = image . resize ( ( int ( dest_w ) , int ( dest_h ) ) , PIL . Image . ANTIALIAS ) return scaled_image": 1269,
 "def list ( self ) : return [self . _pos3d . x , self . _pos3d . y , self . _pos3d . z]": 1270,
 "def GetAttributeNs ( self , localName , namespaceURI ) : ret = libxml2mod . xmlTextReaderGetAttributeNs ( self . _o , localName , namespaceURI ) return ret": 1271,
 "def find_geom ( geom , geoms ) : for i , g in enumerate ( geoms ) : if g is geom : return i": 1272,
 "def _using_stdout ( self ) : if WINDOWS and colorama : # Then self . stream is an AnsiToWin32 object . return self . stream . wrapped is sys . stdout return self . stream is sys . stdout": 1273,
 "def _linearInterpolationTransformMatrix ( matrix1 , matrix2 , value ) : return tuple ( _interpolateValue ( matrix1[i] , matrix2[i] , value ) for i in range ( len ( matrix1 ) ) ) ": 1274,
 "def is_unix_style ( flags ) : return ( util . platform ( ) ! = \" windows \" or ( not bool ( flags & REALPATH ) and get_case ( flags ) ) ) and not flags & _FORCEWIN": 1275,
 "def start ( args ) : application = tornado . web . Application ( [ ( r \" /run \" , run . get_handler ( args ) ) , ( r \" /status \" , run . StatusHandler ) ] ) application . runmonitor = RunMonitor ( ) application . listen ( args . port ) tornado . ioloop . IOLoop . instance ( ) . start ( ) ": 1276,
 "def generic_div ( a , b ) : logger . debug ( ' Called generic_div ( {} , {} ) ' . format ( a , b ) ) return a / b": 1277,
 "def mean ( inlist ) : sum = 0 for item in inlist : sum = sum + item return sum / float ( len ( inlist ) ) ": 1278,
 "def _frombuffer ( ptr , frames , channels , dtype ) : framesize = channels * dtype . itemsize data = np . frombuffer ( ffi . buffer ( ptr , frames * framesize ) , dtype = dtype ) data . shape = -1 , channels return data": 1279,
 "def _single_page_pdf ( page ) : pdf = Pdf . new ( ) pdf . pages . append ( page ) bio = BytesIO ( ) pdf . save ( bio ) bio . seek ( 0 ) return bio . read ( ) ": 1280,
 "def query_fetch_one ( self , query , values ) : self . cursor . execute ( query , values ) retval = self . cursor . fetchone ( ) self . __close_db ( ) return retval": 1281,
 "def walk_tree ( root ) : yield root for child in root . children : for el in walk_tree ( child ) : yield el": 1282,
 "def __consistent_isoformat_utc ( datetime_val ) : isotime = datetime_val . astimezone ( pytz . utc ) . strftime ( \" %Y-%m-%dT%H : %M : %S%z \" ) if isotime[-2] ! = \" : \" : isotime = isotime[ : -2] + \" : \" + isotime[-2 : ] return isotime": 1283,
 "def __iter__ ( self ) : \t\t\t\tfor value , count in self . counts ( ) : \t\t\tfor _ in range ( count ) : \t\t\t\tyield value": 1284,
 "def eintr_retry ( exc_type , f , *args , **kwargs ) : while True : try : return f ( *args , **kwargs ) except exc_type as exc : if exc . errno ! = EINTR : raise else : break": 1285,
 "def dt_to_ts ( value ) : if not isinstance ( value , datetime ) : return value return calendar . timegm ( value . utctimetuple ( ) ) + value . microsecond / 1000000 . 0": 1286,
 "def itervalues ( d , **kw ) : if not PY2 : return iter ( d . values ( **kw ) ) return d . itervalues ( **kw ) ": 1287,
 "def norm_slash ( name ) : if isinstance ( name , str ) : return name . replace ( ' / ' , \" \\\\ \" ) if not is_case_sensitive ( ) else name else : return name . replace ( b ' / ' , b \" \\\\ \" ) if not is_case_sensitive ( ) else name": 1288,
 "def get_java_path ( ) : java_home = os . environ . get ( \" JAVA_HOME \" ) return os . path . join ( java_home , BIN_DIR , \" java \" ) ": 1289,
 "def excel_key ( index ) : X = lambda n : ~n and X ( ( n // 26 ) -1 ) + chr ( 65 + ( n % 26 ) ) or ' ' return X ( int ( index ) ) ": 1290,
 "def test_python_java_rt ( ) : sub_env = { ' PYTHONPATH ' : _build_dir ( ) } log . info ( ' Executing Python unit tests ( against Java runtime classes ) . . . ' ) return jpyutil . _execute_python_scripts ( python_java_rt_tests , env = sub_env ) ": 1291,
 "def split_into_sentences ( s ) : s = re . sub ( r \" \\s+ \" , \" \" , s ) s = re . sub ( r \" [\\\\ . \\\\?\\\\!] \" , \" \\n \" , s ) return s . split ( \" \\n \" ) ": 1292,
 "def get_attributes ( var ) : is_valid = partial ( is_valid_in_template , var ) return list ( filter ( is_valid , dir ( var ) ) ) ": 1293,
 "def _sim_fill ( r1 , r2 , imsize ) : bbsize = ( ( max ( r1[ \" max_x \" ] , r2[ \" max_x \" ] ) - min ( r1[ \" min_x \" ] , r2[ \" min_x \" ] ) ) * ( max ( r1[ \" max_y \" ] , r2[ \" max_y \" ] ) - min ( r1[ \" min_y \" ] , r2[ \" min_y \" ] ) ) ) return 1 . 0 - ( bbsize - r1[ \" size \" ] - r2[ \" size \" ] ) / imsize": 1294,
 "def delimited ( items , character = ' | ' ) : return ' | ' . join ( items ) if type ( items ) in ( list , tuple , set ) else items": 1295,
 "def _timestamp_to_json_row ( value ) : if isinstance ( value , datetime . datetime ) : value = _microseconds_from_datetime ( value ) * 1e-6 return value": 1296,
 "def istype ( obj , check ) : if isinstance ( check , tuple ) : for cls in check : if type ( obj ) is cls : return True return False else : return type ( obj ) is check": 1297,
 "def parse_json_date ( value ) : if not value : return None return datetime . datetime . strptime ( value , JSON_DATETIME_FORMAT ) . replace ( tzinfo = pytz . UTC ) ": 1298,
 "def _to_numeric ( val ) : if isinstance ( val , ( int , float , datetime . datetime , datetime . timedelta ) ) : return val return float ( val ) ": 1299,
 "def read_json ( location ) : location = ensure_path ( location ) with location . open ( ' r ' , encoding = ' utf8 ' ) as f : return ujson . load ( f ) ": 1300,
 "def json_serialize ( obj ) : if isinstance ( obj , datetime ) : return obj . isoformat ( ) if hasattr ( obj , ' id ' ) : return jsonify ( obj . id ) if hasattr ( obj , ' name ' ) : return jsonify ( obj . name ) raise TypeError ( ' {0} is not JSON serializable ' . format ( obj ) ) ": 1301,
 "def load_schema ( schema_path ) : with open ( schema_path , ' r ' ) as schema_file : schema = simplejson . load ( schema_file ) resolver = RefResolver ( ' ' , ' ' , schema . get ( ' models ' , {} ) ) return build_request_to_validator_map ( schema , resolver ) ": 1302,
 "def __init__ ( self , testnet = False , dryrun = False ) : self . testnet = testnet self . dryrun = dryrun": 1303,
 "def unique ( iterable ) : seen = set ( ) return [x for x in iterable if x not in seen and not seen . add ( x ) ]": 1304,
 "def test ( ) : command = ' nosetests --with-coverage --cover-package = pwnurl ' status = subprocess . call ( shlex . split ( command ) ) sys . exit ( status ) ": 1305,
 "def kill_process_children ( pid ) : if sys . platform = = \" darwin \" : kill_process_children_osx ( pid ) elif sys . platform = = \" linux \" : kill_process_children_unix ( pid ) else : pass": 1306,
 "def assert_is_not ( expected , actual , message = None , extra = None ) : assert expected is not actual , _assert_fail_message ( message , expected , actual , \" is \" , extra ) ": 1307,
 "def sigterm ( self , signum , frame ) : self . logger . warning ( \" Caught signal %s . Stopping daemon . \" % signum ) sys . exit ( 0 ) ": 1308,
 "def guess_url ( url ) : if url . lower ( ) . startswith ( \" www . \" ) : # syntactic sugar return \" http : //%s \" % url elif url . lower ( ) . startswith ( \" ftp . \" ) : # syntactic sugar return \" ftp : //%s \" % url return url": 1309,
 "def normalize ( v , axis = None , eps = 1e-10 ) : return v / max ( anorm ( v , axis = axis , keepdims = True ) , eps ) ": 1310,
 "def finish_plot ( ) : plt . legend ( ) plt . grid ( color = ' 0 . 7 ' ) plt . xlabel ( ' x ' ) plt . ylabel ( ' y ' ) plt . show ( ) ": 1311,
 "def s3 ( ctx , bucket_name , data_file , region ) : if not ctx . data_file : ctx . data_file = data_file if not ctx . bucket_name : ctx . bucket_name = bucket_name if not ctx . region : ctx . region = region ctx . type = ' s3 ' ": 1312,
 "def is_safe_url ( url , host = None ) : if not url : return False netloc = urlparse . urlparse ( url ) [1] return not netloc or netloc = = host": 1313,
 "def tail ( self , n = 10 ) : with cython_context ( ) : return SArray ( _proxy = self . __proxy__ . tail ( n ) ) ": 1314,
 "def get_url_args ( url ) : url_data = urllib . parse . urlparse ( url ) arg_dict = urllib . parse . parse_qs ( url_data . query ) return arg_dict": 1315,
 "def colorbar ( height , length , colormap ) : cbar = np . tile ( np . arange ( length ) * 1 . 0 / ( length - 1 ) , ( height , 1 ) ) cbar = ( cbar * ( colormap . values . max ( ) - colormap . values . min ( ) ) + colormap . values . min ( ) ) return colormap . colorize ( cbar ) ": 1316,
 "def set_empty ( self , row , column ) : subplot = self . get_subplot_at ( row , column ) subplot . set_empty ( ) ": 1317,
 "def fromDict ( cls , _dict ) : obj = cls ( ) obj . __dict__ . update ( _dict ) return obj": 1318,
 "def _requiredSize ( shape , dtype ) : \t\treturn math . floor ( np . prod ( np . asarray ( shape , dtype = np . uint64 ) ) * np . dtype ( dtype ) . itemsize ) ": 1319,
 "def normalized ( vector ) : length = numpy . sum ( vector * vector , axis = -1 ) length = numpy . sqrt ( length . reshape ( length . shape + ( 1 , ) ) ) return vector / length": 1320,
 "def static_method ( cls , f ) : setattr ( cls , f . __name__ , staticmethod ( f ) ) return f": 1321,
 "def align_to_mmap ( num , round_up ) : res = ( num // ALLOCATIONGRANULARITY ) * ALLOCATIONGRANULARITY if round_up and ( res ! = num ) : res + = ALLOCATIONGRANULARITY # END handle size return res": 1322,
 "def set ( self , f ) : self . stop ( ) self . _create_timer ( f ) self . start ( ) ": 1323,
 "def close ( self ) : \t\t\t\tif self . _initialized : \t\t\tself . stop ( ) \t\tself . logged_in = False\t\treturn self . serial_h . close ( ) ": 1324,
 "def test ( ) : try : while 1 : x , digs = input ( ' Enter ( x , digs ) : ' ) print x , fix ( x , digs ) , sci ( x , digs ) except ( EOFError , KeyboardInterrupt ) : pass": 1325,
 "def get_flat_size ( self ) : return sum ( np . prod ( v . get_shape ( ) . as_list ( ) ) for v in self . variables . values ( ) ) ": 1326,
 "def read_credentials ( fname ) : with open ( fname , ' r ' ) as f : username = f . readline ( ) . strip ( ' \\n ' ) password = f . readline ( ) . strip ( ' \\n ' ) return username , password": 1327,
 "def b2u ( string ) : if ( isinstance ( string , bytes ) or ( PY2 and isinstance ( string , str ) ) ) : return string . decode ( ' utf-8 ' ) return string": 1328,
 "def validate_int ( value ) : if value and not isinstance ( value , int ) : try : int ( str ( value ) ) except ( TypeError , ValueError ) : raise ValidationError ( ' not a valid number ' ) return value": 1329,
 "def list2dict ( list_of_options ) : d = {} for key , value in list_of_options : d[key] = value return d": 1330,
 "def _values ( self ) : return [ val for serie in self . series for val in serie . values if val is not None ]": 1331,
 "def check_X_y ( X , y ) : if len ( X ) ! = len ( y ) : raise ValueError ( ' Inconsistent input and output data shapes . ' \\ ' found X : {} and y : {} ' . format ( X . shape , y . shape ) ) ": 1332,
 "def AsPrimitiveProto ( self ) : if self . protobuf : result = self . protobuf ( ) result . ParseFromString ( self . SerializeToString ( ) ) return result": 1333,
 "def sav_to_pandas_rpy2 ( input_file ) : import pandas . rpy . common as com w = com . robj . r ( ' foreign : : read . spss ( \" %s \" , to . data . frame = TRUE ) ' % input_file ) return com . convert_robj ( w ) ": 1334,
 "def is_timestamp ( instance ) : if not isinstance ( instance , ( int , str ) ) : return True return datetime . fromtimestamp ( int ( instance ) ) ": 1335,
 "def ln_norm ( x , mu , sigma = 1 . 0 ) : return np . log ( stats . norm ( loc = mu , scale = sigma ) . pdf ( x ) ) ": 1336,
 "def iter_except_top_row_tcs ( self ) : for tr in self . _tbl . tr_lst[self . _top + 1 : self . _bottom] : for tc in tr . tc_lst[self . _left : self . _right] : yield tc": 1337,
 "def web ( host , port ) : from . webserver . web import get_app get_app ( ) . run ( host = host , port = port ) ": 1338,
 "def get_type ( self ) : item_type = self . xmlnode . prop ( \" type \" ) if not item_type : item_type = \" ? \" return item_type . decode ( \" utf-8 \" ) ": 1339,
 "def _is_osx_107 ( ) : if sys . platform ! = ' darwin ' : return False version = platform . mac_ver ( ) [0] return tuple ( map ( int , version . split ( ' . ' ) ) ) [0 : 2] = = ( 10 , 7 ) ": 1340,
 "def close_other_windows ( self ) : main_window_handle = self . current_window_handle for window_handle in self . window_handles : if window_handle = = main_window_handle : continue self . switch_to_window ( window_handle ) self . close ( ) self . switch_to_window ( main_window_handle ) ": 1341,
 "def swap_memory ( ) : mem = _psutil_mswindows . get_virtual_mem ( ) total = mem[2] free = mem[3] used = total - free percent = usage_percent ( used , total , _round = 1 ) return nt_swapmeminfo ( total , used , free , percent , 0 , 0 ) ": 1342,
 "def from_pb ( cls , pb ) : obj = cls . _from_pb ( pb ) obj . _pb = pb return obj": 1343,
 "def _write_json ( file , contents ) : with open ( file , ' w ' ) as f : return json . dump ( contents , f , indent = 2 , sort_keys = True ) ": 1344,
 "def dedupe ( items ) : seen = set ( ) for item in items : if item not in seen : yield item seen . add ( item ) ": 1345,
 "def set_property ( self , key , value ) : self . properties[key] = value self . sync_properties ( ) ": 1346,
 "def _write_color_colorama ( fp , text , color ) : foreground , background , style = get_win_color ( color ) colorama . set_console ( foreground = foreground , background = background , style = style ) fp . write ( text ) colorama . reset_console ( ) ": 1347,
 "def zeros ( self , name , **kwargs ) : return self . _write_op ( self . _zeros_nosync , name , **kwargs ) ": 1348,
 "def save_dict_to_file ( filename , dictionary ) : with open ( filename , ' w ' ) as f : writer = csv . writer ( f ) for k , v in iteritems ( dictionary ) : writer . writerow ( [str ( k ) , str ( v ) ] ) ": 1349,
 "def average_gradient ( data , *kwargs ) : return np . average ( np . array ( np . gradient ( data ) ) **2 ) ": 1350,
 "def safe_dump ( data , stream = None , **kwds ) : return yaml . dump ( data , stream = stream , Dumper = ODYD , **kwds ) ": 1351,
 "def add_plot ( x , y , xl , yl , fig , ax , LATEX = False , linestyle = None , **kwargs ) : if LATEX : xl_data = xl[1] # NOQA yl_data = yl[1] else : xl_data = xl[0] # NOQA yl_data = yl[0] for idx in range ( len ( y ) ) : ax . plot ( x , y[idx] , label = yl_data[idx] , linestyle = linestyle ) ax . legend ( loc = ' upper right ' ) ax . set_ylim ( auto = True ) ": 1352,
 "def load_yaml_file ( file_path : str ) : with codecs . open ( file_path , ' r ' ) as f : return yaml . safe_load ( f ) ": 1353,
 "def safe_unicode ( string ) : if not PY3 : uni = string . replace ( u ' \\u2019 ' , \" ' \" ) return uni . encode ( ' utf-8 ' ) return string": 1354,
 "def yaml_to_param ( obj , name ) : \t\treturn from_pyvalue ( u \" yaml : %s \" % name , unicode ( yaml . dump ( obj ) ) ) ": 1355,
 "def url_fix_common_typos ( url ) : if url . startswith ( \" http// \" ) : url = \" http : // \" + url[6 : ] elif url . startswith ( \" https// \" ) : url = \" https : // \" + url[7 : ] return url": 1356,
 "def yaml ( self ) : return ordered_dump ( OrderedDict ( self ) , Dumper = yaml . SafeDumper , default_flow_style = False ) ": 1357,
 "def matshow ( *args , **kwargs ) : kwargs[ ' interpolation ' ] = kwargs . pop ( ' interpolation ' , ' none ' ) return plt . imshow ( *args , **kwargs ) ": 1358,
 "def extract_all ( zipfile , dest_folder ) : z = ZipFile ( zipfile ) print ( z ) z . extract ( dest_folder ) ": 1359,
 "def handle_m2m ( self , sender , instance , **kwargs ) : self . handle_save ( instance . __class__ , instance ) ": 1360,
 "def extract ( self , destination ) : with zipfile . ZipFile ( self . archive , ' r ' ) as zip_ref : zip_ref . extractall ( destination ) ": 1361,
 "def compress ( data , **kwargs ) : + zopfli . __COMPRESSOR_DOCSTRING__ + \" \" \" Returns : String containing a zlib container \" \" \" kwargs[ ' gzip_mode ' ] = 0 return zopfli . zopfli . compress ( data , **kwargs ) ": 1362,
 "def init_mq ( self ) : mq = self . init_connection ( ) self . init_consumer ( mq ) return mq . connection": 1363,
 "def is_real_floating_dtype ( dtype ) : dtype = np . dtype ( dtype ) return np . issubsctype ( getattr ( dtype , ' base ' , None ) , np . floating ) ": 1364,
 "def max ( self ) : return int ( self . _max ) if not np . isinf ( self . _max ) else self . _max": 1365,
 "def log_loss ( preds , labels ) : log_likelihood = np . sum ( labels * np . log ( preds ) ) / len ( preds ) return -log_likelihood": 1366,
 "def list_of_lists_to_dict ( l ) : d = {} for key , val in l : d . setdefault ( key , [] ) . append ( val ) return d": 1367,
 "def longest_run_1d ( arr ) : v , rl = rle_1d ( arr ) [ : 2] return np . where ( v , rl , 0 ) . max ( ) ": 1368,
 "def simulate ( self ) : min_ = ( -sys . maxsize - 1 ) if self . _min is None else self . _min max_ = sys . maxsize if self . _max is None else self . _max return random . randint ( min_ , max_ ) ": 1369,
 "def in_directory ( path ) : curdir = os . path . abspath ( os . curdir ) os . chdir ( path ) yield os . chdir ( curdir ) ": 1370,
 "def median ( data ) : data . sort ( ) num_values = len ( data ) half = num_values // 2 if num_values % 2 : return data[half] return 0 . 5 * ( data[half-1] + data[half] ) ": 1371,
 "def append_pdf ( input_pdf : bytes , output_writer : PdfFileWriter ) : append_memory_pdf_to_writer ( input_pdf = input_pdf , writer = output_writer ) ": 1372,
 "def date_to_timestamp ( date ) : date_tuple = date . timetuple ( ) timestamp = calendar . timegm ( date_tuple ) * 1000 return timestamp": 1373,
 "def FindMethodByName ( self , name ) : for method in self . methods : if name = = method . name : return method return None": 1374,
 "def mock_decorator ( *args , **kwargs ) : def _called_decorator ( dec_func ) : @wraps ( dec_func ) def _decorator ( *args , **kwargs ) : return dec_func ( ) return _decorator return _called_decorator": 1375,
 "def add_matplotlib_cmap ( cm , name = None ) : global cmaps cmap = matplotlib_to_ginga_cmap ( cm , name = name ) cmaps[cmap . name] = cmap": 1376,
 "def to_bytes ( value ) : vtype = type ( value ) if vtype = = bytes or vtype = = type ( None ) : return value try : return vtype . encode ( value ) except UnicodeEncodeError : pass return value": 1377,
 "def find_one ( self , query ) : mongo_response = yield self . collection . find_one ( query ) raise Return ( self . _obj_cursor_to_dictionary ( mongo_response ) ) ": 1378,
 "def loadb ( b ) : assert isinstance ( b , ( bytes , bytearray ) ) return std_json . loads ( b . decode ( ' utf-8 ' ) ) ": 1379,
 "def test_replace_colon ( ) : data = ( ( \" zone : aap \" , ' @ ' , \" zone@aap \" ) , # s , r , replaced ) for s , r , replaced in data : result = replace_colon ( s , r ) assert result = = replaced": 1380,
 "def init_rotating_logger ( level , logfile , max_files , max_bytes ) : logging . basicConfig ( ) root_logger = logging . getLogger ( ) log_format = \" [% ( asctime ) s] [% ( levelname ) s] % ( filename ) s : % ( message ) s \" root_logger . setLevel ( level ) handler = RotatingFileHandler ( logfile , maxBytes = max_bytes , backupCount = max_files ) handler . setFormatter ( logging . Formatter ( fmt = log_format , datefmt = date_format ) ) root_logger . addHandler ( handler ) for handler in root_logger . handlers : root_logger . debug ( \" Associated handlers - \" + str ( handler ) ) if isinstance ( handler , logging . StreamHandler ) : root_logger . debug ( \" Removing StreamHandler : \" + str ( handler ) ) root_logger . handlers . remove ( handler ) ": 1381,
 "def main ( ctx , connection ) : ctx . obj = Manager ( connection = connection ) ctx . obj . bind ( ) ": 1382,
 "def maybeparens ( lparen , item , rparen ) : return item | lparen . suppress ( ) + item + rparen . suppress ( ) ": 1383,
 "def now ( timezone = None ) : d = datetime . datetime . utcnow ( ) if not timezone : return d return to_timezone ( d , timezone ) . replace ( tzinfo = None ) ": 1384,
 "def matrixTimesVector ( MM , aa ) : bb = np . zeros ( 3 , np . float ) for ii in range ( 3 ) : bb[ii] = np . sum ( MM[ii , : ] * aa ) return bb": 1385,
 "def redirect_stdout ( new_stdout ) : old_stdout , sys . stdout = sys . stdout , new_stdout try : yield None finally : sys . stdout = old_stdout": 1386,
 "def _check_and_convert_bools ( self ) : replacements = { True : ' T ' , False : ' F ' , } for key in self . bools : if isinstance ( self[key] , bool ) : self[key] = replacements[self[key]]": 1387,
 "def __exit__ ( self , *exc ) : if exc[0] is None and exc[1] is None and exc[2] is None : self . commit ( ) else : self . rollback ( ) ": 1388,
 "def stringify_dict_contents ( dct ) : return { str_if_nested_or_str ( k ) : str_if_nested_or_str ( v ) for k , v in dct . items ( ) }": 1389,
 "def up ( self ) : i = self . index ( ) if i ! = None : del self . canvas . layers[i] i = min ( len ( self . canvas . layers ) , i+1 ) self . canvas . layers . insert ( i , self ) ": 1390,
 "def pretty_dict_string ( d , indent = 0 ) : s = ' ' for key , value in sorted ( d . items ( ) ) : s + = ' ' * indent + str ( key ) if isinstance ( value , dict ) : s + = ' \\n ' + pretty_dict_string ( value , indent+1 ) else : s + = ' = ' + str ( value ) + ' \\n ' return s": 1391,
 "def set_locale ( request ) : return request . query . get ( ' lang ' , app . ps . babel . select_locale_by_request ( request ) ) ": 1392,
 "def is_power_of_2 ( num ) : log = math . log2 ( num ) return int ( log ) = = float ( log ) ": 1393,
 "def _qrcode_to_file ( qrcode , out_filepath ) : try : qrcode . save ( out_filepath ) except Exception as exc : raise IOError ( ' Error trying to save QR code file {} . ' . format ( out_filepath ) ) from exc else : return qrcode": 1394,
 "def copy ( obj ) : def copy ( self ) : from copy import deepcopy return deepcopy ( self ) obj . copy = copy return obj": 1395,
 "def shot_noise ( x , severity = 1 ) : c = [60 , 25 , 12 , 5 , 3][severity - 1] x = np . array ( x ) / 255 . x_clip = np . clip ( np . random . poisson ( x * c ) / float ( c ) , 0 , 1 ) * 255 return around_and_astype ( x_clip ) ": 1396,
 "def _normalize ( image ) : offset = tf . constant ( MEAN_RGB , shape = [1 , 1 , 3] ) image - = offset scale = tf . constant ( STDDEV_RGB , shape = [1 , 1 , 3] ) image / = scale return image": 1397,
 "def sometimesish ( fn ) : def wrapped ( *args , **kwargs ) : if random . randint ( 1 , 2 ) = = 1 : return fn ( *args , **kwargs ) return wrapped": 1398,
 "def log_normalize ( data ) : if sp . issparse ( data ) : data = data . copy ( ) data . data = np . log2 ( data . data + 1 ) return data return np . log2 ( data . astype ( np . float64 ) + 1 ) ": 1399,
 "def runiform ( lower , upper , size = None ) : return np . random . uniform ( lower , upper , size ) ": 1400,
 "def decode_arr ( data ) : data = data . encode ( ' utf-8 ' ) return frombuffer ( base64 . b64decode ( data ) , float64 ) ": 1401,
 "def input ( self , pin ) : return self . mraa_gpio . Gpio . read ( self . mraa_gpio . Gpio ( pin ) ) ": 1402,
 "def _iter_keys ( key ) : for i in range ( winreg . QueryInfoKey ( key ) [0] ) : yield winreg . OpenKey ( key , winreg . EnumKey ( key , i ) ) ": 1403,
 "def shape ( self ) : if not self . data : return ( 0 , 0 ) return ( len ( self . data ) , len ( self . dimensions ) ) ": 1404,
 "def one_hot2string ( arr , vocab ) : tokens = one_hot2token ( arr ) indexToLetter = _get_index_dict ( vocab ) return [ ' ' . join ( [indexToLetter[x] for x in row] ) for row in tokens]": 1405,
 "def lambda_from_file ( python_file ) : lambda_function = [] with open ( python_file , ' r ' ) as f : lambda_function . extend ( f . read ( ) . splitlines ( ) ) return awslambda . Code ( ZipFile = ( Join ( ' \\n ' , lambda_function ) ) ) ": 1406,
 "def reverse_code_map ( self ) : return {c . value : ( c . ikey if c . ikey else c . key ) for c in self . codes}": 1407,
 "def html_to_text ( content ) : text = None h2t = html2text . HTML2Text ( ) h2t . ignore_links = False text = h2t . handle ( content ) return text": 1408,
 "def _loadfilepath ( self , filepath , **kwargs ) : with open ( filepath , \" r \" ) as f : data = json . load ( f , **kwargs ) return data": 1409,
 "def get ( url ) : response = urllib . request . urlopen ( url ) data = response . read ( ) data = data . decode ( \" utf-8 \" ) data = json . loads ( data ) return data": 1410,
 "def cli ( yamlfile , root , format ) : print ( CsvGenerator ( yamlfile , format ) . serialize ( classes = root ) ) ": 1411,
 "def dimensions ( path ) : pdf = PdfFileReader ( path ) size = pdf . getPage ( 0 ) . mediaBox return { ' w ' : float ( size[2] ) , ' h ' : float ( size[3] ) }": 1412,
 "def list_apis ( awsclient ) : client_api = awsclient . get_client ( ' apigateway ' ) apis = client_api . get_rest_apis ( ) [ ' items ' ] for api in apis : print ( json2table ( api ) ) ": 1413,
 "def execfile ( fname , variables ) : with open ( fname ) as f : code = compile ( f . read ( ) , fname , ' exec ' ) exec ( code , variables ) ": 1414,
 "def get_code ( module ) : fp = open ( module . path ) try : return compile ( fp . read ( ) , str ( module . name ) , ' exec ' ) finally : fp . close ( ) ": 1415,
 "def aux_insertTree ( childTree , parentTree ) : \t\tif childTree . x1 ! = None and childTree . x2 ! = None : \t\tparentTree . insert ( childTree . x1 , childTree . x2 , childTree . name , childTree . referedObject ) \tfor c in childTree . children : \t\taux_insertTree ( c , parentTree ) ": 1416,
 "def do_serial ( self , p ) : \t\t\t\ttry : \t\t\tself . serial . port = p\t\t\tself . serial . open ( ) \t\t\tprint ' Opening serial port : %s ' % p\t\texcept Exception , e : \t\t\tprint ' Unable to open serial port : %s ' % p": 1417,
 "def get_feature_order ( dataset , features ) : all_features = dataset . get_feature_names ( ) i = [all_features . index ( f ) for f in features] return i": 1418,
 "def circ_permutation ( items ) : permutations = [] for i in range ( len ( items ) ) : permutations . append ( items[i : ] + items[ : i] ) return permutations": 1419,
 "def _format_list ( result ) : if not result : return result if isinstance ( result[0] , dict ) : return _format_list_objects ( result ) table = Table ( [ ' value ' ] ) for item in result : table . add_row ( [iter_to_table ( item ) ] ) return table": 1420,
 "def redirect ( view = None , url = None , **kwargs ) : if view : if url : kwargs[ \" url \" ] = url url = flask . url_for ( view , **kwargs ) current_context . exit ( flask . redirect ( url ) ) ": 1421,
 "def zero_pad ( m , n = 1 ) : return np . pad ( m , ( n , n ) , mode = ' constant ' , constant_values = [0] ) ": 1422,
 "def get ( self , key ) : res = self . connection . get ( key ) print ( res ) return res": 1423,
 "def format_screen ( strng ) : # Paragraph continue par_re = re . compile ( r ' \\\\$ ' , re . MULTILINE ) strng = par_re . sub ( ' ' , strng ) return strng": 1424,
 "def old_pad ( s ) : if len ( s ) % OLD_BLOCK_SIZE = = 0 : return s return Padding . appendPadding ( s , blocksize = OLD_BLOCK_SIZE ) ": 1425,
 "def path ( self ) : return pathlib . Path ( self . package . __file__ ) . resolve ( ) . parent . parent": 1426,
 "def get_max ( qs , field ) : max_field = ' %s__max ' % field num = qs . aggregate ( Max ( field ) ) [max_field] return num if num else 0": 1427,
 "def remove ( self , path ) : p = self . cmd ( ' shell ' , ' rm ' , path ) stdout , stderr = p . communicate ( ) if stdout or stderr : return False else : return True": 1428,
 "def parse ( self ) : f = open ( self . parse_log_path , \" r \" ) self . parse2 ( f ) f . close ( ) ": 1429,
 "def parse_obj ( o ) : r = {} for k , v in o . items ( ) : if is_unable_to_connect ( v ) : r[k] = None try : r[k] = parse_value ( k , v ) except ( ObdPidParserUnknownError , AttributeError , TypeError ) : r[k] = None return r": 1430,
 "def remove_list_duplicates ( lista , unique = False ) : result = [] allready = [] for elem in lista : if elem not in result : result . append ( elem ) else : allready . append ( elem ) if unique : for elem in allready : result = list ( filter ( ( elem ) . __ne__ , result ) ) return result": 1431,
 "def arg_default ( *args , **kwargs ) : parser = argparse . ArgumentParser ( ) parser . add_argument ( *args , **kwargs ) args = vars ( parser . parse_args ( [] ) ) _ , default = args . popitem ( ) return default": 1432,
 "def def_linear ( fun ) : defjvp_argnum ( fun , lambda argnum , g , ans , args , kwargs : fun ( *subval ( args , argnum , g ) , **kwargs ) ) ": 1433,
 "def add_to_parser ( self , parser ) : kwargs = self . _get_kwargs ( ) args = self . _get_args ( ) parser . add_argument ( *args , **kwargs ) ": 1434,
 "def random_choice ( sequence ) : return random . choice ( tuple ( sequence ) if isinstance ( sequence , set ) else sequence ) ": 1435,
 "def unescape ( str ) : out = ' ' prev_backslash = False for char in str : if not prev_backslash and char = = ' \\\\ ' : prev_backslash = True continue out + = char prev_backslash = False return out": 1436,
 "def strip_columns ( tab ) : for colname in tab . colnames : if tab[colname] . dtype . kind in [ ' S ' , ' U ' ] : tab[colname] = np . core . defchararray . strip ( tab[colname] ) ": 1437,
 "def export_all ( self ) : \t\tquery = \t\tfields = ' text ' , ' library ' , ' log_id ' \t\treturn ( dict ( zip ( fields , res ) ) for res in self . db . execute ( query ) ) ": 1438,
 "def seq_to_str ( obj , sep = \" , \" ) : if isinstance ( obj , string_classes ) : return obj elif isinstance ( obj , ( list , tuple ) ) : return sep . join ( [str ( x ) for x in obj] ) else : return str ( obj ) ": 1439,
 "def _precision_recall ( y_true , y_score , ax = None ) : precision , recall , _ = precision_recall_curve ( y_true , y_score ) average_precision = average_precision_score ( y_true , y_score ) if ax is None : ax = plt . gca ( ) ax . plot ( recall , precision , label = ( ' Precision-Recall curve : AUC = {0 : 0 . 2f} ' . format ( average_precision ) ) ) _set_ax_settings ( ax ) return ax": 1440,
 "def remove_dups ( seq ) : seen = set ( ) seen_add = seen . add return [x for x in seq if not ( x in seen or seen_add ( x ) ) ]": 1441,
 "def format_prettytable ( table ) : for i , row in enumerate ( table . rows ) : for j , item in enumerate ( row ) : table . rows[i][j] = format_output ( item ) ptable = table . prettytable ( ) ptable . hrules = prettytable . FRAME ptable . horizontal_char = ' . ' ptable . vertical_char = ' : ' ptable . junction_char = ' : ' return ptable": 1442,
 "def _RemoveIllegalXMLCharacters ( self , xml_string ) : if not isinstance ( xml_string , py2to3 . STRING_TYPES ) : return xml_string return self . _ILLEGAL_XML_RE . sub ( ' \\ufffd ' , xml_string ) ": 1443,
 "def pylog ( self , *args , **kwargs ) : printerr ( self . name , args , kwargs , traceback . format_exc ( ) ) ": 1444,
 "def strip_accents ( s ) : nfkd = unicodedata . normalize ( ' NFKD ' , unicode ( s ) ) return u ' ' . join ( ch for ch in nfkd if not unicodedata . combining ( ch ) ) ": 1445,
 "def indented_show ( text , howmany = 1 ) : print ( StrTemplate . pad_indent ( text = text , howmany = howmany ) ) ": 1446,
 "def key_to_metric ( self , key ) : return ' ' . join ( l if l in string . letters else ' _ ' for l in key ) ": 1447,
 "def get_ram ( self , format_ = \" nl \" ) : \t\t\t\tram = [self . ram . read ( i ) for i in range ( self . ram . size ) ]\t\treturn self . _format_mem ( ram , format_ ) ": 1448,
 "def strip_querystring ( url ) : p = six . moves . urllib . parse . urlparse ( url ) return p . scheme + \" : // \" + p . netloc + p . path": 1449,
 "def dedupe_list ( seq ) : seen = set ( ) return [x for x in seq if not ( x in seen or seen . add ( x ) ) ]": 1450,
 "def to_str ( s ) : if isinstance ( s , bytes ) : s = s . decode ( ' utf-8 ' ) elif not isinstance ( s , str ) : s = str ( s ) return s": 1451,
 "def printOut ( value , end = ' \\n ' ) : sys . stdout . write ( value ) sys . stdout . write ( end ) sys . stdout . flush ( ) ": 1452,
 "def normalize_value ( text ) : result = text . replace ( ' \\n ' , ' ' ) result = re . subn ( ' [ ]{2 , } ' , ' ' , result ) [0] return result": 1453,
 "def IndexOfNth ( s , value , n ) : remaining = n for i in xrange ( 0 , len ( s ) ) : if s[i] = = value : remaining - = 1 if remaining = = 0 : return i return -1": 1454,
 "def remove_file_from_s3 ( awsclient , bucket , key ) : client_s3 = awsclient . get_client ( ' s3 ' ) response = client_s3 . delete_object ( Bucket = bucket , Key = key ) ": 1455,
 "def get_trace_id_from_flask ( ) : if flask is None or not flask . request : return None header = flask . request . headers . get ( _FLASK_TRACE_HEADER ) if header is None : return None trace_id = header . split ( \" / \" , 1 ) [0] return trace_id": 1456,
 "def current_memory_usage ( ) : import psutil proc = psutil . Process ( os . getpid ( ) ) # meminfo = proc . get_memory_info ( ) meminfo = proc . memory_info ( ) rss = meminfo[0] # Resident Set Size / Mem Usage vms = meminfo[1] # Virtual Memory Size / VM Size # NOQA return rss": 1457,
 "def _idx_col2rowm ( d ) : if 0 = = len ( d ) : return 1 if 1 = = len ( d ) : return np . arange ( d[0] ) # order = ' F ' indicates column-major ordering idx = np . array ( np . arange ( np . prod ( d ) ) ) . reshape ( d , order = ' F ' ) . T return idx . flatten ( order = ' F ' ) ": 1458,
 "def get_memory_usage ( ) : process = psutil . Process ( os . getpid ( ) ) mem = process . memory_info ( ) . rss return mem / ( 1024 * 1024 ) ": 1459,
 "def _replace_token_range ( tokens , start , end , replacement ) : tokens = tokens[ : start] + replacement + tokens[end : ] return tokens": 1460,
 "def parse ( self ) : data = [] # add name of section for row in self . soup . find_all ( \" tr \" ) : # cycle through all rows parsed = self . _parse_row ( row ) if parsed : data . append ( parsed ) return data": 1461,
 "def stringify_col ( df , col_name ) : df = df . copy ( ) df[col_name] = df[col_name] . fillna ( \" \" ) df[col_name] = df[col_name] . astype ( str ) return df": 1462,
 "def add_0x ( string ) : if isinstance ( string , bytes ) : string = string . decode ( ' utf-8 ' ) return ' 0x ' + str ( string ) ": 1463,
 "def parse_form ( self , req , name , field ) : return get_value ( req . body_arguments , name , field ) ": 1464,
 "def warn_deprecated ( message , stacklevel = 2 ) : # pragma : no cover warnings . warn ( message , category = DeprecationWarning , stacklevel = stacklevel ) ": 1465,
 "def resize_by_area ( img , size ) : return tf . to_int64 ( tf . image . resize_images ( img , [size , size] , tf . image . ResizeMethod . AREA ) ) ": 1466,
 "def raw_print ( *args , **kw ) : print ( *args , sep = kw . get ( ' sep ' , ' ' ) , end = kw . get ( ' end ' , ' \\n ' ) , file = sys . __stdout__ ) sys . __stdout__ . flush ( ) ": 1467,
 "def popup ( self , title , callfn , initialdir = None ) : super ( DirectorySelection , self ) . popup ( title , callfn , initialdir ) ": 1468,
 "def command_py2to3 ( args ) : from lib2to3 . main import main sys . exit ( main ( \" lib2to3 . fixes \" , args = args . sources ) ) ": 1469,
 "def __is_bound_method ( method ) : if not ( hasattr ( method , \" __func__ \" ) and hasattr ( method , \" __self__ \" ) ) : return False # Bound methods have a __self__ attribute pointing to the owner instance return six . get_method_self ( method ) is not None": 1470,
 "def clean_url ( url ) : if not url . startswith ( ( ' http : // ' , ' https : // ' ) ) : url = f ' http : //{url} ' if not URL_RE . match ( url ) : raise BadURLException ( f ' {url} is not valid ' ) return url": 1471,
 "def stft_magnitude ( signal , fft_length , hop_length = None , window_length = None ) : frames = frame ( signal , window_length , hop_length ) # Apply frame window to each frame . We use a periodic Hann ( cosine of period # window_length ) instead of the symmetric Hann of np . hanning ( period # window_length-1 ) . window = periodic_hann ( window_length ) windowed_frames = frames * window return np . abs ( np . fft . rfft ( windowed_frames , int ( fft_length ) ) ) ": 1472,
 "def make_unique_ngrams ( s , n ) : return set ( s[i : i + n] for i in range ( len ( s ) - n + 1 ) ) ": 1473,
 "def module_name ( self ) : if not self . view_func : return None elif self . _controller_cls : rv = inspect . getmodule ( self . _controller_cls ) . __name__ return rv return inspect . getmodule ( self . view_func ) . __name__": 1474,
 "def _is_leap_year ( year ) : isleap = ( ( np . mod ( year , 4 ) = = 0 ) & ( ( np . mod ( year , 100 ) ! = 0 ) | ( np . mod ( year , 400 ) = = 0 ) ) ) return isleap": 1475,
 "def first_sunday ( self , year , month ) : date = datetime ( year , month , 1 , 0 ) days_until_sunday = 6 - date . weekday ( ) return date + timedelta ( days = days_until_sunday ) ": 1476,
 "def series_index ( self , series ) : for idx , s in enumerate ( self ) : if series is s : return idx raise ValueError ( ' series not in chart data object ' ) ": 1477,
 "def right_outer ( self ) : self . get_collections_data ( ) right_outer_join = self . merge_join_docs ( set ( self . collections_data[ ' right ' ] . keys ( ) ) ) return right_outer_join": 1478,
 "def input_int_default ( question = \" \" , default = 0 ) : answer = input_string ( question ) if answer = = \" \" or answer = = \" yes \" : return default else : return int ( answer ) ": 1479,
 "def to_dict ( dictish ) : if hasattr ( dictish , ' iterkeys ' ) : m = dictish . iterkeys elif hasattr ( dictish , ' keys ' ) : m = dictish . keys else : raise ValueError ( dictish ) return dict ( ( k , dictish[k] ) for k in m ( ) ) ": 1480,
 "def shallow_reverse ( g ) : new_g = networkx . DiGraph ( ) new_g . add_nodes_from ( g . nodes ( ) ) for src , dst , data in g . edges ( data = True ) : new_g . add_edge ( dst , src , **data ) return new_g": 1481,
 "def __matches ( s1 , s2 , ngrams_fn , n = 3 ) : ngrams1 , ngrams2 = set ( ngrams_fn ( s1 , n = n ) ) , set ( ngrams_fn ( s2 , n = n ) ) return ngrams1 . intersection ( ngrams2 ) ": 1482,
 "def sf01 ( arr ) : s = arr . shape return arr . swapaxes ( 0 , 1 ) . reshape ( s[0] * s[1] , *s[2 : ] ) ": 1483,
 "def _rotate ( n , x , y , rx , ry ) : if ry = = 0 : if rx = = 1 : x = n - 1 - x y = n - 1 - y return y , x return x , y": 1484,
 "def redirect_output ( fileobj ) : old = sys . stdout sys . stdout = fileobj try : yield fileobj finally : sys . stdout = old": 1485,
 "def Slice ( a , begin , size ) : return np . copy ( a ) [[slice ( *tpl ) for tpl in zip ( begin , begin+size ) ]] , ": 1486,
 "def round_array ( array_in ) : if isinstance ( array_in , ndarray ) : return np . round ( array_in ) . astype ( int ) else : return int ( np . round ( array_in ) ) ": 1487,
 "def normalize ( self , string ) : return ' ' . join ( [self . _normalize . get ( x , x ) for x in nfd ( string ) ] ) ": 1488,
 "def lower_ext ( abspath ) : fname , ext = os . path . splitext ( abspath ) return fname + ext . lower ( ) ": 1489,
 "def _linear_interpolation ( x , X , Y ) : return ( Y[1] * ( x - X[0] ) + Y[0] * ( X[1] - x ) ) / ( X[1] - X[0] ) ": 1490,
 "def __call__ ( self , func , *args , **kwargs ) : return self . run ( func , *args , **kwargs ) ": 1491,
 "def abort ( err ) : if _debug : abort . _debug ( \" abort %r \" , err ) global local_controllers # tell all the local controllers to abort for controller in local_controllers . values ( ) : controller . abort ( err ) ": 1492,
 "def test ( ) : # pragma : no cover import pytest import os pytest . main ( [os . path . dirname ( os . path . abspath ( __file__ ) ) ] ) ": 1493,
 "def storeByteArray ( self , context , page , len , data , returnError ) : returnError . contents . value = self . IllegalStateError raise NotImplementedError ( \" You must override this method . \" ) ": 1494,
 "def array ( self ) : return np . arange ( self . start , self . stop , self . step ) ": 1495,
 "def test ( nose_argsuments ) : from nose import run params = [ ' __main__ ' , ' -c ' , ' nose . ini ' ] params . extend ( nose_argsuments ) run ( argv = params ) ": 1496,
 "def _save_file ( self , filename , contents ) : with open ( filename , ' w ' ) as f : f . write ( contents ) ": 1497,
 "def resetScale ( self ) : self . img . scale ( 1 . /self . imgScale[0] , 1 . /self . imgScale[1] ) self . imgScale = ( 1 . , 1 . ) ": 1498,
 "def compile_filter ( bpf_filter , iface = None ) : if not TCPDUMP : raise Scapy_Exception ( \" tcpdump is not available . Cannot use filter ! \" ) try : process = subprocess . Popen ( [ conf . prog . tcpdump , \" -p \" , \" -i \" , ( conf . iface if iface is None else iface ) , \" -ddd \" , \" -s \" , str ( MTU ) , bpf_filter] , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) except OSError as ex : raise Scapy_Exception ( \" Failed to attach filter : %s \" % ex ) lines , err = process . communicate ( ) ret = process . returncode if ret : raise Scapy_Exception ( \" Failed to attach filter : tcpdump returned : %s \" % err ) lines = lines . strip ( ) . split ( b \" \\n \" ) return get_bpf_pointer ( lines ) ": 1499,
 "def setdefault ( obj , field , default ) : setattr ( obj , field , getattr ( obj , field , default ) ) ": 1500,
 "def plot_target ( target , ax ) : ax . scatter ( target[0] , target[1] , target[2] , c = \" red \" , s = 80 ) ": 1501,
 "def append ( self , item ) : print ( item ) super ( MyList , self ) . append ( item ) ": 1502,
 "def get_duckduckgo_links ( limit , params , headers ) : \t\tresp = s . get ( ' https : //duckduckgo . com/html ' , params = params , headers = headers ) \tlinks = scrape_links ( resp . content , engine = ' d ' ) \treturn links[ : limit]": 1503,
 "def __dir__ ( self ) : u return sorted ( self . keys ( ) | {m for m in dir ( self . __class__ ) if m . startswith ( ' to_ ' ) } ) ": 1504,
 "def add_argument ( self , dest , nargs = 1 , obj = None ) : if obj is None : obj = dest self . _args . append ( Argument ( dest = dest , nargs = nargs , obj = obj ) ) ": 1505,
 "def get_last ( self , table = None ) : if table is None : table = self . main_table query = ' SELECT * FROM \" %s \" ORDER BY ROWID DESC LIMIT 1; ' % table return self . own_cursor . execute ( query ) . fetchone ( ) ": 1506,
 "def Min ( a , axis , keep_dims ) : return np . amin ( a , axis = axis if not isinstance ( axis , np . ndarray ) else tuple ( axis ) , keepdims = keep_dims ) , ": 1507,
 "def build_parser ( ) : parser = argparse . ArgumentParser ( \" Release packages to pypi \" ) parser . add_argument ( ' --check ' , ' -c ' , action = \" store_true \" , help = \" Do a dry run without uploading \" ) parser . add_argument ( ' component ' , help = \" The component to release as component-version \" ) return parser": 1508,
 "def send_email_message ( self , recipient , subject , html_message , text_message , sender_email , sender_name ) : if not current_app . testing : # pragma : no cover # Prepare email message from flask_sendmail import Message message = Message ( subject , recipients = [recipient] , html = html_message , body = text_message ) # Send email message self . mail . send ( message ) ": 1509,
 "async def _send_plain_text ( self , request : Request , stack : Stack ) : await self . _send_text ( request , stack , None ) ": 1510,
 "def chunks ( arr , size ) : for i in _range ( 0 , len ( arr ) , size ) : yield arr[i : i+size]": 1511,
 "def yield_connections ( sock ) : while True : log . debug ( ' waiting for connection on %s ' , sock . getsockname ( ) ) try : conn , _ = sock . accept ( ) except KeyboardInterrupt : return conn . settimeout ( None ) log . debug ( ' accepted connection on %s ' , sock . getsockname ( ) ) yield conn": 1512,
 "def to_dicts ( recarray ) : for rec in recarray : yield dict ( zip ( recarray . dtype . names , rec . tolist ( ) ) ) ": 1513,
 "def set_if_empty ( self , param , default ) : if not self . has ( param ) : self . set ( param , default ) ": 1514,
 "def is_scalar ( value ) : return np . isscalar ( value ) or ( isinstance ( value , np . ndarray ) and ( len ( np . squeeze ( value ) . shape ) = = 0 ) ) ": 1515,
 "def set_xlimits_widgets ( self , set_min = True , set_max = True ) : xmin , xmax = self . tab_plot . ax . get_xlim ( ) if set_min : self . w . x_lo . set_text ( ' {0} ' . format ( xmin ) ) if set_max : self . w . x_hi . set_text ( ' {0} ' . format ( xmax ) ) ": 1516,
 "def barray ( iterlines ) : lst = [line . encode ( ' utf-8 ' ) for line in iterlines] arr = numpy . array ( lst ) return arr": 1517,
 "def setPixel ( self , x , y , color ) : return _fitz . Pixmap_setPixel ( self , x , y , color ) ": 1518,
 "def _assert_is_type ( name , value , value_type ) : if not isinstance ( value , value_type ) : if type ( value_type ) is tuple : types = ' , ' . join ( t . __name__ for t in value_type ) raise ValueError ( ' {0} must be one of ( {1} ) ' . format ( name , types ) ) else : raise ValueError ( ' {0} must be {1} ' . format ( name , value_type . __name__ ) ) ": 1519,
 "def StringIO ( *args , **kwargs ) : raw = sync_io . StringIO ( *args , **kwargs ) return AsyncStringIOWrapper ( raw ) ": 1520,
 "def _zerosamestates ( self , A ) : for pair in self . samestates : A[pair[0] , pair[1]] = 0 A[pair[1] , pair[0]] = 0": 1521,
 "def get_attribute_name_id ( attr ) : return attr . value . id if isinstance ( attr . value , ast . Name ) else None": 1522,
 "def __iand__ ( self , other ) : self . known & = other . known self . active & = other . active return self": 1523,
 "def get_raw_input ( description , default = False ) : additional = ' ( default : %s ) ' % default if default else ' ' prompt = ' %s%s : ' % ( description , additional ) user_input = input_ ( prompt ) return user_input": 1524,
 "def setup ( app ) : app . connect ( ' autodoc-process-docstring ' , lambda *args : pre_processor ( *args , namer = audiolazy_namer ) ) app . connect ( ' autodoc-skip-member ' , should_skip ) ": 1525,
 "def log_y_cb ( self , w , val ) : self . tab_plot . logy = val self . plot_two_columns ( ) ": 1526,
 "def convert_camel_case_to_snake_case ( name ) : s1 = re . sub ( ' ( . ) ( [A-Z][a-z]+ ) ' , r ' \\1_\\2 ' , name ) return re . sub ( ' ( [a-z0-9] ) ( [A-Z] ) ' , r ' \\1_\\2 ' , s1 ) . lower ( ) ": 1527,
 "def array_size ( x , axis ) : axis_shape = x . shape if axis is None else tuple ( x . shape[a] for a in axis ) return max ( numpy . prod ( axis_shape ) , 1 ) ": 1528,
 "def _mean_dict ( dict_list ) : return {k : np . array ( [d[k] for d in dict_list] ) . mean ( ) for k in dict_list[0] . keys ( ) }": 1529,
 "def average ( arr ) : if len ( arr ) = = 0 : sys . stderr . write ( \" ERROR : no content in array to take average\\n \" ) sys . exit ( ) if len ( arr ) = = 1 : return arr[0] return float ( sum ( arr ) ) /float ( len ( arr ) ) ": 1530,
 "def _aggr_mean ( inList ) : aggrSum = 0 nonNone = 0 for elem in inList : if elem ! = SENTINEL_VALUE_FOR_MISSING_DATA : aggrSum + = elem nonNone + = 1 if nonNone ! = 0 : return aggrSum / nonNone else : return None": 1531,
 "def help ( self ) : print ( ' Resources : ' ) print ( ' ' ) for name in sorted ( self . _resources . keys ( ) ) : methods = sorted ( self . _resources[name] . _methods . keys ( ) ) print ( ' {} : {} ' . format ( bold ( name ) , ' , ' . join ( methods ) ) ) ": 1532,
 "def _repr ( obj ) : vals = \" , \" . join ( \" {} = {!r} \" . format ( name , getattr ( obj , name ) ) for name in obj . _attribs ) if vals : t = \" {} ( name = {} , {} ) \" . format ( obj . __class__ . __name__ , obj . name , vals ) else : t = \" {} ( name = {} ) \" . format ( obj . __class__ . __name__ , obj . name ) return t": 1533,
 "def out ( self , output , newline = True ) : click . echo ( output , nl = newline ) ": 1534,
 "def encode_batch ( self , inputBatch ) : X = inputBatch encode = self . encode Y = np . array ( [ encode ( x ) for x in X] ) return Y": 1535,
 "def parse ( el , typ ) : if not el : return typ ( ) txt = text ( el ) if not txt : return typ ( ) return typ ( txt ) ": 1536,
 "def as_tree ( context ) : tree = _build_tree ( context , 2 , 1 ) if type ( tree ) = = dict : tree = [tree] return Response ( content_type = ' application/json ' , body = json . dumps ( tree ) ) ": 1537,
 "def QA_util_datetime_to_strdate ( dt ) : strdate = \" %04d-%02d-%02d \" % ( dt . year , dt . month , dt . day ) return strdate": 1538,
 "def filter_useless_pass ( source ) : try : marked_lines = frozenset ( useless_pass_line_numbers ( source ) ) except ( SyntaxError , tokenize . TokenError ) : marked_lines = frozenset ( ) sio = io . StringIO ( source ) for line_number , line in enumerate ( sio . readlines ( ) , start = 1 ) : if line_number not in marked_lines : yield line": 1539,
 "def get_bin_indices ( self , values ) : return tuple ( [self . get_axis_bin_index ( values[ax_i] , ax_i ) for ax_i in range ( self . dimensions ) ] ) ": 1540,
 "def register_view ( self , view ) : super ( ListViewController , self ) . register_view ( view ) self . tree_view . connect ( ' button_press_event ' , self . mouse_click ) ": 1541,
 "def Bernstein ( n , k ) : coeff = binom ( n , k ) def _bpoly ( x ) : return coeff * x ** k * ( 1 - x ) ** ( n - k ) return _bpoly": 1542,
 "def abbreviate_dashed ( s ) : r = [] for part in s . split ( ' - ' ) : r . append ( abbreviate ( part ) ) return ' - ' . join ( r ) ": 1543,
 "def maskIndex ( self ) : if isinstance ( self . mask , bool ) : return np . full ( self . data . shape , self . mask , dtype = np . bool ) else : return self . mask": 1544,
 "def _split ( string , splitters ) : part = ' ' for character in string : if character in splitters : yield part part = ' ' else : part + = character yield part": 1545,
 "def split_into_words ( s ) : s = re . sub ( r \" \\W+ \" , \" \" , s ) s = re . sub ( r \" [_0-9]+ \" , \" \" , s ) return s . split ( ) ": 1546,
 "def get_as_bytes ( self , s3_path ) : ( bucket , key ) = self . _path_to_bucket_and_key ( s3_path ) obj = self . s3 . Object ( bucket , key ) contents = obj . get ( ) [ ' Body ' ] . read ( ) return contents": 1547,
 "def render_template ( self , source , **kwargs_context ) : r return self . jinja_env . from_string ( source ) . render ( kwargs_context ) ": 1548,
 "def emit_db_sequence_updates ( engine ) : if engine and engine . name = = ' postgresql ' : # not implemented for other RDBMS; necessity unknown conn = engine . connect ( ) qry = \" \" \" SELECT ' SELECT last_value FROM ' || n . nspname || ' . ' || c . relname || ' ; ' AS qry , n . nspname || ' . ' || c . relname AS qual_name FROM pg_namespace n JOIN pg_class c ON ( n . oid = c . relnamespace ) WHERE c . relkind = ' S ' \" \" \" for ( qry , qual_name ) in list ( conn . execute ( qry ) ) : ( lastval , ) = conn . execute ( qry ) . first ( ) nextval = int ( lastval ) + 1 yield \" ALTER SEQUENCE %s RESTART WITH %s; \" % ( qual_name , nextval ) ": 1549,
 "def method_double_for ( self , method_name ) : if method_name not in self . _method_doubles : self . _method_doubles[method_name] = MethodDouble ( method_name , self . _target ) return self . _method_doubles[method_name]": 1550,
 "def rgba_bytes_tuple ( self , x ) : return tuple ( int ( u*255 . 9999 ) for u in self . rgba_floats_tuple ( x ) ) ": 1551,
 "def fft_bandpassfilter ( data , fs , lowcut , highcut ) : fft = np . fft . fft ( data ) # n = len ( data ) # timestep = 1 . 0 / fs # freq = np . fft . fftfreq ( n , d = timestep ) bp = fft . copy ( ) # Zero out fft coefficients # bp[10 : -10] = 0 # Normalise # bp * = real ( fft . dot ( fft ) ) /real ( bp . dot ( bp ) ) bp * = fft . dot ( fft ) / bp . dot ( bp ) # must multipy by 2 to get the correct amplitude ibp = 12 * np . fft . ifft ( bp ) return ibp": 1552,
 "def print_env_info ( key , out = sys . stderr ) : value = os . getenv ( key ) if value is not None : print ( key , \" = \" , repr ( value ) , file = out ) ": 1553,
 "def is_cached ( file_name ) : \t\tgml_file_path = join ( join ( expanduser ( ' ~ ' ) , OCTOGRID_DIRECTORY ) , file_name ) \treturn isfile ( gml_file_path ) ": 1554,
 "def set_cache_max ( self , cache_name , maxsize , **kwargs ) : cache = self . _get_cache ( cache_name ) cache . set_maxsize ( maxsize , **kwargs ) ": 1555,
 "def _on_release ( self , event ) : if self . _drag_cols or self . _drag_rows : self . _visual_drag . place_forget ( ) self . _dragged_col = None self . _dragged_row = None": 1556,
 "def update_cache ( self , data ) : UTILS . update ( self . _cache , data ) self . _save_cache ( ) ": 1557,
 "def angle ( x , y ) : return arccos ( dot ( x , y ) / ( norm ( x ) *norm ( y ) ) ) *180 . /pi": 1558,
 "def add_object ( self , object ) : if object . id is None : object . get_id ( ) self . db . engine . save ( object ) ": 1559,
 "def _cal_dist2center ( X , center ) : dmemb2cen = scipy . spatial . distance . cdist ( X , center . reshape ( 1 , X . shape[1] ) , metric = ' seuclidean ' ) return ( np . sum ( dmemb2cen ) ) ": 1560,
 "def save_hdf5 ( X , y , path ) : with h5py . File ( path , ' w ' ) as f : is_sparse = 1 if sparse . issparse ( X ) else 0 f[ ' issparse ' ] = is_sparse f[ ' target ' ] = y if is_sparse : if not sparse . isspmatrix_csr ( X ) : X = X . tocsr ( ) f[ ' shape ' ] = np . array ( X . shape ) f[ ' data ' ] = X . data f[ ' indices ' ] = X . indices f[ ' indptr ' ] = X . indptr else : f[ ' data ' ] = X": 1561,
 "def get_gzipped_contents ( input_file ) : zbuf = StringIO ( ) zfile = GzipFile ( mode = \" wb \" , compresslevel = 6 , fileobj = zbuf ) zfile . write ( input_file . read ( ) ) zfile . close ( ) return ContentFile ( zbuf . getvalue ( ) ) ": 1562,
 "def vec_angle ( a , b ) : cosang = np . dot ( a , b ) sinang = fast_norm ( np . cross ( a , b ) ) return np . arctan2 ( sinang , cosang ) ": 1563,
 "def decamelise ( text ) : s = re . sub ( ' ( . ) ( [A-Z][a-z]+ ) ' , r ' \\1_\\2 ' , text ) return re . sub ( ' ( [a-z0-9] ) ( [A-Z] ) ' , r ' \\1_\\2 ' , s ) . lower ( ) ": 1564,
 "def elapsed_time_from ( start_time ) : time_then = make_time ( start_time ) time_now = datetime . utcnow ( ) . replace ( microsecond = 0 ) if time_then is None : return delta_t = time_now - time_then return delta_t": 1565,
 "def _to_lower_alpha_only ( s ) : s = re . sub ( r ' \\n ' , ' ' , s . lower ( ) ) return re . sub ( r ' [^a-z\\s] ' , ' ' , s ) ": 1566,
 "def color_func ( func_name ) : if str ( func_name ) . isdigit ( ) : return term_color ( int ( func_name ) ) return globals ( ) [func_name]": 1567,
 "def token_list_to_text ( tokenlist ) : ZeroWidthEscape = Token . ZeroWidthEscape return ' ' . join ( item[1] for item in tokenlist if item[0] ! = ZeroWidthEscape ) ": 1568,
 "def help ( self , level = 0 ) : self . cmdline_parser . formatter . output_level = level with _patch_optparse ( ) : return self . cmdline_parser . format_help ( ) ": 1569,
 "def get_request ( self , request ) : request . transport_user = self . username request . transport_password = self . api_key return request": 1570,
 "def min_or_none ( val1 , val2 ) : return min ( val1 , val2 , key = lambda x : sys . maxint if x is None else x ) ": 1571,
 "def _run_cmd_get_output ( cmd ) : process = subprocess . Popen ( cmd . split ( ) , stdout = subprocess . PIPE ) out , err = process . communicate ( ) return out or err": 1572,
 "def cartesian_product ( arrays , flat = True , copy = False ) : arrays = np . broadcast_arrays ( *np . ix_ ( *arrays ) ) if flat : return tuple ( arr . flatten ( ) if copy else arr . flat for arr in arrays ) return tuple ( arr . copy ( ) if copy else arr for arr in arrays ) ": 1573,
 "def is_bool_matrix ( l ) : r if isinstance ( l , np . ndarray ) : if l . ndim = = 2 and ( l . dtype = = bool ) : return True return False": 1574,
 "def match ( string , patterns ) : if patterns is None : return True else : return any ( re . match ( pattern , string ) for pattern in patterns ) ": 1575,
 "def tokenize_list ( self , text ) : return [self . get_record_token ( record ) for record in self . analyze ( text ) ]": 1576,
 "def strip_accents ( text ) : normalized_str = unicodedata . normalize ( ' NFD ' , text ) return ' ' . join ( [ c for c in normalized_str if unicodedata . category ( c ) ! = ' Mn ' ] ) ": 1577,
 "def compose ( *funcs ) : return lambda x : reduce ( lambda v , f : f ( v ) , reversed ( funcs ) , x ) ": 1578,
 "def OnCellBackgroundColor ( self , event ) : with undo . group ( _ ( \" Background color \" ) ) : self . grid . actions . set_attr ( \" bgcolor \" , event . color ) self . grid . ForceRefresh ( ) self . grid . update_attribute_toolbar ( ) event . Skip ( ) ": 1579,
 "def build_docs ( directory ) : os . chdir ( directory ) process = subprocess . Popen ( [ \" make \" , \" html \" ] , cwd = directory ) process . communicate ( ) ": 1580,
 "def convert_tstamp ( response ) : \t\tif response is None : \t\t # Allow passing None to convert_tstamp ( ) \t\treturn response\t # Overrides the set timezone to UTC - I think . . . \ttz = timezone . utc if settings . USE_TZ else None\treturn datetime . datetime . fromtimestamp ( response , tz ) ": 1581,
 "def checkbox_uncheck ( self , force_check = False ) : if self . get_attribute ( ' checked ' ) : self . click ( force_click = force_check ) ": 1582,
 "def dict_to_numpy_array ( d ) : return fromarrays ( d . values ( ) , np . dtype ( [ ( str ( k ) , v . dtype ) for k , v in d . items ( ) ] ) ) ": 1583,
 "def adapt_array ( arr ) : out = io . BytesIO ( ) np . save ( out , arr ) out . seek ( 0 ) return sqlite3 . Binary ( out . read ( ) ) ": 1584,
 "def __set_token_expired ( self , value ) : self . _token_expired = datetime . datetime . now ( ) + datetime . timedelta ( seconds = value ) return": 1585,
 "def check_attribute_exists ( instance ) : attributes = instance . get ( ' attributes ' , {} ) . keys ( ) if instance . get ( ' key_attribute ' ) not in attributes : return False label_attr = instance . get ( ' label_attribute ' ) if label_attr and label_attr not in attributes : return False return True": 1586,
 "def dir_path ( dir ) : old_dir = os . getcwd ( ) os . chdir ( dir ) yield os . chdir ( old_dir ) ": 1587,
 "def bisect_index ( a , x ) : i = bisect . bisect_left ( a , x ) if i ! = len ( a ) and a[i] = = x : return i raise ValueError": 1588,
 "def save_form ( self , request , form , change ) : OwnableAdmin . save_form ( self , request , form , change ) return DisplayableAdmin . save_form ( self , request , form , change ) ": 1589,
 "def __next__ ( self ) : # Retrieve the row , thereby incrementing the line number : row = super ( UnicodeReaderWithLineNumber , self ) . __next__ ( ) return self . lineno + 1 , row": 1590,
 "def gaussian_variogram_model ( m , d ) : psill = float ( m[0] ) range_ = float ( m[1] ) nugget = float ( m[2] ) return psill * ( 1 . - np . exp ( -d**2 . / ( range_*4 . /7 . ) **2 . ) ) + nugget": 1591,
 "def title ( msg ) : if sys . platform . startswith ( \" win \" ) : ctypes . windll . kernel32 . SetConsoleTitleW ( tounicode ( msg ) ) ": 1592,
 "def pprint ( self , seconds ) : return ( \" %d : %02d : %02d . %03d \" , reduce ( lambda ll , b : divmod ( ll[0] , b ) + ll[1 : ] , [ ( seconds * 1000 , ) , 1000 , 60 , 60] ) ) ": 1593,
 "def normalize ( data ) : data = data . astype ( float ) data - = data . mean ( ) return data / data . std ( ) ": 1594,
 "def print_tree ( self , indent = 2 ) : config . LOGGER . info ( \" {indent}{data} \" . format ( indent = \" \" * indent , data = str ( self ) ) ) for child in self . children : child . print_tree ( indent + 1 ) ": 1595,
 "def is_readable ( fp , size = 1 ) : read_size = len ( fp . read ( size ) ) fp . seek ( -read_size , 1 ) return read_size = = size": 1596,
 "def strip_head ( sequence , values ) : values = set ( values ) return list ( itertools . dropwhile ( lambda x : x in values , sequence ) ) ": 1597,
 "def check_create_folder ( filename ) : os . makedirs ( os . path . dirname ( filename ) , exist_ok = True ) ": 1598,
 "def to_dict ( self ) : return { \" name \" : self . table_name , \" kind \" : self . table_kind , \" data \" : [r . to_dict ( ) for r in self]}": 1599,
 "def _crop_list_to_size ( l , size ) : for x in range ( size - len ( l ) ) : l . append ( False ) for x in range ( len ( l ) - size ) : l . pop ( ) return l": 1600,
 "def isin_alone ( elems , line ) : found = False for e in elems : if line . strip ( ) . lower ( ) = = e . lower ( ) : found = True break return found": 1601,
 "def unit_key_from_name ( name ) : result = name for old , new in six . iteritems ( UNIT_KEY_REPLACEMENTS ) : result = result . replace ( old , new ) # Collapse redundant underscores and convert to uppercase . result = re . sub ( r ' _+ ' , ' _ ' , result . upper ( ) ) return result": 1602,
 "def string_to_int ( s ) : result = 0 for c in s : if not isinstance ( c , int ) : c = ord ( c ) result = 256 * result + c return result": 1603,
 "def valid_uuid ( value ) : try : uuid . UUID ( value , version = 4 ) return True except ( TypeError , ValueError , AttributeError ) : return False": 1604,
 "def to_dataframe ( products ) : try : import pandas as pd except ImportError : raise ImportError ( \" to_dataframe requires the optional dependency Pandas . \" ) return pd . DataFrame . from_dict ( products , orient = ' index ' ) ": 1605,
 "def _get_ipv4_from_binary ( self , bin_addr ) : return socket . inet_ntop ( socket . AF_INET , struct . pack ( \" !L \" , bin_addr ) ) ": 1606,
 "def is_symlink ( self ) : try : return S_ISLNK ( self . lstat ( ) . st_mode ) except OSError as e : if e . errno ! = ENOENT : raise # Path doesn ' t exist return False": 1607,
 "def is_valid_folder ( parser , arg ) : arg = os . path . abspath ( arg ) if not os . path . isdir ( arg ) : parser . error ( \" The folder %s does not exist! \" % arg ) else : return arg": 1608,
 "def abort ( self ) : self . mutex . release ( ) self . turnstile . release ( ) self . mutex . release ( ) self . turnstile2 . release ( ) ": 1609,
 "def Gaussian ( x , mu , sig ) : return sympy . exp ( - ( x - mu ) **2/ ( 2*sig**2 ) ) /sympy . sqrt ( 2*sympy . pi*sig**2 ) ": 1610,
 "def angle_v2_rad ( vec_a , vec_b ) : # cos ( x ) = A * B / |A| * |B| return math . acos ( vec_a . dot ( vec_b ) / ( vec_a . length ( ) * vec_b . length ( ) ) ) ": 1611,
 "def _rectangular ( n ) : for i in n : if len ( i ) ! = len ( n[0] ) : return False return True": 1612,
 "def is_iterable_of_int ( l ) : r if not is_iterable ( l ) : return False return all ( is_int ( value ) for value in l ) ": 1613,
 "def is_valid_image_extension ( file_path ) : valid_extensions = [ ' . jpeg ' , ' . jpg ' , ' . gif ' , ' . png ' ] _ , extension = os . path . splitext ( file_path ) return extension . lower ( ) in valid_extensions": 1614,
 "def rollback ( self ) : \t\t\t\ttry : \t\t\tif self . connection is not None : \t\t\t\tself . connection . rollback ( ) \t\t\t\tself . _updateCheckTime ( ) \t\t\t\tself . release ( ) \t\texcept Exception , e : \t\t\tpass": 1615,
 "def gevent_monkey_patch_report ( self ) : try : import gevent . socket import socket if gevent . socket . socket is socket . socket : self . log ( \" gevent monkey patching is active \" ) return True else : self . notify_user ( \" gevent monkey patching failed . \" ) except ImportError : self . notify_user ( \" gevent is not installed , monkey patching failed . \" ) return False": 1616,
 "def inside_softimage ( ) : try : import maya return False except ImportError : pass try : from win32com . client import Dispatch as disp disp ( ' XSI . Application ' ) return True except : return False": 1617,
 "def is_int_vector ( l ) : r if isinstance ( l , np . ndarray ) : if l . ndim = = 1 and ( l . dtype . kind = = ' i ' or l . dtype . kind = = ' u ' ) : return True return False": 1618,
 "def test_kwargs_are_optional ( self ) : with patch ( \" sys . exit \" ) as mock_exit : cli = MicroCLITestCase . T ( \" script_name f3 \" . split ( ) ) . run ( ) # kwargs are optional mock_exit . assert_called_with ( 4 ) ": 1619,
 "def is_valid_row ( cls , row ) : for k in row . keys ( ) : if row[k] is None : return False return True": 1620,
 "def unixtime_to_datetime ( ut ) : dt = datetime . datetime . utcfromtimestamp ( ut ) dt = dt . replace ( tzinfo = tz . tzutc ( ) ) return dt": 1621,
 "def is_managed ( ) : for item in sys . argv : if re . search ( r ' manage . py|django-admin|django ' , item ) is not None : return True return False": 1622,
 "def __init__ ( self , operand , operator , **args ) : # Note that it ' s currently not possible to set # parameters in the superclass when creating an instance , # because **args is used by this class itself . super ( UnaryOperator , self ) . __init__ ( ) self . operand = operand self . operator = operator self . args = args": 1623,
 "def _has_fileno ( stream ) : try : stream . fileno ( ) except ( AttributeError , OSError , IOError , io . UnsupportedOperation ) : return False return True": 1624,
 "def to_capitalized_camel_case ( snake_case_string ) : parts = snake_case_string . split ( ' _ ' ) return ' ' . join ( [i . title ( ) for i in parts] ) ": 1625,
 "def has_multiline_items ( maybe_list : Optional[Sequence[str]] ) : return maybe_list and any ( is_multiline ( item ) for item in maybe_list ) ": 1626,
 "def read ( *args ) : return io . open ( os . path . join ( HERE , *args ) , encoding = \" utf-8 \" ) . read ( ) ": 1627,
 "def table_exists ( self , table ) : if not self . dataset_exists ( table . dataset ) : return False try : self . client . tables ( ) . get ( projectId = table . project_id , datasetId = table . dataset_id , tableId = table . table_id ) . execute ( ) except http . HttpError as ex : if ex . resp . status = = 404 : return False raise return True": 1628,
 "def run_func ( entry ) : if entry . func : if entry . args and entry . krgs : return entry . func ( *entry . args , **entry . krgs ) if entry . args : return entry . func ( *entry . args ) if entry . krgs : return entry . func ( **entry . krgs ) return entry . func ( ) ": 1629,
 "def peekiter ( iterable ) : it = iter ( iterable ) one = next ( it ) def gen ( ) : \" \" \" Generator that returns first and proxy other items from source \" \" \" yield one while True : yield next ( it ) return ( one , gen ( ) ) ": 1630,
 "def str_ripper ( self , text ) : return self . pattern . sub ( lambda m : self . rep[re . escape ( m . group ( 0 ) ) ] , text ) ": 1631,
 "def is_local_url ( target ) : ref_url = urlparse ( request . host_url ) test_url = urlparse ( urljoin ( request . host_url , target ) ) return test_url . scheme in ( ' http ' , ' https ' ) and \\ ref_url . netloc = = test_url . netloc": 1632,
 "def getSystemVariable ( self , remote , name ) : if self . _server is not None : return self . _server . getSystemVariable ( remote , name ) ": 1633,
 "def _is_proper_sequence ( seq ) : return ( isinstance ( seq , collections . abc . Sequence ) and not isinstance ( seq , str ) ) ": 1634,
 "def get_data_table ( filename ) : with get_file_object ( filename , \" r \" ) as rf : return DataTable ( list ( csv . reader ( rf ) ) ) ": 1635,
 "def is_image ( filename ) : # note : isfile ( ) also accepts symlinks return os . path . isfile ( filename ) and filename . lower ( ) . endswith ( ImageExts ) ": 1636,
 "def last_modified_date ( filename ) : mtime = os . path . getmtime ( filename ) dt = datetime . datetime . utcfromtimestamp ( mtime ) return dt . replace ( tzinfo = pytz . utc ) ": 1637,
 "def _check_methods ( self , methods ) : for method in methods : if method not in self . ALLOWED_METHODS : raise Exception ( ' Invalid \\ ' %s\\ ' method ' % method ) ": 1638,
 "def timestamp_to_datetime ( cls , time_stamp , localized = True ) : ret = datetime . datetime . utcfromtimestamp ( time_stamp ) if localized : ret = localize ( ret , pytz . utc ) return ret": 1639,
 "def is_iterable_but_not_string ( obj ) : return hasattr ( obj , ' __iter__ ' ) and not isinstance ( obj , str ) and not isinstance ( obj , bytes ) ": 1640,
 "def validate ( datum , schema , field = None , raise_errors = True ) : record_type = extract_record_type ( schema ) result = None validator = VALIDATORS . get ( record_type ) if validator : result = validator ( datum , schema = schema , parent_ns = field , raise_errors = raise_errors ) elif record_type in SCHEMA_DEFS : result = validate ( datum , schema = SCHEMA_DEFS[record_type] , field = field , raise_errors = raise_errors ) else : raise UnknownType ( record_type ) if raise_errors and result is False : raise ValidationError ( ValidationErrorData ( datum , schema , field ) ) return result": 1641,
 "def memory_used ( self ) : if self . _end_memory : memory_used = self . _end_memory - self . _start_memory return memory_used else : return None": 1642,
 "def __validate_email ( self , email ) : e = re . match ( self . EMAIL_ADDRESS_REGEX , email , re . UNICODE ) if e : return email else : error = \" Invalid email address : \" + str ( email ) msg = self . GRIMOIRELAB_INVALID_FORMAT % { ' error ' : error} raise InvalidFormatError ( cause = msg ) ": 1643,
 "def is_readable_dir ( path ) : return os . path . isdir ( path ) and os . access ( path , os . R_OK ) and os . access ( path , os . X_OK ) ": 1644,
 "def email_type ( arg ) : \t\tif not is_valid_email_address ( arg ) : \t\traise argparse . ArgumentTypeError ( \" {0} is not a valid email address \" . format ( repr ( arg ) ) ) \treturn arg": 1645,
 "def SchemaValidate ( self , xsd ) : ret = libxml2mod . xmlTextReaderSchemaValidate ( self . _o , xsd ) return ret": 1646,
 "def arg_bool ( name , default = False ) : v = request . args . get ( name , ' ' ) if not len ( v ) : return default return v in BOOL_TRUISH": 1647,
 "def check_auth ( username , pwd ) : cfg = get_current_config ( ) return username = = cfg[ \" dashboard_httpauth \" ] . split ( \" : \" ) [0] and pwd = = cfg[ \" dashboard_httpauth \" ] . split ( \" : \" ) [1]": 1648,
 "def is_rpm_package_installed ( pkg ) : with settings ( hide ( ' warnings ' , ' running ' , ' stdout ' , ' stderr ' ) , warn_only = True , capture = True ) : result = sudo ( \" rpm -q %s \" % pkg ) if result . return_code = = 0 : return True elif result . return_code = = 1 : return False else : # print error to user print ( result ) raise SystemExit ( ) ": 1649,
 "def is_valid_variable_name ( string_to_check ) : try : parse ( ' {} = None ' . format ( string_to_check ) ) return True except ( SyntaxError , ValueError , TypeError ) : return False": 1650,
 "def _clean_str ( self , s ) : return s . translate ( str . maketrans ( ' ' , ' ' , punctuation ) ) . replace ( ' \\u200b ' , \" \" ) . strip ( ) . lower ( ) ": 1651,
 "def is_empty_object ( n , last ) : if n . strip ( ) : return False # seems to be but can be empty code last = last . strip ( ) markers = { ' ) ' , ' ; ' , } if not last or last[-1] in markers : return False return True": 1652,
 "def _validate_key ( self , key ) : return not any ( [key . startswith ( i ) for i in self . EXCEPTIONS] ) ": 1653,
 "def check ( self , var ) : if not isinstance ( var , _str_type ) : return False return _enum_mangle ( var ) in self . _consts": 1654,
 "def set_value ( self , value ) : if value : self . setChecked ( Qt . Checked ) else : self . setChecked ( Qt . Unchecked ) ": 1655,
 "def install_handle_input ( self ) : self . pointer = self . get_fptr ( ) self . hooked = ctypes . windll . user32 . SetWindowsHookExA ( 13 , self . pointer , ctypes . windll . kernel32 . GetModuleHandleW ( None ) , 0 ) if not self . hooked : return False return True": 1656,
 "def __eq__ ( self , other ) : return isinstance ( other , self . __class__ ) \\ and self . _freeze ( ) = = other . _freeze ( ) ": 1657,
 "def chmod ( f ) : try : os . chmod ( f , S_IWRITE ) # windows ( cover all ) except Exception as e : pass try : os . chmod ( f , 0o777 ) # *nix except Exception as e : pass": 1658,
 "def get_ctype ( rtype , cfunc , *args ) : val_p = backend . ffi . new ( rtype ) args = args + ( val_p , ) cfunc ( *args ) return val_p[0]": 1659,
 "def clean_url ( url ) : parsed = urlparse ( url . strip ( ) ) reconstructed = ParseResult ( parsed . scheme , parsed . netloc , parsed . path , params = ' ' , query = ' ' , fragment = ' ' ) return reconstructed . geturl ( ) ": 1660,
 "def wrap ( string , length , indent ) : newline = \" \\n \" + \" \" * indent return newline . join ( ( string[i : i + length] for i in range ( 0 , len ( string ) , length ) ) ) ": 1661,
 "def close_all ( ) : for key , p in _ALL_PLOTTERS . items ( ) : p . close ( ) _ALL_PLOTTERS . clear ( ) return True": 1662,
 "def write_float ( self , number ) : buf = pack ( self . byte_order + \" f \" , number ) self . write ( buf ) ": 1663,
 "def _delete_whitespace ( self ) : while isinstance ( self . _lines[-1] , ( self . _Space , self . _LineBreak , self . _Indent ) ) : del self . _lines[-1]": 1664,
 "def angle_between_vectors ( x , y ) : dp = dot_product ( x , y ) if dp = = 0 : return 0 xm = magnitude ( x ) ym = magnitude ( y ) return math . acos ( dp / ( xm*ym ) ) * ( 180 . / math . pi ) ": 1665,
 "def socket_close ( self ) : if self . sock ! = NC . INVALID_SOCKET : self . sock . close ( ) self . sock = NC . INVALID_SOCKET": 1666,
 "def _close_websocket ( self ) : close_method = getattr ( self . _websocket , \" close \" , None ) if callable ( close_method ) : asyncio . ensure_future ( close_method ( ) , loop = self . _event_loop ) self . _websocket = None self . _dispatch_event ( event = \" close \" ) ": 1667,
 "def pickle_data ( data , picklefile ) : with open ( picklefile , ' wb ' ) as f : pickle . dump ( data , f , protocol = 2 ) ": 1668,
 "def fit_select_best ( X , y ) : models = [fit ( X , y ) for fit in [fit_linear , fit_quadratic]] errors = map ( lambda model : mse ( y , model . predict ( X ) ) , models ) return min ( zip ( models , errors ) , key = itemgetter ( 1 ) ) [0]": 1669,
 "def softmax ( attrs , inputs , proto_obj ) : if ' axis ' not in attrs : attrs = translation_utils . _add_extra_attributes ( attrs , { ' axis ' : 1} ) return ' softmax ' , attrs , inputs": 1670,
 "def disable_wx ( self ) : if self . _apps . has_key ( GUI_WX ) : self . _apps[GUI_WX] . _in_event_loop = False self . clear_inputhook ( ) ": 1671,
 "def underline ( self , msg ) : return click . style ( msg , underline = True ) if self . colorize else msg": 1672,
 "def on_close ( self , evt ) : self . stop ( ) # DoseWatcher if evt . EventObject is not self : # Avoid deadlocks self . Close ( ) # wx . Frame evt . Skip ( ) ": 1673,
 "def series_table_row_offset ( self , series ) : title_and_spacer_rows = series . index * 2 data_point_rows = series . data_point_offset return title_and_spacer_rows + data_point_rows": 1674,
 "def getChildElementsByTagName ( self , tagName ) : result = [] for child in self . childNodes : if isinstance ( child , Element ) : if child . tagName = = tagName : result . append ( child ) return result": 1675,
 "def mcc ( y_true , y_pred , round = True ) : y_true , y_pred = _mask_value_nan ( y_true , y_pred ) if round : y_true = np . round ( y_true ) y_pred = np . round ( y_pred ) return skm . matthews_corrcoef ( y_true , y_pred ) ": 1676,
 "def from_file ( cls , file_path , validate = True ) : return xmlmap . load_xmlobject_from_file ( file_path , xmlclass = cls , validate = validate ) ": 1677,
 "def kernelDriverActive ( self , interface ) : result = libusb1 . libusb_kernel_driver_active ( self . __handle , interface ) if result = = 0 : return False elif result = = 1 : return True raiseUSBError ( result ) ": 1678,
 "def schemaValidateFile ( self , filename , options ) : ret = libxml2mod . xmlSchemaValidateFile ( self . _o , filename , options ) return ret": 1679,
 "def clear_globals_reload_modules ( self ) : self . code_array . clear_globals ( ) self . code_array . reload_modules ( ) # Clear result cache self . code_array . result_cache . clear ( ) ": 1680,
 "def prox_zero ( X , step ) : return np . zeros ( X . shape , dtype = X . dtype ) ": 1681,
 "def count_rows ( self , table_name ) : self . table_must_exist ( table_name ) query = \" SELECT COUNT ( * ) FROM `%s` \" % table_name . lower ( ) self . own_cursor . execute ( query ) return int ( self . own_cursor . fetchone ( ) [0] ) ": 1682,
 "def POINTER ( obj ) : p = ctypes . POINTER ( obj ) if not isinstance ( p . from_param , classmethod ) : def from_param ( cls , x ) : if x is None : return cls ( ) else : return x p . from_param = classmethod ( from_param ) return p": 1683,
 "def cleanup_lib ( self ) : if not self . using_openmp : # this if statement is necessary because shared libraries that use # OpenMP will core dump when unloaded , this is a well-known issue with OpenMP logging . debug ( ' unloading shared library ' ) _ctypes . dlclose ( self . lib . _handle ) ": 1684,
 "def negate ( self ) : self . from_value , self . to_value = self . to_value , self . from_value self . include_lower , self . include_upper = self . include_upper , self . include_lower": 1685,
 "def get_resource_attribute ( self , attr ) : if attr not in self . resource_attributes : raise KeyError ( \" %s is not in resource attributes \" % attr ) return self . resource_attributes[attr]": 1686,
 "def run ( self ) : self . signal_init ( ) self . listen_init ( ) self . logger . info ( ' starting ' ) self . loop . start ( ) ": 1687,
 "def _ram_buffer ( self ) : # get the address of the RAM address = _LIB . Memory ( self . _env ) # create a buffer from the contents of the address location buffer_ = ctypes . cast ( address , ctypes . POINTER ( RAM_VECTOR ) ) . contents # create a NumPy array from the buffer return np . frombuffer ( buffer_ , dtype = ' uint8 ' ) ": 1688,
 "def _swap_curly ( string ) : return ( string . replace ( ' {{ ' , ' {{ ' ) . replace ( ' {{ ' , ' \\x00 ' ) . replace ( ' { ' , ' {{ ' ) . replace ( ' \\x00 ' , ' { ' ) . replace ( ' }} ' , ' }} ' ) . replace ( ' }} ' , ' \\x00 ' ) . replace ( ' } ' , ' }} ' ) . replace ( ' \\x00 ' , ' } ' ) ) ": 1689,
 "def _int64_feature ( value ) : if not isinstance ( value , list ) : value = [value] return tf . train . Feature ( int64_list = tf . train . Int64List ( value = value ) ) ": 1690,
 "def now_time ( str = False ) : if str : return datetime . datetime . now ( ) . strftime ( \" %Y-%m-%d %H : %M : %S \" ) return datetime . datetime . now ( ) ": 1691,
 "def home ( self ) : self . command ( c . LCD_RETURNHOME ) self . _cursor_pos = ( 0 , 0 ) c . msleep ( 2 ) ": 1692,
 "def _getTypename ( self , defn ) : return ' REAL ' if defn . type . float or ' TIME ' in defn . type . name or defn . dntoeu else ' INTEGER ' ": 1693,
 "def INIT_LIST_EXPR ( self , cursor ) : values = [self . parse_cursor ( child ) for child in list ( cursor . get_children ( ) ) ] return values": 1694,
 "def cio_close ( cio ) : OPENJPEG . opj_cio_close . argtypes = [ctypes . POINTER ( CioType ) ] OPENJPEG . opj_cio_close ( cio ) ": 1695,
 "def remove_trailing_string ( content , trailing ) : if content . endswith ( trailing ) and content ! = trailing : return content[ : -len ( trailing ) ] return content": 1696,
 "def format_vars ( args ) : variables = [] for key , value in args . items ( ) : if value : variables + = [ ' {0} = {1} ' . format ( key , value ) ] return variables": 1697,
 "def kill_dashboard ( self , check_alive = True ) : self . _kill_process_type ( ray_constants . PROCESS_TYPE_DASHBOARD , check_alive = check_alive ) ": 1698,
 "def cat_acc ( y_true , y_pred ) : return np . mean ( y_true . argmax ( axis = 1 ) = = y_pred . argmax ( axis = 1 ) ) ": 1699,
 "def string_to_date ( value ) : if isinstance ( value , datetime . date ) : return value return dateutil . parser . parse ( value ) . date ( ) ": 1700,
 "def softplus ( attrs , inputs , proto_obj ) : new_attrs = translation_utils . _add_extra_attributes ( attrs , { ' act_type ' : ' softrelu ' } ) return ' Activation ' , new_attrs , inputs": 1701,
 "def isoformat ( dt ) : if not isinstance ( dt , datetime . datetime ) : raise TypeError ( \" Must provide datetime . datetime object to isoformat \" ) if dt . tzinfo is None : raise ValueError ( \" naive datetime objects are not allowed beyond the library boundaries \" ) return dt . isoformat ( ) . replace ( \" +00 : 00 \" , \" Z \" ) ": 1702,
 "def print_with_header ( header , message , color , indent = 0 ) : print ( ) padding = ' ' * indent print ( padding + color + BOLD + header + ENDC + color + message + ENDC ) ": 1703,
 "def from_timestamp ( microsecond_timestamp ) : # Create datetime without losing precision from floating point ( yes , this # is actually needed ) : return datetime . datetime . fromtimestamp ( microsecond_timestamp // 1000000 , datetime . timezone . utc ) . replace ( microsecond = ( microsecond_timestamp % 1000000 ) ) ": 1704,
 "def calculate_top_margin ( self ) : \t\t\t\tself . border_top = 5\t\tif self . show_graph_title : \t\t\tself . border_top + = self . title_font_size\t\tself . border_top + = 5\t\tif self . show_graph_subtitle : \t\t\tself . border_top + = self . subtitle_font_size": 1705,
 "def timestamp_from_datetime ( dt ) : try : utc_dt = dt . astimezone ( pytz . utc ) except ValueError : utc_dt = dt . replace ( tzinfo = pytz . utc ) return timegm ( utc_dt . timetuple ( ) ) ": 1706,
 "def _DateToEpoch ( date ) : tz_zero = datetime . datetime . utcfromtimestamp ( 0 ) diff_sec = int ( ( date - tz_zero ) . total_seconds ( ) ) return diff_sec * 1000000": 1707,
 "def created_today ( self ) : if self . datetime . date ( ) = = datetime . today ( ) . date ( ) : return True return False": 1708,
 "def monthly ( date = datetime . date . today ( ) ) : return datetime . date ( date . year , date . month , 1 ) ": 1709,
 "def update_dict ( obj , dict , attributes ) : for attribute in attributes : if hasattr ( obj , attribute ) and getattr ( obj , attribute ) is not None : dict[attribute] = getattr ( obj , attribute ) ": 1710,
 "def _default ( self , obj ) : return obj . __dict__ if isinstance ( obj , JsonObj ) else json . JSONDecoder ( ) . decode ( obj ) ": 1711,
 "def getpackagepath ( ) : moduleDirectory = os . path . dirname ( __file__ ) packagePath = os . path . dirname ( __file__ ) + \" / . . / \" return packagePath": 1712,
 "def print_args ( output = sys . stdout ) : def decorator ( func ) : \" \" \" The decorator function . \" \" \" @wraps ( func ) def _ ( *args , **kwargs ) : \" \" \" The decorated function . \" \" \" output . write ( \" Args : {0} , KwArgs : {1}\\n \" . format ( str ( args ) , str ( kwargs ) ) ) return func ( *args , **kwargs ) return _ return decorator": 1713,
 "def generator_to_list ( fn ) : def wrapper ( *args , **kw ) : return list ( fn ( *args , **kw ) ) return wrapper": 1714,
 "def strip_figures ( figure ) : \t\tfig = []\tfor trace in figure[ ' data ' ] : \t\tfig . append ( dict ( data = [trace] , layout = figure[ ' layout ' ] ) ) \treturn fig": 1715,
 "def Square ( x , a , b , c ) : return a * x ** 2 + b * x + c": 1716,
 "def parameter_vector ( self ) : return np . array ( [getattr ( self , k ) for k in self . parameter_names] ) ": 1717,
 "def position ( self , x , y , text ) : sys . stdout . write ( \" \\x1b7\\x1b[%d;%df%s\\x1b8 \" % ( x , y , text ) ) sys . stdout . flush ( ) ": 1718,
 "def transform ( self , df ) : for name , function in self . outputs : df[name] = function ( df ) ": 1719,
 "def delete ( self , name ) : obj = self . _get_object ( name ) if obj : return self . driver . delete_object ( obj ) ": 1720,
 "def desc ( self ) : return ' {0} ( ID : {1} ) - {2} - {3} ' . format ( self . name , self . device_id , self . type , self . status ) ": 1721,
 "def filter ( self , obj , *args , **kwargs ) : for _ , _ , func in self . _filter_order : obj = func ( obj , *args , **kwargs ) if obj is None : return None return obj": 1722,
 "def fft ( t , y , pow2 = False , window = None , rescale = False ) : # make sure they ' re numpy arrays , and make copies to avoid the referencing error y = _n . array ( y ) t = _n . array ( t ) # if we ' re doing the power of 2 , do it if pow2 : keep = 2**int ( _n . log2 ( len ( y ) ) ) # now resize the data y . resize ( keep ) t . resize ( keep ) # Window the data if not window in [None , False , 0] : try : # Get the windowing array w = eval ( \" _n . \" +window , dict ( _n = _n ) ) ( len ( y ) ) # Store the original variance v0 = _n . average ( abs ( y ) **2 ) # window the time domain data y = y * w # Rescale by the variance ratio if rescale : y = y * _n . sqrt ( v0 / _n . average ( abs ( y ) **2 ) ) except : print ( \" ERROR : Bad window! \" ) return # do the actual fft , and normalize Y = _n . fft . fftshift ( _n . fft . fft ( y ) / len ( t ) ) f = _n . fft . fftshift ( _n . fft . fftfreq ( len ( t ) , t[1]-t[0] ) ) return f , Y": 1723,
 "def click_estimate_slope ( ) : c1 = _pylab . ginput ( ) if len ( c1 ) = = 0 : return None c2 = _pylab . ginput ( ) if len ( c2 ) = = 0 : return None return ( c1[0][1]-c2[0][1] ) / ( c1[0][0]-c2[0][0] ) ": 1724,
 "def _update_index_on_df ( df , index_names ) : if index_names : df = df . set_index ( index_names ) # Remove names from unnamed indexes index_names = _denormalize_index_names ( index_names ) df . index . names = index_names return df": 1725,
 "def is_function ( self ) : if self . is_instance ( ) or self . is_class ( ) : return False return isinstance ( self . callback , ( Callable , classmethod ) ) ": 1726,
 "def build_and_start ( query , directory ) : Async ( target = grep , args = [query , directory] ) . start ( ) ": 1727,
 "def _string_width ( self , s ) : s = str ( s ) w = 0 for char in s : char = ord ( char ) w + = self . character_widths[char] return w * self . font_size / 1000 . 0": 1728,
 "def is_subdir ( a , b ) : a , b = map ( os . path . abspath , [a , b] ) return os . path . commonpath ( [a , b] ) = = b": 1729,
 "def seaborn_bar_ ( self , label = None , style = None , opts = None ) : try : fig = sns . barplot ( self . x , self . y , palette = \" BuGn_d \" ) return fig except Exception as e : self . err ( e , self . seaborn_bar_ , \" Can not get Seaborn bar chart object \" ) ": 1730,
 "def getFileDialogTitle ( msg , title ) : if msg and title : return \" %s - %s \" % ( title , msg ) if msg and not title : return str ( msg ) if title and not msg : return str ( title ) return None": 1731,
 "def img_encode ( arr , **kwargs ) : sio = BytesIO ( ) imsave ( sio , arr , **kwargs ) sio . seek ( 0 ) img_format = kwargs[ ' format ' ] if kwargs . get ( ' format ' ) else ' png ' img_str = base64 . b64encode ( sio . getvalue ( ) ) . decode ( ) return ' data : image/{};base64 , {} ' . format ( img_format , img_str ) ": 1732,
 "def _check_conversion ( key , valid_dict ) : if key not in valid_dict and key not in valid_dict . values ( ) : # Only show users the nice string values keys = [v for v in valid_dict . keys ( ) if isinstance ( v , string_types ) ] raise ValueError ( ' value must be one of %s , not %s ' % ( keys , key ) ) return valid_dict[key] if key in valid_dict else key": 1733,
 "def get_single_item ( d ) : assert len ( d ) = = 1 , ' Single-item dict must have just one item , not %d . ' % len ( d ) return next ( six . iteritems ( d ) ) ": 1734,
 "def bounding_box_from ( points , i , i1 , thr ) : pi = points[i] pi1 = points[i1] min_lat = min ( pi . lat , pi1 . lat ) min_lon = min ( pi . lon , pi1 . lon ) max_lat = max ( pi . lat , pi1 . lat ) max_lon = max ( pi . lon , pi1 . lon ) return min_lat-thr , min_lon-thr , max_lat+thr , max_lon+thr": 1735,
 "def swap ( self ) : self . xmin , self . ymin = self . ymin , self . xmin self . xmax , self . ymax = self . ymax , self . xmax": 1736,
 "def tob ( data , enc = ' utf8 ' ) : return data . encode ( enc ) if isinstance ( data , six . text_type ) else bytes ( data ) ": 1737,
 "def CleanseComments ( line ) : commentpos = line . find ( ' // ' ) if commentpos ! = -1 and not IsCppString ( line[ : commentpos] ) : line = line[ : commentpos] . rstrip ( ) # get rid of /* . . . */ return _RE_PATTERN_CLEANSE_LINE_C_COMMENTS . sub ( ' ' , line ) ": 1738,
 "def set_history_file ( self , path ) : if path : self . history = prompt_toolkit . history . FileHistory ( fixpath ( path ) ) else : self . history = prompt_toolkit . history . InMemoryHistory ( ) ": 1739,
 "def Distance ( lat1 , lon1 , lat2 , lon2 ) : az12 , az21 , dist = wgs84_geod . inv ( lon1 , lat1 , lon2 , lat2 ) return az21 , dist": 1740,
 "def getMaxAffiliationInstanceID ( ) : dbconnectionhanlder = DBConnection ( ) dbconnectionhanlder . cursor . execute ( \" SELECT max ( id ) from `django-tethne_affiliation_instance` \" ) rows = dbconnectionhanlder . cursor . fetchall ( ) dbconnectionhanlder . conn . close ( ) if rows[0][0] is None : return 0 else : return rows[0][0]": 1741,
 "def var ( series ) : if np . issubdtype ( series . dtype , np . number ) : return series . var ( ) else : return np . nan": 1742,
 "def handle_m2m_user ( self , sender , instance , **kwargs ) : self . handle_save ( instance . user . __class__ , instance . user ) ": 1743,
 "def maxId ( self ) : if len ( self . model . db ) = = 0 : return 0 return max ( map ( lambda obj : obj[ \" id \" ] , self . model . db ) ) ": 1744,
 "def lsem ( inlist ) : sd = stdev ( inlist ) n = len ( inlist ) return sd/math . sqrt ( n ) ": 1745,
 "def import_js ( path , lib_name , globals ) : with codecs . open ( path_as_local ( path ) , \" r \" , \" utf-8 \" ) as f : js = f . read ( ) e = EvalJs ( ) e . execute ( js ) var = e . context[ ' var ' ] globals[lib_name] = var . to_python ( ) ": 1746,
 "def parse_code ( url ) : result = urlparse ( url ) query = parse_qs ( result . query ) return query[ ' code ' ]": 1747,
 "def __call__ ( self , args ) : window , ij = args return self . user_func ( srcs , window , ij , global_args ) , window": 1748,
 "def release ( self ) : if self . errored : self . pool . delete_resource ( self ) else : self . pool . release ( self ) ": 1749,
 "def _rm_name_match ( s1 , s2 ) : m_len = min ( len ( s1 ) , len ( s2 ) ) return s1[ : m_len] = = s2[ : m_len]": 1750,
 "def pull_stream ( image ) : return ( json . loads ( s ) for s in _get_docker ( ) . pull ( image , stream = True ) ) ": 1751,
 "def _composed_doc ( fs ) : if not fs : # Argument name for the docstring . return ' n ' return ' {f} ( {g} ) ' . format ( f = fs[0] . __name__ , g = _composed_doc ( fs[1 : ] ) ) ": 1752,
 "def date_to_datetime ( x ) : if not isinstance ( x , datetime ) and isinstance ( x , date ) : return datetime . combine ( x , time ( ) ) return x": 1753,
 "def unpickle_file ( picklefile , **kwargs ) : with open ( picklefile , ' rb ' ) as f : return pickle . load ( f , **kwargs ) ": 1754,
 "def unpatch ( obj , name ) : setattr ( obj , name , getattr ( obj , name ) . original ) ": 1755,
 "def draw ( graph , fname ) : ag = networkx . nx_agraph . to_agraph ( graph ) ag . draw ( fname , prog = ' dot ' ) ": 1756,
 "def items ( iterable ) : if hasattr ( iterable , ' iteritems ' ) : return ( p for p in iterable . iteritems ( ) ) elif hasattr ( iterable , ' items ' ) : return ( p for p in iterable . items ( ) ) else : return ( p for p in enumerate ( iterable ) ) ": 1757,
 "def to_json ( obj ) : i = StringIO . StringIO ( ) w = Writer ( i , encoding = ' UTF-8 ' ) w . write_value ( obj ) return i . getvalue ( ) ": 1758,
 "def _from_dict ( cls , _dict ) : args = {} if ' key ' in _dict : args[ ' key ' ] = Key . _from_dict ( _dict . get ( ' key ' ) ) if ' value ' in _dict : args[ ' value ' ] = Value . _from_dict ( _dict . get ( ' value ' ) ) return cls ( **args ) ": 1759,
 "def _cdf ( self , xloc , dist , base , cache ) : return evaluation . evaluate_forward ( dist , base**xloc , cache = cache ) ": 1760,
 "def parallel ( processes , threads ) : pool = multithread ( threads ) pool . map ( run_process , processes ) pool . close ( ) pool . join ( ) ": 1761,
 "def _kw ( keywords ) : r = {} for k , v in keywords : r[k] = v return r": 1762,
 "def to_snake_case ( text ) : s1 = re . sub ( ' ( . ) ( [A-Z][a-z]+ ) ' , r ' \\1_\\2 ' , text ) return re . sub ( ' ( [a-z0-9] ) ( [A-Z] ) ' , r ' \\1_\\2 ' , s1 ) . lower ( ) ": 1763,
 "def add_index_alias ( es , index_name , alias_name ) : es . indices . put_alias ( index = index_name , name = terms_alias ) ": 1764,
 "def index ( obj , index = INDEX_NAME , doc_type = DOC_TYPE ) : doc = to_dict ( obj ) if doc is None : return id = doc . pop ( ' id ' ) return es_conn . index ( index , doc_type , doc , id = id ) ": 1765,
 "def iterparse ( source , tag , clear = False , events = None ) : for event , elem in ElementTree . iterparse ( source , events = events ) : if elem . tag = = tag : yield elem if clear : elem . clear ( ) ": 1766,
 "def is_rfc2822 ( instance : str ) : if not isinstance ( instance , str ) : return True return email . utils . parsedate ( instance ) is not None": 1767,
 "def b ( s ) : \t\treturn s if isinstance ( s , bytes ) else s . encode ( locale . getpreferredencoding ( ) ) ": 1768,
 "def _check_color_dim ( val ) : val = np . atleast_2d ( val ) if val . shape[1] not in ( 3 , 4 ) : raise RuntimeError ( ' Value must have second dimension of size 3 or 4 ' ) return val , val . shape[1]": 1769,
 "def aug_sysargv ( cmdstr ) : import shlex argv = shlex . split ( cmdstr ) sys . argv . extend ( argv ) ": 1770,
 "def getpass ( self , prompt , default = None ) : return click . prompt ( prompt , hide_input = True , default = default ) ": 1771,
 "def unpack_out ( self , name ) : return self . parse ( , enum_class = self . _import_type ( ) , value = name ) [ \" enum \" ]": 1772,
 "def _set_widget_background_color ( widget , color ) : pal = widget . palette ( ) pal . setColor ( pal . Base , color ) widget . setPalette ( pal ) ": 1773,
 "def get_mi_vec ( slab ) : mvec = np . cross ( slab . lattice . matrix[0] , slab . lattice . matrix[1] ) return mvec / np . linalg . norm ( mvec ) ": 1774,
 "def c2f ( r , i , ctype_name ) : ftype = c2f_dict[ctype_name] return np . typeDict[ctype_name] ( ftype ( r ) + 1j * ftype ( i ) ) ": 1775,
 "def contained_in ( filename , directory ) : filename = os . path . normcase ( os . path . abspath ( filename ) ) directory = os . path . normcase ( os . path . abspath ( directory ) ) return os . path . commonprefix ( [filename , directory] ) = = directory": 1776,
 "def is_collection ( obj ) : col = getattr ( obj , ' __getitem__ ' , False ) val = False if ( not col ) else True if isinstance ( obj , basestring ) : val = False return val": 1777,
 "def log_exception ( exc_info = None , stream = None ) : exc_info = exc_info or sys . exc_info ( ) stream = stream or sys . stderr try : from traceback import print_exception print_exception ( exc_info[0] , exc_info[1] , exc_info[2] , None , stream ) stream . flush ( ) finally : exc_info = None": 1778,
 "def __init__ ( self , filename , formatting_info = False , handle_ambiguous_date = None ) : super ( ) . __init__ ( filename ) self . workbook = xlrd . open_workbook ( self . filename , formatting_info = formatting_info ) self . handle_ambiguous_date = handle_ambiguous_date": 1779,
 "def handle_exception ( error ) : response = jsonify ( error . to_dict ( ) ) response . status_code = error . status_code return response": 1780,
 "def timedcall ( executable_function , *args ) : time_start = time . clock ( ) ; result = executable_function ( *args ) ; time_end = time . clock ( ) ; return ( time_end - time_start , result ) ;": 1781,
 "def is_list_of_list ( item ) : if ( type ( item ) in ( list , tuple ) and len ( item ) and isinstance ( item[0] , ( list , tuple ) ) ) : return True return False": 1782,
 "def is_nullable_list ( val , vtype ) : return ( isinstance ( val , list ) and any ( isinstance ( v , vtype ) for v in val ) and all ( ( isinstance ( v , vtype ) or v is None ) for v in val ) ) ": 1783,
 "def _expand ( self , str , local_vars = {} ) : return ninja_syntax . expand ( str , self . vars , local_vars ) ": 1784,
 "def task_property_present_predicate ( service , task , prop ) : try : response = get_service_task ( service , task ) except Exception as e : pass return ( response is not None ) and ( prop in response ) ": 1785,
 "def _merge_args_with_kwargs ( args_dict , kwargs_dict ) : ret = args_dict . copy ( ) ret . update ( kwargs_dict ) return ret": 1786,
 "def unique_everseen ( seq ) : seen = set ( ) seen_add = seen . add return [x for x in seq if not ( x in seen or seen_add ( x ) ) ]": 1787,
 "def test_for_image ( self , cat , img ) : return self . test_for_category ( cat ) and img in self . items[cat]": 1788,
 "def is_string ( obj ) : if PYTHON3 : str_type = ( bytes , str ) else : str_type = ( bytes , str , unicode ) return isinstance ( obj , str_type ) ": 1789,
 "def parse_float_literal ( ast , _variables = None ) : if isinstance ( ast , ( FloatValueNode , IntValueNode ) ) : return float ( ast . value ) return INVALID": 1790,
 "def is_int ( string ) : try : a = float ( string ) b = int ( a ) except ValueError : return False else : return a = = b": 1791,
 "def stft ( func = None , **kwparams ) : from numpy . fft import fft , ifft ifft_r = lambda *args : ifft ( *args ) . real return stft . base ( transform = fft , inverse_transform = ifft_r ) ( func , **kwparams ) ": 1792,
 "def getvariable ( name ) : import inspect fr = inspect . currentframe ( ) try : while fr : fr = fr . f_back vars = fr . f_locals if name in vars : return vars[name] except : pass return None": 1793,
 "def get_time ( filename ) : \t\tts = os . stat ( filename ) . st_mtime\treturn datetime . datetime . utcfromtimestamp ( ts ) ": 1794,
 "def check_empty_dict ( GET_dict ) : empty = True for k , v in GET_dict . items ( ) : # Don ' t disable on p ( age ) or ' all ' GET param if v and k ! = ' p ' and k ! = ' all ' : empty = False return empty": 1795,
 "def open_file ( file , mode ) : \t\tif hasattr ( file , \" read \" ) : \t\treturn file\tif hasattr ( file , \" open \" ) : \t\treturn file . open ( mode ) \treturn open ( file , mode ) ": 1796,
 "def rewindbody ( self ) : if not self . seekable : raise IOError , \" unseekable file \" self . fp . seek ( self . startofbody ) ": 1797,
 "def _check_2d_shape ( X ) : if X . dtype . names is None and len ( X . shape ) ! = 2 : raise ValueError ( ' X needs to be 2-dimensional , not ' ' {}-dimensional . ' . format ( len ( X . shape ) ) ) ": 1798,
 "def read ( filename ) : return codecs . open ( os . path . join ( __DIR__ , filename ) , ' r ' ) . read ( ) ": 1799,
 "def instance_contains ( container , item ) : return item in ( member for _ , member in inspect . getmembers ( container ) ) ": 1800,
 "def fill_nulls ( self , col : str ) : n = [None , \" \" ] try : self . df[col] = self . df[col] . replace ( n , nan ) except Exception as e : self . err ( e ) ": 1801,
 "def skewness ( data ) : if len ( data ) = = 0 : return None num = moment ( data , 3 ) denom = moment ( data , 2 ) ** 1 . 5 return num / denom if denom ! = 0 else 0 . ": 1802,
 "def inpaint ( self ) : import inpaint filled = inpaint . replace_nans ( np . ma . filled ( self . raster_data , np . NAN ) . astype ( np . float32 ) , 3 , 0 . 01 , 2 ) self . raster_data = np . ma . masked_invalid ( filled ) ": 1803,
 "def available_gpus ( ) : local_device_protos = device_lib . list_local_devices ( ) return [x . name for x in local_device_protos if x . device_type = = ' GPU ' ]": 1804,
 "def cleanLines ( source , lineSep = os . linesep ) : stripped = ( line . strip ( lineSep ) for line in source ) return ( line for line in stripped if len ( line ) ! = 0 ) ": 1805,
 "def allclose ( a , b ) : from numpy import allclose return ( a . shape = = b . shape ) and allclose ( a , b ) ": 1806,
 "def camel_to_snake_case ( name ) : pattern = r ' [A-Z][a-z]+|[A-Z]+ ( ?![a-z] ) ' return ' _ ' . join ( map ( str . lower , re . findall ( pattern , name ) ) ) ": 1807,
 "def clear ( ) : if sys . platform . startswith ( \" win \" ) : call ( \" cls \" , shell = True ) else : call ( \" clear \" , shell = True ) ": 1808,
 "def logout ( cache ) : cache . set ( flask . session[ ' auth0_key ' ] , None ) flask . session . clear ( ) return True": 1809,
 "def retrieve_asset ( filename ) : record = model . Image . get ( asset_name = filename ) if not record : raise http_error . NotFound ( \" File not found \" ) if not record . is_asset : raise http_error . Forbidden ( ) return flask . send_file ( record . file_path , conditional = True ) ": 1810,
 "def _closeResources ( self ) : logger . info ( \" Closing : {} \" . format ( self . _fileName ) ) self . _h5Group . close ( ) self . _h5Group = None": 1811,
 "def view_500 ( request , url = None ) : res = render_to_response ( \" 500 . html \" , context_instance = RequestContext ( request ) ) res . status_code = 500 return res": 1812,
 "def staticdir ( ) : root = os . path . abspath ( os . path . dirname ( __file__ ) ) return os . path . join ( root , \" static \" ) ": 1813,
 "def trim ( self ) : for key , value in list ( iteritems ( self . counters ) ) : if value . empty ( ) : del self . counters[key]": 1814,
 "def filter ( self , f , operator = \" and \" ) : if self . _filtered : self . _filter_dsl . filter ( f ) else : self . _build_filtered_query ( f , operator ) return self": 1815,
 "def flatten ( nested ) : flat_return = list ( ) def __inner_flat ( nested , flat ) : for i in nested : __inner_flat ( i , flat ) if isinstance ( i , list ) else flat . append ( i ) return flat __inner_flat ( nested , flat_return ) return flat_return": 1816,
 "def merge_pdfs ( pdf_filepaths , out_filepath ) : merger = PdfFileMerger ( ) for pdf in pdf_filepaths : merger . append ( PdfFileReader ( open ( pdf , ' rb ' ) ) ) merger . write ( out_filepath ) return out_filepath": 1817,
 "def merge_dict ( data , *args ) : results = {} for current in ( data , ) + args : results . update ( current ) return results": 1818,
 "def flatten ( nested , containers = ( list , tuple ) ) : for item in nested : if hasattr ( item , \" next \" ) or isinstance ( item , containers ) : for subitem in flatten ( item ) : yield subitem else : yield item": 1819,
 "def flatten_array ( grid ) : grid = [grid[i][j] for i in range ( len ( grid ) ) for j in range ( len ( grid[i] ) ) ] while type ( grid[0] ) is list : grid = flatten_array ( grid ) return grid": 1820,
 "def version_jar ( self ) : \t\t\t\tcmd = config . get_command ( ' java ' ) \t\tcmd . append ( ' -jar ' ) \t\tcmd + = self . cmd\t\tself . version ( cmd = cmd , path = self . cmd[0] ) ": 1821,
 "def flatten ( lis ) : new_lis = [] for item in lis : if isinstance ( item , collections . Sequence ) and not isinstance ( item , basestring ) : new_lis . extend ( flatten ( item ) ) else : new_lis . append ( item ) return new_lis": 1822,
 "def parse_comments_for_file ( filename ) : return [parse_comment ( strip_stars ( comment ) , next_line ) for comment , next_line in get_doc_comments ( read_file ( filename ) ) ]": 1823,
 "def count_string_diff ( a , b ) : shortest = min ( len ( a ) , len ( b ) ) return sum ( a[i] ! = b[i] for i in range ( shortest ) ) ": 1824,
 "def are_equal_xml ( a_xml , b_xml ) : a_dom = xml . dom . minidom . parseString ( a_xml ) b_dom = xml . dom . minidom . parseString ( b_xml ) return are_equal_elements ( a_dom . documentElement , b_dom . documentElement ) ": 1825,
 "def generate ( env ) : cplusplus . generate ( env ) env[ ' CXX ' ] = ' CC ' env[ ' CXXFLAGS ' ] = SCons . Util . CLVar ( ' -LANG : std ' ) env[ ' SHCXX ' ] = ' $CXX ' env[ ' SHOBJSUFFIX ' ] = ' . o ' env[ ' STATIC_AND_SHARED_OBJECTS_ARE_THE_SAME ' ] = 1": 1826,
 "def multis_2_mono ( table ) : for row in range ( len ( table ) ) : for column in range ( len ( table[row] ) ) : table[row][column] = table[row][column] . replace ( ' \\n ' , ' ' ) return table": 1827,
 "def _manhattan_distance ( vec_a , vec_b ) : if len ( vec_a ) ! = len ( vec_b ) : raise ValueError ( ' len ( vec_a ) must equal len ( vec_b ) ' ) return sum ( map ( lambda a , b : abs ( a - b ) , vec_a , vec_b ) ) ": 1828,
 "def num_leaves ( tree ) : if tree . is_leaf : return 1 else : return num_leaves ( tree . left_child ) + num_leaves ( tree . right_child ) ": 1829,
 "def xeval ( source , optimize = True ) : native = xcompile ( source , optimize = optimize ) return native ( ) ": 1830,
 "def str2int ( num , radix = 10 , alphabet = BASE85 ) : return NumConv ( radix , alphabet ) . str2int ( num ) ": 1831,
 "def get_substring_idxs ( substr , string ) : return [match . start ( ) for match in re . finditer ( substr , string ) ]": 1832,
 "def _concatenate_virtual_arrays ( arrs , cols = None , scaling = None ) : return None if not len ( arrs ) else ConcatenatedArrays ( arrs , cols , scaling = scaling ) ": 1833,
 "def short_description ( func ) : doc = inspect . getdoc ( func ) if doc is not None : doc = inspect . cleandoc ( doc ) lines = doc . splitlines ( ) return lines[0] return \" \" ": 1834,
 "def get_previous ( self ) : return BillingCycle . objects . filter ( date_range__lt = self . date_range ) . order_by ( ' date_range ' ) . last ( ) ": 1835,
 "def set_global ( node : Node , key : str , value : Any ) : node . node_globals[key] = value": 1836,
 "def to_list ( var ) : if var is None : return [] if isinstance ( var , str ) : var = var . split ( ' \\n ' ) elif not isinstance ( var , list ) : try : var = list ( var ) except TypeError : raise ValueError ( \" {} cannot be converted to the list . \" . format ( var ) ) return var": 1837,
 "def unpunctuate ( s , * , char_blacklist = string . punctuation ) : # remove punctuation s = \" \" . join ( c for c in s if c not in char_blacklist ) # remove consecutive spaces return \" \" . join ( filter ( None , s . split ( \" \" ) ) ) ": 1838,
 "def create_conda_env ( sandbox_dir , env_name , dependencies , options = ( ) ) : env_dir = os . path . join ( sandbox_dir , env_name ) cmdline = [ \" conda \" , \" create \" , \" --yes \" , \" --copy \" , \" --quiet \" , \" -p \" , env_dir] + list ( options ) + dependencies log . info ( \" Creating conda environment : \" ) log . info ( \" command line : %s \" , cmdline ) subprocess . check_call ( cmdline , stderr = subprocess . PIPE , stdout = subprocess . PIPE ) log . debug ( \" Environment created \" ) return env_dir , env_name": 1839,
 "def get_decimal_quantum ( precision ) : assert isinstance ( precision , ( int , decimal . Decimal ) ) return decimal . Decimal ( 10 ) ** ( -precision ) ": 1840,
 "def get_url ( self , cmd , **args ) : return self . http . base_url + self . _mkurl ( cmd , *args ) ": 1841,
 "def detach_all ( self ) : self . detach_all_classes ( ) self . objects . clear ( ) self . index . clear ( ) self . _keepalive[ : ] = []": 1842,
 "def list2dict ( lst ) : dic = {} for k , v in lst : dic[k] = v return dic": 1843,
 "def daterange ( start_date , end_date ) : for n in range ( int ( ( end_date - start_date ) . days ) ) : yield start_date + timedelta ( n ) ": 1844,
 "def energy_string_to_float ( string ) : energy_re = re . compile ( \" ( -?\\d+\\ . \\d+ ) \" ) return float ( energy_re . match ( string ) . group ( 0 ) ) ": 1845,
 "def render ( template = None , ostr = None , **kwargs ) : jinja_environment . filters[ ' texscape ' ] = tex_escape template = template or DEFAULT_TEMPLATE ostr = ostr or sys . stdout jinja_template = jinja_environment . get_template ( template ) jinja_template . stream ( **kwargs ) . dump ( ostr ) ": 1846,
 "def abs_img ( img ) : bool_img = np . abs ( read_img ( img ) . get_data ( ) ) return bool_img . astype ( int ) ": 1847,
 "def get_remote_content ( filepath ) : with hide ( ' running ' ) : temp = BytesIO ( ) get ( filepath , temp ) content = temp . getvalue ( ) . decode ( ' utf-8 ' ) return content . strip ( ) ": 1848,
 "def object_as_dict ( obj ) : return {c . key : getattr ( obj , c . key ) for c in inspect ( obj ) . mapper . column_attrs}": 1849,
 "def twitter_timeline ( screen_name , since_id = None ) : consumer_key = twitter_credential ( ' consumer_key ' ) consumer_secret = twitter_credential ( ' consumer_secret ' ) access_token = twitter_credential ( ' access_token ' ) access_token_secret = twitter_credential ( ' access_secret ' ) auth = tweepy . OAuthHandler ( consumer_key , consumer_secret ) auth . set_access_token ( access_token , access_token_secret ) api = tweepy . API ( auth ) return get_all_tweets ( screen_name , api , since_id ) ": 1850,
 "def size ( self ) : if self is NULL : return 0 return 1 + self . left . size ( ) + self . right . size ( ) ": 1851,
 "def data_directory ( ) : package_directory = os . path . abspath ( os . path . dirname ( __file__ ) ) return os . path . join ( package_directory , \" data \" ) ": 1852,
 "def get_Callable_args_res ( clb ) : try : return clb . __args__ , clb . __result__ except AttributeError : # Python 3 . 6 return clb . __args__[ : -1] , clb . __args__[-1]": 1853,
 "def count_rows_with_nans ( X ) : if X . ndim = = 2 : return np . where ( np . isnan ( X ) . sum ( axis = 1 ) ! = 0 , 1 , 0 ) . sum ( ) ": 1854,
 "def min_depth ( self , root ) : if root is None : return 0 if root . left is not None or root . right is not None : return max ( self . minDepth ( root . left ) , self . minDepth ( root . right ) ) +1 return min ( self . minDepth ( root . left ) , self . minDepth ( root . right ) ) + 1": 1855,
 "def get_language ( self ) : return get_language_parameter ( self . request , self . query_language_key , default = self . get_default_language ( object = object ) ) ": 1856,
 "def entropy ( string ) : p , lns = Counter ( string ) , float ( len ( string ) ) return -sum ( count/lns * math . log ( count/lns , 2 ) for count in p . values ( ) ) ": 1857,
 "def _get_str_columns ( sf ) : return [name for name in sf . column_names ( ) if sf[name] . dtype = = str]": 1858,
 "def _count_leading_whitespace ( text ) : idx = 0 for idx , char in enumerate ( text ) : if not char . isspace ( ) : return idx return idx + 1": 1859,
 "def str2int ( string_with_int ) : return int ( \" \" . join ( [char for char in string_with_int if char in string . digits] ) or 0 ) ": 1860,
 "def get_image_dimension ( self , url ) : w_h = ( None , None ) try : if url . startswith ( ' // ' ) : url = ' http : ' + url data = requests . get ( url ) . content im = Image . open ( BytesIO ( data ) ) w_h = im . size except Exception : logger . warning ( \" Error getting image size {} \" . format ( url ) , exc_info = True ) return w_h": 1861,
 "def ident ( ) : matrix = stypes . emptyDoubleMatrix ( ) libspice . ident_c ( matrix ) return stypes . cMatrixToNumpy ( matrix ) ": 1862,
 "def dir_modtime ( dpath ) : return max ( os . path . getmtime ( d ) for d , _ , _ in os . walk ( dpath ) ) ": 1863,
 "def head_and_tail_print ( self , n = 5 ) : from IPython import display display . display ( display . HTML ( self . _head_and_tail_table ( n ) ) ) ": 1864,
 "def polyline ( *points ) : return Path ( *[Line ( points[i] , points[i+1] ) for i in range ( len ( points ) - 1 ) ] ) ": 1865,
 "def fft_freqs ( n_fft , fs ) : return np . arange ( 0 , ( n_fft // 2 + 1 ) ) / float ( n_fft ) * float ( fs ) ": 1866,
 "def get_func_name ( func ) : func_name = getattr ( func , ' __name__ ' , func . __class__ . __name__ ) module_name = func . __module__ if module_name is not None : module_name = func . __module__ return ' {} . {} ' . format ( module_name , func_name ) return func_name": 1867,
 "def symbol_pos_int ( *args , **kwargs ) : kwargs . update ( { ' positive ' : True , ' integer ' : True} ) return sympy . Symbol ( *args , **kwargs ) ": 1868,
 "def get_git_branch ( git_path = ' git ' ) : branch_match = call ( ( git_path , ' rev-parse ' , ' --symbolic-full-name ' , ' HEAD ' ) ) if branch_match = = \" HEAD \" : return None else : return os . path . basename ( branch_match ) ": 1869,
 "def _to_array ( value ) : if isinstance ( value , ( tuple , list ) ) : return array ( value ) elif isinstance ( value , ( float , int ) ) : return np . float64 ( value ) else : return value": 1870,
 "def url_to_image ( url ) : r = requests . get ( url ) image = StringIO ( r . content ) return image": 1871,
 "def home ( ) : return dict ( links = dict ( api = ' {}{} ' . format ( request . url , PREFIX[1 : ] ) ) ) , \\ HTTPStatus . OK": 1872,
 "def get ( key , default = None ) : data = get_form ( ) or get_query_string ( ) return data . get ( key , default ) ": 1873,
 "def difference ( ydata1 , ydata2 ) : y1 = _n . array ( ydata1 ) y2 = _n . array ( ydata2 ) return ( sum ( y2-y1 ) /len ( ydata1 ) ) ": 1874,
 "def to_simple_rdd ( sc , features , labels ) : pairs = [ ( x , y ) for x , y in zip ( features , labels ) ] return sc . parallelize ( pairs ) ": 1875,
 "def get_available_gpus ( ) : local_device_protos = device_lib . list_local_devices ( ) return [x . name for x in local_device_protos if x . device_type = = ' GPU ' ]": 1876,
 "def create_task ( coro , loop ) : # pragma : no cover if hasattr ( loop , ' create_task ' ) : return loop . create_task ( coro ) return asyncio . Task ( coro , loop = loop ) ": 1877,
 "def conv_block ( inputs , filters , dilation_rates_and_kernel_sizes , **kwargs ) : return conv_block_internal ( conv , inputs , filters , dilation_rates_and_kernel_sizes , **kwargs ) ": 1878,
 "def extract_module_locals ( depth = 0 ) : f = sys . _getframe ( depth + 1 ) global_ns = f . f_globals module = sys . modules[global_ns[ ' __name__ ' ]] return ( module , f . f_locals ) ": 1879,
 "def debug ( sequence ) : points = [] for i , p in enumerate ( sequence ) : copy = Point ( p ) copy[ ' index ' ] = i points . append ( copy ) return sequence . __class__ ( points ) ": 1880,
 "def get_file_md5sum ( path ) : with open ( path , ' rb ' ) as fh : h = str ( hashlib . md5 ( fh . read ( ) ) . hexdigest ( ) ) return h": 1881,
 "def voronoi ( data , line_color = None , line_width = 2 , f_tooltip = None , cmap = None , max_area = 1e4 , alpha = 220 ) : from geoplotlib . layers import VoronoiLayer _global_config . layers . append ( VoronoiLayer ( data , line_color , line_width , f_tooltip , cmap , max_area , alpha ) ) ": 1882,
 "def _elapsed_time ( begin_time , end_time ) : bt = _str2datetime ( begin_time ) et = _str2datetime ( end_time ) return float ( ( et - bt ) . seconds ) ": 1883,
 "def get_var ( self , name ) : for var in self . vars : if var . name = = name : return var else : raise ValueError": 1884,
 "def c_array ( ctype , values ) : if isinstance ( values , np . ndarray ) and values . dtype . itemsize = = ctypes . sizeof ( ctype ) : return ( ctype * len ( values ) ) . from_buffer_copy ( values ) return ( ctype * len ( values ) ) ( *values ) ": 1885,
 "def node__name__ ( self ) : return self . node . __name__ \\ if self . node . __name__ is not None else self . node . __class__ . __name__": 1886,
 "def pointer ( self ) : return ctypes . cast ( ctypes . pointer ( ctypes . c_uint8 . from_buffer ( self . mapping , 0 ) ) , ctypes . c_void_p ) ": 1887,
 "def load_object_by_name ( object_name ) : mod_name , attr = object_name . rsplit ( ' . ' , 1 ) mod = import_module ( mod_name ) return getattr ( mod , attr ) ": 1888,
 "def __get__ ( self , obj , objtype ) : import functools return functools . partial ( self . __call__ , obj ) ": 1889,
 "def matrix_to_gl ( matrix ) : matrix = np . asanyarray ( matrix , dtype = np . float64 ) if matrix . shape ! = ( 4 , 4 ) : raise ValueError ( ' matrix must be ( 4 , 4 ) ! ' ) # switch to column major and flatten to ( 16 , ) column = matrix . T . flatten ( ) # convert to GLfloat glmatrix = ( gl . GLfloat * 16 ) ( *column ) return glmatrix": 1890,
 "def check_output ( args ) : log . debug ( ' run : %s ' , args ) out = subprocess . check_output ( args = args ) . decode ( ' utf-8 ' ) log . debug ( ' out : %r ' , out ) return out": 1891,
 "def format_timestamp ( timestamp ) : tz_info = tz . tzutc ( ) return datetime . fromtimestamp ( timestamp , tz = tz_info ) . strftime ( \" %Y-%m-%dT%H : %M : %S . 000Z \" ) ": 1892,
 "def get_page_text ( self , page ) : url = self . get_page_text_url ( page ) return self . _get_url ( url ) ": 1893,
 "def convert_2_utc ( self , datetime_ , timezone ) : datetime_ = self . tz_mapper[timezone] . localize ( datetime_ ) return datetime_ . astimezone ( pytz . UTC ) ": 1894,
 "def get_parent_folder_name ( file_path ) : return os . path . split ( os . path . split ( os . path . abspath ( file_path ) ) [0] ) [-1]": 1895,
 "def family_directory ( fonts ) : if fonts : dirname = os . path . dirname ( fonts[0] ) if dirname = = ' ' : dirname = ' . ' return dirname": 1896,
 "def decode_bytes ( string ) : if is_string_type ( type ( string ) ) : string = bytes ( string , \" utf-8 \" ) return base64 . decodebytes ( string ) ": 1897,
 "def intToBin ( i ) : # devide in two parts ( bytes ) i1 = i % 256 i2 = int ( i / 256 ) # make string ( little endian ) return chr ( i1 ) + chr ( i2 ) ": 1898,
 "def p ( self ) : return ( self . n-self . nmin ) /max ( ( self . nmax-self . nmin ) , 1 ) ": 1899,
 "def extra_funcs ( *funcs ) : def extra_funcs_decorator ( real_func ) : def wrapper ( *args , **kwargs ) : return real_func ( *args , **kwargs ) wrapper . extra_funcs = list ( funcs ) wrapper . source = inspect . getsource ( real_func ) wrapper . name = real_func . __name__ return wrapper return extra_funcs_decorator": 1900,
 "def basic_word_sim ( word1 , word2 ) : return sum ( [1 for c in word1 if c in word2] ) / max ( len ( word1 ) , len ( word2 ) ) ": 1901,
 "def remove ( parent , idx ) : if isinstance ( parent , dict ) : del parent[idx] elif isinstance ( parent , list ) : del parent[int ( idx ) ] else : raise JSONPathError ( \" Invalid path for operation \" ) ": 1902,
 "def unique ( list ) : unique = []; [unique . append ( x ) for x in list if x not in unique] return unique": 1903,
 "def readwav ( filename ) : from scipy . io . wavfile import read as readwav samplerate , signal = readwav ( filename ) return signal , samplerate": 1904,
 "def option2tuple ( opt ) : if isinstance ( opt[0] , int ) : tup = opt[1] , opt[2 : ] else : tup = opt[0] , opt[1 : ] return tup": 1905,
 "def clean_out_dir ( directory ) : if not isinstance ( directory , path ) : directory = path ( directory ) for file_path in directory . files ( ) : file_path . remove ( ) for dir_path in directory . dirs ( ) : dir_path . rmtree ( ) ": 1906,
 "def get_width ( ) : # Get terminal size ws = struct . pack ( \" HHHH \" , 0 , 0 , 0 , 0 ) ws = fcntl . ioctl ( sys . stdout . fileno ( ) , termios . TIOCGWINSZ , ws ) lines , columns , x , y = struct . unpack ( \" HHHH \" , ws ) width = min ( columns * 39 // 40 , columns - 2 ) return width": 1907,
 "def _normalize_abmn ( abmn ) : abmn_2d = np . atleast_2d ( abmn ) abmn_normalized = np . hstack ( ( np . sort ( abmn_2d[ : , 0 : 2] , axis = 1 ) , np . sort ( abmn_2d[ : , 2 : 4] , axis = 1 ) , ) ) return abmn_normalized": 1908,
 "def size ( dtype ) : dtype = tf . as_dtype ( dtype ) if hasattr ( dtype , ' size ' ) : return dtype . size return np . dtype ( dtype ) . itemsize": 1909,
 "def index ( self , value ) : \t\t\t\tfor i in xrange ( len ( self . parentNode ) ) : \t\t\tif getattr ( self . parentNode[i] , self . Name ) = = value : \t\t\t\treturn i\t\traise ValueError ( value ) ": 1910,
 "def refresh ( self , document ) : \t\t\t\ttry : \t\t\told_cache_size = self . cache_size\t\t\tself . cache_size = 0\t\t\tobj = self . query ( type ( document ) ) . filter_by ( mongo_id = document . mongo_id ) . one ( ) \t\tfinally : \t\t\tself . cache_size = old_cache_size\t\tself . cache_write ( obj ) \t\treturn obj": 1911,
 "def __getitem__ ( self , index ) : row , col = index return self . rows[row][col]": 1912,
 "def update_screen ( self ) : self . clock . tick ( self . FPS ) pygame . display . update ( ) ": 1913,
 "def calc_volume ( self , sample : np . ndarray ) : return sqrt ( np . mean ( np . square ( sample ) ) ) ": 1914,
 "def _get_local_ip ( self ) : try : sock = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM ) # Use Google Public DNS server to determine own IP sock . connect ( ( ' 8 . 8 . 8 . 8 ' , 80 ) ) return sock . getsockname ( ) [0] except socket . error : try : return socket . gethostbyname ( socket . gethostname ( ) ) except socket . gaierror : return ' 127 . 0 . 0 . 1 ' finally : sock . close ( ) ": 1915,
 "def getScriptLocation ( ) : \t\tlocation = os . path . abspath ( \" . / \" ) \tif __file__ . rfind ( \" / \" ) ! = -1 : \t\tlocation = __file__[ : __file__ . rfind ( \" / \" ) ]\treturn location": 1916,
 "def class_name ( obj ) : name = obj . __name__ module = getattr ( obj , ' __module__ ' ) if module : name = f ' {module} . {name} ' return name": 1917,
 "def initialize_api ( flask_app ) : if not flask_restplus : return api = flask_restplus . Api ( version = \" 1 . 0 \" , title = \" My Example API \" ) api . add_resource ( HelloWorld , \" /hello \" ) blueprint = flask . Blueprint ( \" api \" , __name__ , url_prefix = \" /api \" ) api . init_app ( blueprint ) flask_app . register_blueprint ( blueprint ) ": 1918,
 "def register_extension_class ( ext , base , *args , **kwargs ) : ext_instance = ext . plugin ( base , *args , **kwargs ) setattr ( base , ext . name . lstrip ( ' _ ' ) , ext_instance ) ": 1919,
 "def get_top ( self , *args , **kwargs ) : return self . get_content ( self . config[ ' top ' ] , *args , **kwargs ) ": 1920,
 "def size ( self ) : return np . multiply . reduce ( self . shape , dtype = np . int32 ) ": 1921,
 "def length ( self ) : return np . sqrt ( np . sum ( self**2 , axis = 1 ) ) . view ( np . ndarray ) ": 1922,
 "async def join ( self , ctx , * , channel : discord . VoiceChannel ) : if ctx . voice_client is not None : return await ctx . voice_client . move_to ( channel ) await channel . connect ( ) ": 1923,
 "def OnMove ( self , event ) : # Store window position in config position = self . main_window . GetScreenPositionTuple ( ) config[ \" window_position \" ] = repr ( position ) ": 1924,
 "def _handle_chat_name ( self , data ) : self . room . user . nick = data self . conn . enqueue_data ( \" user \" , self . room . user ) ": 1925,
 "def auth_request ( self , url , headers , body ) : return self . req . post ( url , headers , body = body ) ": 1926,
 "def get_plain_image_as_widget ( self ) : arr = self . getwin_array ( order = self . rgb_order ) image = self . _get_qimage ( arr , self . qimg_fmt ) return image": 1927,
 "def _get_loggers ( ) : from . . import loader modules = loader . get_package_modules ( ' logger ' ) return list ( loader . get_plugins ( modules , [_Logger] ) ) ": 1928,
 "def copy ( self ) : return self . __class__ ( field_type = self . get_field_type ( ) , data = self . export_data ( ) ) ": 1929,
 "def ffmpeg_works ( ) : images = np . zeros ( ( 2 , 32 , 32 , 3 ) , dtype = np . uint8 ) try : _encode_gif ( images , 2 ) return True except ( IOError , OSError ) : return False": 1930,
 "def managepy ( cmd , extra = None ) : extra = extra . split ( ) if extra else [] run_django_cli ( [ ' invoke ' , cmd] + extra ) ": 1931,
 "def branches ( self ) : result = self . git ( self . default + [ ' branch ' , ' -a ' , ' --no-color ' ] ) return [l . strip ( ' *\\n ' ) for l in result . split ( ' \\n ' ) if l . strip ( ' *\\n ' ) ]": 1932,
 "def get_qualified_name ( _object ) : module = _object . __module__ if hasattr ( _object , ' __name__ ' ) : _class = _object . __name__ else : _class = _object . __class__ . __name__ return module + ' . ' + _class": 1933,
 "def __init__ ( self , form_post_data = None , *args , **kwargs ) : kwargs . update ( { ' form_post_data ' : form_post_data} ) super ( MongoModelForm , self ) . __init__ ( *args , **kwargs ) ": 1934,
 "def object_to_json ( obj , indent = 2 ) : instance_json = json . dumps ( obj , indent = indent , ensure_ascii = False , cls = DjangoJSONEncoder ) return instance_json": 1935,
 "def full_like ( array , value , dtype = None ) : shared = empty_like ( array , dtype ) shared[ : ] = value return shared": 1936,
 "def __del__ ( self ) : if hasattr ( self , ' _Api ' ) : self . _Api . close ( ) self . _Logger . info ( ' object destroyed ' ) ": 1937,
 "def fill_document ( doc ) : with doc . create ( Section ( ' A section ' ) ) : doc . append ( ' Some regular text and some ' ) doc . append ( italic ( ' italic text . ' ) ) with doc . create ( Subsection ( ' A subsection ' ) ) : doc . append ( ' Also some crazy characters : $& # {} ' ) ": 1938,
 "def hex_to_hsv ( color ) : color = normalize ( color ) color = color[1 : ] # color = tuple ( ord ( c ) /255 . 0 for c in color . decode ( ' hex ' ) ) color = ( int ( color[0 : 2] , base = 16 ) / 255 . 0 , int ( color[2 : 4] , base = 16 ) / 255 . 0 , int ( color[4 : 6] , base = 16 ) / 255 . 0 ) return colorsys . rgb_to_hsv ( *color ) ": 1939,
 "def polite_string ( a_string ) : if is_py3 ( ) and hasattr ( a_string , ' decode ' ) : try : return a_string . decode ( ' utf-8 ' ) except UnicodeDecodeError : return a_string return a_string": 1940,
 "def isfunc ( x ) : return any ( [ inspect . isfunction ( x ) and not asyncio . iscoroutinefunction ( x ) , inspect . ismethod ( x ) and not asyncio . iscoroutinefunction ( x ) ] ) ": 1941,
 "def _get_pretty_string ( obj ) : sio = StringIO ( ) pprint . pprint ( obj , stream = sio ) return sio . getvalue ( ) ": 1942,
 "def action ( self ) : self . return_value = self . function ( *self . args , **self . kwargs ) ": 1943,
 "def _open_url ( url ) : response = requests . get ( url , stream = True ) if response . status_code ! = 200 : raise IOError ( \" Unable to download {} , HTTP {} \" . format ( url , response . status_code ) ) return response": 1944,
 "def set_parent_path ( self , value ) : self . _parent_path = value self . path = value + r ' / ' + self . name self . _update_childrens_parent_path ( ) ": 1945,
 "def normalize_time ( timestamp ) : offset = timestamp . utcoffset ( ) if offset is None : return timestamp return timestamp . replace ( tzinfo = None ) - offset": 1946,
 "def _get_all_constants ( ) : return [ key for key in globals ( ) . keys ( ) if all ( [ not key . startswith ( \" _ \" ) , # publicly accesible key . upper ( ) = = key , # uppercase type ( globals ( ) [key] ) in _ALLOWED # and with type from _ALLOWED ] ) ]": 1947,
 "def inverse_transform ( self , X ) : X = check_array ( X , copy = self . copy ) X - = self . min_ X / = self . scale_ return X": 1948,
 "def closeEvent ( self , e ) : self . emit ( ' close_widget ' ) super ( DockWidget , self ) . closeEvent ( e ) ": 1949,
 "def wipe ( self ) : keys = list ( self . keys ( ) ) . copy ( ) for key in keys : self . delete ( key ) ": 1950,
 "def disassemble_file ( filename , outstream = None ) : filename = check_object_path ( filename ) ( version , timestamp , magic_int , co , is_pypy , source_size ) = load_module ( filename ) if type ( co ) = = list : for con in co : disco ( version , con , outstream ) else : disco ( version , co , outstream , is_pypy = is_pypy ) co = None": 1951,
 "def geodetic_to_ecef ( latitude , longitude , altitude ) : ellip = np . sqrt ( 1 . - earth_b ** 2 / earth_a ** 2 ) r_n = earth_a / np . sqrt ( 1 . - ellip ** 2 * np . sin ( np . deg2rad ( latitude ) ) ** 2 ) # colatitude = 90 . - latitude x = ( r_n + altitude ) * np . cos ( np . deg2rad ( latitude ) ) * np . cos ( np . deg2rad ( longitude ) ) y = ( r_n + altitude ) * np . cos ( np . deg2rad ( latitude ) ) * np . sin ( np . deg2rad ( longitude ) ) z = ( r_n * ( 1 . - ellip ** 2 ) + altitude ) * np . sin ( np . deg2rad ( latitude ) ) return x , y , z": 1952,
 "def scan ( client , query = None , scroll = ' 5m ' , raise_on_error = True , preserve_order = False , size = 1000 , **kwargs ) : if not preserve_order : kwargs[ ' search_type ' ] = ' scan ' # initial search resp = client . search ( body = query , scroll = scroll , size = size , **kwargs ) scroll_id = resp . get ( ' _scroll_id ' ) if scroll_id is None : return first_run = True while True : # if we didn ' t set search_type to scan initial search contains data if preserve_order and first_run : first_run = False else : resp = client . scroll ( scroll_id , scroll = scroll ) for hit in resp[ ' hits ' ][ ' hits ' ] : yield hit # check if we have any errrors if resp[ \" _shards \" ][ \" failed \" ] : logger . warning ( ' Scroll request has failed on %d shards out of %d . ' , resp[ ' _shards ' ][ ' failed ' ] , resp[ ' _shards ' ][ ' total ' ] ) if raise_on_error : raise ScanError ( ' Scroll request has failed on %d shards out of %d . ' % ( resp[ ' _shards ' ][ ' failed ' ] , resp[ ' _shards ' ][ ' total ' ] ) ) scroll_id = resp . get ( ' _scroll_id ' ) # end of scroll if scroll_id is None or not resp[ ' hits ' ][ ' hits ' ] : break": 1953,
 "def is_valid_regex ( regex ) : if len ( regex ) = = 0 : return False try : re . compile ( regex ) return True except sre_constants . error : return False": 1954,
 "def check_length ( value , length ) : _length = len ( value ) if _length ! = length : raise ValueError ( \" length must be %d , not %d \" % \\ ( length , _length ) ) ": 1955,
 "def line_line_collide ( line1 , line2 ) : s , t , success = segment_intersection ( line1[ : , 0] , line1[ : , 1] , line2[ : , 0] , line2[ : , 1] ) if success : return _helpers . in_interval ( s , 0 . 0 , 1 . 0 ) and _helpers . in_interval ( t , 0 . 0 , 1 . 0 ) else : disjoint , _ = parallel_lines_parameters ( line1[ : , 0] , line1[ : , 1] , line2[ : , 0] , line2[ : , 1] ) return not disjoint": 1956,
 "def hard_equals ( a , b ) : if type ( a ) ! = type ( b ) : return False return a = = b": 1957,
 "def _escape ( self , s ) : for ch , r_ch in self . ESCAPE_SETS : s = s . replace ( ch , r_ch ) return s": 1958,
 "def copy ( string , **kwargs ) : window = Tk ( ) window . withdraw ( ) window . clipboard_clear ( ) window . clipboard_append ( string ) window . destroy ( ) return": 1959,
 "def __call__ ( self , xy ) : x , y = xy return ( self . x ( x ) , self . y ( y ) ) ": 1960,
 "def fast_exit ( code ) : sys . stdout . flush ( ) sys . stderr . flush ( ) os . _exit ( code ) ": 1961,
 "def __init__ ( self , ba = None ) : self . bytearray = ba or ( bytearray ( b ' \\0 ' ) * self . SIZEOF ) ": 1962,
 "def safe_rmtree ( directory ) : if os . path . exists ( directory ) : shutil . rmtree ( directory , True ) ": 1963,
 "def double_exponential_moving_average ( data , period ) : catch_errors . check_for_period_error ( data , period ) dema = ( 2 * ema ( data , period ) ) - ema ( ema ( data , period ) , period ) return dema": 1964,
 "def is_file_url ( url ) : from . misc import to_text if not url : return False if not isinstance ( url , six . string_types ) : try : url = getattr ( url , \" url \" ) except AttributeError : raise ValueError ( \" Cannot parse url from unknown type : {0!r} \" . format ( url ) ) url = to_text ( url , encoding = \" utf-8 \" ) return urllib_parse . urlparse ( url . lower ( ) ) . scheme = = \" file \" ": 1965,
 "def save_image ( pdf_path , img_path , page_num ) : pdf_img = Image ( filename = \" {}[{}] \" . format ( pdf_path , page_num ) ) with pdf_img . convert ( \" png \" ) as converted : # Set white background . converted . background_color = Color ( \" white \" ) converted . alpha_channel = \" remove \" converted . save ( filename = img_path ) ": 1966,
 "def version_triple ( tag ) : groups = re . match ( r ' v? ( \\d+ ) \\ . ( \\d+ ) \\ . ( \\d+ ) ' , tag ) . groups ( ) return tuple ( int ( n ) for n in groups ) ": 1967,
 "def __next__ ( self , reward , ask_id , lbl ) : return self . next ( reward , ask_id , lbl ) ": 1968,
 "def contains_extractor ( document ) : tokens = _get_document_tokens ( document ) features = dict ( ( u ' contains ( {0} ) ' . format ( w ) , True ) for w in tokens ) return features": 1969,
 "def clean_tmpdir ( path ) : if os . path . exists ( path ) and \\ os . path . isdir ( path ) : rmtree ( path ) ": 1970,
 "def _heappop_max ( heap ) : lastelt = heap . pop ( ) # raises appropriate IndexError if heap is empty if heap : returnitem = heap[0] heap[0] = lastelt _siftup_max ( heap , 0 ) return returnitem return lastelt": 1971,
 "def get_method_names ( obj ) : method_names = [] for method_name in dir ( obj ) : method = getattr ( obj , method_name ) if MethodReflector . _is_method ( method , method_name ) : method_names . append ( method_name ) return method_names": 1972,
 "def iterate ( obj ) : \t\t\tglobal next , Iteration\tnext = next\tIteration = Iteration\t\ttotal = len ( obj ) if isinstance ( obj , Sized ) else None\titerator = iter ( obj ) \tfirst = True\tlast = False\ti = 0\t\ttry : \t\tvalue = next ( iterator ) \texcept StopIteration : \t\treturn\t\twhile True : \t\ttry : \t\t\tnext_value = next ( iterator ) \t\texcept StopIteration : \t\t\tlast = True\t\t\t\tyield Iteration ( first , last , i , total , value ) \t\tif last : return\t\t\t\tvalue = next_value\t\ti + = 1\t\tfirst = False": 1973,
 "def _select_features ( example , feature_list = None ) : feature_list = feature_list or [ \" inputs \" , \" targets \" ] return {f : example[f] for f in feature_list}": 1974,
 "def wget ( url ) : import urllib . parse request = urllib . request . urlopen ( url ) filestring = request . read ( ) return filestring": 1975,
 "def _read_text ( self , filename ) : with io . open ( filename , ' rt ' , encoding = ' utf-8 ' ) as f : return f . read ( ) ": 1976,
 "def pods ( self ) : return self . core_api . list_namespaced_pod ( self . namespace , label_selector = format_labels ( self . pod_template . metadata . labels ) ) . items": 1977,
 "def _hide_tick_lines_and_labels ( axis ) : for item in axis . get_ticklines ( ) + axis . get_ticklabels ( ) : item . set_visible ( False ) ": 1978,
 "def median_high ( data ) : data = sorted ( data ) n = len ( data ) if n = = 0 : raise StatisticsError ( \" no median for empty data \" ) return data[n // 2]": 1979,
 "def search_overlap ( self , point_list ) : result = set ( ) for j in point_list : self . search_point ( j , result ) return result": 1980,
 "def findMax ( arr ) : out = np . zeros ( shape = arr . shape , dtype = bool ) _calcMax ( arr , out ) return out": 1981,
 "def pout ( msg , log = None ) : _print ( msg , sys . stdout , log_func = log . info if log else None ) ": 1982,
 "def argmax ( l , f = None ) : if f : l = [f ( i ) for i in l] return max ( enumerate ( l ) , key = lambda x : x[1] ) [0]": 1983,
 "def list_i2str ( ilist ) : slist = [] for el in ilist : slist . append ( str ( el ) ) return slist": 1984,
 "def binSearch ( arr , val ) : i = bisect_left ( arr , val ) if i ! = len ( arr ) and arr[i] = = val : return i return -1": 1985,
 "def find ( self , name ) : for i , nm in enumerate ( self . data ) : if nm[-1] = = name : return i return -1": 1986,
 "def multiply ( self , number ) : return self . from_list ( [x * number for x in self . to_list ( ) ] ) ": 1987,
 "def _normalize ( mat : np . ndarray ) : return ( ( mat - mat . min ( ) ) * ( 255 / mat . max ( ) ) ) . astype ( np . uint8 ) ": 1988,
 "def read_stdin ( ) : if sys . stdin . isatty ( ) and sys . stdout . isatty ( ) : print ( ' \\nReading from stdin until end of file ( Ctrl + D ) . . . ' ) return sys . stdin . read ( ) ": 1989,
 "def read_key ( suppress = False ) : event = read_event ( suppress ) return event . name or event . scan_code": 1990,
 "def fit_transform ( self , raw_documents , y = None ) : documents = super ( TfidfVectorizer , self ) . fit_transform ( raw_documents = raw_documents , y = y ) count = CountVectorizer ( encoding = self . encoding , decode_error = self . decode_error , strip_accents = self . strip_accents , lowercase = self . lowercase , preprocessor = self . preprocessor , tokenizer = self . tokenizer , stop_words = self . stop_words , token_pattern = self . token_pattern , ngram_range = self . ngram_range , analyzer = self . analyzer , max_df = self . max_df , min_df = self . min_df , max_features = self . max_features , vocabulary = self . vocabulary_ , binary = self . binary , dtype = self . dtype ) count . fit_transform ( raw_documents = raw_documents , y = y ) self . period_ = count . period_ self . df_ = count . df_ self . n = count . n return documents": 1991,
 "def report_stdout ( host , stdout ) : lines = stdout . readlines ( ) if lines : print ( \" STDOUT from {host} : \" . format ( host = host ) ) for line in lines : print ( line . rstrip ( ) , file = sys . stdout ) ": 1992,
 "def rotateImage ( image , angle ) : image = [list ( row ) for row in image] for n in range ( angle % 4 ) : image = list ( zip ( *image[ : : -1] ) ) return image": 1993,
 "def generate_seed ( seed ) : if seed is None : random . seed ( ) seed = random . randint ( 0 , sys . maxsize ) random . seed ( a = seed ) return seed": 1994,
 "def __clear_buffers ( self ) : try : self . _port . reset_input_buffer ( ) self . _port . reset_output_buffer ( ) except AttributeError : # pySerial 2 . 7 self . _port . flushInput ( ) self . _port . flushOutput ( ) ": 1995,
 "def _change_height ( self , ax , new_value ) : for patch in ax . patches : current_height = patch . get_height ( ) diff = current_height - new_value # we change the bar height patch . set_height ( new_value ) # we recenter the bar patch . set_y ( patch . get_y ( ) + diff * . 5 ) ": 1996,
 "async def terminate ( self ) : self . proc . terminate ( ) await asyncio . wait_for ( self . proc . wait ( ) , self . kill_delay ) if self . proc . returncode is None : self . proc . kill ( ) await self . proc . wait ( ) await super ( ) . terminate ( ) ": 1997,
 "def reportMemory ( k , options , field = None , isBytes = False ) : if options . pretty : return prettyMemory ( int ( k ) , field = field , isBytes = isBytes ) else : if isBytes : k / = 1024 . if field is not None : return \" %*dK \" % ( field - 1 , k ) # -1 for the \" K \" else : return \" %dK \" % int ( k ) ": 1998,
 "def OnUpdateFigurePanel ( self , event ) : if self . updating : return self . updating = True self . figure_panel . update ( self . get_figure ( self . code ) ) self . updating = False": 1999,
 "def format_line ( data , linestyle ) : return linestyle . begin + linestyle . sep . join ( data ) + linestyle . end": 2000,
 "def to_percentage ( number , rounding = 2 ) : number = float ( number ) * 100 number_as_int = int ( number ) rounded = round ( number , rounding ) return ' {}% ' . format ( number_as_int if number_as_int = = rounded else rounded ) ": 2001,
 "def irfftn ( a , s , axes = None ) : return pyfftw . interfaces . numpy_fft . irfftn ( a , s = s , axes = axes , overwrite_input = False , planner_effort = ' FFTW_MEASURE ' , threads = pyfftw_threads ) ": 2002,
 "def closest ( xarr , val ) : idx_closest = np . argmin ( np . abs ( np . array ( xarr ) - val ) ) return idx_closest": 2003,
 "def _most_common ( iterable ) : data = Counter ( iterable ) return max ( data , key = data . __getitem__ ) ": 2004,
 "def to_snake_case ( s ) : return re . sub ( ' ( [^_A-Z] ) ( [A-Z] ) ' , lambda m : m . group ( 1 ) + ' _ ' + m . group ( 2 ) . lower ( ) , s ) ": 2005,
 "def dereference_url ( url ) : res = open_url ( url , method = ' HEAD ' ) res . close ( ) return res . url": 2006,
 "def speedtest ( func , *args , **kwargs ) : n = 100 start = time . time ( ) for i in range ( n ) : func ( *args , **kwargs ) end = time . time ( ) return ( end-start ) /n": 2007,
 "def money ( min = 0 , max = 10 ) : value = random . choice ( range ( min * 100 , max * 100 ) ) return \" %1 . 2f \" % ( float ( value ) / 100 ) ": 2008,
 "def clean_float ( v ) : if v is None or not str ( v ) . strip ( ) : return None return float ( str ( v ) . replace ( ' , ' , ' ' ) ) ": 2009,
 "def random_letters ( n ) : return ' ' . join ( random . SystemRandom ( ) . choice ( string . ascii_letters ) for _ in range ( n ) ) ": 2010,
 "def _file_and_exists ( val , input_files ) : return ( ( os . path . exists ( val ) and os . path . isfile ( val ) ) or val in input_files ) ": 2011,
 "def read_uint ( data , start , length ) : return int . from_bytes ( data[start : start+length] , byteorder = ' big ' ) ": 2012,
 "def example_write_file_to_disk_if_changed ( ) : my_file = FileAsObj ( ' /tmp/example_file . txt ' ) my_file . rm ( my_file . egrep ( ' ^ # ' ) ) if my_file . changed : my_file . save ( ) ": 2013,
 "def chkstr ( s , v ) : if type ( s ) ! = str : raise TypeError ( \" {var} must be str \" . format ( var = v ) ) if not s : raise ValueError ( \" {var} cannot be empty \" . format ( var = v ) ) ": 2014,
 "def get_url_file_name ( url ) : assert isinstance ( url , ( str , _oldstr ) ) return urlparse . urlparse ( url ) . path . split ( ' / ' ) [-1]": 2015,
 "def extent ( self ) : return ( self . intervals[1] . pix1 - 0 . 5 , self . intervals[1] . pix2 - 0 . 5 , self . intervals[0] . pix1 - 0 . 5 , self . intervals[0] . pix2 - 0 . 5 , ) ": 2016,
 "def _get_background_color ( self ) : color = self . cell_attributes[self . key][ \" bgcolor \" ] return tuple ( c / 255 . 0 for c in color_pack2rgb ( color ) ) ": 2017,
 "def resize ( self , size ) : return Image ( self . pil_image . resize ( size , PIL . Image . ANTIALIAS ) ) ": 2018,
 "def min_max_normalize ( img ) : min_img = img . min ( ) max_img = img . max ( ) return ( img - min_img ) / ( max_img - min_img ) ": 2019,
 "def get_date ( date ) : if type ( date ) is str : return datetime . strptime ( date , ' %Y-%m-%d ' ) . date ( ) else : return date": 2020,
 "def get_shape ( img ) : if hasattr ( img , ' shape ' ) : shape = img . shape else : shape = img . get_data ( ) . shape return shape": 2021,
 "def setup_path ( ) : import os . path; import sys if sys . argv[0] : top_dir = os . path . dirname ( os . path . abspath ( sys . argv[0] ) ) sys . path = [os . path . join ( top_dir , \" src \" ) ] + sys . path pass return": 2022,
 "def write_padding ( fp , size , divisor = 2 ) : remainder = size % divisor if remainder : return write_bytes ( fp , struct . pack ( ' %dx ' % ( divisor - remainder ) ) ) return 0": 2023,
 "def incr ( self , key , incr_by = 1 ) : return self . database . hincrby ( self . key , key , incr_by ) ": 2024,
 "def fit_linear ( X , y ) : model = linear_model . LinearRegression ( ) model . fit ( X , y ) return model": 2025,
 "def idx ( df , index ) : if isinstance ( df , ( pd . DataFrame , pd . Series ) ) : return df . iloc[index] else : return df[index , : ]": 2026,
 "def col_frequencies ( col , weights = None , gap_chars = ' - . ' ) : counts = col_counts ( col , weights , gap_chars ) # Reduce to frequencies scale = 1 . 0 / sum ( counts . values ( ) ) return dict ( ( aa , cnt * scale ) for aa , cnt in counts . iteritems ( ) ) ": 2027,
 "def ServerLoggingStartupInit ( ) : global LOGGER if local_log : logging . debug ( \" Using local LogInit from %s \" , local_log ) local_log . LogInit ( ) logging . debug ( \" Using local AppLogInit from %s \" , local_log ) LOGGER = local_log . AppLogInit ( ) else : LogInit ( ) LOGGER = AppLogInit ( ) ": 2028,
 "def intty ( cls ) : # XXX : temporary hack until we can detect if we are in a pipe or not return True if hasattr ( sys . stdout , ' isatty ' ) and sys . stdout . isatty ( ) : return True return False": 2029,
 "def wrap_key ( self , key ) : return tuple ( np . round ( self . integer_cell . shortest_vector ( key ) ) . astype ( int ) ) ": 2030,
 "def index ( self , elem ) : return _coconut . len ( self . _iter ) - self . _iter . index ( elem ) - 1": 2031,
 "def get_inputs_from_cm ( index , cm ) : return tuple ( i for i in range ( cm . shape[0] ) if cm[i][index] ) ": 2032,
 "def main ( filename ) : # Prepare font . font_family = ' arial ' font = Font ( font_family , bold = True ) if not font : raise RuntimeError ( ' No font found for %r ' % font_family ) # Initialize PDF document on a stream . with Document ( ' output . pdf ' ) as document : # Initialize a new page and begin its context . with document . Page ( ) as ctx : # Open the image to embed . with Image ( filename ) as embed : # Set the media box for the page to the same as the # image to embed . ctx . box = embed . box # Embed the image . ctx . embed ( embed ) # Write some text . ctx . add ( Text ( ' Hello World ' , font , size = 14 , x = 100 , y = 60 ) ) ": 2033,
 "def _index_ordering ( redshift_list ) : redshift_list = np . array ( redshift_list ) sort_index = np . argsort ( redshift_list ) return sort_index": 2034,
 "def __mul__ ( self , other ) : return self . _handle_type ( other ) ( self . value * other . value ) ": 2035,
 "def bin_to_int ( string ) : if isinstance ( string , str ) : return struct . unpack ( \" b \" , string ) [0] else : return struct . unpack ( \" b \" , bytes ( [string] ) ) [0]": 2036,
 "def end_index ( self ) : return ( ( self . number - 1 ) * self . paginator . per_page + len ( self . object_list ) ) ": 2037,
 "def prevmonday ( num ) : today = get_today ( ) lastmonday = today - timedelta ( days = today . weekday ( ) , weeks = num ) return lastmonday": 2038,
 "def get_line_ending ( line ) : non_whitespace_index = len ( line . rstrip ( ) ) - len ( line ) if not non_whitespace_index : return ' ' else : return line[non_whitespace_index : ]": 2039,
 "def subkey ( dct , keys ) : key = keys[0] if len ( keys ) = = 1 : return dct[key] return subkey ( dct[key] , keys[1 : ] ) ": 2040,
 "def all_collections ( db ) : \t\tinclude_pattern = r ' ( ?!system\\ . ) ' \treturn ( \t\tdb[name]\t\tfor name in db . list_collection_names ( ) \t\tif re . match ( include_pattern , name ) \t ) ": 2041,
 "def lin_interp ( x , rangeX , rangeY ) : s = ( x - rangeX[0] ) / mag ( rangeX[1] - rangeX[0] ) y = rangeY[0] * ( 1 - s ) + rangeY[1] * s return y": 2042,
 "def intersect_3d ( p1 , p2 ) : v = p2 - p1 normed_v = unit_vector ( v ) nx = normed_v[ : , 0] ny = normed_v[ : , 1] nz = normed_v[ : , 2] xx = np . sum ( nx**2 - 1 ) yy = np . sum ( ny**2 - 1 ) zz = np . sum ( nz**2 - 1 ) xy = np . sum ( nx * ny ) xz = np . sum ( nx * nz ) yz = np . sum ( ny * nz ) M = np . array ( [ ( xx , xy , xz ) , ( xy , yy , yz ) , ( xz , yz , zz ) ] ) x = np . sum ( p1[ : , 0] * ( nx**2 - 1 ) + p1[ : , 1] * ( nx * ny ) + p1[ : , 2] * ( nx * nz ) ) y = np . sum ( p1[ : , 0] * ( nx * ny ) + p1[ : , 1] * ( ny * ny - 1 ) + p1[ : , 2] * ( ny * nz ) ) z = np . sum ( p1[ : , 0] * ( nx * nz ) + p1[ : , 1] * ( ny * nz ) + p1[ : , 2] * ( nz**2 - 1 ) ) return np . linalg . lstsq ( M , np . array ( ( x , y , z ) ) , rcond = None ) [0]": 2043,
 "def gday_of_year ( self ) : return ( self . date - dt . date ( self . date . year , 1 , 1 ) ) . days": 2044,
 "def is_date_type ( cls ) : if not isinstance ( cls , type ) : return False return issubclass ( cls , date ) and not issubclass ( cls , datetime ) ": 2045,
 "def root_parent ( self , category = None ) : return next ( filter ( lambda c : c . is_root , self . hierarchy ( ) ) ) ": 2046,
 "def stop_at ( iterable , idx ) : for i , item in enumerate ( iterable ) : if i = = idx : return yield item": 2047,
 "def previous_quarter ( d ) : from django_toolkit . datetime_util import quarter as datetime_quarter return quarter ( ( datetime_quarter ( datetime ( d . year , d . month , d . day ) ) [0] + timedelta ( days = -1 ) ) . date ( ) ) ": 2048,
 "def links ( cls , page ) : for match in cls . HREF_RE . finditer ( page ) : yield cls . href_match_to_url ( match ) ": 2049,
 "def get_size ( path ) : if os . path . isfile ( path ) : return os . path . getsize ( path ) return sum ( get_size ( os . path . join ( path , f ) ) for f in os . listdir ( path ) ) ": 2050,
 "def _unordered_iterator ( self ) : for i , qs in zip ( self . _queryset_idxs , self . _querysets ) : for item in qs : setattr ( item , ' # ' , i ) yield item": 2051,
 "def _fill ( self ) : try : self . _head = self . _iterable . next ( ) except StopIteration : self . _head = None": 2052,
 "def memsize ( self ) : return self . size + 1 + TYPE . size ( gl . BOUND_TYPE ) * len ( self . bounds ) ": 2053,
 "def load ( raw_bytes ) : try : if not isinstance ( raw_bytes , string_type ) : raw_bytes = raw_bytes . decode ( ) return json . loads ( raw_bytes ) except ValueError as e : raise SerializationException ( str ( e ) ) ": 2054,
 "def _extract_node_text ( node ) : texts = map ( six . text_type . strip , map ( six . text_type , map ( unescape , node . xpath ( \" . //text ( ) \" ) ) ) ) return \" \" . join ( text for text in texts if text ) ": 2055,
 "def compose_all ( tups ) : from . import ast # I weep for humanity return functools . reduce ( lambda x , y : x . compose ( y ) , map ( ast . make_tuple , tups ) , ast . make_tuple ( {} ) ) ": 2056,
 "def json ( body , charset = ' utf-8 ' , **kwargs ) : return json_converter . loads ( text ( body , charset = charset ) ) ": 2057,
 "def get_abi3_suffix ( ) : for suffix , _ , _ in ( s for s in imp . get_suffixes ( ) if s[2] = = imp . C_EXTENSION ) : if ' . abi3 ' in suffix : # Unix return suffix elif suffix = = ' . pyd ' : # Windows return suffix": 2058,
 "def json_dumps ( self , obj ) : return json . dumps ( obj , sort_keys = True , indent = 4 , separators = ( ' , ' , ' : ' ) ) ": 2059,
 "def _cumprod ( l ) : ret = [1] for item in l : ret . append ( ret[-1] * item ) return ret": 2060,
 "def typename ( obj ) : if hasattr ( obj , ' __class__ ' ) : return getattr ( obj , ' __class__ ' ) . __name__ else : return type ( obj ) . __name__": 2061,
 "def json_decode ( data ) : if isinstance ( data , six . binary_type ) : data = data . decode ( ' utf-8 ' ) return json . loads ( data ) ": 2062,
 "def prettify ( elem ) : rough_string = ET . tostring ( elem , ' utf-8 ' ) reparsed = minidom . parseString ( rough_string ) return reparsed . toprettyxml ( indent = \" \\t \" ) ": 2063,
 "def classify_clusters ( points , n = 10 ) : arr = [[p . x , p . y] for p in points . values] clf = KMeans ( n_clusters = n ) clf . fit ( arr ) classes = clf . predict ( arr ) return classes": 2064,
 "def _sourced_dict ( self , source = None , **kwargs ) : if source : kwargs[ ' source ' ] = source elif self . source : kwargs[ ' source ' ] = self . source return kwargs": 2065,
 "def get_element_attribute_or_empty ( element , attribute_name ) : return element . attributes[attribute_name] . value if element . hasAttribute ( attribute_name ) else \" \" ": 2066,
 "def make_lambda ( call ) : empty_args = ast . arguments ( args = [] , vararg = None , kwarg = None , defaults = [] ) return ast . Lambda ( args = empty_args , body = call ) ": 2067,
 "def is_changed ( ) : executed , changed_lines = execute_git ( ' status --porcelain ' , output = False ) merge_not_finished = mod_path . exists ( ' . git/MERGE_HEAD ' ) return changed_lines . strip ( ) or merge_not_finished": 2068,
 "def apply_kwargs ( func , **kwargs ) : new_kwargs = {} params = signature ( func ) . parameters for param_name in params . keys ( ) : if param_name in kwargs : new_kwargs[param_name] = kwargs[param_name] return func ( **new_kwargs ) ": 2069,
 "def run_tests ( self ) : \t\t\t\twith _save_argv ( _sys . argv[ : 1] + self . addopts ) : \t\t\tresult_code = __import__ ( ' pytest ' ) . main ( ) \t\t\tif result_code : \t\t\t\traise SystemExit ( result_code ) ": 2070,
 "def print_matrix ( X , decimals = 1 ) : for row in np . round ( X , decimals = decimals ) : print ( row ) ": 2071,
 "def get_table_width ( table ) : columns = transpose_table ( prepare_rows ( table ) ) widths = [max ( len ( cell ) for cell in column ) for column in columns] return len ( ' + ' + ' | ' . join ( ' - ' * ( w + 2 ) for w in widths ) + ' + ' ) ": 2072,
 "def open01 ( x , limit = 1 . e-6 ) : try : return np . array ( [min ( max ( y , limit ) , 1 . - limit ) for y in x] ) except TypeError : return min ( max ( x , limit ) , 1 . - limit ) ": 2073,
 "def _check_graphviz_available ( output_format ) : try : subprocess . call ( [ \" dot \" , \" -V \" ] , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) except OSError : print ( \" The output format ' %s ' is currently not available . \\n \" \" Please install ' Graphviz ' to have other output formats \" \" than ' dot ' or ' vcg ' . \" % output_format ) sys . exit ( 32 ) ": 2074,
 "def index ( m , val ) : mm = np . array ( m ) idx_tuple = np . where ( mm = = val ) idx = idx_tuple[0] . tolist ( ) return idx": 2075,
 "def _unique_rows_numpy ( a ) : a = np . ascontiguousarray ( a ) unique_a = np . unique ( a . view ( [ ( ' ' , a . dtype ) ] * a . shape[1] ) ) return unique_a . view ( a . dtype ) . reshape ( ( unique_a . shape[0] , a . shape[1] ) ) ": 2076,
 "def executable_exists ( executable ) : for directory in os . getenv ( \" PATH \" ) . split ( \" : \" ) : if os . path . exists ( os . path . join ( directory , executable ) ) : return True return False": 2077,
 "def values ( self ) : values = [] for __ , data in self . items ( ) : values . append ( data ) return values": 2078,
 "def btc_make_p2sh_address ( script_hex ) : h = hashing . bin_hash160 ( binascii . unhexlify ( script_hex ) ) addr = bin_hash160_to_address ( h , version_byte = multisig_version_byte ) return addr": 2079,
 "def get_dimension_array ( array ) : if all ( isinstance ( el , list ) for el in array ) : result = [len ( array ) , len ( max ( [x for x in array] , key = len , ) ) ] # elif array and isinstance ( array , list ) : else : result = [len ( array ) , 1] return result": 2080,
 "def get_dt_list ( fn_list ) : dt_list = np . array ( [fn_getdatetime ( fn ) for fn in fn_list] ) return dt_list": 2081,
 "def poke_array ( self , store , name , elemtype , elements , container , visited , _stack ) : raise NotImplementedError": 2082,
 "def is_valid ( email ) : if isinstance ( email , basestring ) and EMAIL_RE . match ( email ) : return True return False": 2083,
 "def loadmat ( filename ) : data = sploadmat ( filename , struct_as_record = False , squeeze_me = True ) return _check_keys ( data ) ": 2084,
 "def _float_almost_equal ( float1 , float2 , places = 7 ) : if round ( abs ( float2 - float1 ) , places ) = = 0 : return True return False": 2085,
 "def getFunction ( self ) : return functionFactory ( self . code , self . name , self . defaults , self . globals , self . imports , ) ": 2086,
 "def is_text ( obj , name = None ) : try : # python2 ans = isinstance ( obj , basestring ) except NameError : # python3 ans = isinstance ( obj , str ) if name : print ( \" is_text : ( %s ) %s = %s \" % ( ans , name , obj . __class__ ) , file = sys . stderr ) return ans": 2087,
 "def _get_or_create_stack ( name ) : stack = getattr ( _LOCAL_STACKS , name , None ) if stack is None : stack = [] setattr ( _LOCAL_STACKS , name , stack ) return stack": 2088,
 "def unlock ( self ) : if not hasattr ( self , ' session ' ) : raise RuntimeError ( ' Error detected! The session that you want to close does not exist any more! ' ) logger . debug ( \" Closed database session of ' %s ' \" % self . _database ) self . session . close ( ) del self . session": 2089,
 "def find_frequencies ( data , freq = 44100 , bits = 16 ) : # Fast fourier transform n = len ( data ) p = _fft ( data ) uniquePts = numpy . ceil ( ( n + 1 ) / 2 . 0 ) # Scale by the length ( n ) and square the value to get the amplitude p = [ ( abs ( x ) / float ( n ) ) ** 2 * 2 for x in p[0 : uniquePts]] p[0] = p[0] / 2 if n % 2 = = 0 : p[-1] = p[-1] / 2 # Generate the frequencies and zip with the amplitudes s = freq / float ( n ) freqArray = numpy . arange ( 0 , uniquePts * s , s ) return zip ( freqArray , p ) ": 2090,
 "def log_no_newline ( self , msg ) : self . print2file ( self . logfile , False , False , msg ) ": 2091,
 "def close_log ( log , verbose = True ) : if verbose : print ( ' Closing log file : ' , log . name ) # Send closing message . log . info ( ' The log file has been closed . ' ) # Remove all handlers from log . [log . removeHandler ( handler ) for handler in log . handlers]": 2092,
 "def get_geoip ( ip ) : reader = geolite2 . reader ( ) ip_data = reader . get ( ip ) or {} return ip_data . get ( ' country ' , {} ) . get ( ' iso_code ' ) ": 2093,
 "def setLoggerAll ( self , mthd ) : for key in self . _logger_methods : self . _logger_methods[key] = mthd": 2094,
 "def time_range ( from_ = None , to = None ) : # todo datetime conversion args = locals ( ) return { k . replace ( ' _ ' , ' ' ) : v for k , v in args . items ( ) }": 2095,
 "def path_to_list ( pathstr ) : return [elem for elem in pathstr . split ( os . path . pathsep ) if elem]": 2096,
 "def write ( self , text ) : self . logger . log ( self . loglevel , text , extra = { ' terminator ' : None} ) ": 2097,
 "def camelcase_to_slash ( name ) : s1 = re . sub ( ' ( . ) ( [A-Z][a-z]+ ) ' , r ' \\1/\\2 ' , name ) return re . sub ( ' ( [a-z0-9] ) ( [A-Z] ) ' , r ' \\1/\\2 ' , s1 ) . lower ( ) ": 2098,
 "def main ( argv = None ) : args = parse_arguments ( sys . argv if argv is None else argv ) tf . logging . set_verbosity ( tf . logging . INFO ) learn_runner . run ( experiment_fn = get_experiment_fn ( args ) , output_dir = args . job_dir ) ": 2099,
 "def add_suffix ( fullname , suffix ) : name , ext = os . path . splitext ( fullname ) return name + ' _ ' + suffix + ext": 2100,
 "def from_file ( filename , mime = False ) : head , foot = _file_details ( filename ) return _magic ( head , foot , mime , ext_from_filename ( filename ) ) ": 2101,
 "def process_instance ( self , instance ) : self . log . debug ( \" e = mc^2 \" ) self . log . info ( \" About to fail . . \" ) self . log . warning ( \" Failing . . soooon . . \" ) self . log . critical ( \" Ok , you ' re done . \" ) assert False , ": 2102,
 "def markdown_media_css ( ) : return dict ( CSS_SET = posixpath . join ( settings . MARKDOWN_SET_PATH , settings . MARKDOWN_SET_NAME , ' style . css ' ) , CSS_SKIN = posixpath . join ( ' django_markdown ' , ' skins ' , settings . MARKDOWN_EDITOR_SKIN , ' style . css ' ) ) ": 2103,
 "def cross_list ( *sequences ) : result = [[ ]] for seq in sequences : result = [sublist+[item] for sublist in result for item in seq] return result": 2104,
 "def get_filename_safe_string ( string ) : invalid_filename_chars = [ ' \\\\ ' , ' / ' , ' : ' , ' \" ' , ' * ' , ' ? ' , ' | ' , ' \\n ' , ' \\r ' ] if string is None : string = \" None \" for char in invalid_filename_chars : string = string . replace ( char , \" \" ) string = string . rstrip ( \" . \" ) return string": 2105,
 "def aggregate ( d , y_size , x_size ) : if d . ndim ! = 2 : # we can ' t guarantee what blocks we are getting and how # it should be reshaped to do the averaging . raise ValueError ( \" Can ' t aggregrate ( reduce ) data arrays with \" \" more than 2 dimensions . \" ) if not ( x_size . is_integer ( ) and y_size . is_integer ( ) ) : raise ValueError ( \" Aggregation factors are not integers \" ) for agg_size , chunks in zip ( [y_size , x_size] , d . chunks ) : for chunk_size in chunks : if chunk_size % agg_size ! = 0 : raise ValueError ( \" Aggregation requires arrays with \" \" shapes and chunks divisible by the \" \" factor \" ) new_chunks = ( tuple ( int ( x / y_size ) for x in d . chunks[0] ) , tuple ( int ( x / x_size ) for x in d . chunks[1] ) ) return da . core . map_blocks ( _mean , d , y_size , x_size , dtype = d . dtype , chunks = new_chunks ) ": 2106,
 "def Softsign ( a ) : return np . divide ( a , np . add ( np . abs ( a ) , 1 ) ) , ": 2107,
 "def variance ( arr ) : avg = average ( arr ) return sum ( [ ( float ( x ) -avg ) **2 for x in arr] ) /float ( len ( arr ) -1 ) ": 2108,
 "def plot ( self ) : plt . plot ( self . bin_edges , self . hist , self . bin_edges , self . best_pdf ) ": 2109,
 "def _histplot_op ( ax , data , **kwargs ) : bins = get_bins ( data ) ax . hist ( data , bins = bins , align = \" left \" , density = True , **kwargs ) return ax": 2110,
 "def axes_off ( ax ) : ax . set_frame_on ( False ) ax . axes . get_yaxis ( ) . set_visible ( False ) ax . axes . get_xaxis ( ) . set_visible ( False ) ": 2111,
 "def to_camel_case ( snake_case_name ) : bits = snake_case_name . split ( ' _ ' ) return ' ' . join ( [bit . capitalize ( ) for bit in bits] ) ": 2112,
 "def rgb2gray ( img ) : T = np . linalg . inv ( np . array ( [ [1 . 0 , 0 . 956 , 0 . 621] , [1 . 0 , -0 . 272 , -0 . 647] , [1 . 0 , -1 . 106 , 1 . 703] , ] ) ) r_c , g_c , b_c = T[0] r , g , b = np . rollaxis ( as_float_image ( img ) , axis = -1 ) return r_c * r + g_c * g + b_c * b": 2113,
 "def jac ( x , a ) : return ( x-a ) / np . sqrt ( ( ( x-a ) **2 ) . sum ( 1 ) ) [ : , np . newaxis]": 2114,
 "def SegmentMax ( a , ids ) : func = lambda idxs : np . amax ( a[idxs] , axis = 0 ) return seg_map ( func , a , ids ) , ": 2115,
 "def change_cell ( self , x , y , ch , fg , bg ) : self . console . draw_char ( x , y , ch , fg , bg ) ": 2116,
 "def memory_usage ( method ) : def wrapper ( *args , **kwargs ) : logging . info ( ' Memory before method %s is %s . ' , method . __name__ , runtime . memory_usage ( ) . current ( ) ) result = method ( *args , **kwargs ) logging . info ( ' Memory after method %s is %s ' , method . __name__ , runtime . memory_usage ( ) . current ( ) ) return result return wrapper": 2117,
 "def _rendered_size ( text , point_size , font_file ) : emu_per_inch = 914400 px_per_inch = 72 . 0 font = _Fonts . font ( font_file , point_size ) px_width , px_height = font . getsize ( text ) emu_width = int ( px_width / px_per_inch * emu_per_inch ) emu_height = int ( px_height / px_per_inch * emu_per_inch ) return emu_width , emu_height": 2118,
 "def submit_form_id ( step , id ) : form = world . browser . find_element_by_xpath ( str ( ' id ( \" {id} \" ) ' . format ( id = id ) ) ) form . submit ( ) ": 2119,
 "def _tofloat ( obj ) : if \" inf \" in obj . lower ( ) . strip ( ) : return obj try : return int ( obj ) except ValueError : try : return float ( obj ) except ValueError : return obj": 2120,
 "def get_subject ( self , msg ) : text , encoding = decode_header ( msg[ ' subject ' ] ) [-1] try : text = text . decode ( encoding ) # If it ' s already decoded , ignore error except AttributeError : pass return text": 2121,
 "def update ( packages , env = None , user = None ) : packages = ' ' . join ( packages . split ( ' , ' ) ) cmd = _create_conda_cmd ( ' update ' , args = [packages , ' --yes ' , ' -q ' ] , env = env , user = user ) return _execcmd ( cmd , user = user ) ": 2122,
 "def _check_fpos ( self , fp_ , fpos , offset , block ) : if ( fp_ . tell ( ) + offset ! = fpos ) : warnings . warn ( \" Actual \" +block+ \" header size does not match expected \" ) return": 2123,
 "def assert_any_call ( self , *args , **kwargs ) : kall = call ( *args , **kwargs ) if kall not in self . call_args_list : expected_string = self . _format_mock_call_signature ( args , kwargs ) raise AssertionError ( ' %s call not found ' % expected_string ) ": 2124,
 "def update ( self , *args , **kwargs ) : super ( DictProxy , self ) . update ( *args , **kwargs ) return self": 2125,
 "def all_strings ( arr ) : if not isinstance ( [] , list ) : raise TypeError ( \" non-list value found where list is expected \" ) return all ( isinstance ( x , str ) for x in arr ) ": 2126,
 "def install ( ) : @monkeypatch_method ( BaseDatabaseWrapper ) def cursor ( original , self , *args , **kwargs ) : result = original ( *args , **kwargs ) return _DetailedTracingCursorWrapper ( result , self ) logger . debug ( \" Monkey patched SQL \" ) ": 2127,
 "def is_integer ( obj ) : if PYTHON3 : return isinstance ( obj , int ) return isinstance ( obj , ( int , long ) ) ": 2128,
 "def move_up ( lines = 1 , file = sys . stdout ) : move . up ( lines ) . write ( file = file ) ": 2129,
 "def gmove ( pattern , destination ) : for item in glob . glob ( pattern ) : if not move ( item , destination ) : return False return True": 2130,
 "def is_sparse_vector ( x ) : return sp . issparse ( x ) and len ( x . shape ) = = 2 and x . shape[0] = = 1": 2131,
 "def movingaverage ( arr , window ) : m = np . ones ( int ( window ) ) / int ( window ) return scipy . ndimage . convolve1d ( arr , m , axis = 0 , mode = ' reflect ' ) ": 2132,
 "def split_multiline ( value ) : return [element for element in ( line . strip ( ) for line in value . split ( ' \\n ' ) ) if element]": 2133,
 "def has_field ( mc , field_name ) : try : mc . _meta . get_field ( field_name ) except FieldDoesNotExist : return False return True": 2134,
 "def many_until1 ( these , term ) : first = [these ( ) ] these_results , term_result = many_until ( these , term ) return ( first + these_results , term_result ) ": 2135,
 "def allsame ( list_ , strict = True ) : if len ( list_ ) = = 0 : return True first_item = list_[0] return list_all_eq_to ( list_ , first_item , strict ) ": 2136,
 "def ncores_reserved ( self ) : return sum ( task . manager . num_cores for task in self if task . status = = task . S_SUB ) ": 2137,
 "def stop ( self ) : try : self . shutdown ( ) except ( PyMongoError , ServersError ) as exc : logger . info ( \" Killing %s with signal , shutdown command failed : %r \" , self . name , exc ) return process . kill_mprocess ( self . proc ) ": 2138,
 "def build_list_type_validator ( item_validator ) : def validate_list_of_type ( value ) : return [item_validator ( item ) for item in validate_list ( value ) ] return validate_list_of_type": 2139,
 "def allZero ( buffer ) : allZero = True for byte in buffer : if byte ! = \" \\x00 \" : allZero = False break return allZero": 2140,
 "def isstring ( value ) : classes = ( str , bytes ) if pyutils . PY3 else basestring # noqa : F821 return isinstance ( value , classes ) ": 2141,
 "async def scalar ( self , query , as_tuple = False ) : query = self . _swap_database ( query ) return ( await scalar ( query , as_tuple = as_tuple ) ) ": 2142,
 "def raw_connection_from ( engine_or_conn ) : if hasattr ( engine_or_conn , ' cursor ' ) : return engine_or_conn , False if hasattr ( engine_or_conn , ' connection ' ) : return engine_or_conn . connection , False return engine_or_conn . raw_connection ( ) , True": 2143,
 "def executemany ( self , sql , *params ) : fut = self . _run_operation ( self . _impl . executemany , sql , *params ) return fut": 2144,
 "def information ( filename ) : check_if_this_file_exist ( filename ) filename = os . path . abspath ( filename ) result = get_json ( filename ) result = result[0] return result": 2145,
 "def _Enum ( docstring , *names ) : enums = dict ( zip ( names , range ( len ( names ) ) ) ) reverse = dict ( ( value , key ) for key , value in enums . iteritems ( ) ) enums[ ' reverse_mapping ' ] = reverse enums[ ' __doc__ ' ] = docstring return type ( ' Enum ' , ( object , ) , enums ) ": 2146,
 "def is_exe ( fpath ) : return os . path . isfile ( fpath ) and os . access ( fpath , os . X_OK ) ": 2147,
 "def logout ( self ) : self . client . write ( ' exit\\r\\n ' ) self . client . read_all ( ) self . client . close ( ) ": 2148,
 "def get_adjacent_matrix ( self ) : edges = self . edges num_edges = len ( edges ) + 1 adj = np . zeros ( [num_edges , num_edges] ) for k in range ( num_edges - 1 ) : adj[edges[k] . L , edges[k] . R] = 1 adj[edges[k] . R , edges[k] . L] = 1 return adj": 2149,
 "def get_shared_memory_bytes ( ) : # Make sure this is only called on Linux . assert sys . platform = = \" linux \" or sys . platform = = \" linux2 \" shm_fd = os . open ( \" /dev/shm \" , os . O_RDONLY ) try : shm_fs_stats = os . fstatvfs ( shm_fd ) # The value shm_fs_stats . f_bsize is the block size and the # value shm_fs_stats . f_bavail is the number of available # blocks . shm_avail = shm_fs_stats . f_bsize * shm_fs_stats . f_bavail finally : os . close ( shm_fd ) return shm_avail": 2150,
 "def from_json_str ( cls , json_str ) : return cls . from_json ( json . loads ( json_str , cls = JsonDecoder ) ) ": 2151,
 "def is_timestamp ( obj ) : return isinstance ( obj , datetime . datetime ) or is_string ( obj ) or is_int ( obj ) or is_float ( obj ) ": 2152,
 "def ner_chunk ( args ) : chunker = NEChunker ( lang = args . lang ) tag ( chunker , args ) ": 2153,
 "def cell_ends_with_code ( lines ) : if not lines : return False if not lines[-1] . strip ( ) : return False if lines[-1] . startswith ( ' # ' ) : return False return True": 2154,
 "def get_prep_value ( self , value ) : if self . null and value is None : return None return json . dumps ( value , **self . dump_kwargs ) ": 2155,
 "def reset ( self ) : self . prevframe = None self . wasmoving = False self . t0 = 0 self . ismoving = False": 2156,
 "def _get_non_empty_list ( cls , iter ) : res = [] for value in iter : if hasattr ( value , ' items ' ) : value = cls . _get_non_empty_dict ( value ) or None if value is not None : res . append ( value ) return res": 2157,
 "def __exit__ ( self , *args ) : if self . _output_file_handle : self . _output_file_handle . close ( ) self . _output_file_handle = None": 2158,
 "def normalize ( X ) : X = coo_matrix ( X ) X . data = X . data / sqrt ( bincount ( X . row , X . data ** 2 ) ) [X . row] return X": 2159,
 "def get_selected_values ( self , selection ) : return [v for b , v in self . _choices if b & selection]": 2160,
 "def equal ( obj1 , obj2 ) : Comparable . log ( obj1 , obj2 , ' = = ' ) equality = obj1 . equality ( obj2 ) Comparable . log ( obj1 , obj2 , ' = = ' , result = equality ) return equality": 2161,
 "def getMedian ( numericValues ) : theValues = sorted ( numericValues ) if len ( theValues ) % 2 = = 1 : return theValues[ ( len ( theValues ) + 1 ) / 2 - 1] else : lower = theValues[len ( theValues ) / 2 - 1] upper = theValues[len ( theValues ) / 2] return ( float ( lower + upper ) ) / 2": 2162,
 "def check_exists ( filename , oappend = False ) : if op . exists ( filename ) : if oappend : return oappend logging . error ( \" `{0}` found , overwrite ( Y/N ) ? \" . format ( filename ) ) overwrite = ( raw_input ( ) = = ' Y ' ) else : overwrite = True return overwrite": 2163,
 "def _pooling_output_shape ( input_shape , pool_size = ( 2 , 2 ) , strides = None , padding = ' VALID ' ) : dims = ( 1 , ) + pool_size + ( 1 , ) # NHWC spatial_strides = strides or ( 1 , ) * len ( pool_size ) strides = ( 1 , ) + spatial_strides + ( 1 , ) pads = padtype_to_pads ( input_shape , dims , strides , padding ) operand_padded = onp . add ( input_shape , onp . add ( *zip ( *pads ) ) ) t = onp . floor_divide ( onp . subtract ( operand_padded , dims ) , strides ) + 1 return tuple ( t ) ": 2164,
 "def other_ind ( self ) : return np . full ( self . n_min , self . size - 1 , dtype = np . int ) ": 2165,
 "def encode ( strs ) : res = ' ' for string in strs . split ( ) : res + = str ( len ( string ) ) + \" : \" + string return res": 2166,
 "def Max ( a , axis , keep_dims ) : return np . amax ( a , axis = axis if not isinstance ( axis , np . ndarray ) else tuple ( axis ) , keepdims = keep_dims ) , ": 2167,
 "def __connect ( ) : global redis_instance if use_tcp_socket : redis_instance = redis . StrictRedis ( host = hostname , port = port ) else : redis_instance = redis . StrictRedis ( unix_socket_path = unix_socket ) ": 2168,
 "def from_array ( cls , arr ) : return cls ( ) . with_columns ( [ ( f , arr[f] ) for f in arr . dtype . names] ) ": 2169,
 "def from_dict ( cls , d ) : return cls ( **{k : v for k , v in d . items ( ) if k in cls . ENTRIES} ) ": 2170,
 "def objectcount ( data , key ) : objkey = key . upper ( ) return len ( data . dt[objkey] ) ": 2171,
 "def iterexpand ( arry , extra ) : for d in range ( arry . ndim , arry . ndim+extra ) : arry = expand_dims ( arry , axis = d ) return arry": 2172,
 "def aws_to_unix_id ( aws_key_id ) : uid_bytes = hashlib . sha256 ( aws_key_id . encode ( ) ) . digest ( ) [-2 : ] if USING_PYTHON2 : return 2000 + int ( from_bytes ( uid_bytes ) // 2 ) else : return 2000 + ( int . from_bytes ( uid_bytes , byteorder = sys . byteorder ) // 2 ) ": 2173,
 "def flattened_nested_key_indices ( nested_dict ) : outer_keys , inner_keys = collect_nested_keys ( nested_dict ) combined_keys = list ( sorted ( set ( outer_keys + inner_keys ) ) ) return {k : i for ( i , k ) in enumerate ( combined_keys ) }": 2174,
 "def run ( self , *args , **kwargs ) : self . eventloop . run_until_complete ( self . connect ( *args , **kwargs ) ) try : self . eventloop . run_forever ( ) finally : self . eventloop . stop ( ) ": 2175,
 "def ensure_dir_exists ( directory ) : if directory and not os . path . exists ( directory ) : os . makedirs ( directory ) ": 2176,
 "def ReadTif ( tifFile ) : img = Image . open ( tifFile ) img = np . array ( img ) return img": 2177,
 "def append_scope ( self ) : self . stack . current . append ( Scope ( self . stack . current . current ) ) ": 2178,
 "def _isnan ( self ) : if self . _can_hold_na : return isna ( self ) else : # shouldn ' t reach to this condition by checking hasnans beforehand values = np . empty ( len ( self ) , dtype = np . bool_ ) values . fill ( False ) return values": 2179,
 "def send_dir ( self , local_path , remote_path , user = ' root ' ) : self . enable_user ( user ) return self . ssh_pool . send_dir ( user , local_path , remote_path ) ": 2180,
 "def symlink ( source , destination ) : log ( \" Symlinking {} as {} \" . format ( source , destination ) ) cmd = [ ' ln ' , ' -sf ' , source , destination , ] subprocess . check_call ( cmd ) ": 2181,
 "def set_header ( self , key , value ) : self . conn . issue_command ( \" Header \" , _normalize_header ( key ) , value ) ": 2182,
 "def rank ( self ) : r = np . empty ( self . size , np . int ) r[self . sorter] = np . arange ( self . size ) return r": 2183,
 "def batchify ( data , batch_size ) : nbatch = data . shape[0] // batch_size data = data[ : nbatch * batch_size] data = data . reshape ( ( batch_size , nbatch ) ) . T return data": 2184,
 "def _clip ( sid , prefix ) : return sid[len ( prefix ) : ] if sid . startswith ( prefix ) else sid": 2185,
 "def safe_setattr ( obj , name , value ) : try : setattr ( obj , name , value ) return True except AttributeError : return False": 2186,
 "def remover ( file_path ) : if os . path . isfile ( file_path ) : os . remove ( file_path ) return True elif os . path . isdir ( file_path ) : shutil . rmtree ( file_path ) return True else : return False": 2187,
 "def safe_delete ( filename ) : try : os . unlink ( filename ) except OSError as e : if e . errno ! = errno . ENOENT : raise": 2188,
 "def cli ( env , identifier ) : image_mgr = SoftLayer . ImageManager ( env . client ) image_id = helpers . resolve_id ( image_mgr . resolve_ids , identifier , ' image ' ) image_mgr . delete_image ( image_id ) ": 2189,
 "def set_rate ( rate ) : if not ( isinstance ( rate , int ) or isinstance ( rate , float ) ) : raise TypeError ( \" argument to set_rate is expected to be int or float \" ) global loop_duration loop_duration = 1 . 0/rate": 2190,
 "def _platform_pylib_exts ( ) : # nocover import sysconfig valid_exts = [] if six . PY2 : # see also ' SHLIB_EXT ' base_ext = ' . ' + sysconfig . get_config_var ( ' SO ' ) . split ( ' . ' ) [-1] else : # return with and without API flags # handle PEP 3149 -- ABI version tagged . so files base_ext = ' . ' + sysconfig . get_config_var ( ' EXT_SUFFIX ' ) . split ( ' . ' ) [-1] for tag in _extension_module_tags ( ) : valid_exts . append ( ' . ' + tag + base_ext ) valid_exts . append ( base_ext ) return tuple ( valid_exts ) ": 2191,
 "def apply_argument_parser ( argumentsParser , options = None ) : if options is not None : args = argumentsParser . parse_args ( options ) else : args = argumentsParser . parse_args ( ) return args": 2192,
 "def _visual_width ( line ) : return len ( re . sub ( colorama . ansitowin32 . AnsiToWin32 . ANSI_CSI_RE , \" \" , line ) ) ": 2193,
 "def column_exists ( cr , table , column ) : cr . execute ( ' SELECT count ( attname ) FROM pg_attribute ' ' WHERE attrelid = ' ' ( SELECT oid FROM pg_class WHERE relname = %s ) ' ' AND attname = %s ' , ( table , column ) ) return cr . fetchone ( ) [0] = = 1": 2194,
 "def query_sum ( queryset , field ) : return queryset . aggregate ( s = models . functions . Coalesce ( models . Sum ( field ) , 0 ) ) [ ' s ' ]": 2195,
 "def adapter ( data , headers , **kwargs ) : keys = ( ' sep_title ' , ' sep_character ' , ' sep_length ' ) return vertical_table ( data , headers , **filter_dict_by_key ( kwargs , keys ) ) ": 2196,
 "def user_parse ( data ) : _user = data . get ( ' response ' , {} ) . get ( ' user ' , {} ) yield ' id ' , _user . get ( ' name ' ) yield ' username ' , _user . get ( ' name ' ) yield ' link ' , _user . get ( ' blogs ' , [{}] ) [0] . get ( ' url ' ) ": 2197,
 "def clip_image ( image , clip_min , clip_max ) : return np . minimum ( np . maximum ( clip_min , image ) , clip_max ) ": 2198,
 "def clean_time ( time_string ) : # Get a timezone-aware datetime object from the string time = dateutil . parser . parse ( time_string ) if not settings . USE_TZ : # If timezone support is not active , convert the time to UTC and # remove the timezone field time = time . astimezone ( timezone . utc ) . replace ( tzinfo = None ) return time": 2199,
 "def string_to_float_list ( string_var ) : try : return [float ( s ) for s in string_var . strip ( ' [ ' ) . strip ( ' ] ' ) . split ( ' , ' ) ] except : return [float ( s ) for s in string_var . strip ( ' [ ' ) . strip ( ' ] ' ) . split ( ' , ' ) ]": 2200,
 "def parse_query_string ( query ) : result = {} qparts = query . split ( ' & ' ) for item in qparts : key , value = item . split ( ' = ' ) key = key . strip ( ) value = value . strip ( ) result[key] = unquote_plus ( value ) return result": 2201,
 "def get_dict_for_attrs ( obj , attrs ) : data = {} for attr in attrs : data[attr] = getattr ( obj , attr ) return data": 2202,
 "def tree ( string , token = [WORD , POS , CHUNK , PNP , REL , ANCHOR , LEMMA] ) : return Text ( string , token ) ": 2203,
 "def dropna ( self , subset = None ) : subset = check_and_obtain_subset_columns ( subset , self ) not_nas = [v . notna ( ) for v in self[subset] . _iter ( ) ] and_filter = reduce ( lambda x , y : x & y , not_nas ) return self[and_filter]": 2204,
 "def clean_dict_keys ( d ) : new_d = {} for ( k , v ) in d . iteritems ( ) : new_d[str ( k ) ] = v return new_d": 2205,
 "def test3 ( ) : import time p = MVisionProcess ( ) p . start ( ) time . sleep ( 5 ) p . stop ( ) ": 2206,
 "def reprkwargs ( kwargs , sep = ' , ' , fmt = \" {0!s} = {1!r} \" ) : return sep . join ( fmt . format ( k , v ) for k , v in kwargs . iteritems ( ) ) ": 2207,
 "def remove_punctuation ( text , exceptions = [] ) : all_but = [ r ' \\w ' , r ' \\s ' ] all_but . extend ( exceptions ) pattern = ' [^{}] ' . format ( ' ' . join ( all_but ) ) return re . sub ( pattern , ' ' , text ) ": 2208,
 "def is_file ( path ) : try : return path . expanduser ( ) . absolute ( ) . is_file ( ) except AttributeError : return os . path . isfile ( os . path . abspath ( os . path . expanduser ( str ( path ) ) ) ) ": 2209,
 "def exit_and_fail ( self , msg = None , out = None ) : self . exit ( result = PANTS_FAILED_EXIT_CODE , msg = msg , out = out ) ": 2210,
 "def palettebar ( height , length , colormap ) : cbar = np . tile ( np . arange ( length ) * 1 . 0 / ( length - 1 ) , ( height , 1 ) ) cbar = ( cbar * ( colormap . values . max ( ) + 1 - colormap . values . min ( ) ) + colormap . values . min ( ) ) return colormap . palettize ( cbar ) ": 2211,
 "def do_exit ( self , arg ) : if self . current : self . current . close ( ) self . resource_manager . close ( ) del self . resource_manager return True": 2212,
 "def user_return ( self , frame , return_value ) : pdb . Pdb . user_return ( self , frame , return_value ) ": 2213,
 "def unzip_file_to_dir ( path_to_zip , output_directory ) : z = ZipFile ( path_to_zip , ' r ' ) z . extractall ( output_directory ) z . close ( ) ": 2214,
 "def _basic_field_data ( field , obj ) : value = field . value_from_object ( obj ) return {Field . TYPE : FieldType . VAL , Field . VALUE : value}": 2215,
 "def translate_v3 ( vec , amount ) : return Vec3 ( vec . x+amount , vec . y+amount , vec . z+amount ) ": 2216,
 "def _parallel_compare_helper ( class_obj , pairs , x , x_link = None ) : return class_obj . _compute ( pairs , x , x_link ) ": 2217,
 "def datetime_created ( self ) : if self . info ( ) . get ( ' datetime_created ' ) : return dateutil . parser . parse ( self . info ( ) [ ' datetime_created ' ] ) ": 2218,
 "def context ( self ) : if self . _context is not None : return self . _context else : logger . warning ( \" Using shared context without a lock \" ) return self . _executor . _shared_context": 2219,
 "def counter ( items ) : results = {} for item in items : results[item] = results . get ( item , 0 ) + 1 return results": 2220,
 "def filter_bolts ( table , header ) : bolts_info = [] for row in table : if row[0] = = ' bolt ' : bolts_info . append ( row ) return bolts_info , header": 2221,
 "def pylint_raw ( options ) : command = [ ' pylint ' ] command . extend ( options ) proc = subprocess . Popen ( command , stdout = subprocess . PIPE , stderr = subprocess . PIPE ) outs , __ = proc . communicate ( ) return outs . decode ( ) ": 2222,
 "def print_param_values ( self_ ) : self = self_ . self for name , val in self . param . get_param_values ( ) : print ( ' %s . %s = %s ' % ( self . name , name , val ) ) ": 2223,
 "def info ( txt ) : print ( \" %s # %s%s%s \" % ( PR_EMPH_CC , get_time_stamp ( ) , txt , PR_NC ) ) sys . stdout . flush ( ) ": 2224,
 "def pprint ( obj , verbose = False , max_width = 79 , newline = ' \\n ' ) : printer = RepresentationPrinter ( sys . stdout , verbose , max_width , newline ) printer . pretty ( obj ) printer . flush ( ) sys . stdout . write ( newline ) sys . stdout . flush ( ) ": 2225,
 "def pytest_runtest_logreport ( self , report ) : rep = report res = self . config . hook . pytest_report_teststatus ( report = rep ) cat , letter , word = res self . stats . setdefault ( cat , [] ) . append ( rep ) ": 2226,
 "def prettyprint ( d ) : print ( json . dumps ( d , sort_keys = True , indent = 4 , separators = ( \" , \" , \" : \" ) ) ) ": 2227,
 "def printdict ( adict ) : dlist = list ( adict . keys ( ) ) dlist . sort ( ) for i in range ( 0 , len ( dlist ) ) : print ( dlist[i] , adict[dlist[i]] ) ": 2228,
 "def show_progress ( self ) : if self . in_progress_hanging : sys . stdout . write ( ' . ' ) sys . stdout . flush ( ) ": 2229,
 "def pprint ( o , stream = None , indent = 1 , width = 80 , depth = None ) : printer = PrettyPrinter ( stream = stream , indent = indent , width = width , depth = depth ) printer . pprint ( o ) ": 2230,
 "def get ( cls ) : return { SourceRootConfig , Reporting , Reproducer , RunTracker , Changed , BinaryUtil . Factory , Subprocess . Factory }": 2231,
 "def ss ( *args , **kwargs ) : if not args : raise ValueError ( \" you didn ' t pass any arguments to print out \" ) with Reflect . context ( args , **kwargs ) as r : instance = V_CLASS ( r , stream , **kwargs ) return instance . value ( ) . strip ( ) ": 2232,
 "def _shape ( self , df ) : row , col = df . shape return row + df . columns . nlevels , col + df . index . nlevels": 2233,
 "def ansi ( color , text ) : code = COLOR_CODES[color] return ' \\033[1;{0}m{1}{2} ' . format ( code , text , RESET_TERM ) ": 2234,
 "def get_encoding ( binary ) : try : from chardet import detect except ImportError : LOGGER . error ( \" Please install the ' chardet ' module \" ) sys . exit ( 1 ) encoding = detect ( binary ) . get ( ' encoding ' ) return ' iso-8859-1 ' if encoding = = ' CP949 ' else encoding": 2235,
 "def _get_os_environ_dict ( keys ) : return {k : os . environ . get ( k , _UNDEFINED ) for k in keys}": 2236,
 "def to_json ( data ) : return json . dumps ( data , default = lambda x : x . __dict__ , sort_keys = True , indent = 4 ) ": 2237,
 "def getfield ( f ) : if isinstance ( f , list ) : return [getfield ( x ) for x in f] else : return f . value": 2238,
 "def time_string ( seconds ) : s = int ( round ( seconds ) ) # round to nearest second h , s = divmod ( s , 3600 ) # get hours and remainder m , s = divmod ( s , 60 ) # split remainder into minutes and seconds return \" %2i : %02i : %02i \" % ( h , m , s ) ": 2239,
 "def fields ( self ) : return ( self . attributes . values ( ) + self . lists . values ( ) + self . references . values ( ) ) ": 2240,
 "def translate_index_to_position ( self , index ) : # Find start of this line . row , row_index = self . _find_line_start_index ( index ) col = index - row_index return row , col": 2241,
 "def _set_property ( self , val , *args ) : val = UserClassAdapter . _set_property ( self , val , *args ) if val : Adapter . _set_property ( self , val , *args ) return val": 2242,
 "def metadata ( self ) : if not self . _operation . HasField ( \" metadata \" ) : return None return protobuf_helpers . from_any_pb ( self . _metadata_type , self . _operation . metadata ) ": 2243,
 "def stop ( pid ) : if psutil . pid_exists ( pid ) : try : p = psutil . Process ( pid ) p . kill ( ) except Exception : pass": 2244,
 "def get_all_items ( obj ) : if hasattr ( obj , ' getlist ' ) : items = [] for key in obj : for value in obj . getlist ( key ) : items . append ( ( key , value ) ) return items else : return obj . items ( ) ": 2245,
 "def get_translucent_cmap ( r , g , b ) : class TranslucentCmap ( BaseColormap ) : glsl_map = . format ( r , g , b ) return TranslucentCmap ( ) ": 2246,
 "def execute ( self , sql , params = None ) : # wrap in a transaction to ensure things are committed # https : //github . com/smnorris/pgdata/issues/3 with self . engine . begin ( ) as conn : result = conn . execute ( sql , params ) return result": 2247,
 "def each_img ( dir_path ) : for fname in os . listdir ( dir_path ) : if fname . endswith ( ' . jpg ' ) or fname . endswith ( ' . png ' ) or fname . endswith ( ' . bmp ' ) : yield fname": 2248,
 "async def delete ( self ) : the_tuple = await self . queue . delete ( self . tube , self . task_id ) self . update_from_tuple ( the_tuple ) return bool ( self . state = = DONE ) ": 2249,
 "def rndstr ( size = 16 ) : _basech = string . ascii_letters + string . digits return \" \" . join ( [rnd . choice ( _basech ) for _ in range ( size ) ] ) ": 2250,
 "def column ( self ) : line , column = self . source_buffer . decompose_position ( self . begin_pos ) return column": 2251,
 "def get_object_attrs ( obj ) : attrs = [k for k in dir ( obj ) if not k . startswith ( ' __ ' ) ] if not attrs : attrs = dir ( obj ) return attrs": 2252,
 "def zrank ( self , name , value ) : with self . pipe as pipe : value = self . valueparse . encode ( value ) return pipe . zrank ( self . redis_key ( name ) , value ) ": 2253,
 "def view_extreme_groups ( token , dstore ) : data = dstore[ ' disagg_by_grp ' ] . value data . sort ( order = ' extreme_poe ' ) return rst_table ( data[ : : -1] ) ": 2254,
 "def read ( fname ) : content = None with open ( os . path . join ( here , fname ) ) as f : content = f . read ( ) return content": 2255,
 "def OnRootView ( self , event ) : self . adapter , tree , rows = self . RootNode ( ) self . squareMap . SetModel ( tree , self . adapter ) self . RecordHistory ( ) self . ConfigureViewTypeChoices ( ) ": 2256,
 "def read_folder ( directory ) : res = [] for filename in os . listdir ( directory ) : with io . open ( os . path . join ( directory , filename ) , encoding = \" utf-8 \" ) as f : content = f . read ( ) res . append ( content ) return res": 2257,
 "def find_lt ( a , x ) : i = bisect . bisect_left ( a , x ) if i : return a[i-1] raise ValueError": 2258,
 "def yticks ( self ) : return np . linspace ( np . min ( self[ : , 0] ) , np . max ( self[ : , 0] ) , 4 ) ": 2259,
 "def return_type ( type_name , formatter = None ) : def _returns ( func ) : annotated ( func ) func . metadata . typed_returnvalue ( type_name , formatter ) return func return _returns": 2260,
 "def extract_words ( lines ) : for line in lines : for word in re . findall ( r \" \\w+ \" , line ) : yield word": 2261,
 "def r_num ( obj ) : if isinstance ( obj , ( list , tuple ) ) : it = iter else : it = LinesIterator dataset = Dataset ( [Dataset . FLOAT] ) return dataset . load ( it ( obj ) ) ": 2262,
 "def process_module ( self , module ) : if module . file_encoding : encoding = module . file_encoding else : encoding = \" ascii \" with module . stream ( ) as stream : for lineno , line in enumerate ( stream ) : self . _check_encoding ( lineno + 1 , line , encoding ) ": 2263,
 "def map_keys_deep ( f , dct ) : return _map_deep ( lambda k , v : [f ( k , v ) , v] , dct ) ": 2264,
 "def redirect_std ( ) : stdin = sys . stdin stdout = sys . stdout if not sys . stdin . isatty ( ) : sys . stdin = open_raw ( \" /dev/tty \" , \" r \" , 0 ) if not sys . stdout . isatty ( ) : sys . stdout = open_raw ( \" /dev/tty \" , \" w \" , 0 ) return stdin , stdout": 2265,
 "def _help ( ) : statement = ' %s%s ' % ( shelp , phelp % ' , ' . join ( cntx_ . keys ( ) ) ) print statement . strip ( ) ": 2266,
 "def __setitem__ ( self , field , value ) : return self . _client . hset ( self . key_prefix , field , self . _dumps ( value ) ) ": 2267,
 "def mark ( self , n = 1 ) : self . tick_if_necessary ( ) self . count + = n self . m1_rate . update ( n ) self . m5_rate . update ( n ) self . m15_rate . update ( n ) ": 2268,
 "def _post ( self , url , params , uploads = None ) : self . _call ( self . POST , url , params , uploads ) ": 2269,
 "def prep_regex ( patterns ) : flags = 0 if Config . options . case_sensitive else re . I return [re . compile ( pattern , flags ) for pattern in patterns]": 2270,
 "def match_paren ( self , tokens , item ) : match , = tokens return self . match ( match , item ) ": 2271,
 "def remove_legend ( ax = None ) : from pylab import gca , draw if ax is None : ax = gca ( ) ax . legend_ = None draw ( ) ": 2272,
 "def unmatched ( match ) : start , end = match . span ( 0 ) return match . string[ : start]+match . string[end : ]": 2273,
 "def seq ( ) : current_frame = inspect . currentframe ( ) . f_back trace_string = \" \" while current_frame . f_back : trace_string = trace_string + current_frame . f_back . f_code . co_name current_frame = current_frame . f_back return counter . get_from_trace ( trace_string ) ": 2274,
 "def is_valid_email ( email ) : pattern = re . compile ( r ' [\\w\\ . -]+@[\\w\\ . -]+[ . ]\\w+ ' ) return bool ( pattern . match ( email ) ) ": 2275,
 "def _Members ( self , group ) : group . members = set ( group . members ) . union ( self . gids . get ( group . gid , [] ) ) return group": 2276,
 "def kill ( self ) : if self . process : self . process . kill ( ) self . process . wait ( ) ": 2277,
 "def f ( x , a , c ) : v = g ( x , a , c ) return v . dot ( v ) ": 2278,
 "def clean ( ) : run ( ' rm -rf build/ ' ) run ( ' rm -rf dist/ ' ) run ( ' rm -rf puzzle . egg-info ' ) run ( ' find . -name __pycache__ -delete ' ) run ( ' find . -name * . pyc -delete ' ) run ( ' find . -name * . pyo -delete ' ) run ( ' find . -name *~ -delete ' ) log . info ( ' cleaned up ' ) ": 2279,
 "def check_version ( ) : if sys . version_info[0 : 3] = = PYTHON_VERSION_INFO[0 : 3] : return sys . exit ( ansi . error ( ) + ' your virtual env points to the wrong python version . ' ' This is likely because you used a python installer that clobbered ' ' the system installation , which breaks virtualenv creation . ' ' To fix , check this symlink , and delete the installation of python ' ' that it is brokenly pointing to , then delete the virtual env itself ' ' and rerun lore install : ' + os . linesep + os . linesep + BIN_PYTHON + os . linesep ) ": 2280,
 "def _remove_none_values ( dictionary ) : return list ( map ( dictionary . pop , [i for i in dictionary if dictionary[i] is None] ) ) ": 2281,
 "def join ( self , room ) : self . socket . rooms . add ( self . _get_room_name ( room ) ) ": 2282,
 "def _remove_duplicate_files ( xs ) : seen = set ( [] ) out = [] for x in xs : if x[ \" path \" ] not in seen : out . append ( x ) seen . add ( x[ \" path \" ] ) return out": 2283,
 "def on_error ( e ) : # pragma : no cover exname = { ' RuntimeError ' : ' Runtime error ' , ' Value Error ' : ' Value error ' } sys . stderr . write ( ' {} : {}\\n ' . format ( exname[e . __class__ . __name__] , str ( e ) ) ) sys . stderr . write ( ' See file slam_error . log for additional details . \\n ' ) sys . exit ( 1 ) ": 2284,
 "def __copy__ ( self ) : return self . __class__ . load ( self . dump ( ) , context = self . context ) ": 2285,
 "def PopTask ( self ) : try : _ , task = heapq . heappop ( self . _heap ) except IndexError : return None self . _task_identifiers . remove ( task . identifier ) return task": 2286,
 "def _curve ( x1 , y1 , x2 , y2 , hunit = HUNIT , vunit = VUNIT ) : ax1 , ax2 , axm = x1 * hunit , x2 * hunit , ( x1 + x2 ) * hunit / 2 ay1 , ay2 = y1 * vunit , y2 * vunit return pyx . path . curve ( ax1 , ay1 , axm , ay1 , axm , ay2 , ax2 , ay2 ) ": 2287,
 "def once ( func ) : lock = threading . Lock ( ) def new_func ( *args , **kwargs ) : if new_func . called : return with lock : if new_func . called : return rv = func ( *args , **kwargs ) new_func . called = True return rv new_func = update_wrapper ( new_func , func ) new_func . called = False return new_func": 2288,
 "def union_overlapping ( intervals ) : disjoint_intervals = [] for interval in intervals : if disjoint_intervals and disjoint_intervals[-1] . overlaps ( interval ) : disjoint_intervals[-1] = disjoint_intervals[-1] . union ( interval ) else : disjoint_intervals . append ( interval ) return disjoint_intervals": 2289,
 "def _generate_phrases ( self , sentences ) : phrase_list = set ( ) # Create contender phrases from sentences . for sentence in sentences : word_list = [word . lower ( ) for word in wordpunct_tokenize ( sentence ) ] phrase_list . update ( self . _get_phrase_list_from_words ( word_list ) ) return phrase_list": 2290,
 "def unapostrophe ( text ) : text = re . sub ( r ' [%s]s?$ ' % ' ' . join ( APOSTROPHES ) , ' ' , text ) return text": 2291,
 "def _do_remove_prefix ( name ) : res = name if isinstance ( res , str ) : if ( res . find ( ' Table : ' ) = = 0 ) : res = res . replace ( ' Table : ' , ' ' , 1 ) return res": 2292,
 "def do_restart ( self , line ) : self . application . master . Restart ( opendnp3 . RestartType . COLD , restart_callback ) ": 2293,
 "def distinct ( l ) : seen = set ( ) seen_add = seen . add return ( _ for _ in l if not ( _ in seen or seen_add ( _ ) ) ) ": 2294,
 "def fixpath ( path ) : return os . path . normpath ( os . path . realpath ( os . path . expanduser ( path ) ) ) ": 2295,
 "def drop_trailing_zeros_decimal ( num ) : out = str ( num ) return out . rstrip ( ' 0 ' ) . rstrip ( ' . ' ) if ' . ' in out else out": 2296,
 "def rstjinja ( app , docname , source ) : # Make sure we ' re outputting HTML if app . builder . format ! = ' html ' : return src = source[0] rendered = app . builder . templates . render_string ( src , app . config . html_context ) source[0] = rendered": 2297,
 "def conf ( self ) : return self . env . get_template ( ' conf . py . j2 ' ) . render ( metadata = self . metadata , package = self . package ) ": 2298,
 "def render_to_json ( templates , context , request ) : html = render_to_string ( templates , context = context , request = request ) _json = json . dumps ( { \" html \" : html } ) return HttpResponse ( _json ) ": 2299,
 "def specialRound ( number , rounding ) : temp = 0 if rounding = = 0 : temp = number else : temp = round ( number , rounding ) if temp % 1 = = 0 : return int ( temp ) else : return float ( temp ) ": 2300,
 "def requests_request ( method , url , **kwargs ) : session = local_sessions . session response = session . request ( method = method , url = url , **kwargs ) session . close ( ) return response": 2301,
 "def unique ( self , name ) : # Make sure the name is valid name = self . valid ( name ) # Make sure it ' s not too long name = self . trim ( name ) # Now make sure it ' s unique unique_name = name i = 2 while unique_name in self . names : unique_name = name + str ( i ) i + = 1 self . names . add ( unique_name ) return unique_name": 2302,
 "def check_type_and_size_of_param_list ( param_list , expected_length ) : try : assert isinstance ( param_list , list ) assert len ( param_list ) = = expected_length except AssertionError : msg = \" param_list must be a list containing {} elements . \" raise ValueError ( msg . format ( expected_length ) ) return None": 2303,
 "def _request_limit_reached ( exception ) : return isinstance ( exception , requests . HTTPError ) and \\ exception . response . status_code = = requests . status_codes . codes . TOO_MANY_REQUESTS": 2304,
 "def is_float_array ( val ) : return is_np_array ( val ) and issubclass ( val . dtype . type , np . floating ) ": 2305,
 "def _log_disconnect ( self ) : if self . logged : self . server . stats . connectionClosed ( ) self . logged = False": 2306,
 "def download_sdk ( url ) : r = requests . get ( url ) r . raise_for_status ( ) return StringIO ( r . content ) ": 2307,
 "def disable_insecure_request_warning ( ) : import requests from requests . packages . urllib3 . exceptions import InsecureRequestWarning requests . packages . urllib3 . disable_warnings ( InsecureRequestWarning ) ": 2308,
 "def price_rounding ( price , decimals = 2 ) : try : exponent = D ( ' . ' + decimals * ' 0 ' ) except InvalidOperation : # Currencies with no decimal places , ex . JPY , HUF exponent = D ( ) return price . quantize ( exponent , rounding = ROUND_UP ) ": 2309,
 "def process_response ( self , response ) : if response . status_code ! = 200 : raise TwilioException ( ' Unable to fetch page ' , response ) return json . loads ( response . text ) ": 2310,
 "def _pad ( self , text ) : top_bottom = ( \" \\n \" * self . _padding ) + \" \" right_left = \" \" * self . _padding * self . PAD_WIDTH return top_bottom + right_left + text + right_left + top_bottom": 2311,
 "def __get__ ( self , obj , objtype ) : if not self . is_method : self . is_method = True return functools . partial ( self . __call__ , obj ) ": 2312,
 "def execute_only_once ( ) : f = inspect . currentframe ( ) . f_back ident = ( f . f_code . co_filename , f . f_lineno ) if ident in _EXECUTE_HISTORY : return False _EXECUTE_HISTORY . add ( ident ) return True": 2313,
 "def where_is ( strings , pattern , n = 1 , lookup_func = re . match ) : count = 0 for idx , item in enumerate ( strings ) : if lookup_func ( pattern , item ) : count + = 1 if count = = n : return idx return -1": 2314,
 "def sem ( inlist ) : sd = stdev ( inlist ) n = len ( inlist ) return sd / math . sqrt ( n ) ": 2315,
 "def unwind ( self ) : return [ QuadKey ( self . key[ : l+1] ) for l in reversed ( range ( len ( self . key ) ) ) ]": 2316,
 "def polyline ( self , arr ) : for i in range ( 0 , len ( arr ) - 1 ) : self . line ( arr[i][0] , arr[i][1] , arr[i + 1][0] , arr[i + 1][1] ) ": 2317,
 "def print ( *a ) : try : _print ( *a ) return a[0] if len ( a ) = = 1 else a except : _print ( *a ) ": 2318,
 "def clear ( self ) : # Erase current output first . self . erase ( ) # Send \" Erase Screen \" command and go to ( 0 , 0 ) . output = self . output output . erase_screen ( ) output . cursor_goto ( 0 , 0 ) output . flush ( ) self . request_absolute_cursor_position ( ) ": 2319,
 "def _days_in_month ( date ) : if date . month = = 12 : reference = type ( date ) ( date . year + 1 , 1 , 1 ) else : reference = type ( date ) ( date . year , date . month + 1 , 1 ) return ( reference - timedelta ( days = 1 ) ) . day": 2320,
 "def roc_auc ( y_true , y_score ) : notnull = ~np . isnan ( y_true ) fpr , tpr , thresholds = sklearn . metrics . roc_curve ( y_true[notnull] , y_score[notnull] ) return sklearn . metrics . auc ( fpr , tpr ) ": 2321,
 "def format_exception ( e ) : from . utils . printing import fill return ' \\n ' . join ( fill ( line ) for line in traceback . format_exception_only ( type ( e ) , e ) ) ": 2322,
 "def parse_response ( self , resp ) : p , u = self . getparser ( ) p . feed ( resp . content ) p . close ( ) return u . close ( ) ": 2323,
 "def setup_detect_python2 ( ) : if None in [RTs . _rt_py2_detect , RTs . _rtp_py2_detect] : RTs . _rt_py2_detect = RefactoringTool ( py2_detect_fixers ) RTs . _rtp_py2_detect = RefactoringTool ( py2_detect_fixers , { ' print_function ' : True} ) ": 2324,
 "def copy_image_on_background ( image , color = WHITE ) : background = Image . new ( \" RGB \" , image . size , color ) background . paste ( image , mask = image . split ( ) [3] ) return background": 2325,
 "def select_fields_as_sql ( self ) : return comma_join ( list ( self . _fields ) + [ ' %s AS %s ' % ( v , k ) for k , v in self . _calculated_fields . items ( ) ] ) ": 2326,
 "def kill_mprocess ( process ) : if process and proc_alive ( process ) : process . terminate ( ) process . communicate ( ) return not proc_alive ( process ) ": 2327,
 "def get_randomized_guid_sample ( self , item_count ) : dataset = self . get_whitelist ( ) random . shuffle ( dataset ) return dataset[ : item_count]": 2328,
 "def write_image ( filename , image ) : data_format = get_data_format ( filename ) if data_format is MimeType . JPG : LOGGER . warning ( ' Warning : jpeg is a lossy format therefore saved data will be modified . ' ) return Image . fromarray ( image ) . save ( filename ) ": 2329,
 "def plot_and_save ( self , **kwargs ) : self . fig = pyplot . figure ( ) self . plot ( ) self . axes = pyplot . gca ( ) self . save_plot ( self . fig , self . axes , **kwargs ) pyplot . close ( self . fig ) ": 2330,
 "def iterate_chunks ( file , chunk_size ) : chunk = file . read ( chunk_size ) while chunk : yield chunk chunk = file . read ( chunk_size ) ": 2331,
 "def validate_string_list ( lst ) : if not isinstance ( lst , list ) : raise ValueError ( ' input %r must be a list ' % lst ) for x in lst : if not isinstance ( x , basestring ) : raise ValueError ( ' element %r in list must be a string ' % x ) ": 2332,
 "def clean_df ( df , fill_nan = True , drop_empty_columns = True ) : if fill_nan : df = df . fillna ( value = np . nan ) if drop_empty_columns : df = df . dropna ( axis = 1 , how = ' all ' ) return df . sort_index ( ) ": 2333,
 "def extract ( self ) : return np . vstack ( [self[r] for r in self . dtype . names] ) . T . squeeze ( ) ": 2334,
 "def delete_entry ( self , key ) : pipe = self . client . pipeline ( ) pipe . srem ( self . keys_container , key ) pipe . delete ( key ) pipe . execute ( ) ": 2335,
 "def match_files ( files , pattern : Pattern ) : for name in files : if re . match ( pattern , name ) : yield name": 2336,
 "def _selectItem ( self , index ) : self . _selectedIndex = index self . setCurrentIndex ( self . model ( ) . createIndex ( index , 0 ) ) ": 2337,
 "def percentile_index ( a , q ) : return np . where ( a = = np . percentile ( a , q , interpolation = ' nearest ' ) ) [0][0]": 2338,
 "def sanitize_word ( s ) : s = re . sub ( ' [^\\w-]+ ' , ' _ ' , s ) s = re . sub ( ' __+ ' , ' _ ' , s ) return s . strip ( ' _ ' ) ": 2339,
 "def _attach_files ( filepaths , email_ ) : for filepath in filepaths : base = os . path . basename ( filepath ) with open ( filepath , \" rb \" ) as file : part = MIMEApplication ( file . read ( ) , Name = base ) part[ \" Content-Disposition \" ] = ' attachment; filename = \" %s \" ' % base email_ . attach ( part ) ": 2340,
 "def send ( r , stream = False ) : r . send ( stream = stream ) return r . response": 2341,
 "def handle_data ( self , data ) : if data . strip ( ) : data = djeffify_string ( data ) self . djhtml + = data": 2342,
 "def splitext_no_dot ( filename ) : name , ext = os . path . splitext ( filename ) ext = ext . lower ( ) return name , ext . strip ( ' . ' ) ": 2343,
 "def boolean ( flag ) : s = flag . lower ( ) if s in ( ' 1 ' , ' yes ' , ' true ' ) : return True elif s in ( ' 0 ' , ' no ' , ' false ' ) : return False raise ValueError ( ' Unknown flag %r ' % s ) ": 2344,
 "def autoscan ( ) : for port in serial . tools . list_ports . comports ( ) : if is_micropython_usb_device ( port ) : connect_serial ( port[0] ) ": 2345,
 "def _session_set ( self , key , value ) : self . session[self . _session_key ( key ) ] = value": 2346,
 "def internal_reset ( self ) : log . critical ( \" PIA internal_reset ( ) \" ) self . empty_key_toggle = True self . current_input_char = None self . input_repead = 0": 2347,
 "def get_member ( thing_obj , member_string ) : mems = {x[0] : x[1] for x in inspect . getmembers ( thing_obj ) } if member_string in mems : return mems[member_string]": 2348,
 "def _replace_service_arg ( self , name , index , args ) : args[index] = self . get_instantiated_service ( name ) ": 2349,
 "def _dotify ( cls , data ) : return ' ' . join ( char if char in cls . PRINTABLE_DATA else ' . ' for char in data ) ": 2350,
 "def is_set ( self , key ) : data = self . model . get_data ( ) return isinstance ( data[key] , set ) ": 2351,
 "def dropna ( self ) : not_nas = [v . notna ( ) for v in self . values] and_filter = reduce ( lambda x , y : x & y , not_nas ) return self[and_filter]": 2352,
 "def reset_default_logger ( ) : global logger global _loglevel global _logfile global _formatter _loglevel = logging . DEBUG _logfile = None _formatter = None logger = setup_logger ( name = LOGZERO_DEFAULT_LOGGER , logfile = _logfile , level = _loglevel , formatter = _formatter ) ": 2353,
 "def save_pdf ( path ) : pp = PdfPages ( path ) pp . savefig ( pyplot . gcf ( ) ) pp . close ( ) ": 2354,
 "def generate_id ( ) : # TODO : Use six . string_type to Py3 compat try : return unicode ( uuid1 ( ) ) . replace ( u \" - \" , u \" \" ) except NameError : return str ( uuid1 ( ) ) . replace ( u \" - \" , u \" \" ) ": 2355,
 "def is_valid_varname ( varname ) : if not isinstance ( varname , six . string_types ) : return False match_obj = re . match ( varname_regex , varname ) valid_syntax = match_obj is not None valid_name = not keyword . iskeyword ( varname ) isvalid = valid_syntax and valid_name return isvalid": 2356,
 "def setAutoRangeOn ( self , axisNumber ) : setXYAxesAutoRangeOn ( self , self . xAxisRangeCti , self . yAxisRangeCti , axisNumber ) ": 2357,
 "def unique_element ( ll ) : seen = {} result = [] for item in ll : if item in seen : continue seen[item] = 1 result . append ( item ) return result": 2358,
 "def wait_on_rate_limit ( self , value ) : check_type ( value , bool , may_be_none = False ) self . _wait_on_rate_limit = value": 2359,
 "def _send_file ( self , filename ) : # pylint : disable = E1101 ftp = ftplib . FTP ( host = self . host ) ftp . login ( user = self . user , passwd = self . password ) ftp . set_pasv ( True ) ftp . storbinary ( \" STOR %s \" % os . path . basename ( filename ) , file ( filename , ' rb ' ) ) ": 2360,
 "def send_photo ( self , photo : str , caption : str = None , reply : Message = None , on_success : callable = None , reply_markup : botapi . ReplyMarkup = None ) : self . twx . send_photo ( peer = self , photo = photo , caption = caption , reply = reply , reply_markup = reply_markup , on_success = on_success ) ": 2361,
 "def sys_pipes_forever ( encoding = _default_encoding ) : global _mighty_wurlitzer if _mighty_wurlitzer is None : _mighty_wurlitzer = sys_pipes ( encoding ) _mighty_wurlitzer . __enter__ ( ) ": 2362,
 "def _check_for_errors ( etree : ET . ElementTree ) : if etree . getroot ( ) . tag = = ' error ' : raise APIError ( etree . getroot ( ) . text ) ": 2363,
 "def previous_friday ( dt ) : if dt . weekday ( ) = = 5 : return dt - timedelta ( 1 ) elif dt . weekday ( ) = = 6 : return dt - timedelta ( 2 ) return dt": 2364,
 "def save_model ( self , request , obj , form , change ) : obj . author = request . user obj . save ( ) ": 2365,
 "def set_position ( self , x , y , width , height ) : SetWindowPos ( self . _hwnd , None , x , y , width , height , ctypes . c_uint ( 0 ) ) ": 2366,
 "def set_constraint_bound ( self , name , value ) : index = self . _get_constraint_index ( name ) self . upper_bounds[index] = value self . _reset_solution ( ) ": 2367,
 "def set_axis_options ( self , row , column , text ) : subplot = self . get_subplot_at ( row , column ) subplot . set_axis_options ( text ) ": 2368,
 "def set_default ( self , key , value ) : k = self . _real_key ( key . lower ( ) ) self . _defaults[k] = value": 2369,
 "def stringc ( text , color ) : if has_colors : text = str ( text ) return \" \\033[ \" +codeCodes[color]+ \" m \" +text+ \" \\033[0m \" else : return text": 2370,
 "def chunks ( iterable , chunk ) : for i in range ( 0 , len ( iterable ) , chunk ) : yield iterable[i : i + chunk]": 2371,
 "def _print_memory ( self , memory ) : for addr , value in memory . items ( ) : print ( \" 0x%08x : 0x%08x ( %d ) \" % ( addr , value , value ) ) ": 2372,
 "def sort_by_name ( self ) : super ( JSSObjectList , self ) . sort ( key = lambda k : k . name ) ": 2373,
 "def cached_query ( qs , timeout = None ) : cache_key = generate_cache_key ( qs ) return get_cached ( cache_key , list , args = ( qs , ) , timeout = None ) ": 2374,
 "def csort ( objs , key ) : idxs = dict ( ( obj , i ) for ( i , obj ) in enumerate ( objs ) ) return sorted ( objs , key = lambda obj : ( key ( obj ) , idxs[obj] ) ) ": 2375,
 "def validate_type ( self , type_ ) : if type_ is not None and type_ not in self . types_set : raise ValueError ( ' Invalid type for %s : %s ' % ( self . __class__ , type_ ) ) ": 2376,
 "def mpl_outside_legend ( ax , **kwargs ) : box = ax . get_position ( ) ax . set_position ( [box . x0 , box . y0 , box . width * 0 . 75 , box . height] ) # Put a legend to the right of the current axis ax . legend ( loc = ' upper left ' , bbox_to_anchor = ( 1 , 1 ) , **kwargs ) ": 2377,
 "def smooth_array ( array , amount = 1 ) : if amount = = 0 : return array # we have to store the old values in a temp array to keep the # smoothing from affecting the smoothing new_array = _n . array ( array ) for n in range ( len ( array ) ) : new_array[n] = smooth ( array , n , amount ) return new_array": 2378,
 "def pick_unused_port ( self ) : s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) s . bind ( ( ' 127 . 0 . 0 . 1 ' , 0 ) ) _ , port = s . getsockname ( ) s . close ( ) return port": 2379,
 "def run ( context , port ) : global ctx ctx = context app . run ( port = port ) ": 2380,
 "def enter_room ( self , sid , room , namespace = None ) : return self . server . enter_room ( sid , room , namespace = namespace or self . namespace ) ": 2381,
 "def end ( self ) : if not self . args . disable_autodiscover : self . autodiscover_client . close ( ) self . server . end ( ) ": 2382,
 "def delistify ( x ) : if isinstance ( x , list ) : x = [e . replace ( \" ' \" , \" \" ) for e in x] return ' - ' . join ( sorted ( x ) ) return x": 2383,
 "def access_to_sympy ( self , var_name , access ) : base_sizes = self . variables[var_name][1] expr = sympy . Number ( 0 ) for dimension , a in enumerate ( access ) : base_size = reduce ( operator . mul , base_sizes[dimension+1 : ] , sympy . Integer ( 1 ) ) expr + = base_size*a return expr": 2384,
 "def get_py_source ( file ) : try : response = None pysource = \" \" if regexp_py . search ( file ) is None : response = { \" error \" : \" Only Python source files are allowed . ( * . py ) \" } else : with open ( file , ' r ' ) as pyfile : pysource = pyfile . read ( ) response = { \" data \" : pysource} except Exception as e : response = { \" error \" : str ( e ) } finally : return response": 2385,
 "def _root_mean_square_error ( y , y_pred , w ) : return np . sqrt ( np . average ( ( ( y_pred - y ) ** 2 ) , weights = w ) ) ": 2386,
 "def toArray ( self ) : arr = np . zeros ( ( self . size , ) , dtype = np . float64 ) arr[self . indices] = self . values return arr": 2387,
 "def step_next_line ( self ) : self . _eol . append ( self . position ) self . _lineno + = 1 self . _col_offset = 0": 2388,
 "def read_sphinx_environment ( pth ) : with open ( pth , ' rb ' ) as fo : env = pickle . load ( fo ) return env": 2389,
 "def _is_image_sequenced ( image ) : try : image . seek ( 1 ) image . seek ( 0 ) result = True except EOFError : result = False return result": 2390,
 "def consecutive ( data , stepsize = 1 ) : return np . split ( data , np . where ( np . diff ( data ) ! = stepsize ) [0] + 1 ) ": 2391,
 "def __contains__ ( self , key ) : assert isinstance ( key , basestring ) return dict . __contains__ ( self , key . lower ( ) ) ": 2392,
 "def reindent ( s , numspaces ) : leading_space = numspaces * ' ' lines = [leading_space + line . strip ( ) for line in s . splitlines ( ) ] return ' \\n ' . join ( lines ) ": 2393,
 "def wrap_count ( method ) : number = 0 while hasattr ( method , ' __aspects_orig ' ) : number + = 1 method = method . __aspects_orig return number": 2394,
 "def insert_many ( self , items ) : return SessionContext . session . execute ( self . insert ( values = [ to_dict ( item , self . c ) for item in items ] ) , ) . rowcount": 2395,
 "def get_count ( self , query ) : count_q = query . statement . with_only_columns ( [func . count ( ) ] ) . order_by ( None ) count = query . session . execute ( count_q ) . scalar ( ) return count": 2396,
 "def downgrade ( directory , sql , tag , x_arg , revision ) : _downgrade ( directory , revision , sql , tag , x_arg ) ": 2397,
 "def sqliteRowsToDicts ( sqliteRows ) : return map ( lambda r : dict ( zip ( r . keys ( ) , r ) ) , sqliteRows ) ": 2398,
 "def get_type_len ( self ) : # Check types and set type/len self . get_sql ( ) return self . type , self . len , self . len_decimal": 2399,
 "def exists ( self , filepath ) : if self . is_ssh ( filepath ) : self . _check_ftp ( ) remotepath = self . _get_remote ( filepath ) try : self . ftp . stat ( remotepath ) except IOError as e : if e . errno = = errno . ENOENT : return False else : return True else : return os . path . exists ( filepath ) ": 2400,
 "def ensure_tuple ( obj ) : if obj is None : return tuple ( ) if isinstance ( obj , Iterable ) and not isinstance ( obj , six . string_types ) : return tuple ( obj ) return obj , ": 2401,
 "def calculate_bounding_box ( data ) : mins = data . min ( 0 ) maxes = data . max ( 0 ) return mins , maxes": 2402,
 "def _create_complete_graph ( node_ids ) : g = nx . Graph ( ) g . add_nodes_from ( node_ids ) for ( i , j ) in combinations ( node_ids , 2 ) : g . add_edge ( i , j ) return g": 2403,
 "def glr_path_static ( ) : return os . path . abspath ( os . path . join ( os . path . dirname ( __file__ ) , ' _static ' ) ) ": 2404,
 "def image_format ( value ) : if value . image . format . upper ( ) not in constants . ALLOWED_IMAGE_FORMATS : raise ValidationError ( MESSAGE_INVALID_IMAGE_FORMAT ) ": 2405,
 "def standard_deviation ( numbers ) : numbers = list ( numbers ) if not numbers : return 0 mean = sum ( numbers ) / len ( numbers ) return ( sum ( ( n - mean ) ** 2 for n in numbers ) / len ( numbers ) ) ** . 5": 2406,
 "def fetch_header ( self ) : query = self . query ( ) . add_query_parameter ( req = ' header ' ) return self . _parse_messages ( self . get_query ( query ) . content ) [0]": 2407,
 "def dt2str ( dt , flagSeconds = True ) : if isinstance ( dt , str ) : return dt return dt . strftime ( _FMTS if flagSeconds else _FMT ) ": 2408,
 "def add_device_callback ( self , callback ) : _LOGGER . debug ( ' Added new callback %s ' , callback ) self . _cb_new_device . append ( callback ) ": 2409,
 "def any_contains_any ( strings , candidates ) : for string in strings : for c in candidates : if c in string : return True": 2410,
 "def load ( cls , fname ) : with open ( fname ) as f : content = f . readlines ( ) return Flow . from_json ( ' ' . join ( content ) ) ": 2411,
 "def _write_config ( config , cfg_file ) : directory = os . path . dirname ( cfg_file ) if not os . path . exists ( directory ) : os . makedirs ( directory ) with open ( cfg_file , \" w+ \" ) as output_file : config . write ( output_file ) ": 2412,
 "def dump_stmt_strings ( stmts , fname ) : with open ( fname , ' wb ' ) as fh : for st in stmts : fh . write ( ( ' %s\\n ' % st ) . encode ( ' utf-8 ' ) ) ": 2413,
 "def validate_stringlist ( s ) : if isinstance ( s , six . string_types ) : return [six . text_type ( v . strip ( ) ) for v in s . split ( ' , ' ) if v . strip ( ) ] else : try : return list ( map ( validate_str , s ) ) except TypeError as e : raise ValueError ( e . message ) ": 2414,
 "def write_line ( self , line , count = 1 ) : self . write ( line ) self . write_newlines ( count ) ": 2415,
 "def make_strslice ( lineno , s , lower , upper ) : return symbols . STRSLICE . make_node ( lineno , s , lower , upper ) ": 2416,
 "def filedata ( self ) : if self . _filedata_api is None : self . _filedata_api = self . get_filedata_api ( ) return self . _filedata_api": 2417,
 "def _str_to_list ( s ) : _list = s . split ( \" , \" ) return list ( map ( lambda i : i . lstrip ( ) , _list ) ) ": 2418,
 "def backward_char ( self , e ) : # ( C-b ) u self . l_buffer . backward_char ( self . argument_reset ) self . finalize ( ) ": 2419,
 "def top ( n , width = WIDTH , style = STYLE ) : return hrule ( n , width , linestyle = STYLES[style] . top ) ": 2420,
 "def _repr_strip ( mystring ) : r = repr ( mystring ) if r . startswith ( \" ' \" ) and r . endswith ( \" ' \" ) : return r[1 : -1] else : return r": 2421,
 "def text_remove_empty_lines ( text ) : lines = [ line . rstrip ( ) for line in text . splitlines ( ) if line . strip ( ) ] return \" \\n \" . join ( lines ) ": 2422,
 "def strip_spaces ( value , sep = None , join = True ) : value = value . strip ( ) value = [v . strip ( ) for v in value . split ( sep ) ] join_sep = sep or ' ' return join_sep . join ( value ) if join else value": 2423,
 "def chmod ( scope , filename , mode ) : for file in filename : os . chmod ( file , mode[0] ) return True": 2424,
 "def set_title ( self , title , **kwargs ) : ax = self . get_axes ( ) ax . set_title ( title , **kwargs ) ": 2425,
 "def show_yticklabels ( self , row , column ) : subplot = self . get_subplot_at ( row , column ) subplot . show_yticklabels ( ) ": 2426,
 "def _replace_file ( path , content ) : if os . path . exists ( path ) : with open ( path , ' r ' ) as f : if content = = f . read ( ) : print ( \" Not overwriting {} because it is unchanged \" . format ( path ) , file = sys . stderr ) return with open ( path , ' w ' ) as f : f . write ( content ) ": 2427,
 "def correspond ( text ) : subproc . stdin . write ( text ) subproc . stdin . flush ( ) return drain ( ) ": 2428,
 "def numberp ( v ) : return ( not ( isinstance ( v , bool ) ) and ( isinstance ( v , int ) or isinstance ( v , float ) ) ) ": 2429,
 "def replace_variable_node ( node , annotation ) : assert type ( node ) is ast . Assign , ' nni . variable is not annotating assignment expression ' assert len ( node . targets ) = = 1 , ' Annotated assignment has more than one left-hand value ' name , expr = parse_nni_variable ( annotation ) assert test_variable_equal ( node . targets[0] , name ) , ' Annotated variable has wrong name ' node . value = expr return node": 2430,
 "def _swap_rows ( self , i , j ) : L = np . eye ( 3 , dtype = ' intc ' ) L[i , i] = 0 L[j , j] = 0 L[i , j] = 1 L[j , i] = 1 self . _L . append ( L . copy ( ) ) self . _A = np . dot ( L , self . _A ) ": 2431,
 "def transformer ( data , label ) : data = mx . image . imresize ( data , IMAGE_SIZE , IMAGE_SIZE ) data = mx . nd . transpose ( data , ( 2 , 0 , 1 ) ) data = data . astype ( np . float32 ) / 128 . 0 - 1 return data , label": 2432,
 "def purge_duplicates ( list_in ) : _list = [] for item in list_in : if item not in _list : _list . append ( item ) return _list": 2433,
 "def get_point_hash ( self , point ) : return geohash . encode ( point . latitude , point . longitude , self . precision ) ": 2434,
 "def __eq__ ( self , anotherset ) : if not isinstance ( anotherset , LR0ItemSet ) : raise TypeError if len ( self . itemlist ) ! = len ( anotherset . itemlist ) : return False for element in self . itemlist : if element not in anotherset . itemlist : return False return True": 2435,
 "def paint ( self , tbl ) : if not isinstance ( tbl , Table ) : logging . error ( \" unable to paint table : invalid object \" ) return False self . term . stream . write ( self . term . clear ) self . term . stream . write ( str ( tbl ) ) return True": 2436,
 "def check_int ( integer ) : if not isinstance ( integer , str ) : return False if integer[0] in ( ' - ' , ' + ' ) : return integer[1 : ] . isdigit ( ) return integer . isdigit ( ) ": 2437,
 "def timedelta2millisecond ( td ) : milliseconds = td . days * 24 * 60 * 60 * 1000 milliseconds + = td . seconds * 1000 milliseconds + = td . microseconds / 1000 return milliseconds": 2438,
 "def __getitem__ ( self , name ) : if name not in self . _collections : self . _collections[name] = Collection ( self . db , name ) return self . _collections[name]": 2439,
 "def _get_example_length ( example ) : length = tf . maximum ( tf . shape ( example[0] ) [0] , tf . shape ( example[1] ) [0] ) return length": 2440,
 "def flatten4d3d ( x ) : xshape = shape_list ( x ) result = tf . reshape ( x , [xshape[0] , xshape[1] * xshape[2] , xshape[3]] ) return result": 2441,
 "def get_indent ( text ) : indent = ' ' ret = re . match ( r ' ( \\s* ) ' , text ) if ret : indent = ret . group ( 1 ) return indent": 2442,
 "def is_lazy_iterable ( obj ) : return isinstance ( obj , ( types . GeneratorType , collections . MappingView , six . moves . range , enumerate ) ) ": 2443,
 "def is_in ( self , search_list , pair ) : index = -1 for nr , i in enumerate ( search_list ) : if ( np . all ( i = = pair ) ) : return nr return index": 2444,
 "def is_readable ( filename ) : return os . path . isfile ( filename ) and os . access ( filename , os . R_OK ) ": 2445,
 "def _genTex2D ( self ) : for face in range ( 6 ) : gl . glTexImage2D ( self . target0 + face , 0 , self . internal_fmt , self . width , self . height , 0 , self . pixel_fmt , gl . GL_UNSIGNED_BYTE , 0 ) ": 2446,
 "def int2str ( num , radix = 10 , alphabet = BASE85 ) : return NumConv ( radix , alphabet ) . int2str ( num ) ": 2447,
 "def start ( self ) : if not self . _is_running : self . _do_run = True self . _thread . start ( ) return self": 2448,
 "def is_valid_uid ( uid ) : pattern = r ' ^[A-Za-z][A-Za-z0-9]{10}$ ' if not isinstance ( uid , string_types ) : return False return bool ( re . compile ( pattern ) . match ( uid ) ) ": 2449,
 "def seconds ( num ) : now = pytime . time ( ) end = now + num until ( end ) ": 2450,
 "def format_time ( time ) : h , r = divmod ( time / 1000 , 3600 ) m , s = divmod ( r , 60 ) return \" %02d : %02d : %02d \" % ( h , m , s ) ": 2451,
 "def fileModifiedTimestamp ( fname ) : modifiedTime = os . path . getmtime ( fname ) stamp = time . strftime ( ' %Y-%m-%d ' , time . localtime ( modifiedTime ) ) return stamp": 2452,
 "def start ( self ) : self . streams . append ( sys . stdout ) sys . stdout = self . stream": 2453,
 "def current_offset ( local_tz = None ) : if local_tz is None : local_tz = DEFAULT_LOCAL_TZ dt = local_tz . localize ( datetime . now ( ) ) return dt . utcoffset ( ) ": 2454,
 "def __hash__ ( self ) : return hash ( ( type ( self ) , self . domain , self . range , self . partition ) ) ": 2455,
 "def set_cursor_position ( self , position ) : position = self . get_position ( position ) cursor = self . textCursor ( ) cursor . setPosition ( position ) self . setTextCursor ( cursor ) self . ensureCursorVisible ( ) ": 2456,
 "def clear_timeline ( self ) : self . _timeline . delete ( tk . ALL ) self . _canvas_ticks . delete ( tk . ALL ) ": 2457,
 "async def iso ( self , source ) : from datetime import datetime unix_timestamp = int ( source ) return datetime . fromtimestamp ( unix_timestamp ) . isoformat ( ) ": 2458,
 "def listfolderpath ( p ) : for entry in scandir . scandir ( p ) : if entry . is_dir ( ) : yield entry . path": 2459,
 "def render_template ( env , filename , values = None ) : if not values : values = {} tmpl = env . get_template ( filename ) return tmpl . render ( values ) ": 2460,
 "def listified_tokenizer ( source ) : io_obj = io . StringIO ( source ) return [list ( a ) for a in tokenize . generate_tokens ( io_obj . readline ) ]": 2461,
 "def save_notebook ( work_notebook , write_file ) : with open ( write_file , ' w ' ) as out_nb : json . dump ( work_notebook , out_nb , indent = 2 ) ": 2462,
 "def conv3x3 ( in_channels , out_channels , stride = 1 ) : return nn . Conv2d ( in_channels , out_channels , kernel_size = 3 , stride = stride , padding = 1 , bias = False ) ": 2463,
 "def camel_to_ ( s ) : s1 = re . sub ( ' ( . ) ( [A-Z][a-z]+ ) ' , r ' \\1_\\2 ' , s ) return re . sub ( ' ( [a-z0-9] ) ( [A-Z] ) ' , r ' \\1_\\2 ' , s1 ) . lower ( ) ": 2464,
 "def toJson ( protoObject , indent = None ) : # Using the internal method because this way we can reformat the JSON js = json_format . MessageToDict ( protoObject , False ) return json . dumps ( js , indent = indent ) ": 2465,
 "def toListInt ( value ) : if TypeConverters . _can_convert_to_list ( value ) : value = TypeConverters . toList ( value ) if all ( map ( lambda v : TypeConverters . _is_integer ( v ) , value ) ) : return [int ( v ) for v in value] raise TypeError ( \" Could not convert %s to list of ints \" % value ) ": 2466,
 "def cmd_dns_lookup_reverse ( ip_address , verbose ) : if verbose : logging . basicConfig ( level = logging . INFO , format = ' % ( message ) s ' ) print ( \" Looking up %s . . . \" % ip_address , file = sys . stderr ) answer = lookup_reverse ( ip_address ) if answer : print ( json . dumps ( answer , indent = 4 ) ) else : print ( \" [X] %s is not valid IPv4/IPV6 address \" % ip_address ) return True": 2467,
 "def stop_process ( self ) : self . _process . terminate ( ) if not self . _process . waitForFinished ( 100 ) : self . _process . kill ( ) ": 2468,
 "def stop ( self ) : # unsetup_fuse ( ) self . fuse_process . teardown ( ) for uuid in self . processes : self . processes[uuid] . terminate ( ) ": 2469,
 "def forward ( self , step ) : x = self . pos_x + math . cos ( math . radians ( self . rotation ) ) * step y = self . pos_y + math . sin ( math . radians ( self . rotation ) ) * step prev_brush_state = self . brush_on self . brush_on = True self . move ( x , y ) self . brush_on = prev_brush_state": 2470,
 "def l2_norm ( arr ) : arr = np . asarray ( arr ) return np . sqrt ( np . dot ( arr . ravel ( ) . squeeze ( ) , arr . ravel ( ) . squeeze ( ) ) ) ": 2471,
 "def default_strlen ( strlen = None ) : if strlen is not None : _default_types_status[ ' default_strlen ' ] = strlen # update the typeDicts as needed lstring_as_obj ( _default_types_status[ ' lstring_as_obj ' ] ) ilwd_as_int ( _default_types_status[ ' ilwd_as_int ' ] ) return _default_types_status[ ' default_strlen ' ]": 2472,
 "def onLeftDown ( self , event = None ) : if event is None : return self . cursor_mode_action ( ' leftdown ' , event = event ) self . ForwardEvent ( event = event . guiEvent ) ": 2473,
 "def omnihash ( obj ) : if isinstance ( obj , set ) : return hash ( frozenset ( omnihash ( e ) for e in obj ) ) elif isinstance ( obj , ( tuple , list ) ) : return hash ( tuple ( omnihash ( e ) for e in obj ) ) elif isinstance ( obj , dict ) : return hash ( frozenset ( ( k , omnihash ( v ) ) for k , v in obj . items ( ) ) ) else : return hash ( obj ) ": 2474,
 "def cover ( session ) : session . interpreter = ' python3 . 6 ' session . install ( ' coverage ' , ' pytest-cov ' ) session . run ( ' coverage ' , ' report ' , ' --show-missing ' , ' --fail-under = 100 ' ) session . run ( ' coverage ' , ' erase ' ) ": 2475,
 "def find_one ( line , lookup ) : match = re . search ( lookup , line ) if match : if match . group ( 1 ) : return match . group ( 1 ) return False": 2476,
 "def teardown_test ( self , context ) : context . test . tearDownClass ( ) context . test . _post_teardown ( run = True ) del context . test": 2477,
 "def glog ( x , l = 2 ) : return np . log ( ( x+np . sqrt ( x**2+l**2 ) ) /2 ) /np . log ( l ) ": 2478,
 "def _ioctl ( self , func , args ) : import fcntl return fcntl . ioctl ( self . sockfd . fileno ( ) , func , args ) ": 2479,
 "def inheritdoc ( method ) : method . __doc__ = getattr ( str , method . __name__ ) . __doc__ return method": 2480,
 "def split_elements ( value ) : l = [v . strip ( ) for v in value . split ( ' , ' ) ] if len ( l ) = = 1 : l = value . split ( ) return l": 2481,
 "def _remove_from_index ( index , obj ) : try : index . value_map[indexed_value ( index , obj ) ] . remove ( obj . id ) except KeyError : pass": 2482,
 "def keys ( self , index = None ) : with self . _lmdb . begin ( ) as txn : return [key . decode ( ) for key , _ in txn . cursor ( ) ]": 2483,
 "def make_bound ( lower , upper , lineno ) : return symbols . BOUND . make_node ( lower , upper , lineno ) ": 2484,
 "def load_image ( fname ) : with open ( fname , \" rb \" ) as f : i = Image . open ( fname ) # i . load ( ) return i": 2485,
 "def get_dict_to_encoded_url ( data ) : unicode_data = dict ( [ ( k , smart_str ( v ) ) for k , v in data . items ( ) ] ) encoded = urllib . urlencode ( unicode_data ) return encoded": 2486,
 "def load ( self , filename = ' classifier . dump ' ) : ifile = open ( filename , ' r+ ' ) self . classifier = pickle . load ( ifile ) ifile . close ( ) ": 2487,
 "def get_body_size ( params , boundary ) : size = sum ( p . get_size ( boundary ) for p in MultipartParam . from_params ( params ) ) return size + len ( boundary ) + 6": 2488,
 "def load_graph_from_rdf ( fname ) : print ( \" reading RDF from \" + fname + \" . . . . \" ) store = Graph ( ) store . parse ( fname , format = \" n3 \" ) print ( \" Loaded \" + str ( len ( store ) ) + \" tuples \" ) return store": 2489,
 "def __init__ ( self , usb ) : self . _usb = usb self . _protocol = self . protocol_handler ( usb ) ": 2490,
 "def _if ( ctx , logical_test , value_if_true = 0 , value_if_false = False ) : return value_if_true if conversions . to_boolean ( logical_test , ctx ) else value_if_false": 2491,
 "def _find ( string , sub_string , start_index ) : result = string . find ( sub_string , start_index ) if result = = -1 : raise TokenError ( \" expected ' {0} ' \" . format ( sub_string ) ) return result": 2492,
 "def human_uuid ( ) : return base64 . b32encode ( hashlib . sha1 ( uuid . uuid4 ( ) . bytes ) . digest ( ) ) . lower ( ) . strip ( ' = ' ) ": 2493,
 "def safe_int ( val , default = None ) : try : val = int ( val ) except ( ValueError , TypeError ) : val = default return val": 2494,
 "def normal_log_q ( self , z ) : means , scale = self . get_means_and_scales ( ) return ss . norm . logpdf ( z , loc = means , scale = scale ) ": 2495,
 "def process_request ( self , request , response ) : self . logger . info ( ' Requested : {0} {1} {2} ' . format ( request . method , request . relative_uri , request . content_type ) ) ": 2496,
 "def v_normalize ( v ) : vmag = v_magnitude ( v ) return [ v[i]/vmag for i in range ( len ( v ) ) ]": 2497,
 "def map ( cls , iterable , func , *a , **kw ) : return cls ( func ( x , *a , **kw ) for x in iterable ) ": 2498,
 "def OnTogglePlay ( self , event ) : if self . player . get_state ( ) = = vlc . State . Playing : self . player . pause ( ) else : self . player . play ( ) event . Skip ( ) ": 2499,
 "def clean_with_zeros ( self , x ) : x[~np . any ( np . isnan ( x ) | np . isinf ( x ) , axis = 1 ) ] = 0 return x": 2500,
 "def get_process_handle ( self ) : # The handle doesn ' t need to be closed . # See http : //msdn . microsoft . com/en-us/library/ms681423 ( VS . 85 ) . aspx hProcess = self . raw . u . CreateProcessInfo . hProcess if hProcess in ( 0 , win32 . NULL , win32 . INVALID_HANDLE_VALUE ) : hProcess = None else : hProcess = ProcessHandle ( hProcess , False , win32 . PROCESS_ALL_ACCESS ) return hProcess": 2501,
 "def _position ( ) : cursor = POINT ( ) ctypes . windll . user32 . GetCursorPos ( ctypes . byref ( cursor ) ) return ( cursor . x , cursor . y ) ": 2502,
 "def comment ( self , s , **args ) : self . write ( u \" // \" ) self . writeln ( s = s , **args ) ": 2503,
 "def vectorize ( values ) : if isinstance ( values , list ) : return ' , ' . join ( str ( v ) for v in values ) return values": 2504,
 "def top_1_tpu ( inputs ) : inputs_max = tf . reduce_max ( inputs , axis = -1 , keepdims = True ) mask = tf . to_int32 ( tf . equal ( inputs_max , inputs ) ) index = tf . range ( tf . shape ( inputs ) [-1] ) * mask return tf . squeeze ( inputs_max , -1 ) , tf . reduce_max ( index , axis = -1 ) ": 2505,
 "def close ( self ) : if self . _connection : self . _connection . close ( ) self . _response . close ( ) ": 2506,
 "def retry_call ( func , cleanup = lambda : None , retries = 0 , trap = ( ) ) : \t\tattempts = count ( ) if retries = = float ( ' inf ' ) else range ( retries ) \tfor attempt in attempts : \t\ttry : \t\t\treturn func ( ) \t\texcept trap : \t\t\tcleanup ( ) \treturn func ( ) ": 2507,
 "def reduce_json ( data ) : return reduce ( lambda x , y : int ( x ) + int ( y ) , data . values ( ) ) ": 2508,
 "def convert_value ( bind , value ) : type_name = get_type ( bind ) try : return typecast . cast ( type_name , value ) except typecast . ConverterError : return value": 2509,
 "def chop ( seq , size ) : chunk = lambda i : seq[i : i+size] return map ( chunk , xrange ( 0 , len ( seq ) , size ) ) ": 2510,
 "def write_str2file ( pathname , astr ) : fname = pathname fhandle = open ( fname , ' wb ' ) fhandle . write ( astr ) fhandle . close ( ) ": 2511,
 "def MatrixInverse ( a , adj ) : return np . linalg . inv ( a if not adj else _adjoint ( a ) ) , ": 2512,
 "def _write_color_ansi ( fp , text , color ) : fp . write ( esc_ansicolor ( color ) ) fp . write ( text ) fp . write ( AnsiReset ) ": 2513,
 "def _show_traceback ( method ) : def m ( self , *args , **kwargs ) : try : return ( method ( self , *args , **kwargs ) ) except Exception as e : ip = get_ipython ( ) if ip is None : self . log . warning ( \" Exception in widget method %s : %s \" , method , e , exc_info = True ) else : ip . showtraceback ( ) return m": 2514,
 "def _write_pidfile ( pidfile ) : pid = str ( os . getpid ( ) ) handle = open ( pidfile , ' w ' ) try : handle . write ( \" %s\\n \" % pid ) finally : handle . close ( ) ": 2515,
 "def random_color ( _min = MIN_COLOR , _max = MAX_COLOR ) : return color ( random . randint ( _min , _max ) ) ": 2516,
 "def SegmentMin ( a , ids ) : func = lambda idxs : np . amin ( a[idxs] , axis = 0 ) return seg_map ( func , a , ids ) , ": 2517,
 "def save_dot ( self , fd ) : from pylon . io import DotWriter DotWriter ( self ) . write ( fd ) ": 2518,
 "def _prepare_proxy ( self , conn ) : conn . set_tunnel ( self . _proxy_host , self . port , self . proxy_headers ) conn . connect ( ) ": 2519,
 "def cleanup_nodes ( doc ) : for node in doc . documentElement . childNodes : if node . nodeType = = Node . TEXT_NODE and node . nodeValue . isspace ( ) : doc . documentElement . removeChild ( node ) return doc": 2520,
 "def _run_asyncio ( loop , zmq_context ) : try : asyncio . set_event_loop ( loop ) loop . run_forever ( ) except : pass finally : loop . close ( ) zmq_context . destroy ( 1000 ) ": 2521,
 "def _is_iterable ( item ) : return isinstance ( item , collections . Iterable ) and not isinstance ( item , six . string_types ) ": 2522,
 "def _parse ( self , date_str , format = ' %Y-%m-%d ' ) : rv = pd . to_datetime ( date_str , format = format ) if hasattr ( rv , ' to_pydatetime ' ) : rv = rv . to_pydatetime ( ) return rv": 2523,
 "def normalize_text ( text , line_len = 80 , indent = \" \" ) : return \" \\n \" . join ( textwrap . wrap ( text , width = line_len , initial_indent = indent , subsequent_indent = indent ) ) ": 2524,
 "def threadid ( self ) : current = self . thread . ident main = get_main_thread ( ) if main is None : return current else : return current if current ! = main . ident else None": 2525,
 "def trans_from_matrix ( matrix ) : t = np . zeros ( ( 4 , 4 ) ) for i in range ( 4 ) : for j in range ( 4 ) : t[i , j] = matrix . GetElement ( i , j ) return t": 2526,
 "def get_file_extension_type ( filename ) : ext = get_file_extension ( filename ) if ext : for name , group in EXTENSIONS . items ( ) : if ext in group : return name return \" OTHER \" ": 2527,
 "def inspect_cuda ( ) : nvcc_settings = nvcc_compiler_settings ( ) sysconfig . get_config_vars ( ) nvcc_compiler = ccompiler . new_compiler ( ) sysconfig . customize_compiler ( nvcc_compiler ) customize_compiler_for_nvcc ( nvcc_compiler , nvcc_settings ) output = inspect_cuda_version_and_devices ( nvcc_compiler , nvcc_settings ) return json . loads ( output ) , nvcc_settings": 2528,
 "def iteritems ( data , **kwargs ) : return iter ( data . items ( **kwargs ) ) if IS_PY3 else data . iteritems ( **kwargs ) ": 2529,
 "def random_id ( size = 8 , chars = string . ascii_letters + string . digits ) : \t\treturn ' ' . join ( random . choice ( chars ) for _ in range ( size ) ) ": 2530,
 "def require_root ( fn ) : @wraps ( fn ) def xex ( *args , **kwargs ) : assert os . geteuid ( ) = = 0 , \\ \" You have to be root to run function ' %s ' . \" % fn . __name__ return fn ( *args , **kwargs ) return xex": 2531,
 "def normalize ( self ) : if self . preprocessed_data . empty : data = self . original_data else : data = self . preprocessed_data data = pd . DataFrame ( preprocessing . normalize ( data ) , columns = data . columns , index = data . index ) self . preprocessed_data = data": 2532,
 "def normalize ( df , style = ' mean ' ) : if style = = ' mean ' : df_mean , df_std = df . mean ( ) , df . std ( ) return ( df-df_mean ) /df_std elif style = = ' minmax ' : col_min , col_max = df . min ( ) , df . max ( ) return ( df-col_min ) / ( col_max-col_min ) else : return style ( df ) ": 2533,
 "def get_qapp ( ) : global app app = QtGui . QApplication . instance ( ) if app is None : app = QtGui . QApplication ( [] , QtGui . QApplication . GuiClient ) return app": 2534,
 "def column_names ( self , table ) : table_info = self . execute ( u ' PRAGMA table_info ( %s ) ' % quote ( table ) ) return ( column[ ' name ' ] for column in table_info ) ": 2535,
 "def get_iter_string_reader ( stdin ) : bufsize = 1024 iter_str = ( stdin[i : i + bufsize] for i in range ( 0 , len ( stdin ) , bufsize ) ) return get_iter_chunk_reader ( iter_str ) ": 2536,
 "def __str__ ( self ) : if not hasattr ( self , ' _str ' ) : self . _str = self . function ( *self . args , **self . kwargs ) return self . _str": 2537,
 "def to_string ( s , encoding = ' utf-8 ' ) : if six . PY2 : return s . encode ( encoding ) if isinstance ( s , bytes ) : return s . decode ( encoding ) return s": 2538,
 "def get_tweepy_auth ( twitter_api_key , twitter_api_secret , twitter_access_token , twitter_access_token_secret ) : auth = tweepy . OAuthHandler ( twitter_api_key , twitter_api_secret ) auth . set_access_token ( twitter_access_token , twitter_access_token_secret ) return auth": 2539,
 "def urlencoded ( body , charset = ' ascii ' , **kwargs ) : return parse_query_string ( text ( body , charset = charset ) , False ) ": 2540,
 "def aloha_to_html ( html_source ) : xml = aloha_to_etree ( html_source ) return etree . tostring ( xml , pretty_print = True ) ": 2541,
 "def exit ( self ) : if self . confirm_exit : if self . ask_yes_no ( ' Do you really want to exit ( [y]/n ) ? ' , ' y ' ) : self . ask_exit ( ) else : self . ask_exit ( ) ": 2542,
 "def __del__ ( self ) : if self . _cleanup_session : self . _session . loop . run_until_complete ( self . _session . close ( ) ) ": 2543,
 "def get_just_date ( self ) : return datetime . datetime ( self . date_time . year , self . date_time . month , self . date_time . day ) ": 2544,
 "def __getitem__ ( self , key ) : return self . from_rdd ( self . _rdd . map ( lambda x : x[key] ) ) ": 2545,
 "def load_file_to_base64_str ( f_path ) : path = abs_path ( f_path ) with io . open ( path , ' rb ' ) as f : f_bytes = f . read ( ) base64_str = base64 . b64encode ( f_bytes ) . decode ( \" utf-8 \" ) return base64_str": 2546,
 "def url_to_image ( url , flag = cv2 . IMREAD_COLOR ) : resp = urlopen ( url ) image = np . asarray ( bytearray ( resp . read ( ) ) , dtype = \" uint8 \" ) image = cv2 . imdecode ( image , flag ) return image": 2547,
 "def visible_area ( self ) : # looks like zeach has a nice big screen half_viewport = Vec ( 1920 , 1080 ) / 2 / self . scale top_left = self . world . center - half_viewport bottom_right = self . world . center + half_viewport return top_left , bottom_right": 2548,
 "def read_numpy ( fd , byte_order , dtype , count ) : return numpy . fromfile ( fd , byte_order+dtype[-1] , count ) ": 2549,
 "def fit_gaussian ( x , y , yerr , p0 ) : try : popt , pcov = curve_fit ( gaussian , x , y , sigma = yerr , p0 = p0 , absolute_sigma = True ) except RuntimeError : return [0] , [0] return popt , pcov": 2550,
 "def resize_image_with_crop_or_pad ( img , target_height , target_width ) : h , w = target_height , target_width max_h , max_w , c = img . shape # crop img = crop_center ( img , min ( max_h , h ) , min ( max_w , w ) ) # pad padded_img = np . zeros ( shape = ( h , w , c ) , dtype = img . dtype ) padded_img[ : img . shape[0] , : img . shape[1] , : img . shape[2]] = img return padded_img": 2551,
 "def load_from_file ( cls , file_path : str ) : with open ( file_path , \" r \" ) as f : data = json . load ( f ) item = cls . decode ( data = data ) return item": 2552,
 "def __call__ ( self , img ) : return F . pad ( img , self . padding , self . fill , self . padding_mode ) ": 2553,
 "def rAsciiLine ( ifile ) : _line = ifile . readline ( ) . strip ( ) while len ( _line ) = = 0 : _line = ifile . readline ( ) . strip ( ) return _line": 2554,
 "def filter_query ( s ) : matches = re . findall ( r ' ( ? : \" ( [^ \" ]* ) \" ) | ( [^ \" ]* ) ' , s ) result_quoted = [t[0] . strip ( ) for t in matches if t[0]] result_unquoted = [t[1] . strip ( ) for t in matches if t[1]] return result_quoted , result_unquoted": 2555,
 "def eof ( fd ) : b = fd . read ( 1 ) end = len ( b ) = = 0 if not end : curpos = fd . tell ( ) fd . seek ( curpos - 1 ) return end": 2556,
 "def read_large_int ( self , bits , signed = True ) : return int . from_bytes ( self . read ( bits // 8 ) , byteorder = ' little ' , signed = signed ) ": 2557,
 "def get_starting_chunk ( filename , length = 1024 ) : # Ensure we open the file in binary mode with open ( filename , ' rb ' ) as f : chunk = f . read ( length ) return chunk": 2558,
 "def standard_input ( ) : with click . get_text_stream ( \" stdin \" ) as stdin : while stdin . readable ( ) : line = stdin . readline ( ) if line : yield line . strip ( ) . encode ( \" utf-8 \" ) ": 2559,
 "def cor ( y_true , y_pred ) : y_true , y_pred = _mask_nan ( y_true , y_pred ) return np . corrcoef ( y_true , y_pred ) [0 , 1]": 2560,
 "def log_magnitude_spectrum ( frames ) : return N . log ( N . abs ( N . fft . rfft ( frames ) ) . clip ( 1e-5 , N . inf ) ) ": 2561,
 "def multi_pop ( d , *args ) : retval = {} for key in args : if key in d : retval[key] = d . pop ( key ) return retval": 2562,
 "def _ReturnConnection ( self ) : \t\t\t\tif self . conn is not None : \t\t\tif self . connInfo . commitOnEnd is True or self . commitOnEnd is True : \t\t\t\tself . conn . Commit ( ) \t\t\t\t\t\t\t\tPool ( ) . returnConnection ( self . conn ) \t\t\tself . conn = None": 2563,
 "def from_url ( url , db = None , **kwargs ) : from redis . client import Redis return Redis . from_url ( url , db , **kwargs ) ": 2564,
 "def parse_prefix ( identifier ) : pf , id = ( ) , identifier if \" | \" in identifier : pf , id = tuple ( identifier . split ( ' | ' ) [ : -1] ) , identifier . split ( ' | ' ) [-1] return pf , id": 2565,
 "def ordered_yaml_dump ( data , stream = None , Dumper = None , **kwds ) : Dumper = Dumper or yaml . Dumper class OrderedDumper ( Dumper ) : pass def _dict_representer ( dumper , data ) : return dumper . represent_mapping ( yaml . resolver . BaseResolver . DEFAULT_MAPPING_TAG , data . items ( ) ) OrderedDumper . add_representer ( OrderedDict , _dict_representer ) return yaml . dump ( data , stream , OrderedDumper , **kwds ) ": 2566,
 "def to_dict ( self ) : return { ' schema ' : self . schema , ' name ' : self . name , ' columns ' : [col . to_dict ( ) for col in self . _columns] , ' foreign_keys ' : self . foreign_keys . to_dict ( ) , ' ref_keys ' : self . ref_keys . to_dict ( ) }": 2567,
 "def replace_print ( fileobj = sys . stderr ) : printer = _Printer ( fileobj ) previous_stdout = sys . stdout sys . stdout = printer try : yield printer finally : sys . stdout = previous_stdout": 2568,
 "def _delete_keys ( dct , keys ) : c = deepcopy ( dct ) assert isinstance ( keys , list ) for k in keys : c . pop ( k ) return c": 2569,
 "def var_dump ( *obs ) : \t\ti = 0\tfor x in obs : \t\t\t\tstr = var_dump_output ( x , 0 , ' ' , ' \\n ' , True ) \t\tprint ( str . strip ( ) ) \t\t\t\t # dump ( x , 0 , i , ' ' , object ) \t\ti + = 1": 2570,
 "def camelcase_underscore ( name ) : s1 = re . sub ( ' ( . ) ( [A-Z][a-z]+ ) ' , r ' \\1_\\2 ' , name ) return re . sub ( ' ( [a-z0-9] ) ( [A-Z] ) ' , r ' \\1_\\2 ' , s1 ) . lower ( ) ": 2571,
 "def first ( series , order_by = None ) : if order_by is not None : series = order_series_by ( series , order_by ) first_s = series . iloc[0] return first_s": 2572,
 "def clean ( self , text ) : return ' ' . join ( [c for c in text if c in self . alphabet] ) ": 2573,
 "def __normalize_list ( self , msg ) : if isinstance ( msg , list ) : msg = \" \" . join ( msg ) return list ( map ( lambda x : x . strip ( ) , msg . split ( \" , \" ) ) ) ": 2574,
 "def Print ( x , data , message , **kwargs ) : # pylint : disable = invalid-name return PrintOperation ( x , data , message , **kwargs ) . outputs[0]": 2575,
 "def clean_py_files ( path ) : for dirname , subdirlist , filelist in os . walk ( path ) : for f in filelist : if f . endswith ( ' py ' ) : os . remove ( os . path . join ( dirname , f ) ) ": 2576,
 "def clean_whitespace ( statement ) : import re # Replace linebreaks and tabs with spaces statement . text = statement . text . replace ( ' \\n ' , ' ' ) . replace ( ' \\r ' , ' ' ) . replace ( ' \\t ' , ' ' ) # Remove any leeding or trailing whitespace statement . text = statement . text . strip ( ) # Remove consecutive spaces statement . text = re . sub ( ' + ' , ' ' , statement . text ) return statement": 2577,
 "def _to_base_type ( self , msg ) : ent = _message_to_entity ( msg , self . _modelclass ) ent . blob_ = self . _protocol_impl . encode_message ( msg ) return ent": 2578,
 "def py3round ( number ) : if abs ( round ( number ) - number ) = = 0 . 5 : return int ( 2 . 0 * round ( number / 2 . 0 ) ) return int ( round ( number ) ) ": 2579,
 "def strip_xml_namespace ( root ) : try : root . tag = root . tag . split ( ' } ' ) [1] except IndexError : pass for element in root . getchildren ( ) : strip_xml_namespace ( element ) ": 2580,
 "def clean ( s ) : lines = [l . rstrip ( ) for l in s . split ( ' \\n ' ) ] return ' \\n ' . join ( lines ) ": 2581,
 "def time_func ( func , name , *args , **kwargs ) : tic = time . time ( ) out = func ( *args , **kwargs ) toc = time . time ( ) print ( ' %s took %0 . 2f seconds ' % ( name , toc - tic ) ) return out": 2582,
 "def get_unique_indices ( df , axis = 1 ) : return dict ( zip ( df . columns . names , dif . columns . levels ) ) ": 2583,
 "def validate_string ( option , value ) : if isinstance ( value , string_type ) : return value raise TypeError ( \" Wrong type for %s , value must be \" \" an instance of %s \" % ( option , string_type . __name__ ) ) ": 2584,
 "def __init__ ( self , master = None , compound = tk . RIGHT , autohidescrollbar = True , **kwargs ) : ttk . Frame . __init__ ( self , master ) self . columnconfigure ( 1 , weight = 1 ) self . rowconfigure ( 0 , weight = 1 ) self . listbox = tk . Listbox ( self , **kwargs ) if autohidescrollbar : self . scrollbar = AutoHideScrollbar ( self , orient = tk . VERTICAL , command = self . listbox . yview ) else : self . scrollbar = ttk . Scrollbar ( self , orient = tk . VERTICAL , command = self . listbox . yview ) self . config_listbox ( yscrollcommand = self . scrollbar . set ) if compound is not tk . LEFT and compound is not tk . RIGHT : raise ValueError ( \" Invalid compound value passed : {0} \" . format ( compound ) ) self . __compound = compound self . _grid_widgets ( ) ": 2585,
 "def pop_all ( self ) : with self . lock : output = list ( self . queue ) self . queue . clear ( ) return output": 2586,
 "def join ( mapping , bind , values ) : return [ ' ' . join ( [six . text_type ( v ) for v in values if v is not None] ) ]": 2587,
 "def _replace_docstring_header ( paragraph ) : # Replace Markdown headers in docstrings with light headers in bold . paragraph = re . sub ( _docstring_header_pattern , r ' *\\1* ' , paragraph , ) paragraph = re . sub ( _docstring_parameters_pattern , r ' \\n* `\\1` ( \\2 ) \\n ' , paragraph , ) return paragraph": 2588,
 "def raise_ ( exception = ABSENT , *args , **kwargs ) : if exception is ABSENT : raise else : if inspect . isclass ( exception ) : raise exception ( *args , **kwargs ) else : if args or kwargs : raise TypeError ( \" can ' t pass arguments along with \" \" exception object to raise_ ( ) \" ) raise exception": 2589,
 "def from_traceback ( cls , tb ) : while tb . tb_next : tb = tb . tb_next return cls ( tb . tb_frame . f_code , current_offset = tb . tb_lasti ) ": 2590,
 "def camel_to_underscore ( string ) : string = FIRST_CAP_RE . sub ( r ' \\1_\\2 ' , string ) return ALL_CAP_RE . sub ( r ' \\1_\\2 ' , string ) . lower ( ) ": 2591,
 "def _scale_shape ( dshape , scale = ( 1 , 1 , 1 ) ) : nshape = np . round ( np . array ( dshape ) * np . array ( scale ) ) return tuple ( nshape . astype ( np . int ) ) ": 2592,
 "def get_value ( key , obj , default = missing ) : if isinstance ( key , int ) : return _get_value_for_key ( key , obj , default ) return _get_value_for_keys ( key . split ( ' . ' ) , obj , default ) ": 2593,
 "def get_package_info ( package ) : url = ' https : //pypi . python . org/pypi/{}/json ' . format ( package ) r = requests . get ( url ) r . raise_for_status ( ) return r . json ( ) ": 2594,
 "def _add ( self , codeobj ) : assert isinstance ( codeobj , CodeVariable ) self . variables . append ( codeobj ) ": 2595,
 "def make_key ( observer ) : if hasattr ( observer , \" __self__ \" ) : inst = observer . __self__ method_name = observer . __name__ key = ( id ( inst ) , method_name ) else : key = id ( observer ) return key": 2596,
 "def get_attr ( self , method_name ) : return self . attrs . get ( method_name ) or self . get_callable_attr ( method_name ) ": 2597,
 "def _shape ( self ) : return tuple ( reversed ( self . output_dims ( ) ) ) + tuple ( reversed ( self . input_dims ( ) ) ) ": 2598,
 "def set_json_item ( key , value ) : data = get_json ( ) data[key] = value request = get_request ( ) request[ \" BODY \" ] = json . dumps ( data ) ": 2599,
 "def sub ( name , func , **kwarg ) : sp = subparsers . add_parser ( name , **kwarg ) sp . set_defaults ( func = func ) sp . arg = sp . add_argument return sp": 2600,
 "def add_text_to_image ( fname , txt , opFilename ) : ft = ImageFont . load ( \" T : //user//dev//src//python//_AS_LIB//timR24 . pil \" ) # wh = ft . getsize ( txt ) print ( \" Adding text \" , txt , \" to \" , fname , \" pixels wide to file \" , opFilename ) im = Image . open ( fname ) draw = ImageDraw . Draw ( im ) draw . text ( ( 0 , 0 ) , txt , fill = ( 0 , 0 , 0 ) , font = ft ) del draw im . save ( opFilename ) ": 2601,
 "def similarity_transformation ( rot , mat ) : return np . dot ( rot , np . dot ( mat , np . linalg . inv ( rot ) ) ) ": 2602,
 "def _iter_response ( self , url , params = None ) : if params is None : params = {} params[ ' page_number ' ] = 1 # Last page lists itself as next page while True : response = self . _request ( url , params ) for item in response[ ' result_data ' ] : yield item # Last page lists itself as next page if response[ ' service_meta ' ][ ' next_page_number ' ] = = params[ ' page_number ' ] : break params[ ' page_number ' ] + = 1": 2603,
 "def round_figures ( x , n ) : return round ( x , int ( n - math . ceil ( math . log10 ( abs ( x ) ) ) ) ) ": 2604,
 "def fetch_token ( self , **kwargs ) : return super ( AsanaOAuth2Session , self ) . fetch_token ( self . token_url , client_secret = self . client_secret , **kwargs ) ": 2605,
 "def _handle_shell ( self , cfg_file , *args , **options ) : args = ( \" --interactive \" , ) + args return supervisorctl . main ( ( \" -c \" , cfg_file ) + args ) ": 2606,
 "def interpolate ( table , field , fmt , **kwargs ) : conv = lambda v : fmt % v return convert ( table , field , conv , **kwargs ) ": 2607,
 "def to_lisp ( o , keywordize_keys : bool = True ) : if not isinstance ( o , ( dict , frozenset , list , set , tuple ) ) : return o else : # pragma : no cover return _to_lisp_backup ( o , keywordize_keys = keywordize_keys ) ": 2608,
 "def rotateImage ( img , angle ) : imgR = scipy . ndimage . rotate ( img , angle , reshape = False ) return imgR": 2609,
 "def make_table_map ( table , headers ) : header_parts = {} for i , h in enumerate ( headers ) : header_parts[h] = ' row[{}] ' . format ( i ) body_code = ' lambda row : [{}] ' . format ( ' , ' . join ( header_parts . get ( c . name , ' None ' ) for c in table . columns ) ) header_code = ' lambda row : [{}] ' . format ( ' , ' . join ( header_parts . get ( c . name , \" ' {} ' \" . format ( c . name ) ) for c in table . columns ) ) return eval ( header_code ) , eval ( body_code ) ": 2610,
 "def print_statements ( self ) : for i , stmt in enumerate ( self . statements ) : print ( \" %s : %s \" % ( i , stmt ) ) ": 2611,
 "def download_file ( bucket_name , path , target , sagemaker_session ) : path = path . lstrip ( ' / ' ) boto_session = sagemaker_session . boto_session s3 = boto_session . resource ( ' s3 ' ) bucket = s3 . Bucket ( bucket_name ) bucket . download_file ( path , target ) ": 2612,
 "def set_subparsers_args ( self , *args , **kwargs ) : self . subparsers_args = args self . subparsers_kwargs = kwargs": 2613,
 "def save_keras_definition ( keras_model , path ) : model_json = keras_model . to_json ( ) with open ( path , \" w \" ) as json_file : json_file . write ( model_json ) ": 2614,
 "def add_arguments ( parser ) : parser . add_argument ( ' -o ' , ' --old-environment ' , help = ' Old environment name ' , required = True ) parser . add_argument ( ' -n ' , ' --new-environment ' , help = ' New environment name ' , required = True ) ": 2615,
 "def adapt_array ( arr ) : out = io . BytesIO ( ) np . save ( out , arr ) , out . seek ( 0 ) return buffer ( out . read ( ) ) ": 2616,
 "def ensure_iterable ( inst ) : if isinstance ( inst , string_types ) : return [inst] elif not isinstance ( inst , collections . Iterable ) : return [inst] else : return inst": 2617,
 "def write ( url , content , **args ) : with FTPSResource ( url , **args ) as resource : resource . write ( content ) ": 2618,
 "def dump_nparray ( self , obj , class_name = numpy_ndarray_class_name ) : return { \" $ \" + class_name : self . _json_convert ( obj . tolist ( ) ) }": 2619,
 "def get_seconds_until_next_day ( now = None ) : if now is None : now = arrow . utcnow ( ) return ( now . ceil ( ' day ' ) - now ) . seconds": 2620,
 "def expect_all ( a , b ) : assert all ( _a = = _b for _a , _b in zip_longest ( a , b ) ) ": 2621,
 "async def repeat ( ctx , times : int , content = ' repeating . . . ' ) : for i in range ( times ) : await ctx . send ( content ) ": 2622,
 "async def wait_and_quit ( loop ) : \t\tfrom pylp . lib . tasks import running\tif running : \t\tawait asyncio . wait ( map ( lambda runner : runner . future , running ) ) ": 2623,
 "def generate_split_tsv_lines ( fn , header ) : for line in generate_tsv_psms_line ( fn ) : yield {x : y for ( x , y ) in zip ( header , line . strip ( ) . split ( ' \\t ' ) ) }": 2624,
 "def add_form_widget_attr ( field , attr_name , attr_value , replace = 0 ) : if not replace : attr = field . field . widget . attrs . get ( attr_name , ' ' ) attr + = force_text ( attr_value ) field . field . widget . attrs[attr_name] = attr return field else : field . field . widget . attrs[attr_name] = attr_value return field": 2625,
 "def add ( self , value ) : if value not in self . _set : self . _set . add ( value ) self . _list . add ( value ) ": 2626,
 "def filter_symlog ( y , base = 10 . 0 ) : log_base = np . log ( base ) sign = np . sign ( y ) logs = np . log ( np . abs ( y ) / log_base ) return sign * logs": 2627,
 "def __init__ ( self , interval , key ) : self . interval = interval self . key = key": 2628,
 "def setwinsize ( self , rows , cols ) : self . _winsize = ( rows , cols ) self . pty . set_size ( cols , rows ) ": 2629,
 "def delete ( gandi , resource ) : result = gandi . dnssec . delete ( resource ) gandi . echo ( ' Delete successful . ' ) return result": 2630,
 "def create_aws_lambda ( ctx , bucket , region_name , aws_access_key_id , aws_secret_access_key ) : from canari . commands . create_aws_lambda import create_aws_lambda create_aws_lambda ( ctx . project , bucket , region_name , aws_access_key_id , aws_secret_access_key ) ": 2631,
 "def confusion_matrix ( self ) : return plot . confusion_matrix ( self . y_true , self . y_pred , self . target_names , ax = _gen_ax ( ) ) ": 2632,
 "def s2b ( s ) : ret = [] for c in s : ret . append ( bin ( ord ( c ) ) [2 : ] . zfill ( 8 ) ) return \" \" . join ( ret ) ": 2633,
 "def show_approx ( self , numfmt = ' % . 3g ' ) : return ' , ' . join ( [ ( ' %s : ' + numfmt ) % ( v , p ) for ( v , p ) in sorted ( self . prob . items ( ) ) ] ) ": 2634,
 "def _transform_triple_numpy ( x ) : return np . array ( [x . head , x . relation , x . tail] , dtype = np . int64 ) ": 2635,
 "def text ( el , strip = True ) : if not el : return \" \" text = el . text if strip : text = text . strip ( ) return text": 2636,
 "def get_boto_session ( region , aws_access_key_id = None , aws_secret_access_key = None , aws_session_token = None ) : return boto3 . session . Session ( region_name = region , aws_secret_access_key = aws_secret_access_key , aws_access_key_id = aws_access_key_id , aws_session_token = aws_session_token ) ": 2637,
 "def ibatch ( iterable , size ) : source = iter ( iterable ) while True : batch = itertools . islice ( source , size ) yield itertools . chain ( [next ( batch ) ] , batch ) ": 2638,
 "def disable_cert_validation ( ) : current_context = ssl . _create_default_https_context ssl . _create_default_https_context = ssl . _create_unverified_context try : yield finally : ssl . _create_default_https_context = current_context": 2639,
 "def get_cache ( self , decorated_function , *args , **kwargs ) : \t\t\t\thas_value = self . has ( decorated_function , *args , **kwargs ) \t\tcached_value = None\t\tif has_value is True : \t\t\tcached_value = self . get_result ( decorated_function , *args , **kwargs ) \t\treturn WCacheStorage . CacheEntry ( has_value = has_value , cached_value = cached_value ) ": 2640,
 "def unsort_vector ( data , indices_of_increasing ) : return numpy . array ( [data[indices_of_increasing . index ( i ) ] for i in range ( len ( data ) ) ] ) ": 2641,
 "def swap_priority ( self , key1 , key2 ) : heap = self . _heap position = self . _position if key1 not in self or key2 not in self : raise KeyError pos1 , pos2 = position[key1] , position[key2] heap[pos1] . key , heap[pos2] . key = key2 , key1 position[key1] , position[key2] = pos2 , pos1": 2642,
 "def recursively_get_files_from_directory ( directory ) : return [ os . path . join ( root , filename ) for root , directories , filenames in os . walk ( directory ) for filename in filenames ]": 2643,
 "def _set_module_names_for_sphinx ( modules : List , new_name : str ) : for obj in modules : obj . __module__ = new_name": 2644,
 "def _depr ( fn , usage , stacklevel = 3 ) : warn ( ' {0} is deprecated . Use {1} instead ' . format ( fn , usage ) , stacklevel = stacklevel , category = DeprecationWarning ) ": 2645,
 "def _run_once ( self ) : try : self . do_wait ( ) self . _execute_wakeup_tasks ( ) self . _trigger_timers ( ) except Exception as e : Log . error ( \" Error occured during _run_once ( ) : \" + str ( e ) ) Log . error ( traceback . format_exc ( ) ) self . should_exit = True": 2646,
 "def from_pydatetime ( cls , pydatetime ) : return cls ( date = Date . from_pydate ( pydatetime . date ) , time = Time . from_pytime ( pydatetime . time ) ) ": 2647,
 "def set_scrollregion ( self , event = None ) : self . canvas . configure ( scrollregion = self . canvas . bbox ( ' all ' ) ) ": 2648,
 "def is_alive ( self ) : response = self . get_monitoring_heartbeat ( ) if response . status_code = = 200 and response . content = = ' alive ' : return True return False": 2649,
 "def _subclassed ( base , *classes ) : return all ( map ( lambda obj : isinstance ( obj , base ) , classes ) ) ": 2650,
 "def _opt_call_from_base_type ( self , value ) : if isinstance ( value , _BaseValue ) : value = self . _call_from_base_type ( value . b_val ) return value": 2651,
 "def _port_not_in_use ( ) : s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) port = 0 s . bind ( ( ' ' , port ) ) _ , port = s . getsockname ( ) return port": 2652,
 "def copy ( a ) : shared = anonymousmemmap ( a . shape , dtype = a . dtype ) shared[ : ] = a[ : ] return shared": 2653,
 "def load ( self , name ) : name = ctypes . util . find_library ( name ) return ctypes . cdll . LoadLibrary ( name ) ": 2654,
 "def _maybe_to_categorical ( array ) : if isinstance ( array , ( ABCSeries , ABCCategoricalIndex ) ) : return array . _values elif isinstance ( array , np . ndarray ) : return Categorical ( array ) return array": 2655,
 "def circstd ( dts , axis = 2 ) : R = np . abs ( np . exp ( 1 . 0j * dts ) . mean ( axis = axis ) ) return np . sqrt ( -2 . 0 * np . log ( R ) ) ": 2656,
 "def save_config_value ( request , response , key , value ) : request . session[key] = value response . set_cookie ( key , value , expires = one_year_from_now ( ) ) return response": 2657,
 "def set_label ( self , object , label ) : label_name = self . label if label_name[ : 1] ! = ' = ' : xsetattr ( object , label_name , label ) ": 2658,
 "def add_exec_permission_to ( target_file ) : mode = os . stat ( target_file ) . st_mode os . chmod ( target_file , mode | stat . S_IXUSR ) ": 2659,
 "def _is_subsequence_of ( self , sub , sup ) : return bool ( re . search ( \" . * \" . join ( sub ) , sup ) ) ": 2660,
 "def AmericanDateToEpoch ( self , date_str ) : try : epoch = time . strptime ( date_str , \" %m/%d/%Y \" ) return int ( calendar . timegm ( epoch ) ) * 1000000 except ValueError : return 0": 2661,
 "def _is_valid_api_url ( self , url ) : # Check response is a JSON with ok : 1 data = {} try : r = requests . get ( url , proxies = self . proxy_servers ) content = to_text_string ( r . content , encoding = ' utf-8 ' ) data = json . loads ( content ) except Exception as error : logger . error ( str ( error ) ) return data . get ( ' ok ' , 0 ) = = 1": 2662,
 "def cudaMalloc ( count , ctype = None ) : ptr = ctypes . c_void_p ( ) status = _libcudart . cudaMalloc ( ctypes . byref ( ptr ) , count ) cudaCheckStatus ( status ) if ctype ! = None : ptr = ctypes . cast ( ptr , ctypes . POINTER ( ctype ) ) return ptr": 2663,
 "def convert_time_string ( date_str ) : dt , _ , _ = date_str . partition ( \" . \" ) dt = datetime . strptime ( dt , \" %Y-%m-%dT%H : %M : %S \" ) return dt": 2664,
 "def Sum ( a , axis , keep_dims ) : return np . sum ( a , axis = axis if not isinstance ( axis , np . ndarray ) else tuple ( axis ) , keepdims = keep_dims ) , ": 2665,
 "def is_git_repo ( ) : cmd = \" git \" , \" rev-parse \" , \" --git-dir \" try : subprocess . run ( cmd , stdout = subprocess . DEVNULL , check = True ) return True except subprocess . CalledProcessError : return False": 2666,
 "def is_archlinux ( ) : if platform . system ( ) . lower ( ) = = ' linux ' : if platform . linux_distribution ( ) = = ( ' ' , ' ' , ' ' ) : # undefined distribution . Fixed in python 3 . if os . path . exists ( ' /etc/arch-release ' ) : return True return False": 2667,
 "def lazy_reverse_binmap ( f , xs ) : return ( f ( y , x ) for x , y in zip ( xs , xs[1 : ] ) ) ": 2668,
 "def isin ( self , column , compare_list ) : return [x in compare_list for x in self . _data[self . _columns . index ( column ) ]]": 2669,
 "def jsonify ( symbol ) : try : # all symbols have a toJson method , try it return json . dumps ( symbol . toJson ( ) , indent = ' ' ) except AttributeError : pass return json . dumps ( symbol , indent = ' ' ) ": 2670,
 "def table_width ( self ) : outer_widths = max_dimensions ( self . table_data , self . padding_left , self . padding_right ) [2] outer_border = 2 if self . outer_border else 0 inner_border = 1 if self . inner_column_border else 0 return table_width ( outer_widths , outer_border , inner_border ) ": 2671,
 "def save_as_png ( self , filename , width = 300 , height = 250 , render_time = 1 ) : self . driver . set_window_size ( width , height ) self . driver . get ( ' file : //{path}/{filename} ' . format ( path = os . getcwd ( ) , filename = filename + \" . html \" ) ) time . sleep ( render_time ) self . driver . save_screenshot ( filename + \" . png \" ) ": 2672,
 "def is_all_field_none ( self ) : if self . _type_ is not None : return False if self . _value is not None : return False if self . _name is not None : return False return True": 2673,
 "def _get_line_no_from_comments ( py_line ) : matched = LINECOL_COMMENT_RE . match ( py_line ) if matched : return int ( matched . group ( 1 ) ) else : return 0": 2674,
 "def is_integer_array ( val ) : return is_np_array ( val ) and issubclass ( val . dtype . type , np . integer ) ": 2675,
 "def can_route ( self , endpoint , method = None , **kwargs ) : view = flask . current_app . view_functions . get ( endpoint ) if not view : endpoint , args = flask . _request_ctx . top . match ( endpoint ) view = flask . current_app . view_functions . get ( endpoint ) if not view : return False return self . can ( ' http . ' + ( method or ' GET ' ) . lower ( ) , view , **kwargs ) ": 2676,
 "def best ( self ) : b = ( -1e999999 , None ) for k , c in iteritems ( self . counts ) : b = max ( b , ( c , k ) ) return b[1]": 2677,
 "def test_value ( self , value ) : if not isinstance ( value , float ) : raise ValueError ( ' expected float value : ' + str ( type ( value ) ) ) ": 2678,
 "def _column_resized ( self , col , old_width , new_width ) : self . dataTable . setColumnWidth ( col , new_width ) self . _update_layout ( ) ": 2679,
 "def from_df ( data_frame ) : labels = data_frame . keys ( ) . tolist ( ) data = data_frame . values . tolist ( ) return SqlTable ( labels , data , \" { : . 3f} \" , \" \\n \" ) ": 2680,
 "def transpose ( table ) : t = [] for i in range ( 0 , len ( table[0] ) ) : t . append ( [row[i] for row in table] ) return t": 2681,
 "def truncate ( self , table ) : if isinstance ( table , ( list , set , tuple ) ) : for t in table : self . _truncate ( t ) else : self . _truncate ( table ) ": 2682,
 "def rsa_eq ( key1 , key2 ) : pn1 = key1 . public_numbers ( ) pn2 = key2 . public_numbers ( ) # Check if two RSA keys are in fact the same if pn1 = = pn2 : return True else : return False": 2683,
 "def dispatch ( self , request , *args , **kwargs ) : self . request = DownstreamRequest ( request ) self . args = args self . kwargs = kwargs self . _verify_config ( ) self . middleware = MiddlewareSet ( self . proxy_middleware ) return self . proxy ( ) ": 2684,
 "def str_dict ( some_dict ) : return {str ( k ) : str ( v ) for k , v in some_dict . items ( ) }": 2685,
 "def to_list ( self ) : return [[int ( self . table . cell_values[0][1] ) , int ( self . table . cell_values[0][2] ) ] , [int ( self . table . cell_values[1][1] ) , int ( self . table . cell_values[1][2] ) ]]": 2686,
 "def stop_capture ( self ) : super ( Treal , self ) . stop_capture ( ) if self . _machine : self . _machine . close ( ) self . _stopped ( ) ": 2687,
 "def _tableExists ( self , tableName ) : cursor = _conn . execute ( . format ( tableName ) ) exists = cursor . fetchone ( ) is not None cursor . close ( ) return exists": 2688,
 "def search_for_tweets_about ( user_id , params ) : url = \" https : //api . twitter . com/1 . 1/search/tweets . json \" response = make_twitter_request ( url , user_id , params ) return process_tweets ( response . json ( ) [ \" statuses \" ] ) ": 2689,
 "def chmod_plus_w ( path ) : path_mode = os . stat ( path ) . st_mode path_mode & = int ( ' 777 ' , 8 ) path_mode | = stat . S_IWRITE os . chmod ( path , path_mode ) ": 2690,
 "def multipart_parse_json ( api_url , data ) : headers = { ' Content-Type ' : ' application/x-www-form-urlencoded ' } response_text = requests . post ( api_url , data = data , headers = headers ) \\ . text . encode ( ' ascii ' , errors = ' replace ' ) return json . loads ( response_text . decode ( ) ) ": 2691,
 "def finished ( self ) : self . progress_bar . set_state ( ProgressBar . STATE_DONE ) self . progress_bar . show ( ) ": 2692,
 "def shutdown ( ) : global handler , transport , protocol if handler is not None : handler . close ( ) transport . close ( ) handler = None transport = None protocol = None": 2693,
 "def __cmp__ ( self , other ) : # Stops python 2 from allowing comparsion of arbitrary objects raise TypeError ( ' unorderable types : {} , {} ' ' ' . format ( self . __class__ . __name__ , type ( other ) ) ) ": 2694,
 "def parse ( self , data , mimetype ) : encoding = mimetype . params . get ( ' charset ' ) or ' utf-8 ' return json . loads ( data . decode ( encoding ) ) ": 2695,
 "def install_from_zip ( url ) : fname = ' tmp . zip ' downlad_file ( url , fname ) unzip_file ( fname ) print ( \" Removing {} \" . format ( fname ) ) os . unlink ( fname ) ": 2696,
 "def get_conn ( self ) : conn = self . get_connection ( self . cloudant_conn_id ) self . _validate_connection ( conn ) cloudant_session = cloudant ( user = conn . login , passwd = conn . password , account = conn . host ) return cloudant_session": 2697,
 "def push ( self , el ) : count = next ( self . counter ) heapq . heappush ( self . _queue , ( el , count ) ) ": 2698,
 "def update_target ( self , name , current , total ) : self . refresh ( self . _bar ( name , current , total ) ) ": 2699,
 "def get_input ( input_func , input_str ) : val = input_func ( \" Please enter your {0} : \" . format ( input_str ) ) while not val or not len ( val . strip ( ) ) : val = input_func ( \" You didn ' t enter a valid {0} , please try again : \" . format ( input_str ) ) return val": 2700,
 "def print_display_png ( o ) : s = latex ( o , mode = ' plain ' ) s = s . strip ( ' $ ' ) # As matplotlib does not support display style , dvipng backend is # used here . png = latex_to_png ( ' $$%s$$ ' % s , backend = ' dvipng ' ) return png": 2701,
 "def dist ( x1 , x2 , axis = 0 ) : return np . linalg . norm ( x2 - x1 , axis = axis ) ": 2702,
 "def get_indentation ( func ) : src_lines = getsourcelines ( func ) [0] for line in src_lines : if not ( line . startswith ( ' @ ' ) or line . startswith ( ' def ' ) or line . lstrip ( ) . startswith ( ' # ' ) ) : return line[ : len ( line ) - len ( line . lstrip ( ) ) ] return pytypes . default_indent": 2703,
 "def counter_from_str ( self , string ) : string_list = [chars for chars in string if chars not in self . punctuation] string_joined = ' ' . join ( string_list ) tokens = self . punkt . word_tokenize ( string_joined ) return Counter ( tokens ) ": 2704,
 "def _make_index ( df , cols = META_IDX ) : return pd . MultiIndex . from_tuples ( pd . unique ( list ( zip ( *[df[col] for col in cols] ) ) ) , names = tuple ( cols ) ) ": 2705,
 "def _try_compile ( source , name ) : try : c = compile ( source , name , ' eval ' ) except SyntaxError : c = compile ( source , name , ' exec ' ) return c": 2706,
 "def _sort_lambda ( sortedby = ' cpu_percent ' , sortedby_secondary = ' memory_percent ' ) : ret = None if sortedby = = ' io_counters ' : ret = _sort_io_counters elif sortedby = = ' cpu_times ' : ret = _sort_cpu_times return ret": 2707,
 "def items ( self , limit = 0 ) : i = ItemIterator ( self . iterator ) i . limit = limit return i": 2708,
 "def __init__ ( self , root_section = ' lago ' , defaults = {} ) : self . root_section = root_section self . _defaults = defaults self . _config = defaultdict ( dict ) self . _config . update ( self . load ( ) ) self . _parser = None": 2709,
 "def conv2d ( x_input , w_matrix ) : return tf . nn . conv2d ( x_input , w_matrix , strides = [1 , 1 , 1 , 1] , padding = ' SAME ' ) ": 2710,
 "def percent_d ( data , period ) : p_k = percent_k ( data , period ) percent_d = sma ( p_k , 3 ) return percent_d": 2711,
 "def line_segment ( X0 , X1 ) : r X0 = sp . around ( X0 ) . astype ( int ) X1 = sp . around ( X1 ) . astype ( int ) if len ( X0 ) = = 3 : L = sp . amax ( sp . absolute ( [[X1[0]-X0[0]] , [X1[1]-X0[1]] , [X1[2]-X0[2]]] ) ) + 1 x = sp . rint ( sp . linspace ( X0[0] , X1[0] , L ) ) . astype ( int ) y = sp . rint ( sp . linspace ( X0[1] , X1[1] , L ) ) . astype ( int ) z = sp . rint ( sp . linspace ( X0[2] , X1[2] , L ) ) . astype ( int ) return [x , y , z] else : L = sp . amax ( sp . absolute ( [[X1[0]-X0[0]] , [X1[1]-X0[1]]] ) ) + 1 x = sp . rint ( sp . linspace ( X0[0] , X1[0] , L ) ) . astype ( int ) y = sp . rint ( sp . linspace ( X0[1] , X1[1] , L ) ) . astype ( int ) return [x , y]": 2712,
 "def version ( self ) : url : str = get_url ( \" /service/version . json \" ) params = { \" service \" : \" remote \" } r = self . _request ( url = url , params = params ) return r . json ( ) ": 2713,
 "def multiply ( traj ) : z = traj . x*traj . y traj . f_add_result ( ' z ' , z = z , comment = ' I am the product of two reals! ' ) ": 2714,
 "def getOffset ( self , loc ) : return Location ( loc . x - self . x , loc . y - self . y ) ": 2715,
 "def unit_ball_L2 ( shape ) : x = tf . Variable ( tf . zeros ( shape ) ) return constrain_L2 ( x ) ": 2716,
 "def correlation ( df , rowvar = False ) : # Create a correlation matrix for all correlations # of the columns ( filled with na for all values ) df = df . copy ( ) maskv = np . ma . masked_where ( np . isnan ( df . values ) , df . values ) cdf = np . ma . corrcoef ( maskv , rowvar = False ) cdf = pd . DataFrame ( np . array ( cdf ) ) cdf . columns = df . columns cdf . index = df . columns cdf = cdf . sort_index ( level = 0 , axis = 1 ) cdf = cdf . sort_index ( level = 0 ) return cdf": 2717,
 "def assert_visible ( self , locator , msg = None ) : e = driver . find_elements_by_locator ( locator ) if len ( e ) = = 0 : raise AssertionError ( \" Element at %s was not found \" % locator ) assert e . is_displayed ( ) ": 2718,
 "def distance ( vec1 , vec2 ) : if isinstance ( vec1 , Vector2 ) \\ and isinstance ( vec2 , Vector2 ) : dist_vec = vec2 - vec1 return dist_vec . length ( ) else : raise TypeError ( \" vec1 and vec2 must be Vector2 ' s \" ) ": 2719,
 "def compute_gradient ( self ) : delta = self . predict ( self . X ) - self . y return delta . dot ( self . X ) / len ( self . X ) ": 2720,
 "def _get_indent_length ( line ) : result = 0 for char in line : if char = = \" \" : result + = 1 elif char = = \" \\t \" : result + = _TAB_LENGTH else : break return result": 2721,
 "def quit ( self ) : logger . debug ( \" ArgosApplication . quit called \" ) assert len ( self . mainWindows ) = = 0 , \\ \" Bug : still {} windows present at application quit! \" . format ( len ( self . mainWindows ) ) self . qApplication . quit ( ) ": 2722,
 "def state ( self ) : return { ' c ' : self . c , ' s0 ' : self . s0 , ' s1 ' : self . s1 , ' s2 ' : self . s2}": 2723,
 "def indent ( self ) : blk = IndentBlock ( self , self . _indent ) self . _indent + = 1 return blk": 2724,
 "def nlargest ( self , n = None ) : \t\t\t\tif n is None : \t\t\treturn sorted ( self . counts ( ) , key = itemgetter ( 1 ) , reverse = True ) \t\telse : \t\t\treturn heapq . nlargest ( n , self . counts ( ) , key = itemgetter ( 1 ) ) ": 2725,
 "def get_cov ( config ) : # Check with hasplugin to avoid getplugin exception in older pytest . if config . pluginmanager . hasplugin ( ' _cov ' ) : plugin = config . pluginmanager . getplugin ( ' _cov ' ) if plugin . cov_controller : return plugin . cov_controller . cov return None": 2726,
 "def setblocking ( fd , blocking ) : if not fcntl : warnings . warn ( ' setblocking ( ) not supported on Windows ' ) flags = fcntl . fcntl ( fd , fcntl . F_GETFL ) if blocking : flags | = os . O_NONBLOCK else : flags & = ~os . O_NONBLOCK fcntl . fcntl ( fd , fcntl . F_SETFL , flags ) ": 2727,
 "def process_kill ( pid , sig = None ) : sig = sig or signal . SIGTERM os . kill ( pid , sig ) ": 2728,
 "def get_readline_tail ( self , n = 10 ) : end = self . shell . readline . get_current_history_length ( ) + 1 start = max ( end-n , 1 ) ghi = self . shell . readline . get_history_item return [ghi ( x ) for x in range ( start , end ) ]": 2729,
 "def surface ( cls , predstr ) : lemma , pos , sense , _ = split_pred_string ( predstr ) return cls ( Pred . SURFACE , lemma , pos , sense , predstr ) ": 2730,
 "def set_icon ( self , bmp ) : _icon = wx . EmptyIcon ( ) _icon . CopyFromBitmap ( bmp ) self . SetIcon ( _icon ) ": 2731,
 "def _update_bordercolor ( self , bordercolor ) : border_color = wx . SystemSettings_GetColour ( wx . SYS_COLOUR_ACTIVEBORDER ) border_color . SetRGB ( bordercolor ) self . linecolor_choice . SetColour ( border_color ) ": 2732,
 "def connect ( *args , **kwargs ) : kwargs[ ' cursor_factory ' ] = TraceCursor conn = pg_connect ( *args , **kwargs ) return conn": 2733,
 "def get_screen_resolution ( self ) : widget = QDesktopWidget ( ) geometry = widget . availableGeometry ( widget . primaryScreen ( ) ) return geometry . width ( ) , geometry . height ( ) ": 2734,
 "def from_tuple ( tup ) : if len ( tup ) not in ( 2 , 3 ) : raise ValueError ( ' tuple must contain 2 or 3 elements , not : %d ( %r ' % ( len ( tup ) , tup , ) , ) return range ( *tup ) ": 2735,
 "def submit ( self , fn , *args , **kwargs ) : corofn = asyncio . coroutine ( lambda : fn ( *args , **kwargs ) ) return run_coroutine_threadsafe ( corofn ( ) , self . loop ) ": 2736,
 "def sample_correlations ( self ) : C = np . corrcoef ( self . X . T ) corr_matrix = ExpMatrix ( genes = self . samples , samples = self . samples , X = C ) return corr_matrix": 2737,
 "def clone_with_copy ( src_path , dest_path ) : log . info ( ' Cloning directory tree %s to %s ' , src_path , dest_path ) shutil . copytree ( src_path , dest_path ) ": 2738,
 "def heappop_max ( heap ) : lastelt = heap . pop ( ) # raises appropriate IndexError if heap is empty if heap : returnitem = heap[0] heap[0] = lastelt _siftup_max ( heap , 0 ) return returnitem return lastelt": 2739,
 "def coverage ( ) : run ( \" coverage run --source {PROJECT_NAME} -m py . test \" . format ( PROJECT_NAME = PROJECT_NAME ) ) run ( \" coverage report -m \" ) run ( \" coverage html \" ) webbrowser . open ( ' file : // ' + os . path . realpath ( \" htmlcov/index . html \" ) , new = 2 ) ": 2740,
 "def new_from_list ( cls , items , **kwargs ) : obj = cls ( **kwargs ) for item in items : obj . append ( ListItem ( item ) ) return obj": 2741,
 "def csvtolist ( inputstr ) : reader = csv . reader ( [inputstr] , skipinitialspace = True ) output = [] for r in reader : output + = r return output": 2742,
 "def putkeyword ( self , keyword , value , makesubrecord = False ) : return self . _table . putcolkeyword ( self . _column , keyword , value , makesubrecord ) ": 2743,
 "def format_op_hdr ( ) : txt = ' Base Filename ' . ljust ( 36 ) + ' ' txt + = ' Lines ' . rjust ( 7 ) + ' ' txt + = ' Words ' . rjust ( 7 ) + ' ' txt + = ' Unique ' . ljust ( 8 ) + ' ' return txt": 2744,
 "def format_arg ( value ) : translator = repr if isinstance ( value , six . string_types ) else six . text_type return translator ( value ) ": 2745,
 "def makedirs ( directory ) : parent = os . path . dirname ( os . path . abspath ( directory ) ) if not os . path . exists ( parent ) : makedirs ( parent ) os . mkdir ( directory ) ": 2746,
 "def create_db_schema ( cls , cur , schema_name ) : create_schema_script = \" CREATE SCHEMA {0} ;\\n \" . format ( schema_name ) cur . execute ( create_schema_script ) ": 2747,
 "def create_rot2d ( angle ) : ca = math . cos ( angle ) sa = math . sin ( angle ) return np . array ( [[ca , -sa] , [sa , ca]] ) ": 2748,
 "def sp_rand ( m , n , a ) : if m = = 0 or n = = 0 : return spmatrix ( [] , [] , [] , ( m , n ) ) nnz = min ( max ( 0 , int ( round ( a*m*n ) ) ) , m*n ) nz = matrix ( random . sample ( range ( m*n ) , nnz ) , tc = ' i ' ) return spmatrix ( normal ( nnz , 1 ) , nz%m , matrix ( [int ( ii ) for ii in nz/m] ) , ( m , n ) ) ": 2749,
 "def append_table ( self , name , **kwargs ) : self . stack . append ( Table ( name , **kwargs ) ) ": 2750,
 "def build_gui ( self , container ) : vbox = Widgets . VBox ( ) vbox . set_border_width ( 0 ) w = Viewers . GingaViewerWidget ( viewer = self ) vbox . add_widget ( w , stretch = 1 ) # need to put this in an hbox with an expanding label or the # browser wants to resize the canvas , distorting it hbox = Widgets . HBox ( ) hbox . add_widget ( vbox , stretch = 0 ) hbox . add_widget ( Widgets . Label ( ' ' ) , stretch = 1 ) container . set_widget ( hbox ) ": 2751,
 "def add_object ( self , obj ) : if obj . top_level_object : if isinstance ( obj , DotNetNamespace ) : self . namespaces[obj . name] = obj self . objects[obj . id] = obj": 2752,
 "def get_2D_samples_gauss ( n , m , sigma , random_state = None ) : return make_2D_samples_gauss ( n , m , sigma , random_state = None ) ": 2753,
 "def str_to_class ( class_name ) : mod_str , cls_str = class_name . rsplit ( ' . ' , 1 ) mod = __import__ ( mod_str , globals ( ) , locals ( ) , [ ' ' ] ) cls = getattr ( mod , cls_str ) return cls": 2754,
 "def next ( self ) : # I ' m pretty sure this is the completely wrong way to go about this , but # oh well , this works . if not hasattr ( self , ' _iter ' ) : self . _iter = self . readrow_as_dict ( ) return self . _iter . next ( ) ": 2755,
 "def move_datetime_year ( dt , direction , num_shifts ) : delta = relativedelta ( years = +num_shifts ) return _move_datetime ( dt , direction , delta ) ": 2756,
 "def getBuffer ( x ) : b = bytes ( x ) return ( c_ubyte * len ( b ) ) . from_buffer_copy ( bytes ( x ) ) ": 2757,
 "def __enter__ ( self ) : clone = self . clone ( ) self . _contexts . append ( clone ) self . reset ( ) return self": 2758,
 "def custodian_archive ( packages = None ) : modules = { ' c7n ' , ' pkg_resources ' } if packages : modules = filter ( None , modules . union ( packages ) ) return PythonPackageArchive ( *sorted ( modules ) ) ": 2759,
 "def group ( data , num ) : return [data[i : i+num] for i in range ( 0 , len ( data ) , num ) ]": 2760,
 "def to_query_parameters ( parameters ) : if parameters is None : return [] if isinstance ( parameters , collections_abc . Mapping ) : return to_query_parameters_dict ( parameters ) return to_query_parameters_list ( parameters ) ": 2761,
 "def replace_month_abbr_with_num ( date_str , lang = DEFAULT_DATE_LANG ) : num , abbr = get_month_from_date_str ( date_str , lang ) return re . sub ( abbr , str ( num ) , date_str , flags = re . IGNORECASE ) ": 2762,
 "def parse_datetime ( dt_str , format ) : t = time . strptime ( dt_str , format ) return datetime ( t[0] , t[1] , t[2] , t[3] , t[4] , t[5] , t[6] , pytz . UTC ) ": 2763,
 "def _converter ( self , value ) : if not isinstance ( value , datetime . date ) : raise TypeError ( ' {0} is not valid date ' . format ( value ) ) return value": 2764,
 "def set_as_object ( self , value ) : self . clear ( ) map = MapConverter . to_map ( value ) self . append ( map ) ": 2765,
 "def datetime_to_timestamp ( dt ) : delta = dt - datetime . utcfromtimestamp ( 0 ) return delta . seconds + delta . days * 24 * 3600": 2766,
 "def replace_all ( text , dic ) : for i , j in dic . iteritems ( ) : text = text . replace ( i , j ) return text": 2767,
 "def to_pydatetime ( self ) : dt = datetime . datetime . combine ( self . _date . to_pydate ( ) , self . _time . to_pytime ( ) ) from . tz import FixedOffsetTimezone return dt . replace ( tzinfo = _utc ) . astimezone ( FixedOffsetTimezone ( self . _offset ) ) ": 2768,
 "def __enter__ ( self ) : self . logger = logging . getLogger ( ' pip . download ' ) self . logger . addFilter ( self ) ": 2769,
 "def triangle_area ( pt1 , pt2 , pt3 ) : r a = 0 . 0 a + = pt1[0] * pt2[1] - pt2[0] * pt1[1] a + = pt2[0] * pt3[1] - pt3[0] * pt2[1] a + = pt3[0] * pt1[1] - pt1[0] * pt3[1] return abs ( a ) / 2": 2770,
 "def parse_command_args ( ) : parser = argparse . ArgumentParser ( description = ' Register PB devices . ' ) parser . add_argument ( ' num_pb ' , type = int , help = ' Number of PBs devices to register . ' ) return parser . parse_args ( ) ": 2771,
 "def __len__ ( self ) : length = 0 for typ , siz , _ in self . format : length + = siz return length": 2772,
 "def decompress ( f ) : r = meta ( f . read ( 60 ) ) return r , decomprest ( f , r[4] ) ": 2773,
 "def delete_cell ( self , key ) : try : self . code_array . pop ( key ) except KeyError : pass self . grid . code_array . result_cache . clear ( ) ": 2774,
 "def pop ( ) : pid = os . getpid ( ) thread = threading . current_thread ( ) Wdb . _instances . pop ( ( pid , thread ) ) ": 2775,
 "def runcoro ( async_function ) : future = _asyncio . run_coroutine_threadsafe ( async_function , client . loop ) result = future . result ( ) return result": 2776,
 "def remove ( self , key ) : item = self . item_finder . pop ( key ) item[-1] = None self . removed_count + = 1": 2777,
 "def lock_file ( f , block = False ) : try : flags = fcntl . LOCK_EX if not block : flags | = fcntl . LOCK_NB fcntl . flock ( f . fileno ( ) , flags ) except IOError as e : if e . errno in ( errno . EACCES , errno . EAGAIN ) : raise SystemExit ( \" ERROR : %s is locked by another process . \" % f . name ) raise": 2778,
 "def determine_interactive ( self ) : \t\t\t\ttry : \t\t\tif not sys . stdout . isatty ( ) or os . getpgrp ( ) ! = os . tcgetpgrp ( sys . stdout . fileno ( ) ) : \t\t\t\tself . interactive = 0\t\t\t\treturn False\t\texcept Exception : \t\t\tself . interactive = 0\t\t\treturn False\t\tif self . interactive = = 0 : \t\t\treturn False\t\treturn True": 2779,
 "def create_bigquery_table ( self , database , schema , table_name , callback , sql ) : conn = self . get_thread_connection ( ) client = conn . handle view_ref = self . table_ref ( database , schema , table_name , conn ) view = google . cloud . bigquery . Table ( view_ref ) callback ( view ) with self . exception_handler ( sql ) : client . create_table ( view ) ": 2780,
 "def _guess_extract_method ( fname ) : for method , extensions in _EXTRACTION_METHOD_TO_EXTS : for ext in extensions : if fname . endswith ( ext ) : return method return ExtractMethod . NO_EXTRACT": 2781,
 "def bootstrap_indexes ( data , n_samples = 10000 ) : for _ in xrange ( n_samples ) : yield randint ( data . shape[0] , size = ( data . shape[0] , ) ) ": 2782,
 "def compute_boxplot ( self , series ) : from matplotlib . cbook import boxplot_stats series = series[series . notnull ( ) ] if len ( series . values ) = = 0 : return {} elif not is_numeric_dtype ( series ) : return self . non_numeric_stats ( series ) stats = boxplot_stats ( list ( series . values ) ) [0] stats[ ' count ' ] = len ( series . values ) stats[ ' fliers ' ] = \" | \" . join ( map ( str , stats[ ' fliers ' ] ) ) return stats": 2783,
 "def IsBinary ( self , filename ) : \t\t\t\tmimetype = mimetypes . guess_type ( filename ) [0]\t\tif not mimetype : \t\t\treturn False # e . g . README , \" real \" binaries usually have an extension\t\t # special case for text files which don ' t start with text/\t\tif mimetype in TEXT_MIMETYPES : \t\t\treturn False\t\treturn not mimetype . startswith ( \" text/ \" ) ": 2784,
 "def retrieve_by_id ( self , id_ ) : items_with_id = [item for item in self if item . id = = int ( id_ ) ] if len ( items_with_id ) = = 1 : return items_with_id[0] . retrieve ( ) ": 2785,
 "def install_rpm_py ( ) : python_path = sys . executable cmd = ' {0} install . py ' . format ( python_path ) exit_status = os . system ( cmd ) if exit_status ! = 0 : raise Exception ( ' Command failed : {0} ' . format ( cmd ) ) ": 2786,
 "def enable_ssl ( self , *args , **kwargs ) : if self . handshake_sent : raise SSLError ( ' can only enable SSL before handshake ' ) self . secure = True self . sock = ssl . wrap_socket ( self . sock , *args , **kwargs ) ": 2787,
 "def convert_timeval ( seconds_since_epoch ) : frac , whole = math . modf ( seconds_since_epoch ) microseconds = math . floor ( frac * 1000000 ) seconds = math . floor ( whole ) return seconds , microseconds": 2788,
 "def growthfromrange ( rangegrowth , startdate , enddate ) : _yrs = ( pd . Timestamp ( enddate ) - pd . Timestamp ( startdate ) ) . total_seconds ( ) /\\ dt . timedelta ( 365 . 25 ) . total_seconds ( ) return yrlygrowth ( rangegrowth , _yrs ) ": 2789,
 "def recursively_update ( d , d2 ) : for k , v in d2 . items ( ) : if k in d : if isinstance ( v , dict ) : recursively_update ( d[k] , v ) continue d[k] = v": 2790,
 "def reject ( self ) : if self . hideWindow ( ) : self . hideWindow ( ) . show ( ) self . close ( ) self . deleteLater ( ) ": 2791,
 "def robust_int ( v ) : if isinstance ( v , int ) : return v if isinstance ( v , float ) : return int ( v ) v = str ( v ) . replace ( ' , ' , ' ' ) if not v : return None return int ( v ) ": 2792,
 "def send ( socket , data , num_bytes = 20 ) : pickled_data = pickle . dumps ( data , -1 ) length = str ( len ( pickled_data ) ) . zfill ( num_bytes ) socket . sendall ( length . encode ( ) ) socket . sendall ( pickled_data ) ": 2793,
 "def _trim_zeros_complex ( str_complexes , na_rep = ' NaN ' ) : def separate_and_trim ( str_complex , na_rep ) : num_arr = str_complex . split ( ' + ' ) return ( _trim_zeros_float ( [num_arr[0]] , na_rep ) + [ ' + ' ] + _trim_zeros_float ( [num_arr[1][ : -1]] , na_rep ) + [ ' j ' ] ) return [ ' ' . join ( separate_and_trim ( x , na_rep ) ) for x in str_complexes]": 2794,
 "def display ( self ) : w , h = self . session . window_size ( ) return Display ( w*self . scale , h*self . scale ) ": 2795,
 "def _snake_to_camel_case ( value ) : words = value . split ( \" _ \" ) return words[0] + \" \" . join ( map ( str . capitalize , words[1 : ] ) ) ": 2796,
 "def deleted ( self , instance ) : self . session_manager . delete ( instance , commit = True ) return ' ' , HTTPStatus . NO_CONTENT": 2797,
 "def page_title ( step , title ) : with AssertContextManager ( step ) : assert_equals ( world . browser . title , title ) ": 2798,
 "def __run ( self ) : sys . settrace ( self . globaltrace ) self . __run_backup ( ) self . run = self . __run_backup": 2799,
 "def main ( ) : parser = get_args_parser ( ) args = parser . parse_args ( ) config = Config . from_parse_args ( args ) migrate ( config ) ": 2800,
 "def __to_localdatetime ( val ) : try : dt = datetime . strptime ( val , __DATE_FORMAT ) dt = pytz . timezone ( __TIMEZONE ) . localize ( dt ) return dt except ( ValueError , TypeError ) : return None": 2801,
 "def merge ( database = None , directory = None , verbose = None ) : router = get_router ( directory , database , verbose ) router . merge ( ) ": 2802,
 "def _add_params_docstring ( params ) : p_string = \" \\nAccepts the following paramters : \\n \" for param in params : p_string + = \" name : %s , required : %s , description : %s \\n \" % ( param[ ' name ' ] , param[ ' required ' ] , param[ ' description ' ] ) return p_string": 2803,
 "def from_string ( cls , string ) : # find enum value for attr in dir ( cls ) : value = getattr ( cls , attr ) if value = = string : return value # if not found , log warning and return the value passed in logger . warning ( \" {} is not a valid enum value for {} . \" . format ( string , cls . __name__ ) ) return string": 2804,
 "def callJavaFunc ( func , *args ) : gateway = _get_gateway ( ) args = [_py2java ( gateway , a ) for a in args] result = func ( *args ) return _java2py ( gateway , result ) ": 2805,
 "def to_str ( obj ) : if not isinstance ( obj , str ) and PY3 and isinstance ( obj , bytes ) : obj = obj . decode ( ' utf-8 ' ) return obj if isinstance ( obj , string_types ) else str ( obj ) ": 2806,
 "def ucamel_method ( func ) : frame_locals = inspect . currentframe ( ) . f_back . f_locals frame_locals[snake2ucamel ( func . __name__ ) ] = func return func": 2807,
 "def validate ( self ) : validator = Draft4Validator ( self . SCHEMA ) if not validator . is_valid ( self . config ) : for err in validator . iter_errors ( self . config ) : LOGGER . error ( str ( err . message ) ) validator . validate ( self . config ) ": 2808,
 "def bbox ( self ) : return BoundingBox ( self . slices[1] . start , self . slices[1] . stop , self . slices[0] . start , self . slices[0] . stop ) ": 2809,
 "def _draw_lines_internal ( self , coords , colour , bg ) : for i , ( x , y ) in enumerate ( coords ) : if i = = 0 : self . _screen . move ( x , y ) else : self . _screen . draw ( x , y , colour = colour , bg = bg , thin = True ) ": 2810,
 "def change_dir ( directory ) : def cd_decorator ( func ) : @wraps ( func ) def wrapper ( *args , **kwargs ) : org_path = os . getcwd ( ) os . chdir ( directory ) func ( *args , **kwargs ) os . chdir ( org_path ) return wrapper return cd_decorator": 2811,
 "def TextWidget ( *args , **kw ) : kw[ ' value ' ] = str ( kw[ ' value ' ] ) kw . pop ( ' options ' , None ) return TextInput ( *args , **kw ) ": 2812,
 "def scale_dtype ( arr , dtype ) : max_int = np . iinfo ( dtype ) . max return ( arr * max_int ) . astype ( dtype ) ": 2813,
 "def shape_list ( l , shape , dtype ) : return np . array ( l , dtype = dtype ) . reshape ( shape ) ": 2814,
 "def get_record_by_name ( self , index , name ) : result = self . ES . search ( index = index , body = { \" query \" : { \" match_phrase \" : { \" name \" : name , } } } ) hits = result[ \" hits \" ][ \" hits \" ] if not hits : return {} elif len ( hits ) = = 1 : return hits[0][ \" _source \" ] else : # Mult . records found with same prefix . See if a single record whose name attr matches # the match phrase exactly ( in a lower-case comparison ) . for h in hits : source = h[ \" _source \" ] record_name = source[ \" name \" ] if record_name . lower ( ) . strip ( ) = = name . lower ( ) . strip ( ) : return source msg = \" match_phrase search found multiple records matching query ' {} ' for index ' {} ' . \" . format ( name , index ) raise MultipleHitsException ( msg ) ": 2815,
 "def add_datetime ( dataframe , timestamp_key = ' UNIXTIME ' ) : def convert_data ( timestamp ) : return datetime . fromtimestamp ( float ( timestamp ) / 1e3 , UTC_TZ ) try : log . debug ( \" Adding DATETIME column to the data \" ) converted = dataframe[timestamp_key] . apply ( convert_data ) dataframe[ ' DATETIME ' ] = converted except KeyError : log . warning ( \" Could not add DATETIME column \" ) ": 2816,
 "def keys ( self ) : result = [] if self . fresh_index is not None : result + = self . fresh_index . keys ( ) if self . opt_index is not None : result + = self . opt_index . keys ( ) return result": 2817,
 "def all_documents ( index = INDEX_NAME ) : query = { ' query ' : { ' match_all ' : {} } } for result in raw_query ( query , index = index ) : yield result": 2818,
 "def flat ( l ) : newl = [] for i in range ( len ( l ) ) : for j in range ( len ( l[i] ) ) : newl . append ( l[i][j] ) return newl": 2819,
 "def ylabelsize ( self , size , index = 1 ) : self . layout[ ' yaxis ' + str ( index ) ][ ' titlefont ' ][ ' size ' ] = size return self": 2820,
 "def _extract_value ( self , value ) : return ModelEndpoint . _value_map . get ( smart_str ( value ) . lower ( ) , value ) ": 2821,
 "def __getattribute__ ( self , attr ) : if ( attr not in object . __getattribute__ ( self , ' __dict__ ' ) and attr not in Etree . __dict__ ) : return object . __getattribute__ ( self . _etree , attr ) return object . __getattribute__ ( self , attr ) ": 2822,
 "def decode_unicode_string ( string ) : if string . startswith ( ' [BASE64-DATA] ' ) and string . endswith ( ' [/BASE64-DATA] ' ) : return base64 . b64decode ( string[len ( ' [BASE64-DATA] ' ) : -len ( ' [/BASE64-DATA] ' ) ] ) return string": 2823,
 "def add_element_to_doc ( doc , tag , value ) : element = doc . find ( \" . //%s \" % tag ) if element is None : element = etree . SubElement ( doc , tag ) element . text = value": 2824,
 "def make_exception_message ( exc ) : if str ( exc ) : return ' %s : %s\\n ' % ( exc . __class__ . __name__ , exc ) else : return ' %s\\n ' % ( exc . __class__ . __name__ ) ": 2825,
 "def prepare_query_params ( **kwargs ) : return [ ( sub_key , sub_value ) for key , value in kwargs . items ( ) for sub_key , sub_value in expand ( value , key ) if sub_value is not None ]": 2826,
 "def expandvars_dict ( settings ) : return dict ( ( key , os . path . expandvars ( value ) ) for key , value in settings . iteritems ( ) ) ": 2827,
 "def get_numbers ( s ) : result = map ( int , re . findall ( r ' [0-9]+ ' , unicode ( s ) ) ) return result + [1] * ( 2 - len ( result ) ) ": 2828,
 "def is_nested_object ( obj ) : if isinstance ( obj , ABCSeries ) and is_object_dtype ( obj ) : if any ( isinstance ( v , ABCSeries ) for v in obj . values ) : return True return False": 2829,
 "def get_data ( self ) : try : return DocumentDataDict ( self . __dict__[ ' data ' ] ) except KeyError : self . _lazy_load ( ) return DocumentDataDict ( self . __dict__[ ' data ' ] ) ": 2830,
 "def ffmpeg_version ( ) : cmd = [ ' ffmpeg ' , ' -version ' ] output = sp . check_output ( cmd ) aac_codecs = [ x for x in output . splitlines ( ) if \" ffmpeg version \" in str ( x ) ][0] hay = aac_codecs . decode ( ' ascii ' ) match = re . findall ( r ' ffmpeg version ( \\d+\\ . ) ? ( \\d+\\ . ) ? ( \\*|\\d+ ) ' , hay ) if match : return \" \" . join ( match[0] ) else : return None": 2831,
 "def is_same_file ( filename1 , filename2 ) : if filename1 = = filename2 : return True if os . name = = ' posix ' : return os . path . samefile ( filename1 , filename2 ) return is_same_filename ( filename1 , filename2 ) ": 2832,
 "def file_read ( filename ) : fobj = open ( filename , ' r ' ) ; source = fobj . read ( ) ; fobj . close ( ) return source": 2833,
 "def get_column_definition ( self , table , column ) : # Parse column definitions for match for col in self . get_column_definition_all ( table ) : if col . strip ( ' ` ' ) . startswith ( column ) : return col . strip ( ' , ' ) ": 2834,
 "def is_palindrome ( string , strict = True ) : if is_full_string ( string ) : if strict : return reverse ( string ) = = string return is_palindrome ( SPACES_RE . sub ( ' ' , string ) ) return False": 2835,
 "def remove_na_arraylike ( arr ) : if is_extension_array_dtype ( arr ) : return arr[notna ( arr ) ] else : return arr[notna ( lib . values_from_object ( arr ) ) ]": 2836,
 "def contains_geometric_info ( var ) : return isinstance ( var , tuple ) and len ( var ) = = 2 and all ( isinstance ( val , ( int , float ) ) for val in var ) ": 2837,
 "def init_app ( self , app ) : app . config . from_pyfile ( ' {0} . cfg ' . format ( app . name ) , silent = True ) ": 2838,
 "def converged ( matrix1 , matrix2 ) : if isspmatrix ( matrix1 ) or isspmatrix ( matrix2 ) : return sparse_allclose ( matrix1 , matrix2 ) return np . allclose ( matrix1 , matrix2 ) ": 2839,
 "def getFlaskResponse ( responseString , httpStatus = 200 ) : return flask . Response ( responseString , status = httpStatus , mimetype = MIMETYPE ) ": 2840,
 "def fmt_sz ( intval ) : try : return fmt . human_size ( intval ) except ( ValueError , TypeError ) : return \" N/A \" . rjust ( len ( fmt . human_size ( 0 ) ) ) ": 2841,
 "def replace_nones ( dict_or_list ) : def replace_none_in_value ( value ) : if isinstance ( value , basestring ) and value . lower ( ) = = \" none \" : return None return value items = dict_or_list . iteritems ( ) if isinstance ( dict_or_list , dict ) else enumerate ( dict_or_list ) for accessor , value in items : if isinstance ( value , ( dict , list ) ) : replace_nones ( value ) else : dict_or_list[accessor] = replace_none_in_value ( value ) ": 2842,
 "def isdir ( self , path ) : result = True try : self . sftp_client . lstat ( path ) except FileNotFoundError : result = False return result": 2843,
 "def cartesian_lists ( d ) : return [{k : v for k , v in zip ( d . keys ( ) , args ) } for args in itertools . product ( *d . values ( ) ) ]": 2844,
 "def iiscgi ( application ) : \t\ttry : \t\tfrom wsgiref . handlers import IISCGIHandler\texcept ImportError : \t\tprint ( \" Python 3 . 2 or newer is required . \" ) \t\tif not __debug__ : \t\twarnings . warn ( \" Interactive debugging and other persistence-based processes will not work . \" ) \t\tIISCGIHandler ( ) . run ( application ) ": 2845,
 "def arguments_as_dict ( cls , *args , **kwargs ) : all_args = ( None , ) + args return inspect . getcallargs ( cls . run , *all_args , **kwargs ) ": 2846,
 "def update ( self , **kwargs ) : for key , value in kwargs . items ( ) : setattr ( self , key , value ) ": 2847,
 "def hamming ( s , t ) : if len ( s ) ! = len ( t ) : raise ValueError ( ' Hamming distance needs strings of equal length . ' ) return sum ( s_ ! = t_ for s_ , t_ in zip ( s , t ) ) ": 2848,
 "def get_free_mb ( folder ) : if platform . system ( ) = = ' Windows ' : free_bytes = ctypes . c_ulonglong ( 0 ) ctypes . windll . kernel32 . GetDiskFreeSpaceExW ( ctypes . c_wchar_p ( folder ) , None , None , ctypes . pointer ( free_bytes ) ) return free_bytes . value/1024/1024 else : st = os . statvfs ( folder ) return st . f_bavail * st . f_frsize/1024/1024": 2849,
 "def filtany ( entities , **kw ) : ret = set ( ) for k , v in kw . items ( ) : for entity in entities : if getattr ( entity , k ) ( ) = = v : ret . add ( entity ) return ret": 2850,
 "def sine_wave ( i , frequency = FREQUENCY , framerate = FRAMERATE , amplitude = AMPLITUDE ) : omega = 2 . 0 * pi * float ( frequency ) sine = sin ( omega * ( float ( i ) / float ( framerate ) ) ) return float ( amplitude ) * sine": 2851,
 "def _cdf ( self , xloc , dist , cache ) : return evaluation . evaluate_forward ( dist , numpy . e**xloc , cache = cache ) ": 2852,
 "def manhattan ( h1 , h2 ) : # # 7 us @array , 31 us @list \\w 100 bins r h1 , h2 = __prepare_histogram ( h1 , h2 ) return scipy . sum ( scipy . absolute ( h1 - h2 ) ) ": 2853,
 "def data_from_techshop_ws ( tws_url ) : r = requests . get ( tws_url ) if r . status_code = = 200 : data = BeautifulSoup ( r . text , \" lxml \" ) else : data = \" There was an error while accessing data on techshop . ws . \" return data": 2854,
 "def deskew ( S ) : x = np . zeros ( 3 ) x[0] = S[2 , 1] x[1] = S[0 , 2] x[2] = S[1 , 0] return x": 2855,
 "def get_distance_matrix ( x ) : square = nd . sum ( x ** 2 . 0 , axis = 1 , keepdims = True ) distance_square = square + square . transpose ( ) - ( 2 . 0 * nd . dot ( x , x . transpose ( ) ) ) return nd . sqrt ( distance_square ) ": 2856,
 "def _mean_absolute_error ( y , y_pred , w ) : return np . average ( np . abs ( y_pred - y ) , weights = w ) ": 2857,
 "def dft ( blk , freqs , normalize = True ) : dft_data = ( sum ( xn * cexp ( -1j * n * f ) for n , xn in enumerate ( blk ) ) for f in freqs ) if normalize : lblk = len ( blk ) return [v / lblk for v in dft_data] return list ( dft_data ) ": 2858,
 "def softmax ( xs ) : ys = xs - np . max ( xs ) exps = np . exp ( ys ) return exps / exps . sum ( axis = 0 ) ": 2859,
 "def timestamp_filename ( basename , ext = None ) : dt = datetime . now ( ) . strftime ( ' %Y%m%d-%H%M%S-%f ' ) if ext : return ' %s-%s . %s ' % ( basename , dt , ext ) return ' %s-%s ' % ( basename , dt ) ": 2860,
 "def random_id ( length ) : def char ( ) : \" \" \" Generate single random char \" \" \" return random . choice ( string . ascii_letters + string . digits ) return \" \" . join ( char ( ) for _ in range ( length ) ) ": 2861,
 "def get_incomplete_path ( filename ) : random_suffix = \" \" . join ( random . choice ( string . ascii_uppercase + string . digits ) for _ in range ( 6 ) ) return filename + \" . incomplete \" + random_suffix": 2862,
 "def adjacency ( tree ) : dd = ids ( tree ) N = len ( dd ) A = np . zeros ( ( N , N ) ) def _adj ( node ) : if np . isscalar ( node ) : return elif isinstance ( node , tuple ) and len ( node ) = = 2 : A[dd[node] , dd[node[0]]] = 1 A[dd[node[0]] , dd[node]] = 1 _adj ( node[0] ) A[dd[node] , dd[node[1]]] = 1 A[dd[node[1]] , dd[node]] = 1 _adj ( node[1] ) _adj ( tree ) return A": 2863,
 "def generate_random_id ( size = 6 , chars = string . ascii_uppercase + string . digits ) : return \" \" . join ( random . choice ( chars ) for x in range ( size ) ) ": 2864,
 "def nest ( thing ) : tfutil = util . get_module ( ' tensorflow . python . util ' ) if tfutil : return tfutil . nest . flatten ( thing ) else : return [thing]": 2865,
 "def get_ref_dict ( self , schema ) : schema_key = make_schema_key ( schema ) ref_schema = build_reference ( \" schema \" , self . openapi_version . major , self . refs[schema_key] ) if getattr ( schema , \" many \" , False ) : return { \" type \" : \" array \" , \" items \" : ref_schema} return ref_schema": 2866,
 "def text_response ( self , contents , code = 200 , headers = {} ) : return Response ( contents , status = code , headers = { ' Content-Type ' : ' text/plain ' } ) ": 2867,
 "def make_name ( estimator ) : if estimator is not None : if isinstance ( estimator , six . string_types ) : estimator_name = estimator else : estimator_name = estimator . __class__ . __name__ else : estimator_name = None return estimator_name": 2868,
 "def OnContextMenu ( self , event ) : self . grid . PopupMenu ( self . grid . contextmenu ) event . Skip ( ) ": 2869,
 "def list_files ( directory ) : return [f for f in pathlib . Path ( directory ) . iterdir ( ) if f . is_file ( ) and not f . name . startswith ( ' . ' ) ]": 2870,
 "def filter_query_string ( query ) : return ' & ' . join ( [q for q in query . split ( ' & ' ) if not ( q . startswith ( ' _k = ' ) or q . startswith ( ' _e = ' ) or q . startswith ( ' _s ' ) ) ] ) ": 2871,
 "def unique_items ( seq ) : seen = set ( ) return [x for x in seq if not ( x in seen or seen . add ( x ) ) ]": 2872,
 "def adjust ( cols , light ) : raw_colors = [cols[0] , *cols , \" # FFFFFF \" , \" # 000000 \" , *cols , \" # FFFFFF \" ] return colors . generic_adjust ( raw_colors , light ) ": 2873,
 "def median_date ( dt_list ) : # dt_list_sort = sorted ( dt_list ) idx = len ( dt_list ) /2 if len ( dt_list ) % 2 = = 0 : md = mean_date ( [dt_list[idx-1] , dt_list[idx]] ) else : md = dt_list[idx] return md": 2874,
 "def RadiusGrid ( gridSize ) : x , y = np . mgrid[0 : gridSize , 0 : gridSize] x = x- ( gridSize-1 . 0 ) /2 . 0 y = y- ( gridSize-1 . 0 ) /2 . 0 return np . abs ( x+1j*y ) ": 2875,
 "def __absolute__ ( self , uri ) : return op . abspath ( op . join ( self . __path__ , uri ) ) ": 2876,
 "def autocorr_coeff ( x , t , tau1 , tau2 ) : return corr_coeff ( x , x , t , tau1 , tau2 ) ": 2877,
 "def paren_change ( inputstring , opens = opens , closes = closes ) : count = 0 for c in inputstring : if c in opens : # open parens/brackets/braces count - = 1 elif c in closes : # close parens/brackets/braces count + = 1 return count": 2878,
 "def count ( data , axis = None ) : return np . sum ( np . logical_not ( isnull ( data ) ) , axis = axis ) ": 2879,
 "def string_to_list ( string , sep = \" , \" , filter_empty = False ) : return [value . strip ( ) for value in string . split ( sep ) if ( not filter_empty or value ) ]": 2880,
 "def sparse_to_matrix ( sparse ) : sparse = np . asanyarray ( sparse , dtype = np . int ) if not util . is_shape ( sparse , ( -1 , 3 ) ) : raise ValueError ( ' sparse must be ( n , 3 ) ! ' ) shape = sparse . max ( axis = 0 ) + 1 matrix = np . zeros ( np . product ( shape ) , dtype = np . bool ) multiplier = np . array ( [np . product ( shape[1 : ] ) , shape[2] , 1] ) index = ( sparse * multiplier ) . sum ( axis = 1 ) matrix[index] = True dense = matrix . reshape ( shape ) return dense": 2881,
 "def get_size ( self ) : self . curses . setupterm ( ) return self . curses . tigetnum ( ' cols ' ) , self . curses . tigetnum ( ' lines ' ) ": 2882,
 "def get_mouse_location ( self ) : x = ctypes . c_int ( 0 ) y = ctypes . c_int ( 0 ) screen_num = ctypes . c_int ( 0 ) _libxdo . xdo_get_mouse_location ( self . _xdo , ctypes . byref ( x ) , ctypes . byref ( y ) , ctypes . byref ( screen_num ) ) return mouse_location ( x . value , y . value , screen_num . value ) ": 2883,
 "def write_property ( fh , key , value ) : if key is COMMENT : write_comment ( fh , value ) return _require_string ( key , ' keys ' ) _require_string ( value , ' values ' ) fh . write ( _escape_key ( key ) ) fh . write ( b ' = ' ) fh . write ( _escape_value ( value ) ) fh . write ( b ' \\n ' ) ": 2884,
 "def get_current_branch ( ) : cmd = [ \" git \" , \" rev-parse \" , \" --abbrev-ref \" , \" HEAD \" ] output = subprocess . check_output ( cmd , stderr = subprocess . STDOUT ) return output . strip ( ) . decode ( \" utf-8 \" ) ": 2885,
 "def _get_config_or_default ( self , key , default , as_type = lambda x : x ) : if self . main_config . has_option ( self . main_section , key ) : return as_type ( self . main_config . get ( self . main_section , key ) ) return default": 2886,
 "def disable_stdout_buffering ( ) : stdout_orig = sys . stdout sys . stdout = os . fdopen ( sys . stdout . fileno ( ) , ' w ' , 0 ) # NOTE ( brandyn ) : This removes the original stdout return stdout_orig": 2887,
 "def remove_ext ( fname ) : bn = os . path . basename ( fname ) return os . path . splitext ( bn ) [0]": 2888,
 "def uint8sc ( im ) : im = np . asarray ( im ) immin = im . min ( ) immax = im . max ( ) imrange = immax - immin return cv2 . convertScaleAbs ( im - immin , alpha = 255 / imrange ) ": 2889,
 "def qualified_name_import ( cls ) : parts = qualified_name ( cls ) . split ( ' . ' ) return \" from {} import {} \" . format ( ' . ' . join ( parts[ : -1] ) , parts[-1] ) ": 2890,
 "def server ( self ) : try : tar = urllib2 . urlopen ( self . registry ) meta = tar . info ( ) return int ( meta . getheaders ( \" Content-Length \" ) [0] ) except ( urllib2 . URLError , IndexError ) : return \" \" ": 2891,
 "def cric__decision_tree ( ) : model = sklearn . tree . DecisionTreeClassifier ( random_state = 0 , max_depth = 4 ) # we want to explain the raw probability outputs of the trees model . predict = lambda X : model . predict_proba ( X ) [ : , 1] return model": 2892,
 "def get_properties ( cls ) : property_names = [p for p in dir ( cls ) if isinstance ( getattr ( cls , p ) , property ) ] return property_names": 2893,
 "def cleanup ( self ) : for file in glob . glob ( self . basename + ' * ' ) : os . unlink ( file ) ": 2894,
 "def get_coordinates_by_full_name ( self , name ) : person = self . get_person_by_full_name ( name ) if not person : return ' ' , ' ' return person . latitude , person . longitude": 2895,
 "def get_model ( name ) : model = MODELS . get ( name . lower ( ) , None ) assert model , \" Could not locate model by name ' %s ' \" % name return model": 2896,
 "def get_month_start_date ( self ) : now = timezone . now ( ) return timezone . datetime ( day = 1 , month = now . month , year = now . year , tzinfo = now . tzinfo ) ": 2897,
 "def get_propety_by_name ( pif , name ) : warn ( \" This method has been deprecated in favor of get_property_by_name \" ) return next ( ( x for x in pif . properties if x . name = = name ) , None ) ": 2898,
 "def update ( self , params ) : dev_info = self . json_state . get ( ' deviceInfo ' ) dev_info . update ( {k : params[k] for k in params if dev_info . get ( k ) } ) ": 2899,
 "def compare_dict ( da , db ) : sa = set ( da . items ( ) ) sb = set ( db . items ( ) ) diff = sa & sb return dict ( sa - diff ) , dict ( sb - diff ) ": 2900,
 "def _increase_file_handle_limit ( ) : logging . info ( ' Increasing file handle limit to {} ' . format ( constants . FILE_HANDLE_LIMIT ) ) resource . setrlimit ( resource . RLIMIT_NOFILE , ( constants . FILE_HANDLE_LIMIT , resource . RLIM_INFINITY ) ) ": 2901,
 "def datetime_delta_to_ms ( delta ) : delta_ms = delta . days * 24 * 60 * 60 * 1000 delta_ms + = delta . seconds * 1000 delta_ms + = delta . microseconds / 1000 delta_ms = int ( delta_ms ) return delta_ms": 2902,
 "def dt2ts ( dt ) : # Note : no assertion to really keep this fast assert isinstance ( dt , ( datetime . datetime , datetime . date ) ) ret = time . mktime ( dt . timetuple ( ) ) if isinstance ( dt , datetime . datetime ) : ret + = 1e-6 * dt . microsecond return ret": 2903,
 "def Print ( self ) : for val , prob in sorted ( self . d . iteritems ( ) ) : print ( val , prob ) ": 2904,
 "def parse_env_var ( s ) : parts = s . split ( ' = ' , 1 ) if len ( parts ) = = 2 : k , v = parts return ( k , v ) k = parts[0] return ( k , os . getenv ( k , ' ' ) ) ": 2905,
 "def get_user_id_from_email ( self , email ) : accts = self . get_all_user_accounts ( ) for acct in accts : if acct[ ' email ' ] = = email : return acct[ ' id ' ] return None": 2906,
 "def process_bool_arg ( arg ) : if isinstance ( arg , bool ) : return arg elif isinstance ( arg , basestring ) : if arg . lower ( ) in [ \" true \" , \" 1 \" ] : return True elif arg . lower ( ) in [ \" false \" , \" 0 \" ] : return False": 2907,
 "def graph_from_dot_file ( path ) : fd = file ( path , ' rb ' ) data = fd . read ( ) fd . close ( ) return graph_from_dot_data ( data ) ": 2908,
 "def getAttributeData ( self , name , channel = None ) : return self . _getNodeData ( name , self . _ATTRIBUTENODE , channel ) ": 2909,
 "def __getLogger ( cls ) : if cls . __logger is None : cls . __logger = opf_utils . initLogger ( cls ) return cls . __logger": 2910,
 "def depgraph_to_dotsrc ( dep_graph , show_cycles , nodot , reverse ) : if show_cycles : dotsrc = cycles2dot ( dep_graph , reverse = reverse ) elif not nodot : dotsrc = dep2dot ( dep_graph , reverse = reverse ) else : dotsrc = None return dotsrc": 2911,
 "def commit ( self , message = None , amend = False , stage = True ) : return git_commit ( self . repo_dir , message = message , amend = amend , stage = stage ) ": 2912,
 "def wrap ( text , width = 70 , **kwargs ) : w = TextWrapper ( width = width , **kwargs ) return w . wrap ( text ) ": 2913,
 "def split_every ( iterable , n ) : # TODO : Remove this , or make it return a generator . i = iter ( iterable ) piece = list ( islice ( i , n ) ) while piece : yield piece piece = list ( islice ( i , n ) ) ": 2914,
 "def _read_group_h5 ( filename , groupname ) : with h5py . File ( filename , ' r ' ) as h5f : data = h5f[groupname][ ( ) ] return data": 2915,
 "def Value ( self , name ) : if name in self . _enum_type . values_by_name : return self . _enum_type . values_by_name[name] . number raise ValueError ( ' Enum %s has no value defined for name %s ' % ( self . _enum_type . name , name ) ) ": 2916,
 "def async_comp_check ( self , original , loc , tokens ) : return self . check_py ( \" 36 \" , \" async comprehension \" , original , loc , tokens ) ": 2917,
 "def _size_36 ( ) : from shutil import get_terminal_size dim = get_terminal_size ( ) if isinstance ( dim , list ) : return dim[0] , dim[1] return dim . lines , dim . columns": 2918,
 "def fail ( message = None , exit_status = None ) : print ( ' Error : ' , message , file = sys . stderr ) sys . exit ( exit_status or 1 ) ": 2919,
 "def _from_list_dict ( cls , list_dic ) : return cls ( {_convert_id ( dic[cls . CHAMP_ID] ) : dict ( dic ) for dic in list_dic} ) ": 2920,
 "def get_filesize ( self , pdf ) : try : filesize = float ( pdf . get_size ( ) ) return filesize / 1024 except ( POSKeyError , TypeError ) : return 0": 2921,
 "def parse ( filename ) : with open ( filename ) as f : parser = ASDLParser ( ) return parser . parse ( f . read ( ) ) ": 2922,
 "def set_timeout ( scope , timeout ) : conn = scope . get ( ' __connection__ ' ) conn . set_timeout ( int ( timeout[0] ) ) return True": 2923,
 "def send_file ( self , local_path , remote_path , user = ' root ' , unix_mode = None ) : self . enable_user ( user ) return self . ssh_pool . send_file ( user , local_path , remote_path , unix_mode = unix_mode ) ": 2924,
 "def _fill_array_from_list ( the_list , the_array ) : for i , val in enumerate ( the_list ) : the_array[i] = val return the_array": 2925,
 "def assign_to ( self , obj ) : obj . x = self . x obj . y = self . y": 2926,
 "def BROADCAST_FILTER_NOT ( func ) : return lambda u , command , *args , **kwargs : not func ( u , command , *args , **kwargs ) ": 2927,
 "def filter_list_by_indices ( lst , indices ) : return [x for i , x in enumerate ( lst ) if i in indices]": 2928,
 "def registered_filters_list ( self ) : return [filter_name for filter_name in self . __jinja2_environment . filters . keys ( ) if filter_name not in self . __jinja2_predefined_filters ]": 2929,
 "def get_average_color ( colors ) : c = reduce ( color_reducer , colors ) total = len ( colors ) return tuple ( v / total for v in c ) ": 2930,
 "def is_valid_file ( parser , arg ) : arg = os . path . abspath ( arg ) if not os . path . exists ( arg ) : parser . error ( \" The file %s does not exist! \" % arg ) else : return arg": 2931,
 "def user_exists ( username ) : try : pwd . getpwnam ( username ) user_exists = True except KeyError : user_exists = False return user_exists": 2932,
 "def clear ( self ) : self . _fwdm . clear ( ) self . _invm . clear ( ) self . _sntl . nxt = self . _sntl . prv = self . _sntl": 2933,
 "def get_months_apart ( d1 , d2 ) : return ( d1 . year - d2 . year ) *12 + d1 . month - d2 . month": 2934,
 "def Gaussian ( x , a , x0 , sigma , y0 ) : return a * np . exp ( - ( x - x0 ) ** 2 / ( 2 * sigma ** 2 ) ) + y0": 2935,
 "def _increment ( self , *args ) : value = self . _var . get ( ) if self . _resolution : value = self . _start + int ( round ( ( value - self . _start ) / self . _resolution ) ) * self . _resolution self . _var . set ( value ) self . display_value ( value ) ": 2936,
 "def clear ( self ) : self . _imgobj = None try : # See if there is an image on the canvas self . canvas . delete_object_by_tag ( self . _canvas_img_tag ) self . redraw ( ) except KeyError : pass": 2937,
 "def make_2d ( ary ) : dim_0 , *_ = np . atleast_1d ( ary ) . shape return ary . reshape ( dim_0 , -1 , order = \" F \" ) ": 2938,
 "def is_executable ( path ) : return os . path . isfile ( path ) and os . access ( path , os . X_OK ) ": 2939,
 "def run ( self ) : try : self . run_checked ( ) except KeyboardInterrupt : thread . interrupt_main ( ) except Exception : self . internal_error ( ) ": 2940,
 "def callPlaybook ( self , playbook , ansibleArgs , wait = True , tags = [ \" all \" ] ) : playbook = os . path . join ( self . playbooks , playbook ) # Path to playbook being executed verbosity = \" -vvvvv \" if logger . isEnabledFor ( logging . DEBUG ) else \" -v \" command = [ \" ansible-playbook \" , verbosity , \" --tags \" , \" , \" . join ( tags ) , \" --extra-vars \" ] command . append ( \" \" . join ( [ \" = \" . join ( i ) for i in ansibleArgs . items ( ) ] ) ) # Arguments being passed to playbook command . append ( playbook ) logger . debug ( \" Executing Ansible call `%s` \" , \" \" . join ( command ) ) p = subprocess . Popen ( command ) if wait : p . communicate ( ) if p . returncode ! = 0 : # FIXME : parse error codes raise RuntimeError ( \" Ansible reported an error when executing playbook %s \" % playbook ) ": 2941,
 "def wait_until_exit ( self ) : [t . join ( ) for t in self . threads] self . threads = list ( ) ": 2942,
 "def cleanup_storage ( *args ) : ShardedClusters ( ) . cleanup ( ) ReplicaSets ( ) . cleanup ( ) Servers ( ) . cleanup ( ) sys . exit ( 0 ) ": 2943,
 "def get_csrf_token ( response ) : cookie_headers = [ h . decode ( ' ascii ' ) for h in response . headers . getlist ( \" Set-Cookie \" ) ] if not cookie_headers : return None csrf_headers = [ h for h in cookie_headers if h . startswith ( \" csrftoken = \" ) ] if not csrf_headers : return None match = re . match ( \" csrftoken = ( [^ ;]+ ) ; \" , csrf_headers[-1] ) return match . group ( 1 ) ": 2944,
 "def exception_format ( ) : return \" \" . join ( traceback . format_exception ( sys . exc_info ( ) [0] , sys . exc_info ( ) [1] , sys . exc_info ( ) [2] ) ) ": 2945,
 "def ttl ( self ) : ret = 3600 cn = self . get_process ( ) if \" ttl \" in cn : ret = cn[ \" ttl \" ] return ret": 2946,
 "def move_back ( self , dt ) : self . _position = self . _old_position self . rect . topleft = self . _position self . feet . midbottom = self . rect . midbottom": 2947,
 "def is_empty ( self ) : if ( ( ( self . channels = = [] ) and ( not self . shape = = ( 0 , 0 ) ) ) or ( ( not self . channels = = [] ) and ( self . shape = = ( 0 , 0 ) ) ) ) : raise RuntimeError ( \" Channels-shape mismatch . \" ) return self . channels = = [] and self . shape = = ( 0 , 0 ) ": 2948,
 "def update_not_existing_kwargs ( to_update , update_from ) : if to_update is None : to_update = {} to_update . update ( {k : v for k , v in update_from . items ( ) if k not in to_update} ) return to_update": 2949,
 "def insert_slash ( string , every = 2 ) : return os . path . join ( string[i : i+every] for i in xrange ( 0 , len ( string ) , every ) ) ": 2950,
 "def circles_pycairo ( width , height , color ) : cairo_color = color / rgb ( 255 , 255 , 255 ) surface = cairo . ImageSurface ( cairo . FORMAT_ARGB32 , width , height ) ctx = cairo . Context ( surface ) # draw a circle in the center ctx . new_path ( ) ctx . set_source_rgb ( cairo_color . red , cairo_color . green , cairo_color . blue ) ctx . arc ( width / 2 , height / 2 , width / 2 , 0 , 2 * pi ) ctx . fill ( ) surface . write_to_png ( ' circles . png ' ) ": 2951,
 "def combinations ( l ) : result = [] for x in xrange ( len ( l ) - 1 ) : ls = l[x + 1 : ] for y in ls : result . append ( ( l[x] , y ) ) return result": 2952,
 "def _get_history_next ( self ) : if self . _has_history : ret = self . _input_history . return_history ( 1 ) self . string = ret self . _curs_pos = len ( ret ) ": 2953,
 "def set_user_password ( environment , parameter , password ) : username = ' %s : %s ' % ( environment , parameter ) return password_set ( username , password ) ": 2954,
 "def R_rot_3d ( th ) : sx , sy , sz = np . sin ( th ) . T cx , cy , cz = np . cos ( th ) . T R = np . empty ( ( len ( th ) , 3 , 3 ) , dtype = np . float ) R[ : , 0 , 0] = cy * cz R[ : , 0 , 1] = -cy * sz R[ : , 0 , 2] = sy R[ : , 1 , 0] = sx * sy * cz + cx * sz R[ : , 1 , 1] = -sx * sy * sz + cx * cz R[ : , 1 , 2] = -sx * cy R[ : , 2 , 0] = -cx * sy * cz + sx * sz R[ : , 2 , 1] = cx * sy * sz + sx * cz R[ : , 2 , 2] = cx * cy return R": 2955,
 "def read_dict_from_file ( file_path ) : with open ( file_path ) as file : lines = file . read ( ) . splitlines ( ) obj = {} for line in lines : key , value = line . split ( ' : ' , maxsplit = 1 ) obj[key] = eval ( value ) return obj": 2956,
 "def calc_list_average ( l ) : total = 0 . 0 for value in l : total + = value return total / len ( l ) ": 2957,
 "def do_rewind ( self , line ) : self . print_response ( \" Rewinding from frame %s to 0 \" % self . bot . _frame ) self . bot . _frame = 0": 2958,
 "def _file_exists ( path , filename ) : return os . path . isfile ( os . path . join ( path , filename ) ) ": 2959,
 "def unproject ( self , xy ) : ( x , y ) = xy lng = x/EARTH_RADIUS * RAD_TO_DEG lat = 2 * atan ( exp ( y/EARTH_RADIUS ) ) - pi/2 * RAD_TO_DEG return ( lng , lat ) ": 2960,
 "def _cosine ( a , b ) : return 1 . * len ( a & b ) / ( math . sqrt ( len ( a ) ) * math . sqrt ( len ( b ) ) ) ": 2961,
 "def count ( self , X ) : # Sum on axis 0 ( by columns ) , each column is a word # Convert the matrix to an array # Squeeze to remove the 1 dimension objects ( like ravel ) return np . squeeze ( np . asarray ( X . sum ( axis = 0 ) ) ) ": 2962,
 "def get_current_frames ( ) : return dict ( ( thread_id , { ' frame ' : thread2list ( frame ) , ' time ' : None} ) for thread_id , frame in sys . _current_frames ( ) . items ( ) ) ": 2963,
 "def _replace_none ( self , aDict ) : for k , v in aDict . items ( ) : if v is None : aDict[k] = ' none ' ": 2964,
 "def _get_image_numpy_dtype ( self ) : try : ftype = self . _info[ ' img_equiv_type ' ] npy_type = _image_bitpix2npy[ftype] except KeyError : raise KeyError ( \" unsupported fits data type : %d \" % ftype ) return npy_type": 2965,
 "def _get_item_position ( self , idx ) : start = 0 if idx = = 0 else self . _index[idx - 1] + 1 end = self . _index[idx] return start , end": 2966,
 "def warn ( self , text ) : \t\t\t\tself . logger . warn ( \" {}{} \" . format ( self . message_prefix , text ) ) ": 2967,
 "def get_model_index_properties ( instance , index ) : mapping = get_index_mapping ( index ) doc_type = instance . _meta . model_name . lower ( ) return list ( mapping[ \" mappings \" ][doc_type][ \" properties \" ] . keys ( ) ) ": 2968,
 "def copy ( self ) : out = type ( self ) ( ) for series in self : out . append ( series . copy ( ) ) return out": 2969,
 "def markdown_to_text ( body ) : # Turn our input into HTML md = markdown . markdown ( body , extensions = [ ' markdown . extensions . extra ' ] ) # Safely parse HTML so that we don ' t have to parse it ourselves soup = BeautifulSoup ( md , ' html . parser ' ) # Return just the text of the parsed HTML return soup . get_text ( ) ": 2970,
 "def HttpResponse401 ( request , template = KEY_AUTH_401_TEMPLATE , content = KEY_AUTH_401_CONTENT , content_type = KEY_AUTH_401_CONTENT_TYPE ) : return AccessFailedResponse ( request , template , content , content_type , status = 401 ) ": 2971,
 "def objectproxy_realaddress ( obj ) : voidp = QROOT . TPython . ObjectProxy_AsVoidPtr ( obj ) return C . addressof ( C . c_char . from_buffer ( voidp ) ) ": 2972,
 "def GetMountpoints ( ) : devices = {} for filesys in GetFileSystems ( ) : devices[filesys . f_mntonname] = ( filesys . f_mntfromname , filesys . f_fstypename ) return devices": 2973,
 "def _GetValue ( self , name ) : for value in self . values : if value . name = = name : return value": 2974,
 "def owner ( self ) : if self . _owner : return self . _owner elif not self . abstract : return self . read_meta ( ) . _owner raise EmptyDocumentException ( ) ": 2975,
 "def is_iterable ( value ) : return isinstance ( value , np . ndarray ) or isinstance ( value , list ) or isinstance ( value , tuple ) , value": 2976,
 "def leaf_nodes ( self ) : # Now contains all nodes that contain dependencies . deps = {item for sublist in self . edges . values ( ) for item in sublist} # contains all nodes *without* any dependencies ( leaf nodes ) return self . nodes - deps": 2977,
 "def check_color ( cls , raw_image ) : # sum ( img . convert ( \" L \" ) . getextrema ( ) ) in ( 0 , 2 ) extrema = raw_image . convert ( \" L \" ) . getextrema ( ) if extrema = = ( 255 , 255 ) : # all white raise cls . MonoImageException": 2978,
 "def findMin ( arr ) : out = np . zeros ( shape = arr . shape , dtype = bool ) _calcMin ( arr , out ) return out": 2979,
 "def get_property ( self , property_name ) : prop = self . find_property ( property_name ) if prop : return prop . get_value ( ) return None": 2980,
 "def byte2int ( s , index = 0 ) : if six . PY2 : return ord ( s[index] ) return s[index]": 2981,
 "def indent ( text , amount , ch = ' ' ) : padding = amount * ch return ' ' . join ( padding+line for line in text . splitlines ( True ) ) ": 2982,
 "def _get_minidom_tag_value ( station , tag_name ) : tag = station . getElementsByTagName ( tag_name ) [0] . firstChild if tag : return tag . nodeValue return None": 2983,
 "def interpolate_slice ( slice_rows , slice_cols , interpolator ) : fine_rows = np . arange ( slice_rows . start , slice_rows . stop , slice_rows . step ) fine_cols = np . arange ( slice_cols . start , slice_cols . stop , slice_cols . step ) return interpolator ( fine_cols , fine_rows ) ": 2984,
 "def _getVirtualScreenRect ( self ) : SM_XVIRTUALSCREEN = 76 # Left of virtual screen SM_YVIRTUALSCREEN = 77 # Top of virtual screen SM_CXVIRTUALSCREEN = 78 # Width of virtual screen SM_CYVIRTUALSCREEN = 79 # Height of virtual screen return ( self . _user32 . GetSystemMetrics ( SM_XVIRTUALSCREEN ) , \\ self . _user32 . GetSystemMetrics ( SM_YVIRTUALSCREEN ) , \\ self . _user32 . GetSystemMetrics ( SM_CXVIRTUALSCREEN ) , \\ self . _user32 . GetSystemMetrics ( SM_CYVIRTUALSCREEN ) ) ": 2985,
 "def resample ( grid , wl , flux ) : flux_rs = ( interpolate . interp1d ( wl , flux ) ) ( grid ) return flux_rs": 2986,
 "def pythonise ( id , encoding = ' ascii ' ) : replace = { ' - ' : ' _ ' , ' : ' : ' _ ' , ' / ' : ' _ ' } func = lambda id , pair : id . replace ( pair[0] , pair[1] ) id = reduce ( func , replace . iteritems ( ) , id ) id = ' _%s ' % id if id[0] in string . digits else id return id . encode ( encoding ) ": 2987,
 "def getEventTypeNameFromEnum ( self , eType ) : fn = self . function_table . getEventTypeNameFromEnum result = fn ( eType ) return result": 2988,
 "def bbox ( img ) : rows = np . any ( img , axis = 1 ) cols = np . any ( img , axis = 0 ) rmin , rmax = np . where ( rows ) [0][[0 , -1]] cmin , cmax = np . where ( cols ) [0][[0 , -1]] return rmin , rmax , cmin , cmax": 2989,
 "def query_proc_row ( procname , args = ( ) , factory = None ) : for row in query_proc ( procname , args , factory ) : return row return None": 2990,
 "def hex_escape ( bin_str ) : printable = string . ascii_letters + string . digits + string . punctuation + ' ' return ' ' . join ( ch if ch in printable else r ' 0x{0 : 02x} ' . format ( ord ( ch ) ) for ch in bin_str ) ": 2991,
 "def get_files ( dir_name ) : return [ ( os . path . join ( ' . ' , d ) , [os . path . join ( d , f ) for f in files] ) for d , _ , files in os . walk ( dir_name ) ]": 2992,
 "def get_highlighted_code ( name , code , type = ' terminal ' ) : import logging try : import pygments pygments except ImportError : return code from pygments import highlight from pygments . lexers import guess_lexer_for_filename , ClassNotFound from pygments . formatters import TerminalFormatter try : lexer = guess_lexer_for_filename ( name , code ) formatter = TerminalFormatter ( ) content = highlight ( code , lexer , formatter ) except ClassNotFound : logging . debug ( \" Couldn ' t guess Lexer , will not use pygments . \" ) content = code return content": 2993,
 "def pretty_xml ( data ) : parsed_string = minidom . parseString ( data . decode ( ' utf-8 ' ) ) return parsed_string . toprettyxml ( indent = ' \\t ' , encoding = ' utf-8 ' ) ": 2994,
 "def get_chunks ( source , chunk_len ) : return ( source[i : i + chunk_len] for i in range ( 0 , len ( source ) , chunk_len ) ) ": 2995,
 "def prepare_path ( path ) : if type ( path ) = = list : return os . path . join ( *path ) return path": 2996,
 "def is_valid_data ( obj ) : if obj : try : tmp = json . dumps ( obj , default = datetime_encoder ) del tmp except ( TypeError , UnicodeDecodeError ) : return False return True": 2997,
 "def _deserialize_datetime ( self , data ) : for key in data : if isinstance ( data[key] , dict ) : if data[key] . get ( ' type ' ) = = ' datetime ' : data[key] = \\ datetime . datetime . fromtimestamp ( data[key][ ' value ' ] ) return data": 2998,
 "def set_float ( val ) : out = None if not val in ( None , ' ' ) : try : out = float ( val ) except ValueError : return None if numpy . isnan ( out ) : out = default return out": 2999,
 "def parse_list ( cls , api , json_list ) : results = [] for json_obj in json_list : if json_obj : obj = cls . parse ( api , json_obj ) results . append ( obj ) return results": 3000,
 "def test ( ) : debuglevel = 0 while sys . argv[1 : ] and sys . argv[1] = = ' -d ' : debuglevel = debuglevel + 1 del sys . argv[1] host = ' localhost ' if sys . argv[1 : ] : host = sys . argv[1] port = 0 if sys . argv[2 : ] : portstr = sys . argv[2] try : port = int ( portstr ) except ValueError : port = socket . getservbyname ( portstr , ' tcp ' ) tn = Telnet ( ) tn . set_debuglevel ( debuglevel ) tn . open ( host , port ) tn . interact ( ) tn . close ( ) ": 3001,
 "def with_headers ( self , headers ) : for key , value in headers . items ( ) : self . with_header ( key , value ) return self": 3002,
 "def normalize_matrix ( matrix ) : abs_matrix = np . abs ( matrix . copy ( ) ) return abs_matrix / abs_matrix . max ( ) ": 3003,
 "def process_result_value ( self , value , dialect ) : if value is not None : value = simplejson . loads ( value ) return value": 3004,
 "def lmx_h1k_f64k ( ) : hparams = lmx_base ( ) hparams . hidden_size = 1024 hparams . filter_size = 65536 hparams . batch_size = 2048 return hparams": 3005,
 "def extend ( self , item ) : if not isinstance ( item , list ) : raise TypeError ( ' You can only extend lists with lists . ' ' You supplied \\ \" %s\\ \" ' % type ( item ) ) for entry in item : if not isinstance ( entry , str ) : raise TypeError ( ' Members of this object must be strings . ' ' You supplied \\ \" %s\\ \" ' % type ( entry ) ) list . append ( self , entry ) ": 3006,
 "def prettifysql ( sql ) : pretty = [] for line in sql . split ( ' \\n ' ) : pretty . extend ( [ \" %s , \\n \" % x for x in line . split ( ' , ' ) ] ) return pretty": 3007,
 "def print_datetime_object ( dt ) : print ( dt ) print ( ' ctime : ' , dt . ctime ( ) ) print ( ' tuple : ' , dt . timetuple ( ) ) print ( ' ordinal : ' , dt . toordinal ( ) ) print ( ' Year : ' , dt . year ) print ( ' Mon : ' , dt . month ) print ( ' Day : ' , dt . day ) ": 3008,
 "def str_time_to_day_seconds ( time ) : t = str ( time ) . split ( ' : ' ) seconds = int ( t[0] ) * 3600 + int ( t[1] ) * 60 + int ( t[2] ) return seconds": 3009,
 "def _first_and_last_element ( arr ) : if isinstance ( arr , np . ndarray ) or hasattr ( arr , ' data ' ) : # numpy array or sparse matrix with . data attribute data = arr . data if sparse . issparse ( arr ) else arr return data . flat[0] , data . flat[-1] else : # Sparse matrices without . data attribute . Only dok_matrix at # the time of writing , in this case indexing is fast return arr[0 , 0] , arr[-1 , -1]": 3010,
 "def load ( cls , fname ) : with open ( fname ) as f : return Config ( **json . load ( f ) ) ": 3011,
 "def show_correlation_matrix ( self , correlation_matrix ) : cr_plot . create_correlation_matrix_plot ( correlation_matrix , self . title , self . headers_to_test ) pyplot . show ( ) ": 3012,
 "def load ( path ) : with open ( path , ' r ' ) as props : properties = Properties . load ( props ) return PushDb ( properties ) ": 3013,
 "def get_height_for_line ( self , lineno ) : if self . wrap_lines : return self . ui_content . get_height_for_line ( lineno , self . window_width ) else : return 1": 3014,
 "def load ( filename ) : if not os . path . exists ( filename ) : LOG . error ( \" load object - File ' %s ' does not exist . \" , filename ) return None obj = None with open ( filename , ' rb ' ) as obj_file : obj = dill . load ( obj_file ) return obj": 3015,
 "def toggle_word_wrap ( self ) : self . setWordWrapMode ( not self . wordWrapMode ( ) and QTextOption . WordWrap or QTextOption . NoWrap ) return True": 3016,
 "async def load_unicode ( reader ) : ivalue = await load_uvarint ( reader ) fvalue = bytearray ( ivalue ) await reader . areadinto ( fvalue ) return str ( fvalue , ' utf8 ' ) ": 3017,
 "def _openResources ( self ) : arr = np . load ( self . _fileName , allow_pickle = ALLOW_PICKLE ) check_is_an_array ( arr ) self . _array = arr": 3018,
 "def load ( self , path ) : with io . open ( path , ' rb ' ) as fin : self . weights = pickle . load ( fin ) ": 3019,
 "def _IsDirectory ( parent , item ) : return tf . io . gfile . isdir ( os . path . join ( parent , item ) ) ": 3020,
 "def elem_find ( self , field , value ) : if isinstance ( value , ( int , float , str ) ) : value = [value] f = list ( self . __dict__[field] ) uid = np . vectorize ( f . index ) ( value ) return self . get_idx ( uid ) ": 3021,
 "def camel_case ( self , snake_case ) : components = snake_case . split ( ' _ ' ) return components[0] + \" \" . join ( x . title ( ) for x in components[1 : ] ) ": 3022,
 "def simple_memoize ( callable_object ) : cache = dict ( ) def wrapper ( *rest ) : if rest not in cache : cache[rest] = callable_object ( *rest ) return cache[rest] return wrapper": 3023,
 "def buttonUp ( self , button = mouse . LEFT ) : self . _lock . acquire ( ) mouse . release ( button ) self . _lock . release ( ) ": 3024,
 "def moving_average ( array , n = 3 ) : ret = _np . cumsum ( array , dtype = float ) ret[n : ] = ret[n : ] - ret[ : -n] return ret[n - 1 : ] / n": 3025,
 "def make_stream_handler ( graph , formatter ) : return { \" class \" : graph . config . logging . stream_handler . class_ , \" formatter \" : formatter , \" level \" : graph . config . logging . level , \" stream \" : graph . config . logging . stream_handler . stream , }": 3026,
 "def GetLoggingLocation ( ) : frame = inspect . currentframe ( ) this_file = frame . f_code . co_filename frame = frame . f_back while frame : if this_file = = frame . f_code . co_filename : if ' cdbg_logging_location ' in frame . f_locals : ret = frame . f_locals[ ' cdbg_logging_location ' ] if len ( ret ) ! = 3 : return ( None , None , None ) return ret frame = frame . f_back return ( None , None , None ) ": 3027,
 "def _set_axis_limits ( self , which , lims , d , scale , reverse = False ) : setattr ( self . limits , which + ' lims ' , lims ) setattr ( self . limits , ' d ' + which , d ) setattr ( self . limits , which + ' scale ' , scale ) if reverse : setattr ( self . limits , ' reverse_ ' + which + ' _axis ' , True ) return": 3028,
 "def osx_clipboard_get ( ) : p = subprocess . Popen ( [ ' pbpaste ' , ' -Prefer ' , ' ascii ' ] , stdout = subprocess . PIPE ) text , stderr = p . communicate ( ) # Text comes in with old Mac \\r line endings . Change them to \\n . text = text . replace ( ' \\r ' , ' \\n ' ) return text": 3029,
 "def colorize ( string , color , *args , **kwargs ) : string = string . format ( *args , **kwargs ) return color + string + colorama . Fore . RESET": 3030,
 "def unpickle_stats ( stats ) : stats = cPickle . loads ( stats ) stats . stream = True return stats": 3031,
 "def set_executable ( filename ) : st = os . stat ( filename ) os . chmod ( filename , st . st_mode | stat . S_IEXEC ) ": 3032,
 "def create_search_url ( self ) : url = ' ? ' for key , value in self . arguments . items ( ) : url + = ' %s = %s& ' % ( quote_plus ( key ) , quote_plus ( value ) ) self . url = url[ : -1] return self . url": 3033,
 "def append_user_agent ( self , user_agent ) : old_ua = self . session . headers . get ( ' User-Agent ' , ' ' ) ua = old_ua + ' ' + user_agent self . session . headers[ ' User-Agent ' ] = ua . strip ( ) ": 3034,
 "def makedirs ( path ) : if not os . path . isdir ( path ) : os . makedirs ( path ) return path": 3035,
 "def server ( port ) : args = [ ' python ' , ' manage . py ' , ' runserver ' ] if port : args . append ( port ) run . main ( args ) ": 3036,
 "def check ( modname ) : for dependency in DEPENDENCIES : if dependency . modname = = modname : return dependency . check ( ) else : raise RuntimeError ( \" Unkwown dependency %s \" % modname ) ": 3037,
 "def generate_dumper ( self , mapfile , names ) : return self . build_template ( mapfile , names , self . _dumpdata_template ) ": 3038,
 "def health_check ( self ) : logger . debug ( ' Health Check on S3 file for : {namespace} ' . format ( namespace = self . namespace ) ) try : self . client . head_object ( Bucket = self . bucket_name , Key = self . data_file ) return True except ClientError as e : logger . debug ( ' Error encountered with S3 . Assume unhealthy ' ) ": 3039,
 "def maxlevel ( lst ) : maxlev = 0 def f ( lst , level ) : nonlocal maxlev if isinstance ( lst , list ) : level + = 1 maxlev = max ( level , maxlev ) for item in lst : f ( item , level ) f ( lst , 0 ) return maxlev": 3040,
 "def peak_memory_usage ( ) : if sys . platform . startswith ( ' win ' ) : p = psutil . Process ( ) return p . memory_info ( ) . peak_wset / 1024 / 1024 mem = resource . getrusage ( resource . RUSAGE_SELF ) . ru_maxrss factor_mb = 1 / 1024 if sys . platform = = ' darwin ' : factor_mb = 1 / ( 1024 * 1024 ) return mem * factor_mb": 3041,
 "def is_clicked ( self , MouseStateType ) : return self . previous_mouse_state . query_state ( MouseStateType ) and ( not self . current_mouse_state . query_state ( MouseStateType ) ) ": 3042,
 "def listunion ( ListOfLists ) : u = [] for s in ListOfLists : if s ! = None : u . extend ( s ) return u": 3043,
 "def _check_for_duplicate_sequence_names ( self , fasta_file_path ) : found_sequence_names = set ( ) for record in SeqIO . parse ( fasta_file_path , ' fasta ' ) : name = record . name if name in found_sequence_names : return name found_sequence_names . add ( name ) return False": 3044,
 "def dict_merge ( set1 , set2 ) : return dict ( list ( set1 . items ( ) ) + list ( set2 . items ( ) ) ) ": 3045,
 "def alter_change_column ( self , table , column , field ) : return self . _update_column ( table , column , lambda a , b : b ) ": 3046,
 "def update_loan_entry ( database , entry ) : entry = clean_entry ( entry ) database . loans . update ( { ' recordID ' : entry[ ' recordID ' ]} , { ' $set ' : entry} , upsert = True ) ": 3047,
 "def json_obj_to_cursor ( self , json ) : cursor = json_util . loads ( json ) if \" id \" in json : cursor[ \" _id \" ] = ObjectId ( cursor[ \" id \" ] ) del cursor[ \" id \" ] return cursor": 3048,
 "def check_permission_safety ( path ) : f_stats = os . stat ( path ) return ( f_stats . st_mode & ( stat . S_IRWXG | stat . S_IRWXO ) ) = = 0 and f_stats . st_uid = = os . getuid ( ) ": 3049,
 "def erase ( self ) : with self . _at_last_line ( ) : self . stream . write ( self . _term . clear_eol ) self . stream . flush ( ) ": 3050,
 "def set_cursor ( self , x , y ) : curses . curs_set ( 1 ) self . screen . move ( y , x ) ": 3051,
 "def close ( self ) : if self . db is not None : self . db . commit ( ) self . db . close ( ) self . db = None return": 3052,
 "def compute_partition_size ( result , processes ) : try : return max ( math . ceil ( len ( result ) / processes ) , 1 ) except TypeError : return 1": 3053,
 "def __iadd__ ( self , other_model ) : warn ( ' use model . merge instead ' , DeprecationWarning ) return self . merge ( other_model , objective = ' sum ' , inplace = True ) ": 3054,
 "def machine_info ( ) : import psutil BYTES_IN_GIG = 1073741824 . 0 free_bytes = psutil . virtual_memory ( ) . total return [{ \" memory \" : float ( \" % . 1f \" % ( free_bytes / BYTES_IN_GIG ) ) , \" cores \" : multiprocessing . cpu_count ( ) , \" name \" : socket . gethostname ( ) }]": 3055,
 "def is_value_type_valid_for_exact_conditions ( self , value ) : # No need to check for bool since bool is a subclass of int if isinstance ( value , string_types ) or isinstance ( value , ( numbers . Integral , float ) ) : return True return False": 3056,
 "def _root ( self ) : _n = self while _n . parent : _n = _n . parent return _n": 3057,
 "def pair_strings_sum_formatter ( a , b ) : if b[ : 1] = = \" - \" : return \" {0} - {1} \" . format ( a , b[1 : ] ) return \" {0} + {1} \" . format ( a , b ) ": 3058,
 "def drop_all_tables ( self ) : for table_name in self . table_names ( ) : self . execute_sql ( \" DROP TABLE %s \" % table_name ) self . connection . commit ( ) ": 3059,
 "def Cinv ( self ) : try : return np . linalg . inv ( self . c ) except np . linalg . linalg . LinAlgError : print ( ' Warning : non-invertible noise covariance matrix c . ' ) return np . eye ( self . c . shape[0] ) ": 3060,
 "def _method_scope ( input_layer , name ) : global _in_method_scope # pylint : disable = protected-access with input_layer . g . as_default ( ) , \\ scopes . var_and_name_scope ( None if _in_method_scope else input_layer . _scope ) , \\ scopes . var_and_name_scope ( ( name , None ) ) as ( scope , var_scope ) : was_in_method_scope = _in_method_scope yield scope , var_scope _in_method_scope = was_in_method_scope": 3061,
 "def is_serializable ( obj ) : if inspect . isclass ( obj ) : return Serializable . is_serializable_type ( obj ) return isinstance ( obj , Serializable ) or hasattr ( obj , ' _asdict ' ) ": 3062,
 "def Pyramid ( pos = ( 0 , 0 , 0 ) , s = 1 , height = 1 , axis = ( 0 , 0 , 1 ) , c = \" dg \" , alpha = 1 ) : return Cone ( pos , s , height , axis , c , alpha , 4 ) ": 3063,
 "def run ( self ) : try : import nose arguments = [sys . argv[0]] + list ( self . test_args ) return nose . run ( argv = arguments ) except ImportError : print ( ) print ( \" *** Nose library missing . Please install it . *** \" ) print ( ) raise": 3064,
 "def get_wordnet_syns ( word ) : synonyms = [] regex = r \" _ \" pat = re . compile ( regex ) synset = nltk . wordnet . wordnet . synsets ( word ) for ss in synset : for swords in ss . lemma_names : synonyms . append ( pat . sub ( \" \" , swords . lower ( ) ) ) synonyms = f7 ( synonyms ) return synonyms": 3065,
 "def vals2bins ( vals , res = 100 ) : # flatten if list of lists if any ( isinstance ( el , list ) for el in vals ) : vals = list ( itertools . chain ( *vals ) ) return list ( np . digitize ( vals , np . linspace ( np . min ( vals ) , np . max ( vals ) +1 , res+1 ) ) - 1 ) ": 3066,
 "def _decode_request ( self , encoded_request ) : obj = self . serializer . loads ( encoded_request ) return request_from_dict ( obj , self . spider ) ": 3067,
 "def unit_vector ( x ) : y = np . array ( x , dtype = ' float ' ) return y/norm ( y ) ": 3068,
 "def register_type ( cls , name ) : x = TypeDefinition ( name , ( cls , ) , ( ) ) Validator . types_mapping[name] = x": 3069,
 "def pairwise_indices ( self ) : return np . array ( [sig . pairwise_indices for sig in self . values] ) . T": 3070,
 "def printmp ( msg ) : filler = ( 80 - len ( msg ) ) * ' ' print ( msg + filler , end = ' \\r ' ) sys . stdout . flush ( ) ": 3071,
 "def _numpy_bytes_to_char ( arr ) : # ensure the array is contiguous arr = np . array ( arr , copy = False , order = ' C ' , dtype = np . string_ ) return arr . reshape ( arr . shape + ( 1 , ) ) . view ( ' S1 ' ) ": 3072,
 "def delete ( self , row ) : i = self . _get_key_index ( row ) del self . keys[i]": 3073,
 "def _sanitize ( text ) : d = { ' -LRB- ' : ' ( ' , ' -RRB- ' : ' ) ' } return re . sub ( ' | ' . join ( d . keys ( ) ) , lambda m : d[m . group ( 0 ) ] , text ) ": 3074,
 "def read_mm_header ( fd , byte_order , dtype , count ) : return numpy . rec . fromfile ( fd , MM_HEADER , 1 , byteorder = byte_order ) [0]": 3075,
 "def as_html ( self ) : if not self . _folium_map : self . draw ( ) return self . _inline_map ( self . _folium_map , self . _width , self . _height ) ": 3076,
 "def name ( self ) : return ' ' . join ( ' _%s ' % c if c . isupper ( ) else c for c in self . __class__ . __name__ ) . strip ( ' _ ' ) . lower ( ) ": 3077,
 "def _is_date_data ( self , data_type ) : dt = DATA_TYPES[data_type] if isinstance ( self . data , dt[ ' type ' ] ) : self . type = data_type . upper ( ) self . len = None return True": 3078,
 "def part ( z , s ) : r if sage_included : if s = = 1 : return np . real ( z ) elif s = = -1 : return np . imag ( z ) elif s = = 0 : return z else : if s = = 1 : return z . real elif s = = -1 : return z . imag elif s = = 0 : return z": 3079,
 "def seq_include ( records , filter_regex ) : regex = re . compile ( filter_regex ) for record in records : if regex . search ( str ( record . seq ) ) : yield record": 3080,
 "def get_image ( self , source ) : buf = StringIO ( source . read ( ) ) return Image . open ( buf ) ": 3081,
 "def tokenize_words ( self , text ) : return [ self . strip_punctuation ( word ) for word in text . split ( ' ' ) if self . strip_punctuation ( word ) ]": 3082,
 "def GaussianBlur ( X , ksize_width , ksize_height , sigma_x , sigma_y ) : return image_transform ( X , cv2 . GaussianBlur , ksize = ( ksize_width , ksize_height ) , sigmaX = sigma_x , sigmaY = sigma_y ) ": 3083,
 "def zoom_cv ( x , z ) : if z = = 0 : return x r , c , *_ = x . shape M = cv2 . getRotationMatrix2D ( ( c/2 , r/2 ) , 0 , z+1 . ) return cv2 . warpAffine ( x , M , ( c , r ) ) ": 3084,
 "def warp ( self , warp_matrix , img , iflag = cv2 . INTER_NEAREST ) : height , width = img . shape[ : 2] warped_img = np . zeros_like ( img , dtype = img . dtype ) # Check if image to warp is 2D or 3D . If 3D need to loop over channels if ( self . interpolation_type = = InterpolationType . LINEAR ) or img . ndim = = 2 : warped_img = cv2 . warpAffine ( img . astype ( np . float32 ) , warp_matrix , ( width , height ) , flags = iflag ) . astype ( img . dtype ) elif img . ndim = = 3 : for idx in range ( img . shape[-1] ) : warped_img[ . . . , idx] = cv2 . warpAffine ( img[ . . . , idx] . astype ( np . float32 ) , warp_matrix , ( width , height ) , flags = iflag ) . astype ( img . dtype ) else : raise ValueError ( ' Image has incorrect number of dimensions : {} ' . format ( img . ndim ) ) return warped_img": 3085,
 "def __exit__ ( self , type , value , traceback ) : if not self . asarfile : return self . asarfile . close ( ) self . asarfile = None": 3086,
 "def set_stop_handler ( self ) : signal . signal ( signal . SIGTERM , self . graceful_stop ) signal . signal ( signal . SIGABRT , self . graceful_stop ) signal . signal ( signal . SIGINT , self . graceful_stop ) ": 3087,
 "def get_table_metadata ( engine , table ) : metadata = MetaData ( ) metadata . reflect ( bind = engine , only = [table] ) table_metadata = Table ( table , metadata , autoload = True ) return table_metadata": 3088,
 "def _import ( module , cls ) : global Scanner try : cls = str ( cls ) mod = __import__ ( str ( module ) , globals ( ) , locals ( ) , [cls] , 1 ) Scanner = getattr ( mod , cls ) except ImportError : pass": 3089,
 "def autopage ( self ) : while self . items : yield from self . items self . items = self . fetch_next ( ) ": 3090,
 "def find ( command , on ) : output_lines = parse_man_page ( command , on ) click . echo ( ' ' . join ( output_lines ) ) ": 3091,
 "def FromString ( self , string ) : if string . lower ( ) in ( \" false \" , \" no \" , \" n \" ) : return False if string . lower ( ) in ( \" true \" , \" yes \" , \" y \" ) : return True raise TypeValueError ( \" %s is not recognized as a boolean value . \" % string ) ": 3092,
 "def to_datetime ( value ) : if value is None : return None if isinstance ( value , six . integer_types ) : return parser . parse ( value ) return parser . isoparse ( value ) ": 3093,
 "def word_to_id ( self , word ) : if word in self . vocab : return self . vocab[word] else : return self . unk_id": 3094,
 "def run ( args ) : raw_arguments = get_arguments ( args[1 : ] ) process_arguments ( raw_arguments ) walk . run ( ) return True": 3095,
 "def reload_localzone ( ) : global _cache_tz _cache_tz = pytz . timezone ( get_localzone_name ( ) ) utils . assert_tz_offset ( _cache_tz ) return _cache_tz": 3096,
 "def OnPasteAs ( self , event ) : data = self . main_window . clipboard . get_clipboard ( ) key = self . main_window . grid . actions . cursor with undo . group ( _ ( \" Paste As . . . \" ) ) : self . main_window . actions . paste_as ( key , data ) self . main_window . grid . ForceRefresh ( ) event . Skip ( ) ": 3097,
 "def getoutput_pexpect ( self , cmd ) : try : return pexpect . run ( self . sh , args = [ ' -c ' , cmd] ) . replace ( ' \\r\\n ' , ' \\n ' ) except KeyboardInterrupt : print ( ' ^C ' , file = sys . stderr , end = ' ' ) ": 3098,
 "def get_stripped_file_lines ( filename ) : try : lines = open ( filename ) . readlines ( ) except FileNotFoundError : fatal ( \" Could not open file : {!r} \" . format ( filename ) ) return [line . strip ( ) for line in lines]": 3099,
 "def unpickle ( pickle_file ) : pickle = None with open ( pickle_file , \" rb \" ) as pickle_f : pickle = dill . load ( pickle_f ) if not pickle : LOG . error ( \" Could not load python object from file \" ) return pickle": 3100,
 "def get ( ) : result = runCommand ( ' facter --json ' , raise_error_on_fail = True ) json_facts = result[1] facts = json . loads ( json_facts ) return facts": 3101,
 "def highlight_region ( plt , start_x , end_x ) : start_x = convert_to_mdate ( start_x ) end_x = convert_to_mdate ( end_x ) plt . axvspan ( start_x , end_x , color = CONSTANTS . HIGHLIGHT_COLOR , alpha = CONSTANTS . HIGHLIGHT_ALPHA ) ": 3102,
 "def load_search_freq ( fp = SEARCH_FREQ_JSON ) : try : with open ( fp ) as f : return Counter ( json . load ( f ) ) except FileNotFoundError : return Counter ( ) ": 3103,
 "def barv ( d , plt , title = None , rotation = ' vertical ' ) : labels = sorted ( d , key = d . get , reverse = True ) index = range ( len ( labels ) ) plt . xticks ( index , labels , rotation = rotation ) plt . bar ( index , [d[v] for v in labels] ) if title is not None : plt . title ( title ) ": 3104,
 "def blocking ( func , *args , **kwargs ) : pool = get_io_pool ( ) fut = pool . submit ( func , *args , **kwargs ) return fut . result ( ) ": 3105,
 "def get_longest_orf ( orfs ) : sorted_orf = sorted ( orfs , key = lambda x : len ( x[ ' sequence ' ] ) , reverse = True ) [0] return sorted_orf": 3106,
 "def _next_token ( self , skipws = True ) : self . _token = next ( self . _tokens ) . group ( 0 ) return self . _next_token ( ) if skipws and self . _token . isspace ( ) else self . _token": 3107,
 "def Print ( self , output_writer ) : if self . _filters : output_writer . Write ( ' Filters : \\n ' ) for file_entry_filter in self . _filters : file_entry_filter . Print ( output_writer ) ": 3108,
 "def __call__ ( self , _ ) : if self . iter % self . step = = 0 : print ( self . fmt . format ( self . iter ) , **self . kwargs ) self . iter + = 1": 3109,
 "def print_bintree ( tree , indent = ' ' ) : for n in sorted ( tree . keys ( ) ) : print \" %s%s \" % ( indent * depth ( n , tree ) , n ) ": 3110,
 "def parse_cookies ( self , req , name , field ) : return core . get_value ( req . COOKIES , name , field ) ": 3111,
 "def cycle_focus ( self ) : windows = self . windows ( ) new_index = ( windows . index ( self . active_window ) + 1 ) % len ( windows ) self . active_window = windows[new_index]": 3112,
 "def __call__ ( self , _ ) : if self . iter % self . step = = 0 : self . pbar . update ( self . step ) self . iter + = 1": 3113,
 "def int32_to_negative ( int32 ) : dct = {} if int32 = = 4294967295 : # Special case in some structures ( note , this is just a workaround ) return -1 for i in range ( -1000 , -1 ) : dct[np . uint32 ( i ) ] = i if int32 in dct : return dct[int32] else : return int32": 3114,
 "def acknowledge_time ( self ) : if ( self . is_acknowledged and self . _proto . acknowledgeInfo . HasField ( ' acknowledgeTime ' ) ) : return parse_isostring ( self . _proto . acknowledgeInfo . acknowledgeTime ) return None": 3115,
 "def use_theme ( theme ) : global current current = theme import scene if scene . current is not None : scene . current . stylize ( ) ": 3116,
 "def packagenameify ( s ) : return ' ' . join ( w if w in ACRONYMS else w . title ( ) for w in s . split ( ' . ' ) [-1 : ] ) ": 3117,
 "def store_many ( self , sql , values ) : cursor = self . get_cursor ( ) cursor . executemany ( sql , values ) self . conn . commit ( ) ": 3118,
 "def hide ( self ) : if not HidePrevention ( self . window ) . may_hide ( ) : return self . hidden = True self . get_widget ( ' window-root ' ) . unstick ( ) self . window . hide ( ) ": 3119,
 "def isBlockComment ( self , line , column ) : return self . _highlighter is not None and \\ self . _highlighter . isBlockComment ( self . document ( ) . findBlockByNumber ( line ) , column ) ": 3120,
 "def handle_qbytearray ( obj , encoding ) : if isinstance ( obj , QByteArray ) : obj = obj . data ( ) return to_text_string ( obj , encoding = encoding ) ": 3121,
 "def _obj_cursor_to_dictionary ( self , cursor ) : if not cursor : return cursor cursor = json . loads ( json . dumps ( cursor , cls = BSONEncoder ) ) if cursor . get ( \" _id \" ) : cursor[ \" id \" ] = cursor . get ( \" _id \" ) del cursor[ \" _id \" ] return cursor": 3122,
 "def get_range ( self , start = None , stop = None ) : \t\t\t\treturn self . from_iterable ( self . ranges ( start , stop ) ) ": 3123,
 "def LinSpace ( start , stop , num ) : return np . linspace ( start , stop , num = num , dtype = np . float32 ) , ": 3124,
 "def _ratelimited_get ( self , *args , **kwargs ) : with self . _ratelimiter : resp = self . session . get ( *args , **kwargs ) # It ' s possible that Space-Track will return HTTP status 500 with a # query rate limit violation . This can happen if a script is cancelled # before it has finished sleeping to satisfy the rate limit and it is # started again . # # Let ' s catch this specific instance and retry once if it happens . if resp . status_code = = 500 : # Let ' s only retry if the error page tells us it ' s a rate limit # violation . if ' violated your query rate limit ' in resp . text : # Mimic the RateLimiter callback behaviour . until = time . time ( ) + self . _ratelimiter . period t = threading . Thread ( target = self . _ratelimit_callback , args = ( until , ) ) t . daemon = True t . start ( ) time . sleep ( self . _ratelimiter . period ) # Now retry with self . _ratelimiter : resp = self . session . get ( *args , **kwargs ) return resp": 3125,
 "def close ( self ) : if self . _subprocess is not None : os . killpg ( self . _subprocess . pid , signal . SIGTERM ) self . _subprocess = None": 3126,
 "def split_comment ( cls , code ) : if ' # ' not in code : return code # : Remove comments only ( leave quoted strings as they are ) subf = lambda m : ' ' if m . group ( 0 ) [0] = = ' # ' else m . group ( 0 ) return re . sub ( cls . re_pytokens , subf , code ) ": 3127,
 "def scale_image ( image , new_width ) : ( original_width , original_height ) = image . size aspect_ratio = original_height/float ( original_width ) new_height = int ( aspect_ratio * new_width ) # This scales it wider than tall , since characters are biased new_image = image . resize ( ( new_width*2 , new_height ) ) return new_image": 3128,
 "def readme ( ) : try : import pypandoc readme_content = pypandoc . convert ( ' README . md ' , ' rst ' ) except ( IOError , ImportError ) : print ( \" Warning : no pypandoc module found . \" ) try : readme_content = open ( ' README . md ' ) . read ( ) except IOError : readme_content = ' ' return readme_content": 3129,
 "def _fast_read ( self , infile ) : infile . seek ( 0 ) return ( int ( infile . read ( ) . decode ( ) . strip ( ) ) ) ": 3130,
 "def _read_json_file ( self , json_file ) : self . log . debug ( \" Reading ' %s ' JSON file . . . \" % json_file ) with open ( json_file , ' r ' ) as f : return json . load ( f , object_pairs_hook = OrderedDict ) ": 3131,
 "def get_list_from_file ( file_name ) : with open ( file_name , mode = ' r ' , encoding = ' utf-8 ' ) as f1 : lst = f1 . readlines ( ) return lst": 3132,
 "def kick ( self , channel , nick , comment = \" \" ) : self . send_items ( ' KICK ' , channel , nick , comment and ' : ' + comment ) ": 3133,
 "def read_data ( file , endian , num = 1 ) : res = struct . unpack ( endian + ' L ' * num , file . read ( num * 4 ) ) if len ( res ) = = 1 : return res[0] return res": 3134,
 "def hstrlen ( self , name , key ) : with self . pipe as pipe : return pipe . hstrlen ( self . redis_key ( name ) , key ) ": 3135,
 "def get_default_preds ( ) : g = ontospy . Ontospy ( rdfsschema , text = True , verbose = False , hide_base_schemas = False ) classes = [ ( x . qname , x . bestDescription ( ) ) for x in g . all_classes] properties = [ ( x . qname , x . bestDescription ( ) ) for x in g . all_properties] commands = [ ( ' exit ' , ' exits the terminal ' ) , ( ' show ' , ' show current buffer ' ) ] return rdfschema + owlschema + classes + properties + commands": 3136,
 "def changed ( self ) : return dict ( ( field , self . previous ( field ) ) for field in self . fields if self . has_changed ( field ) ) ": 3137,
 "def _get_info ( self , host , port , unix_socket , auth ) : client = self . _client ( host , port , unix_socket , auth ) if client is None : return None info = client . info ( ) del client return info": 3138,
 "def extract_table_names ( query ) : # a good old fashioned regex . turns out this worked better than actually parsing the code tables_blocks = re . findall ( r ' ( ? : FROM|JOIN ) \\s+ ( \\w+ ( ? : \\s* , \\s*\\w+ ) * ) ' , query , re . IGNORECASE ) tables = [tbl for block in tables_blocks for tbl in re . findall ( r ' \\w+ ' , block ) ] return set ( tables ) ": 3139,
 "def _npiter ( arr ) : for a in np . nditer ( arr , flags = [ \" refs_ok \" ] ) : c = a . item ( ) if c is not None : yield c": 3140,
 "def pages ( self ) : rev = self . db . get ( ' site : rev ' ) if int ( rev ) ! = self . revision : self . reload_site ( ) return self . _pages": 3141,
 "def logx_linear ( x , a , b ) : x = np . log ( x ) return a*x + b": 3142,
 "def get_cube ( name ) : manager = get_manager ( ) if not manager . has_cube ( name ) : raise NotFound ( ' No such cube : %r ' % name ) return manager . get_cube ( name ) ": 3143,
 "def mark ( self , lineno , count = 1 ) : self . sourcelines[lineno] = self . sourcelines . get ( lineno , 0 ) + count": 3144,
 "def dedupFasta ( reads ) : seen = set ( ) add = seen . add for read in reads : hash_ = md5 ( read . sequence . encode ( ' UTF-8 ' ) ) . digest ( ) if hash_ not in seen : add ( hash_ ) yield read": 3145,
 "def pop ( self , key ) : if key in self . _keys : self . _keys . remove ( key ) super ( ListDict , self ) . pop ( key ) ": 3146,
 "def isolate_element ( self , x ) : members = list ( self . members ( x ) ) self . delete_set ( x ) self . union ( * ( v for v in members if v ! = x ) ) ": 3147,
 "def focusInEvent ( self , event ) : self . focus_changed . emit ( ) return super ( ControlWidget , self ) . focusInEvent ( event ) ": 3148,
 "def __pop_top_frame ( self ) : popped = self . __stack . pop ( ) if self . __stack : self . __stack[-1] . process_subframe ( popped ) ": 3149,
 "def close_stream ( self ) : \t\t\t\tself . keep_listening = False\t\tself . stream . stop ( ) \t\tself . stream . close ( ) ": 3150,
 "def strip_html ( string , keep_tag_content = False ) : r = HTML_TAG_ONLY_RE if keep_tag_content else HTML_RE return r . sub ( ' ' , string ) ": 3151,
 "def print_log ( text , *colors ) : sys . stderr . write ( sprint ( \" {} : {} \" . format ( script_name , text ) , *colors ) + \" \\n \" ) ": 3152,
 "def remove_property ( self , key = None , value = None ) : for k , v in self . properties[ : ] : if ( key is None or key = = k ) and ( value is None or value = = v ) : del ( self . properties[self . properties . index ( ( k , v ) ) ] ) ": 3153,
 "def fail_print ( error ) : print ( COLORS . fail , error . message , COLORS . end ) print ( COLORS . fail , error . errors , COLORS . end ) ": 3154,
 "def generic_add ( a , b ) : print logger . info ( ' Called generic_add ( {} , {} ) ' . format ( a , b ) ) return a + b": 3155,
 "def pretty_print_post ( req ) : print ( ( ' {}\\n{}\\n{}\\n\\n{} ' . format ( ' -----------START----------- ' , req . method + ' ' + req . url , ' \\n ' . join ( ' {} : {} ' . format ( k , v ) for k , v in list ( req . headers . items ( ) ) ) , req . body , ) ) ) ": 3156,
 "def object_type_repr ( obj ) : if obj is None : return ' None ' elif obj is Ellipsis : return ' Ellipsis ' if obj . __class__ . __module__ = = ' __builtin__ ' : name = obj . __class__ . __name__ else : name = obj . __class__ . __module__ + ' . ' + obj . __class__ . __name__ return ' %s object ' % name": 3157,
 "def __call__ ( self , r ) : r . headers[ ' Authorization ' ] = ' JWT {jwt} ' . format ( jwt = self . token ) return r": 3158,
 "def head ( self , path , query = None , data = None , redirects = True ) : return self . request ( ' HEAD ' , path , query , None , redirects ) ": 3159,
 "def session ( self ) : self . _session = requests . session ( ) yield self . _session . close ( ) self . _session = None": 3160,
 "def Exponential ( x , a , tau , y0 ) : return np . exp ( x / tau ) * a + y0": 3161,
 "def send_post ( self , url , data , remove_header = None ) : return self . send_request ( method = \" post \" , url = url , data = data , remove_header = remove_header ) ": 3162,
 "def inverseHistogram ( hist , bin_range ) : data = hist . astype ( float ) / np . min ( hist[np . nonzero ( hist ) ] ) new_data = np . empty ( shape = np . sum ( data , dtype = int ) ) i = 0 xvals = np . linspace ( bin_range[0] , bin_range[1] , len ( data ) ) for d , x in zip ( data , xvals ) : new_data[i : i + d] = x i + = int ( d ) return new_data": 3163,
 "async def set_http_proxy ( cls , url : typing . Optional[str] ) : await cls . set_config ( \" http_proxy \" , \" \" if url is None else url ) ": 3164,
 "def get_db_version ( session ) : value = session . query ( ProgramInformation . value ) . filter ( ProgramInformation . name = = \" db_version \" ) . scalar ( ) return int ( value ) ": 3165,
 "def _rnd_datetime ( self , start , end ) : return self . from_utctimestamp ( random . randint ( int ( self . to_utctimestamp ( start ) ) , int ( self . to_utctimestamp ( end ) ) , ) ) ": 3166,
 "def __getattr__ ( self , name ) : try : return self . __dict__[name] except KeyError : if hasattr ( self . _properties , name ) : return getattr ( self . _properties , name ) ": 3167,
 "def stats ( self ) : import ns1 . rest . stats return ns1 . rest . stats . Stats ( self . config ) ": 3168,
 "def restore_default_settings ( ) : global __DEFAULTS __DEFAULTS . CACHE_DIR = defaults . CACHE_DIR __DEFAULTS . SET_SEED = defaults . SET_SEED __DEFAULTS . SEED = defaults . SEED logging . info ( ' Settings reverted to their default values . ' ) ": 3169,
 "def set_mem_per_proc ( self , mem_mb ) : super ( ) . set_mem_per_proc ( mem_mb ) self . qparams[ \" mem_per_cpu \" ] = self . mem_per_proc": 3170,
 "def logout ( ) : flogin . logout_user ( ) next = flask . request . args . get ( ' next ' ) return flask . redirect ( next or flask . url_for ( \" user \" ) ) ": 3171,
 "def dict_pick ( dictionary , allowed_keys ) : return {key : value for key , value in viewitems ( dictionary ) if key in allowed_keys}": 3172,
 "def click ( self ) : try : self . wait_until_clickable ( ) . web_element . click ( ) except StaleElementReferenceException : # Retry if element has changed self . web_element . click ( ) return self": 3173,
 "def standard_db_name ( file_column_name ) : found = id_re . findall ( file_column_name ) if not found : return file_column_name return ' _ ' . join ( x[0] . lower ( ) for x in found ) ": 3174,
 "def edge_index ( self ) : return dict ( ( edge , index ) for index , edge in enumerate ( self . edges ) ) ": 3175,
 "def remove_instance ( self , item ) : self . instances . remove ( item ) self . remove_item ( item ) ": 3176,
 "def success_response ( **data ) : data_out = {} data_out[ \" status \" ] = \" success \" data_out . update ( data ) js = dumps ( data_out , default = date_handler ) return Response ( js , status = 200 , mimetype = \" application/json \" ) ": 3177,
 "def copy_to_temp ( object ) : temp_file = NamedTemporaryFile ( delete = False ) _copy_and_close ( object , temp_file ) return temp_file . name": 3178,
 "def get_short_url ( self ) : return reverse ( ' post_short_url ' , args = ( self . forum . slug , self . slug , self . id ) ) ": 3179,
 "def text_cleanup ( data , key , last_type ) : if key in data and last_type = = STRING_TYPE : data[key] = data[key] . strip ( ) return data": 3180,
 "def replace ( s , replace ) : for r in replace : s = s . replace ( *r ) return s": 3181,
 "def convert ( name ) : s1 = re . sub ( ' ( . ) ( [A-Z][a-z]+ ) ' , r ' \\1_\\2 ' , name ) return re . sub ( ' ( [a-z0-9] ) ( [A-Z] ) ' , r ' \\1_\\2 ' , s1 ) . lower ( ) ": 3182,
 "def to_comment ( value ) : if value is None : return if len ( value . split ( ' \\n ' ) ) = = 1 : return \" * \" + value else : return ' \\n ' . join ( [ ' * ' + l for l in value . split ( ' \\n ' ) [ : -1]] ) ": 3183,
 "def str_from_file ( path ) : with open ( path ) as f : s = f . read ( ) . strip ( ) return s": 3184,
 "def stop_server ( self ) : self . stop = True while self . task_count : time . sleep ( END_RESP ) self . terminate = True": 3185,
 "def is_writable_by_others ( filename ) : mode = os . stat ( filename ) [stat . ST_MODE] return mode & stat . S_IWOTH": 3186,
 "def write ( self ) : with open ( self . path , ' w ' ) as file_ : file_ . write ( self . content ) ": 3187,
 "def _summarize_object_type ( model ) : # the fields for the service ' s model model_fields = {field . name : field for field in list ( model . fields ( ) ) } # summarize the model return { ' fields ' : [{ ' name ' : key , ' type ' : type ( convert_peewee_field ( value ) ) . __name__ } for key , value in model_fields . items ( ) ] }": 3188,
 "def fetch_hg_push_log ( repo_name , repo_url ) : newrelic . agent . add_custom_parameter ( \" repo_name \" , repo_name ) process = HgPushlogProcess ( ) process . run ( repo_url + ' /json-pushes/?full = 1&version = 2 ' , repo_name ) ": 3189,
 "def main ( ) : setup_main_logger ( console = True , file_logging = False ) params = argparse . ArgumentParser ( description = \" Averages parameters from multiple models . \" ) arguments . add_average_args ( params ) args = params . parse_args ( ) average_parameters ( args ) ": 3190,
 "def update_cursor_position ( self , line , index ) : value = ' Line {} , Col {} ' . format ( line + 1 , index + 1 ) self . set_value ( value ) ": 3191,
 "def demo ( quiet , shell , speed , prompt , commentecho ) : run ( DEMO , shell = shell , speed = speed , test_mode = TESTING , prompt_template = prompt , quiet = quiet , commentecho = commentecho , ) ": 3192,
 "def scroll_element_into_view ( self ) : x = self . web_element . location[ ' x ' ] y = self . web_element . location[ ' y ' ] self . driver . execute_script ( ' window . scrollTo ( {0} , {1} ) ' . format ( x , y ) ) return self": 3193,
 "def na_if ( series , *values ) : series = pd . Series ( series ) series[series . isin ( values ) ] = np . nan return series": 3194,
 "def getcolslice ( self , blc , trc , inc = [] , startrow = 0 , nrow = -1 , rowincr = 1 ) : return self . _table . getcolslice ( self . _column , blc , trc , inc , startrow , nrow , rowincr ) ": 3195,
 "def ylim ( self , low , high , index = 1 ) : self . layout[ ' yaxis ' + str ( index ) ][ ' range ' ] = [low , high] return self": 3196,
 "def grow_slice ( slc , size ) : return slice ( max ( 0 , slc . start-1 ) , min ( size , slc . stop+1 ) ) ": 3197,
 "def sort_data ( x , y ) : xy = sorted ( zip ( x , y ) ) x , y = zip ( *xy ) return x , y": 3198,
 "def _split_arrs ( array_2d , slices ) : if len ( array_2d ) = = 0 : return np . empty ( 0 , dtype = np . object ) rtn = np . empty ( len ( slices ) + 1 , dtype = np . object ) start = 0 for i , s in enumerate ( slices ) : rtn[i] = array_2d[start : s] start = s rtn[-1] = array_2d[start : ] return rtn": 3199,
 "def ynticks ( self , nticks , index = 1 ) : self . layout[ ' yaxis ' + str ( index ) ][ ' nticks ' ] = nticks return self": 3200,
 "def empty ( self , start = None , stop = None ) : \t\t\t\tself . set ( NOT_SET , start = start , stop = stop ) ": 3201,
 "def linebuffered_stdout ( ) : if sys . stdout . line_buffering : return sys . stdout orig = sys . stdout new = type ( orig ) ( orig . buffer , encoding = orig . encoding , errors = orig . errors , line_buffering = True ) new . mode = orig . mode return new": 3202,
 "def main ( argv , version = DEFAULT_VERSION ) : tarball = download_setuptools ( ) _install ( tarball , _build_install_args ( argv ) ) ": 3203,
 "def _sha1_for_file ( filename ) : with open ( filename , \" rb \" ) as fileobj : contents = fileobj . read ( ) return hashlib . sha1 ( contents ) . hexdigest ( ) ": 3204,
 "def sha1 ( s ) : h = hashlib . new ( ' sha1 ' ) h . update ( s ) return h . hexdigest ( ) ": 3205,
 "def from_years_range ( start_year , end_year ) : start = datetime . date ( start_year , 1 , 1 ) end = datetime . date ( end_year , 12 , 31 ) return DateRange ( start , end ) ": 3206,
 "def has_virtualenv ( self ) : with self . settings ( warn_only = True ) : ret = self . run_or_local ( ' which virtualenv ' ) . strip ( ) return bool ( ret ) ": 3207,
 "def timed_call ( func , *args , log_level = ' DEBUG ' , **kwargs ) : start = time ( ) r = func ( *args , **kwargs ) t = time ( ) - start log ( log_level , \" Call to ' {} ' took { : 0 . 6f}s \" . format ( func . __name__ , t ) ) return r": 3208,
 "def display_pil_image ( im ) : from IPython . core import display b = BytesIO ( ) im . save ( b , format = ' png ' ) data = b . getvalue ( ) ip_img = display . Image ( data = data , format = ' png ' , embed = True ) return ip_img . _repr_png_ ( ) ": 3209,
 "def signal_handler ( signal_name , frame ) : sys . stdout . flush ( ) print ( \" \\nSIGINT in frame signal received . Quitting . . . \" ) sys . stdout . flush ( ) sys . exit ( 0 ) ": 3210,
 "def update_one ( self , query , doc ) : if self . table is None : self . build_table ( ) if u \" $set \" in doc : doc = doc[u \" $set \" ] allcond = self . parse_query ( query ) try : result = self . table . update ( doc , allcond ) except : # TODO : check table . update result # check what pymongo does in that case result = None return UpdateResult ( raw_result = result ) ": 3211,
 "def unescape_all ( string ) : def escape_single ( matchobj ) : return _unicode_for_entity_with_name ( matchobj . group ( 1 ) ) return entities . sub ( escape_single , string ) ": 3212,
 "def log_request ( self , code = ' - ' , size = ' - ' ) : if self . server . logRequests : BaseHTTPServer . BaseHTTPRequestHandler . log_request ( self , code , size ) ": 3213,
 "def calculate_size ( name , timeout ) : data_size = 0 data_size + = calculate_size_str ( name ) data_size + = LONG_SIZE_IN_BYTES return data_size": 3214,
 "def _skip_frame ( self ) : size = self . read_size ( ) for i in range ( size+1 ) : line = self . _f . readline ( ) if len ( line ) = = 0 : raise StopIteration": 3215,
 "def _skip_newlines ( self ) : while self . _cur_token[ ' type ' ] is TT . lbreak and not self . _finished : self . _increment ( ) ": 3216,
 "def indent ( txt , spacing = 4 ) : return prefix ( str ( txt ) , ' ' . join ( [ ' ' for _ in range ( spacing ) ] ) ) ": 3217,
 "def NeuralNetLearner ( dataset , sizes ) : activations = map ( lambda n : [0 . 0 for i in range ( n ) ] , sizes ) weights = [] def predict ( example ) : unimplemented ( ) return predict": 3218,
 "def _re_raise_as ( NewExc , *args , **kw ) : etype , val , tb = sys . exc_info ( ) raise NewExc ( *args , **kw ) , None , tb": 3219,
 "def partition ( a , sz ) : return [a[i : i+sz] for i in range ( 0 , len ( a ) , sz ) ]": 3220,
 "def output_scores ( self , name = None ) : return tf . nn . softmax ( self . label_logits , name = name ) ": 3221,
 "def comment ( self , s , **args ) : self . writeln ( s = u ' comment \" %s \" ' % s , **args ) ": 3222,
 "def sbessely ( x , N ) : out = np . zeros ( N , dtype = np . float64 ) out[0] = -np . cos ( x ) / x out[1] = -np . cos ( x ) / ( x ** 2 ) - np . sin ( x ) / x for n in xrange ( 2 , N ) : out[n] = ( ( 2 . 0 * n - 1 . 0 ) / x ) * out[n - 1] - out[n - 2] return out": 3223,
 "def split_len ( s , length ) : return [s[i : i+length] for i in range ( 0 , len ( s ) , length ) ]": 3224,
 "def __init__ ( self ) : # Root parser self . parser = argparse . ArgumentParser ( ) # Subparsers self . subparsers = self . parser . add_subparsers ( ) # Parser dictionary , to avoir overwriting existing parsers self . parsers = {}": 3225,
 "def upoint2exprpoint ( upoint ) : point = dict ( ) for uniqid in upoint[0] : point[_LITS[uniqid]] = 0 for uniqid in upoint[1] : point[_LITS[uniqid]] = 1 return point": 3226,
 "def logical_or ( self , other ) : return self . operation ( other , lambda x , y : int ( x or y ) ) ": 3227,
 "def get_random_id ( length ) : alphabet = string . ascii_uppercase + string . ascii_lowercase + string . digits return ' ' . join ( random . choice ( alphabet ) for _ in range ( length ) ) ": 3228,
 "def save ( self ) : self . session . add ( self ) self . session . flush ( ) return self": 3229,
 "def md_to_text ( content ) : text = None html = markdown . markdown ( content ) if html : text = html_to_text ( content ) return text": 3230,
 "def get_last_id ( self , cur , table = ' reaction ' ) : cur . execute ( \" SELECT seq FROM sqlite_sequence WHERE name = ' {0} ' \" . format ( table ) ) result = cur . fetchone ( ) if result is not None : id = result[0] else : id = 0 return id": 3231,
 "def _plot ( self ) : for serie in self . series[ : : -1 if self . stack_from_top else 1] : self . line ( serie ) for serie in self . secondary_series[ : : -1 if self . stack_from_top else 1] : self . line ( serie , True ) ": 3232,
 "def validate_args ( **args ) : \t\tif not args[ ' query ' ] : \t\tprint ( \" \\nMissing required query argument . \" ) \t\tsys . exit ( ) \tfor key in DEFAULTS : \t\tif key not in args : \t\t\targs[key] = DEFAULTS[key]\treturn args": 3233,
 "def stop ( self , reason = None ) : self . logger . info ( ' stopping ' ) self . loop . stop ( pyev . EVBREAK_ALL ) ": 3234,
 "def jaccard ( c_1 , c_2 ) : nom = np . intersect1d ( c_1 , c_2 ) . size denom = np . union1d ( c_1 , c_2 ) . size return nom/denom": 3235,
 "def _encode_gif ( images , fps ) : writer = WholeVideoWriter ( fps ) writer . write_multi ( images ) return writer . finish ( ) ": 3236,
 "def load_logged_in_user ( ) : user_id = session . get ( \" user_id \" ) g . user = User . query . get ( user_id ) if user_id is not None else None": 3237,
 "def u2b ( string ) : if ( ( PY2 and isinstance ( string , unicode ) ) or ( ( not PY2 ) and isinstance ( string , str ) ) ) : return string . encode ( ' utf-8 ' ) return string": 3238,
 "def process_docstring ( app , what , name , obj , options , lines ) : # pylint : disable = unused-argument # pylint : disable = too-many-arguments lines . extend ( _format_contracts ( what = what , obj = obj ) ) ": 3239,
 "def FromString ( s , **kwargs ) : f = StringIO . StringIO ( s ) return FromFile ( f , **kwargs ) ": 3240,
 "def findLastCharIndexMatching ( text , func ) : for i in range ( len ( text ) - 1 , -1 , -1 ) : if func ( text[i] ) : return i": 3241,
 "def RoundToSeconds ( cls , timestamp ) : leftovers = timestamp % definitions . MICROSECONDS_PER_SECOND scrubbed = timestamp - leftovers rounded = round ( float ( leftovers ) / definitions . MICROSECONDS_PER_SECOND ) return int ( scrubbed + rounded * definitions . MICROSECONDS_PER_SECOND ) ": 3242,
 "def __init__ ( self , capacity = 10 ) : super ( ) . __init__ ( ) self . _array = [None] * capacity self . _front = 0 self . _rear = 0": 3243,
 "def camelcase ( string ) : string = re . sub ( r \" ^[\\-_\\ . ] \" , ' ' , str ( string ) ) if not string : return string return lowercase ( string[0] ) + re . sub ( r \" [\\-_\\ . \\s] ( [a-z] ) \" , lambda matched : uppercase ( matched . group ( 1 ) ) , string[1 : ] ) ": 3244,
 "def asin ( x ) : if isinstance ( x , UncertainFunction ) : mcpts = np . arcsin ( x . _mcpts ) return UncertainFunction ( mcpts ) else : return np . arcsin ( x ) ": 3245,
 "def synchronized ( obj ) : if hasattr ( obj , ' synchronizable_condition ' ) : return obj . synchronizable_condition elif callable ( obj ) : @functools . wraps ( obj ) def wrapper ( self , *args , **kwargs ) : with self . synchronizable_condition : return obj ( self , *args , **kwargs ) return wrapper else : raise TypeError ( ' expected Synchronizable instance or callable to decorate ' ) ": 3246,
 "def setencoding ( ) : encoding = \" ascii \" # Default value set by _PyUnicode_Init ( ) if 0 : # Enable to support locale aware default string encodings . import locale loc = locale . getdefaultlocale ( ) if loc[1] : encoding = loc[1] if 0 : # Enable to switch off string to Unicode coercion and implicit # Unicode to string conversion . encoding = \" undefined \" if encoding ! = \" ascii \" : # On Non-Unicode builds this will raise an AttributeError . . . sys . setdefaultencoding ( encoding ) ": 3247,
 "def pass_from_pipe ( cls ) : is_pipe = not sys . stdin . isatty ( ) return is_pipe and cls . strip_last_newline ( sys . stdin . read ( ) ) ": 3248,
 "def post_worker_init ( worker ) : quit_command = ' CTRL-BREAK ' if sys . platform = = ' win32 ' else ' CONTROL-C ' sys . stdout . write ( \" Django version {djangover} , Gunicorn version {gunicornver} , \" \" using settings {settings!r}\\n \" \" Starting development server at {urls}\\n \" \" Quit the server with {quit_command} . \\n \" . format ( djangover = django . get_version ( ) , gunicornver = gunicorn . __version__ , settings = os . environ . get ( ' DJANGO_SETTINGS_MODULE ' ) , urls = ' , ' . join ( ' http : //{0}/ ' . format ( b ) for b in worker . cfg . bind ) , quit_command = quit_command , ) , ) ": 3249,
 "def unique_everseen ( iterable , filterfalse_ = itertools . filterfalse ) : # Itertools recipes : # https : //docs . python . org/3/library/itertools . html # itertools-recipes seen = set ( ) seen_add = seen . add for element in filterfalse_ ( seen . __contains__ , iterable ) : seen_add ( element ) yield element": 3250,
 "def get_tensor_device ( self , tensor_name ) : tensor = self . _name_to_tensor ( tensor_name ) if isinstance ( tensor , tf . Tensor ) : return tensor . device else : # mtf . Tensor return None": 3251,
 "def mask_nonfinite ( self ) : self . mask = np . logical_and ( self . mask , ( np . isfinite ( self . intensity ) ) ) ": 3252,
 "def sg_init ( sess ) : r # initialize variables sess . run ( tf . group ( tf . global_variables_initializer ( ) , tf . local_variables_initializer ( ) ) ) ": 3253,
 "def main ( args ) : start = time . time ( ) output = get ( args ) _safe_exit ( start , output ) ": 3254,
 "def chunks ( iterable , n ) : for i in range ( 0 , len ( iterable ) , n ) : yield iterable[i : i + n]": 3255,
 "def _check_format ( file_path , content ) : # TODO : replace with JSON schema validation if not content : # testcase file content is empty err_msg = u \" Testcase file content is empty : {} \" . format ( file_path ) logger . log_error ( err_msg ) raise exceptions . FileFormatError ( err_msg ) elif not isinstance ( content , ( list , dict ) ) : # testcase file content does not match testcase format err_msg = u \" Testcase file content format invalid : {} \" . format ( file_path ) logger . log_error ( err_msg ) raise exceptions . FileFormatError ( err_msg ) ": 3256,
 "def do_wordwrap ( s , width = 79 , break_long_words = True ) : import textwrap return u ' \\n ' . join ( textwrap . wrap ( s , width = width , expand_tabs = False , replace_whitespace = False , break_long_words = break_long_words ) ) ": 3257,
 "def from_json ( value , **kwargs ) : if isinstance ( value , string_types ) : value = value . upper ( ) if value in ( ' TRUE ' , ' Y ' , ' YES ' , ' ON ' ) : return True if value in ( ' FALSE ' , ' N ' , ' NO ' , ' OFF ' ) : return False if isinstance ( value , int ) : return value raise ValueError ( ' Could not load boolean from JSON : {} ' . format ( value ) ) ": 3258,
 "def is_progressive ( image ) : if not isinstance ( image , Image . Image ) : # Can only check PIL images for progressive encoding . return False return ( ' progressive ' in image . info ) or ( ' progression ' in image . info ) ": 3259,
 "def set ( self ) : with self . __cond : self . __flag = True self . __cond . notify_all ( ) ": 3260,
 "def dumps ( obj ) : return json . dumps ( obj , indent = 4 , sort_keys = True , cls = CustomEncoder ) ": 3261,
 "def timediff ( time ) : now = datetime . datetime . utcnow ( ) diff = now - time diff_sec = diff . total_seconds ( ) return diff_sec": 3262,
 "def is_webdriver_ios ( webdriver ) : browser = webdriver . capabilities[ ' browserName ' ] if ( browser = = u ( ' iPhone ' ) or browser = = u ( ' iPad ' ) ) : return True else : return False": 3263,
 "def hms_to_seconds ( time_string ) : s = time_string . split ( ' : ' ) hours = int ( s[0] ) minutes = int ( s[1] ) secs = float ( s[2] ) return hours * 3600 + minutes * 60 + secs": 3264,
 "def sort_func ( self , key ) : if key = = self . _KEYS . VALUE : return ' aaa ' if key = = self . _KEYS . SOURCE : return ' zzz ' return key": 3265,
 "def on_key_press ( self , symbol , modifiers ) : self . keyboard_event ( symbol , self . keys . ACTION_PRESS , modifiers ) ": 3266,
 "def _end_del ( self ) : text = self . edit_text[ : self . edit_pos] self . set_edit_text ( text ) ": 3267,
 "def _get ( self , pos ) : res = None , None if pos is not None : try : res = self[pos] , pos except ( IndexError , KeyError ) : pass return res": 3268,
 "def get_access_datetime ( filepath ) : import tzlocal tz = tzlocal . get_localzone ( ) mtime = datetime . fromtimestamp ( os . path . getatime ( filepath ) ) return mtime . replace ( tzinfo = tz ) ": 3269,
 "def hide ( self ) : self . tk . withdraw ( ) self . _visible = False if self . _modal : self . tk . grab_release ( ) ": 3270,
 "def clear_last_lines ( self , n ) : self . term . stream . write ( self . term . move_up * n + self . term . clear_eos ) self . term . stream . flush ( ) ": 3271,
 "def _on_scale ( self , event ) : self . _entry . delete ( 0 , tk . END ) self . _entry . insert ( 0 , str ( self . _variable . get ( ) ) ) ": 3272,
 "def write_to ( f , mode ) : if hasattr ( f , ' write ' ) : yield f else : f = open ( f , mode ) yield f f . close ( ) ": 3273,
 "def lemmatize ( self , text , best_guess = True , return_frequencies = False ) : \t\t\t\tif isinstance ( text , str ) : \t\t\ttokens = wordpunct_tokenize ( text ) \t\telif isinstance ( text , list ) : \t\t\ttokens = text\t\telse : \t\t\traise TypeError ( \" lemmatize only works with strings or lists of string tokens . \" ) \t\treturn [self . _lemmatize_token ( token , best_guess , return_frequencies ) for token in tokens]": 3274,
 "def _sort_tensor ( tensor ) : sorted_ , _ = tf . nn . top_k ( tensor , k = tf . shape ( input = tensor ) [-1] ) sorted_ . set_shape ( tensor . shape ) return sorted_": 3275,
 "def re_raise ( self ) : if self . exc_info is not None : six . reraise ( type ( self ) , self , self . exc_info[2] ) else : raise self": 3276,
 "def _linear_seaborn_ ( self , label = None , style = None , opts = None ) : xticks , yticks = self . _get_ticks ( opts ) try : fig = sns . lmplot ( self . x , self . y , data = self . df ) fig = self . _set_with_height ( fig , opts ) return fig except Exception as e : self . err ( e , self . linear_ , \" Can not draw linear regression chart \" ) ": 3277,
 "def comma_delimited_to_list ( list_param ) : if isinstance ( list_param , list ) : return list_param if isinstance ( list_param , str ) : return list_param . split ( ' , ' ) else : return []": 3278,
 "def unique ( transactions ) : seen = set ( ) # TODO : Handle comments return [x for x in transactions if not ( x in seen or seen . add ( x ) ) ]": 3279,
 "def readCommaList ( fileList ) : names = fileList . split ( ' , ' ) fileList = [] for item in names : fileList . append ( item ) return fileList": 3280,
 "def _get_triplet_value_list ( self , graph , identity , rdf_type ) : values = [] for elem in graph . objects ( identity , rdf_type ) : values . append ( elem . toPython ( ) ) return values": 3281,
 "def load_feature ( fname , language ) : fname = os . path . abspath ( fname ) feat = parse_file ( fname , language ) return feat": 3282,
 "def parsed_args ( ) : parser = argparse . ArgumentParser ( description = , epilog = \" \" ) parser . add_argument ( ' command ' , nargs = ' * ' , help = \" Name of the function to run with arguments \" ) args = parser . parse_args ( ) return ( args , parser ) ": 3283,
 "def _correct_args ( func , kwargs ) : args = inspect . getargspec ( func ) [0] return [kwargs[arg] for arg in args] + kwargs[ ' __args ' ]": 3284,
 "def unpack ( self , s ) : return self . _create ( super ( NamedStruct , self ) . unpack ( s ) ) ": 3285,
 "def sarea_ ( self , col , x = None , y = None , rsum = None , rmean = None ) : \t\t\t\ttry : \t\t\tcharts = self . _multiseries ( col , x , y , \" area \" , rsum , rmean ) \t\t\treturn hv . Area . stack ( charts ) \t\texcept Exception as e : \t\t\tself . err ( e , self . sarea_ , \" Can not draw stacked area chart \" ) ": 3286,
 "def subscribe_to_quorum_channel ( self ) : from dallinger . experiment_server . sockets import chat_backend self . log ( \" Bot subscribing to quorum channel . \" ) chat_backend . subscribe ( self , \" quorum \" ) ": 3287,
 "def on_welcome ( self , connection , event ) : connection . join ( self . channel , key = settings . IRC_CHANNEL_KEY or \" \" ) ": 3288,
 "def venv ( ) : try : import virtualenv # NOQA except ImportError : sh ( \" %s -m pip install virtualenv \" % PYTHON ) if not os . path . isdir ( \" venv \" ) : sh ( \" %s -m virtualenv venv \" % PYTHON ) sh ( \" venv\\\\Scripts\\\\pip install -r %s \" % ( REQUIREMENTS_TXT ) ) ": 3289,
 "def _raise_error_if_column_exists ( dataset , column_name = ' dataset ' , dataset_variable_name = ' dataset ' , column_name_error_message_name = ' column_name ' ) : err_msg = ' The SFrame {0} must contain the column {1} . ' . format ( dataset_variable_name , column_name_error_message_name ) if column_name not in dataset . column_names ( ) : raise ToolkitError ( str ( err_msg ) ) ": 3290,
 "def format ( x , format ) : # don ' t change the dtype , otherwise for each block the dtype may be different ( string length ) sl = vaex . strings . format ( x , format ) return column . ColumnStringArrow ( sl . bytes , sl . indices , sl . length , sl . offset , string_sequence = sl ) ": 3291,
 "def print_table ( *args , **kwargs ) : t = format_table ( *args , **kwargs ) click . echo ( t ) ": 3292,
 "def world_to_view ( v ) : return v . x * config . scale_x , v . y * config . scale_y": 3293,
 "def quadratic_bezier ( start , end , c0 = ( 0 , 0 ) , c1 = ( 0 , 0 ) , steps = 50 ) : steps = np . linspace ( 0 , 1 , steps ) sx , sy = start ex , ey = end cx0 , cy0 = c0 cx1 , cy1 = c1 xs = ( ( 1-steps ) **3*sx + 3* ( ( 1-steps ) **2 ) *steps*cx0 + 3* ( 1-steps ) *steps**2*cx1 + steps**3*ex ) ys = ( ( 1-steps ) **3*sy + 3* ( ( 1-steps ) **2 ) *steps*cy0 + 3* ( 1-steps ) *steps**2*cy1 + steps**3*ey ) return np . column_stack ( [xs , ys] ) ": 3294,
 "def volume ( self ) : volume = abs ( self . primitive . polygon . area * self . primitive . height ) return volume": 3295,
 "def eval_script ( self , expr ) : ret = self . conn . issue_command ( \" Evaluate \" , expr ) return json . loads ( \" [%s] \" % ret ) [0]": 3296,
 "def get_page_and_url ( session , url ) : reply = get_reply ( session , url ) return reply . text , reply . url": 3297,
 "def manhattan_distance_numpy ( object1 , object2 ) : return numpy . sum ( numpy . absolute ( object1 - object2 ) , axis = 1 ) . T": 3298,
 "def check_by_selector ( self , selector ) : elem = find_element_by_jquery ( world . browser , selector ) if not elem . is_selected ( ) : elem . click ( ) ": 3299,
 "def autobuild_python_test ( path ) : env = Environment ( tools = [] ) target = env . Command ( [ ' build/test/output/pytest . log ' ] , [path] , action = env . Action ( run_pytest , \" Running python unit tests \" ) ) env . AlwaysBuild ( target ) ": 3300,
 "def find_elements_by_id ( self , id_ ) : return self . find_elements ( by = By . ID , value = id_ ) ": 3301,
 "def add_arrow ( self , x1 , y1 , x2 , y2 , **kws ) : self . panel . add_arrow ( x1 , y1 , x2 , y2 , **kws ) ": 3302,
 "def flush ( self ) : for name in self . item_names : item = self[name] item . flush ( ) self . file . flush ( ) ": 3303,
 "def base64ToImage ( imgData , out_path , out_file ) : fh = open ( os . path . join ( out_path , out_file ) , \" wb \" ) fh . write ( imgData . decode ( ' base64 ' ) ) fh . close ( ) del fh return os . path . join ( out_path , out_file ) ": 3304,
 "def serialize_yaml_tofile ( filename , resource ) : stream = file ( filename , \" w \" ) yaml . dump ( resource , stream , default_flow_style = False ) ": 3305,
 "def write_config ( self , outfile ) : utils . write_yaml ( self . config , outfile , default_flow_style = False ) ": 3306,
 "def _rel ( self , path ) : return os . path . relpath ( str ( path ) , self . _parent ) . replace ( os . path . sep , ' / ' ) ": 3307,
 "def merge ( self , other ) : newstart = min ( self . _start , other . start ) newend = max ( self . _end , other . end ) return Range ( newstart , newend ) ": 3308,
 "def xml_str_to_dict ( s ) : xml = minidom . parseString ( s ) return pythonzimbra . tools . xmlserializer . dom_to_dict ( xml . firstChild ) ": 3309,
 "def send_notice ( self , text ) : return self . client . api . send_notice ( self . room_id , text ) ": 3310,
 "def validate ( self , xml_input ) : parsed_xml = etree . parse ( self . _handle_xml ( xml_input ) ) try : return self . xmlschema . validate ( parsed_xml ) except AttributeError : raise CannotValidate ( ' Set XSD to validate the XML ' ) ": 3311,
 "def is_empty ( self ) : non_type_attributes = [attr for attr in self . node . attrib . keys ( ) if attr ! = ' type ' ] return len ( self . node ) = = 0 and len ( non_type_attributes ) = = 0 \\ and not self . node . text and not self . node . tail": 3312,
 "def roll_dice ( ) : sums = 0 # will return the sum of the roll calls . while True : roll = random . randint ( 1 , 6 ) sums + = roll if ( input ( \" Enter y or n to continue : \" ) . upper ( ) ) = = ' N ' : print ( sums ) # prints the sum of the roll calls break": 3313,
 "def ensure_index ( self , key , unique = False ) : return self . collection . ensure_index ( key , unique = unique ) ": 3314,
 "def extract_zip ( zip_path , target_folder ) : with zipfile . ZipFile ( zip_path ) as archive : archive . extractall ( target_folder ) ": 3315,
 "def order_by ( self , *fields ) : doc = [] for field in fields : if field . startswith ( ' - ' ) : doc . append ( ( field . strip ( ' - ' ) , pymongo . DESCENDING ) ) else : doc . append ( ( field , pymongo . ASCENDING ) ) return self . sort ( doc ) ": 3316,
 "def compressBuffer ( buffer ) : # http : //jython . xhaus . com/http-compression-in-python-and-jython/ zbuf = cStringIO . StringIO ( ) zfile = gzip . GzipFile ( mode = ' wb ' , fileobj = zbuf , compresslevel = 9 ) zfile . write ( buffer ) zfile . close ( ) return zbuf . getvalue ( ) ": 3317,
 "def pieces ( array , chunk_size ) : for i in range ( 0 , len ( array ) , chunk_size ) : yield array[i : i+chunk_size]": 3318,
 "def from_series ( cls , series ) : # TODO : add a ' name ' parameter name = series . name df = pd . DataFrame ( {name : series} ) ds = Dataset . from_dataframe ( df ) return ds[name]": 3319,
 "def access ( self , accessor , timeout = None ) : if self . loop . is_running ( ) : raise RuntimeError ( \" Loop is already running \" ) coro = asyncio . wait_for ( accessor , timeout , loop = self . loop ) return self . loop . run_until_complete ( coro ) ": 3320,
 "def interpolate_nearest ( self , xi , yi , zdata ) : if zdata . size ! = self . npoints : raise ValueError ( ' zdata should be same size as mesh ' ) zdata = self . _shuffle_field ( zdata ) ist = np . ones_like ( xi , dtype = np . int32 ) ist , dist = _tripack . nearnds ( xi , yi , ist , self . _x , self . _y , self . lst , self . lptr , self . lend ) return zdata[ist - 1]": 3321,
 "def ub_to_str ( string ) : if not isinstance ( string , str ) : if six . PY2 : return str ( string ) else : return string . decode ( ) return string": 3322,
 "def isemptyfile ( filepath ) : exists = os . path . exists ( safepath ( filepath ) ) if exists : filesize = os . path . getsize ( safepath ( filepath ) ) return filesize = = 0 else : return False": 3323,
 "def is_enum_type ( type_ ) : return isinstance ( type_ , type ) and issubclass ( type_ , tuple ( _get_types ( Types . ENUM ) ) ) ": 3324,
 "def is_alive ( self ) : try : self . wait ( 0 ) except WindowsError : e = sys . exc_info ( ) [1] return e . winerror = = win32 . WAIT_TIMEOUT return False": 3325,
 "def bytes_to_str ( s , encoding = ' utf-8 ' ) : if six . PY3 and isinstance ( s , bytes ) : return s . decode ( encoding ) return s": 3326,
 "def clean ( some_string , uppercase = False ) : if uppercase : return some_string . strip ( ) . upper ( ) else : return some_string . strip ( ) . lower ( ) ": 3327,
 "def render ( template , context ) : path , filename = os . path . split ( template ) return jinja2 . Environment ( loader = jinja2 . FileSystemLoader ( path or ' . / ' ) ) . get_template ( filename ) . render ( context ) ": 3328,
 "def ensure_us_time_resolution ( val ) : if np . issubdtype ( val . dtype , np . datetime64 ) : val = val . astype ( ' datetime64[us] ' ) elif np . issubdtype ( val . dtype , np . timedelta64 ) : val = val . astype ( ' timedelta64[us] ' ) return val": 3329,
 "def setup_request_sessions ( self ) : self . req_session = requests . Session ( ) self . req_session . headers . update ( self . headers ) ": 3330,
 "def lognormcdf ( x , mu , tau ) : x = np . atleast_1d ( x ) return np . array ( [0 . 5 * ( 1 - flib . derf ( - ( np . sqrt ( tau / 2 ) ) * ( np . log ( y ) - mu ) ) ) for y in x] ) ": 3331,
 "def run ( self ) : LOGGER . debug ( \" rabbitmq . Service . run \" ) try : self . channel . start_consuming ( ) except Exception as e : LOGGER . warn ( \" rabbitmq . Service . run - Exception raised while consuming \" ) ": 3332,
 "def filter_duplicate_key ( line , message , line_number , marked_line_numbers , source , previous_line = ' ' ) : if marked_line_numbers and line_number = = sorted ( marked_line_numbers ) [0] : return ' ' return line": 3333,
 "def reseed_random ( seed ) : r = random . Random ( seed ) random_internal_state = r . getstate ( ) set_random_state ( random_internal_state ) ": 3334,
 "def getYamlDocument ( filePath ) : with open ( filePath ) as stream : doc = yaml . load ( stream ) return doc": 3335,
 "def generate_hash ( filepath ) : fr = FileReader ( filepath ) data = fr . read_bin ( ) return _calculate_sha256 ( data ) ": 3336,
 "def versions_request ( self ) : ret = self . handle_api_exceptions ( ' GET ' , ' ' , api_ver = ' ' ) return [str_dict ( x ) for x in ret . json ( ) ]": 3337,
 "def _parse_response ( self , response ) : response_dict = {} for line in response . splitlines ( ) : key , value = response . split ( \" = \" , 1 ) response_dict[key] = value return response_dict": 3338,
 "def print ( cls , *args , **kwargs ) : # pylint : disable = protected-access with _shared . _PRINT_LOCK : print ( *args , **kwargs ) _sys . stdout . flush ( ) ": 3339,
 "def values ( self ) : for val in self . _client . hvals ( self . key_prefix ) : yield self . _loads ( val ) ": 3340,
 "def parse_domain ( url ) : domain_match = lib . DOMAIN_REGEX . match ( url ) if domain_match : return domain_match . group ( ) ": 3341,
 "def de_blank ( val ) : ret = list ( val ) if type ( val ) = = list : for idx , item in enumerate ( val ) : if item . strip ( ) = = ' ' : ret . remove ( item ) else : ret[idx] = item . strip ( ) return ret": 3342,
 "def slugify ( string ) : string = re . sub ( ' [^\\w . -] ' , ' ' , string ) string = string . replace ( \" \" , \" - \" ) return string": 3343,
 "def normal_noise ( points ) : return np . random . rand ( 1 ) * np . random . randn ( points , 1 ) \\ + random . sample ( [2 , -2] , 1 ) ": 3344,
 "def _request ( self , data ) : return requests . post ( self . endpoint , data = data . encode ( \" ascii \" ) ) . content": 3345,
 "def strip_accents ( string ) : return u ' ' . join ( ( character for character in unicodedata . normalize ( ' NFD ' , string ) if unicodedata . category ( character ) ! = ' Mn ' ) ) ": 3346,
 "def pp_xml ( body ) : pretty = xml . dom . minidom . parseString ( body ) return pretty . toprettyxml ( indent = \" \" ) ": 3347,
 "def insort_no_dup ( lst , item ) : import bisect ix = bisect . bisect_left ( lst , item ) if lst[ix] ! = item : lst[ix : ix] = [item]": 3348,
 "def log_finished ( self ) : \t\t\t\tdelta = time . perf_counter ( ) - self . start_time\t\tlogger . log ( \" Finished ' \" , logger . cyan ( self . name ) , \t\t\t \" ' after \" , logger . magenta ( time_to_text ( delta ) ) ) ": 3349,
 "def remove_last_entry ( self ) : self . current_beat - = 1 . 0 / self . bar[-1][1] self . bar = self . bar[ : -1] return self . current_beat": 3350,
 "def __convert_none_to_zero ( self , ts ) : if not ts : return ts ts_clean = [val if val else 0 for val in ts] return ts_clean": 3351,
 "def qubits ( self ) : return [ ( v , i ) for k , v in self . qregs . items ( ) for i in range ( v . size ) ]": 3352,
 "def _clean_name ( self , prefix , obj ) : return ' {}{}_{} ' . format ( prefix , self . _uid ( ) , ' ' . join ( c for c in obj . name if c . isalnum ( ) ) ) ": 3353,
 "def close_connection ( self ) : if self . url_connection is None : # no connection is open return try : self . url_connection . close ( ) except Exception : # ignore close errors pass self . url_connection = None": 3354,
 "def lint_file ( in_file , out_file = None ) : for line in in_file : print ( line . strip ( ) , file = out_file ) ": 3355,
 "def is_number ( obj ) : return isinstance ( obj , ( int , float , np . int_ , np . float_ ) ) ": 3356,
 "def _clear ( self ) : self . _finished = False self . _measurement = None self . _message = None self . _message_body = None": 3357,
 "def _updateItemComboBoxIndex ( self , item , column , num ) : item . _combobox_current_index[column] = num item . _combobox_current_value[column] = item . _combobox_option_list[column][num][0]": 3358,
 "def _convert ( tup , dictlist ) : di = {} for a , b in tup : di . setdefault ( a , [] ) . append ( b ) for key , val in di . items ( ) : dictlist . append ( ( key , val ) ) return dictlist": 3359,
 "def _cast_boolean ( value ) : _BOOLEANS = { ' 1 ' : True , ' yes ' : True , ' true ' : True , ' on ' : True , ' 0 ' : False , ' no ' : False , ' false ' : False , ' off ' : False , ' ' : False} value = str ( value ) if value . lower ( ) not in _BOOLEANS : raise ValueError ( ' Not a boolean : %s ' % value ) return _BOOLEANS[value . lower ( ) ]": 3360,
 "def lambda_tuple_converter ( func ) : if func is not None and func . __code__ . co_argcount = = 1 : return lambda *args : func ( args[0] if len ( args ) = = 1 else args ) else : return func": 3361,
 "def replace_list ( items , match , replacement ) : return [replace ( item , match , replacement ) for item in items]": 3362,
 "def _get_user_agent ( self ) : user_agent = request . headers . get ( ' User-Agent ' ) if user_agent : user_agent = user_agent . encode ( ' utf-8 ' ) return user_agent or ' ' ": 3363,
 "def _list_available_rest_versions ( self ) : url = \" https : //{0}/api/api_version \" . format ( self . _target ) data = self . _request ( \" GET \" , url , reestablish_session = False ) return data[ \" version \" ]": 3364,
 "def has_edge ( self , p_from , p_to ) : return p_from in self . _edges and p_to in self . _edges[p_from]": 3365,
 "def type ( self ) : if self is FeatureType . TIMESTAMP : return list if self is FeatureType . BBOX : return BBox return dict": 3366,
 "async def send_message ( ) : jar = aiohttp . CookieJar ( unsafe = True ) websession = aiohttp . ClientSession ( cookie_jar = jar ) modem = eternalegypt . Modem ( hostname = sys . argv[1] , websession = websession ) await modem . login ( password = sys . argv[2] ) await modem . sms ( phone = sys . argv[3] , message = sys . argv[4] ) await modem . logout ( ) await websession . close ( ) ": 3367,
 "def partition_all ( n , iterable ) : it = iter ( iterable ) while True : chunk = list ( itertools . islice ( it , n ) ) if not chunk : break yield chunk": 3368,
 "def get_date_field ( datetimes , field ) : return np . array ( [getattr ( date , field ) for date in datetimes] ) ": 3369,
 "def generate_hash ( self , length = 30 ) : import random , string chars = string . ascii_letters + string . digits ran = random . SystemRandom ( ) . choice hash = ' ' . join ( ran ( chars ) for i in range ( length ) ) return hash": 3370,
 "def convert_args_to_sets ( f ) : @wraps ( f ) def wrapper ( *args , **kwargs ) : args = ( setify ( x ) for x in args ) return f ( *args , **kwargs ) return wrapper": 3371,
 "def __or__ ( self , other ) : if not isinstance ( other , set ) : return NotImplemented return self . union ( other ) ": 3372,
 "def map_with_obj ( f , dct ) : f_dict = {} for k , v in dct . items ( ) : f_dict[k] = f ( k , v ) return f_dict": 3373,
 "def parse_markdown ( markdown_content , site_settings ) : markdown_extensions = set_markdown_extensions ( site_settings ) html_content = markdown . markdown ( markdown_content , extensions = markdown_extensions , ) return html_content": 3374,
 "def _rgbtomask ( self , obj ) : dat = obj . get_image ( ) . get_data ( ) # RGB arrays return dat . sum ( axis = 2 ) . astype ( np . bool ) ": 3375,
 "def floor ( self ) : return Point ( int ( math . floor ( self . x ) ) , int ( math . floor ( self . y ) ) ) ": 3376,
 "def lint ( ctx : click . Context , amend : bool = False , stage : bool = False ) : _lint ( ctx , amend , stage ) ": 3377,
 "def _save_cookies ( requests_cookiejar , filename ) : with open ( filename , ' wb ' ) as handle : pickle . dump ( requests_cookiejar , handle ) ": 3378,
 "def seconds_to_hms ( input_seconds ) : minutes , seconds = divmod ( input_seconds , 60 ) hours , minutes = divmod ( minutes , 60 ) hours = int ( hours ) minutes = int ( minutes ) seconds = str ( int ( seconds ) ) . zfill ( 2 ) return hours , minutes , seconds": 3379,
 "def p_if_statement_2 ( self , p ) : p[0] = ast . If ( predicate = p[3] , consequent = p[5] , alternative = p[7] ) ": 3380,
 "def get_closest_index ( myList , myNumber ) : closest_values_index = _np . where ( self . time = = take_closest ( myList , myNumber ) ) [0][0] return closest_values_index": 3381,
 "def update_table_row ( self , table , row_idx ) : try : table[row_idx][ ' timestamp ' ] = self . timestamp table[row_idx][ ' status ' ] = self . status except IndexError : print ( \" Index error \" , len ( table ) , row_idx ) ": 3382,
 "def check_no_element_by_selector ( self , selector ) : elems = find_elements_by_jquery ( world . browser , selector ) if elems : raise AssertionError ( \" Expected no matching elements , found {} . \" . format ( len ( elems ) ) ) ": 3383,
 "def POST ( self , *args , **kwargs ) : return self . _handle_api ( self . API_POST , args , kwargs ) ": 3384,
 "def run ( *tasks : Awaitable , loop : asyncio . AbstractEventLoop = asyncio . get_event_loop ( ) ) : futures = [asyncio . ensure_future ( task , loop = loop ) for task in tasks] return loop . run_until_complete ( asyncio . gather ( *futures ) ) ": 3385,
 "def setobjattr ( obj , key , value ) : try : setattr ( obj , key , int ( value ) ) except ValueError : try : setattr ( obj , key , float ( value ) ) except ValueError : # string if not number try : setattr ( obj , key , str ( value ) ) except UnicodeEncodeError : setattr ( obj , key , value ) ": 3386,
 "def _update_fontcolor ( self , fontcolor ) : textcolor = wx . SystemSettings_GetColour ( wx . SYS_COLOUR_WINDOWTEXT ) textcolor . SetRGB ( fontcolor ) self . textcolor_choice . SetColour ( textcolor ) ": 3387,
 "def dim_axis_label ( dimensions , separator = ' , ' ) : if not isinstance ( dimensions , list ) : dimensions = [dimensions] return separator . join ( [d . pprint_label for d in dimensions] ) ": 3388,
 "def writefile ( openedfile , newcontents ) : openedfile . seek ( 0 ) openedfile . truncate ( ) openedfile . write ( newcontents ) ": 3389,
 "def enable_proxy ( self , host , port ) : self . proxy = [host , _number ( port ) ] self . proxy_enabled = True": 3390,
 "def update ( self ) : if self . single_channel : self . im . set_data ( self . data[self . ind , : , : ] ) else : self . im . set_data ( self . data[self . ind , : , : , : ] ) self . ax . set_ylabel ( ' time frame %s ' % self . ind ) self . im . axes . figure . canvas . draw ( ) ": 3391,
 "def comments ( tag , limit = 0 , flags = 0 , **kwargs ) : return [comment for comment in cm . CommentsMatch ( tag ) . get_comments ( limit ) ]": 3392,
 "def smallest_signed_angle ( source , target ) : dth = target - source dth = ( dth + np . pi ) % ( 2 . 0 * np . pi ) - np . pi return dth": 3393,
 "def close_error_dlg ( self ) : if self . error_dlg . dismiss_box . isChecked ( ) : self . dismiss_error = True self . error_dlg . reject ( ) ": 3394,
 "def list_autoscaling_group ( region , filter_by_kwargs ) : conn = boto . ec2 . autoscale . connect_to_region ( region ) groups = conn . get_all_groups ( ) return lookup ( groups , filter_by = filter_by_kwargs ) ": 3395,
 "def __len__ ( self ) : return self . chunk_length ( ) + len ( self . type ) + len ( self . header ) + 4": 3396,
 "def _to_bstr ( l ) : if isinstance ( l , str ) : l = l . encode ( ' ascii ' , ' backslashreplace ' ) elif not isinstance ( l , bytes ) : l = str ( l ) . encode ( ' ascii ' , ' backslashreplace ' ) return l": 3397,
 "def batch ( input_iter , batch_size = 32 ) : input_iter = iter ( input_iter ) next_ = list ( itertools . islice ( input_iter , batch_size ) ) while next_ : yield next_ next_ = list ( itertools . islice ( input_iter , batch_size ) ) ": 3398,
 "def lighting ( im , b , c ) : if b = = 0 and c = = 1 : return im mu = np . average ( im ) return np . clip ( ( im-mu ) *c+mu+b , 0 . , 1 . ) . astype ( np . float32 ) ": 3399,
 "def elliot_function ( signal , derivative = False ) : s = 1 # steepness abs_signal = ( 1 + np . abs ( signal * s ) ) if derivative : return 0 . 5 * s / abs_signal**2 else : # Return the activation signal return 0 . 5* ( signal * s ) / abs_signal + 0 . 5": 3400,
 "def get_element_offset ( self , ty , position ) : offset = ffi . lib . LLVMPY_OffsetOfElement ( self , ty , position ) if offset = = -1 : raise ValueError ( \" Could not determined offset of {}th \" \" element of the type ' {} ' . Is it a struct type? \" . format ( position , str ( ty ) ) ) return offset": 3401,
 "def shall_skip ( app , module , private ) : logger . debug ( ' Testing if %s should be skipped . ' , module ) # skip if it has a \" private \" name and this is selected if module ! = ' __init__ . py ' and module . startswith ( ' _ ' ) and \\ not private : logger . debug ( ' Skip %s because its either private or __init__ . ' , module ) return True logger . debug ( ' Do not skip %s ' , module ) return False": 3402,
 "def stack_push ( self , thing ) : # increment sp sp = self . regs . sp + self . arch . stack_change self . regs . sp = sp return self . memory . store ( sp , thing , endness = self . arch . memory_endness ) ": 3403,
 "def stackplot ( marray , seconds = None , start_time = None , ylabels = None ) : tarray = np . transpose ( marray ) stackplot_t ( tarray , seconds = seconds , start_time = start_time , ylabels = ylabels ) plt . show ( ) ": 3404,
 "def range ( *args , interval = 0 ) : agen = from_iterable . raw ( builtins . range ( *args ) ) return time . spaceout . raw ( agen , interval ) if interval else agen": 3405,
 "def find_task_by_id ( self , id , session = None ) : with self . _session ( session ) as session : return session . query ( TaskRecord ) . get ( id ) ": 3406,
 "def getExperiments ( uuid : str ) : return jsonify ( [x . deserialize ( ) for x in Experiment . query . all ( ) ] ) ": 3407,
 "def stop ( self , timeout = None ) : logger . debug ( \" docker plugin - Close thread for container {} \" . format ( self . _container . name ) ) self . _stopper . set ( ) ": 3408,
 "def inc_date ( date_obj , num , date_fmt ) : return ( date_obj + timedelta ( days = num ) ) . strftime ( date_fmt ) ": 3409,
 "def excepthook ( self , except_type , exception , traceback ) : if except_type is DeepReferenceError : print ( exception . msg ) else : self . default_excepthook ( except_type , exception , traceback ) ": 3410,
 "def toList ( variable , types = ( basestring , int , float , ) ) : if isinstance ( variable , types ) : return [variable] else : return variable": 3411,
 "def is_stats_query ( query ) : if not query : return False # remove all \" enclosed strings nq = re . sub ( r ' \" [^ \" ]* \" ' , ' ' , query ) # check if there ' s | . . . . select if re . findall ( r ' \\| . *\\bselect\\b ' , nq , re . I|re . DOTALL ) : return True return False": 3412,
 "def to_bytes ( s , encoding = \" utf-8 \" ) : if isinstance ( s , six . binary_type ) : return s if six . PY3 : return bytes ( s , encoding ) return s . encode ( encoding ) ": 3413,
 "def empty_tree ( input_list ) : for item in input_list : if not isinstance ( item , list ) or not empty_tree ( item ) : return False return True": 3414,
 "def _uptime_syllable ( ) : global __boottime try : __boottime = os . stat ( ' /dev/pty/mst/pty0 ' ) . st_mtime return time . time ( ) - __boottime except ( NameError , OSError ) : return None": 3415,
 "def ss_tot ( self ) : return np . sum ( np . square ( self . y - self . ybar ) , axis = 0 ) ": 3416,
 "def list2string ( inlist , delimit = ' ' ) : stringlist = [makestr ( _ ) for _ in inlist] return string . join ( stringlist , delimit ) ": 3417,
 "def get_tile_location ( self , x , y ) : x1 , y1 = self . origin x1 + = self . BORDER + ( self . BORDER + self . cell_width ) * x y1 + = self . BORDER + ( self . BORDER + self . cell_height ) * y return x1 , y1": 3418,
 "def tfds_dir ( ) : return os . path . dirname ( os . path . dirname ( os . path . dirname ( __file__ ) ) ) ": 3419,
 "def has_value_name ( self , name ) : for val , _ in self . _values : if val = = name : return True return False": 3420,
 "def querySQL ( self , sql , args = ( ) ) : if self . debug : result = timeinto ( self . queryTimes , self . _queryandfetch , sql , args ) else : result = self . _queryandfetch ( sql , args ) return result": 3421,
 "def get_top_priority ( self ) : if self . is_empty ( ) : raise IndexError ( \" Priority queue is empty . \" ) _ , _ , element = heapq . heappop ( self . pq ) if element in self . element_finder : del self . element_finder[element] return element": 3422,
 "def is_list_of_ipachars ( obj ) : if isinstance ( obj , list ) : for e in obj : if not isinstance ( e , IPAChar ) : return False return True return False": 3423,
 "def is_numeric_dtype ( dtype ) : dtype = np . dtype ( dtype ) return np . issubsctype ( getattr ( dtype , ' base ' , None ) , np . number ) ": 3424,
 "def default_number_converter ( number_str ) : is_int = ( number_str . startswith ( ' - ' ) and number_str[1 : ] . isdigit ( ) ) or number_str . isdigit ( ) # FIXME : this handles a wider range of numbers than allowed by the json standard , # etc . : float ( ' nan ' ) and float ( ' inf ' ) . But is this a problem? return int ( number_str ) if is_int else float ( number_str ) ": 3425,
 "def _open_text ( fname , **kwargs ) : if PY3 : kwargs . setdefault ( ' encoding ' , ENCODING ) kwargs . setdefault ( ' errors ' , ENCODING_ERRS ) return open ( fname , \" rt \" , **kwargs ) ": 3426,
 "def get_active_window ( ) : active_win = None default = wnck . screen_get_default ( ) while gtk . events_pending ( ) : gtk . main_iteration ( False ) window_list = default . get_windows ( ) if len ( window_list ) = = 0 : print \" No Windows Found \" for win in window_list : if win . is_active ( ) : active_win = win . get_name ( ) return active_win": 3427,
 "def _is_valid_url ( self , url ) : try : r = requests . head ( url , proxies = self . proxy_servers ) value = r . status_code in [200] except Exception as error : logger . error ( str ( error ) ) value = False return value": 3428,
 "def _id ( self ) : return ( self . __class__ , self . number_of_needles , self . needle_positions , self . left_end_needle ) ": 3429,
 "def isdir ( s ) : try : st = os . stat ( s ) except os . error : return False return stat . S_ISDIR ( st . st_mode ) ": 3430,
 "def _push_render ( self ) : bokeh . io . push_notebook ( handle = self . handle ) self . last_update = time . time ( ) ": 3431,
 "def make_writeable ( filename ) : if not os . access ( filename , os . W_OK ) : st = os . stat ( filename ) new_permissions = stat . S_IMODE ( st . st_mode ) | stat . S_IWUSR os . chmod ( filename , new_permissions ) ": 3432,
 "def add_parent ( self , parent ) : parent . add_child ( self ) self . parent = parent return parent": 3433,
 "def find_object ( self , object_type ) : node = self while node is not None : if isinstance ( node . obj , object_type ) : return node . obj node = node . parent": 3434,
 "def file_md5sum ( filename ) : hash_md5 = hashlib . md5 ( ) with open ( filename , ' rb ' ) as f : for chunk in iter ( lambda : f . read ( 1024 * 4 ) , b ' ' ) : hash_md5 . update ( chunk ) return hash_md5 . hexdigest ( ) ": 3435,
 "def _clear_dir ( dirName ) : # If we got here , clear dir for fname in os . listdir ( dirName ) : try : os . remove ( os . path . join ( dirName , fname ) ) except Exception : pass try : os . rmdir ( dirName ) except Exception : pass": 3436,
 "def bit_clone ( bits ) : new = BitSet ( bits . size ) new . ior ( bits ) return new": 3437,
 "def _clone ( self , *args , **kwargs ) : for attr in ( \" _search_terms \" , \" _search_fields \" , \" _search_ordered \" ) : kwargs[attr] = getattr ( self , attr ) return super ( SearchableQuerySet , self ) . _clone ( *args , **kwargs ) ": 3438,
 "def invert ( dict_ ) : ensure_mapping ( dict_ ) return dict_ . __class__ ( izip ( itervalues ( dict_ ) , iterkeys ( dict_ ) ) ) ": 3439,
 "def execute_until_false ( method , interval_s ) : # pylint : disable = invalid-name interval = Interval ( method , stop_if_false = True ) interval . start ( interval_s ) return interval": 3440,
 "def _get_url ( url ) : try : data = HTTP_SESSION . get ( url , stream = True ) data . raise_for_status ( ) except requests . exceptions . RequestException as exc : raise FetcherException ( exc ) return data": 3441,
 "def _get_type ( self , value ) : if value is None : return type ( None ) elif type ( value ) in int_types : return int elif type ( value ) in float_types : return float elif isinstance ( value , binary_type ) : return binary_type else : return text_type": 3442,
 "def read_next_block ( infile , block_size = io . DEFAULT_BUFFER_SIZE ) : chunk = infile . read ( block_size ) while chunk : yield chunk chunk = infile . read ( block_size ) ": 3443,
 "def sprint ( text , *colors ) : return \" \\33[{}m{content}\\33[{}m \" . format ( \" ; \" . join ( [str ( color ) for color in colors] ) , RESET , content = text ) if IS_ANSI_TERMINAL and colors else text": 3444,
 "def explained_variance ( returns , values ) : exp_var = 1 - torch . var ( returns - values ) / torch . var ( returns ) return exp_var . item ( ) ": 3445,
 "def nrows_expected ( self ) : return np . prod ( [i . cvalues . shape[0] for i in self . index_axes] ) ": 3446,
 "def clean_whitespace ( string , compact = False ) : for a , b in ( ( ' \\r\\n ' , ' \\n ' ) , ( ' \\r ' , ' \\n ' ) , ( ' \\n\\n ' , ' \\n ' ) , ( ' \\t ' , ' ' ) , ( ' ' , ' ' ) ) : string = string . replace ( a , b ) if compact : for a , b in ( ( ' \\n ' , ' ' ) , ( ' [ ' , ' [ ' ) , ( ' ' , ' ' ) , ( ' ' , ' ' ) , ( ' ' , ' ' ) ) : string = string . replace ( a , b ) return string . strip ( ) ": 3447,
 "def np_counts ( self ) : counts = defaultdict ( int ) for phrase in self . noun_phrases : counts[phrase] + = 1 return counts": 3448,
 "def student_t ( degrees_of_freedom , confidence = 0 . 95 ) : return scipy . stats . t . interval ( alpha = confidence , df = degrees_of_freedom ) [-1]": 3449,
 "def connect ( *args , **kwargs ) : global __CONNECTION if __CONNECTION is None : __CONNECTION = Connection ( *args , **kwargs ) return __CONNECTION": 3450,
 "def install_postgres ( user = None , dbname = None , password = None ) : execute ( pydiploy . django . install_postgres_server , user = user , dbname = dbname , password = password ) ": 3451,
 "def make_segments ( x , y ) : points = np . array ( [x , y] ) . T . reshape ( -1 , 1 , 2 ) segments = np . concatenate ( [points[ : -1] , points[1 : ]] , axis = 1 ) return segments": 3452,
 "def _do_layout ( self ) : sizer_csvoptions = wx . FlexGridSizer ( 5 , 4 , 5 , 5 ) # Adding parameter widgets to sizer_csvoptions leftpos = wx . LEFT | wx . ADJUST_MINSIZE rightpos = wx . RIGHT | wx . EXPAND current_label_margin = 0 # smaller for left column other_label_margin = 15 for label , widget in zip ( self . param_labels , self . param_widgets ) : sizer_csvoptions . Add ( label , 0 , leftpos , current_label_margin ) sizer_csvoptions . Add ( widget , 0 , rightpos , current_label_margin ) current_label_margin , other_label_margin = \\ other_label_margin , current_label_margin sizer_csvoptions . AddGrowableCol ( 1 ) sizer_csvoptions . AddGrowableCol ( 3 ) self . sizer_csvoptions = sizer_csvoptions": 3453,
 "def coords_on_grid ( self , x , y ) : if isinstance ( x , float ) : x = int ( self . _round ( x ) ) if isinstance ( y , float ) : y = int ( self . _round ( y ) ) if not self . _y_coord_down : y = self . _extents - y return x , y": 3454,
 "def set_xlimits ( self , row , column , min = None , max = None ) : subplot = self . get_subplot_at ( row , column ) subplot . set_xlimits ( min , max ) ": 3455,
 "def schemaParse ( self ) : ret = libxml2mod . xmlSchemaParse ( self . _o ) if ret is None : raise parserError ( ' xmlSchemaParse ( ) failed ' ) __tmp = Schema ( _obj = ret ) return __tmp": 3456,
 "def convolve_fft ( array , kernel ) : array = np . asarray ( array , dtype = np . complex ) kernel = np . asarray ( kernel , dtype = np . complex ) if array . ndim ! = kernel . ndim : raise ValueError ( \" Image and kernel must have same number of \" \" dimensions \" ) array_shape = array . shape kernel_shape = kernel . shape new_shape = np . array ( array_shape ) + np . array ( kernel_shape ) array_slices = [] kernel_slices = [] for ( new_dimsize , array_dimsize , kernel_dimsize ) in zip ( new_shape , array_shape , kernel_shape ) : center = new_dimsize - ( new_dimsize + 1 ) // 2 array_slices + = [slice ( center - array_dimsize // 2 , center + ( array_dimsize + 1 ) // 2 ) ] kernel_slices + = [slice ( center - kernel_dimsize // 2 , center + ( kernel_dimsize + 1 ) // 2 ) ] array_slices = tuple ( array_slices ) kernel_slices = tuple ( kernel_slices ) if not np . all ( new_shape = = array_shape ) : big_array = np . zeros ( new_shape , dtype = np . complex ) big_array[array_slices] = array else : big_array = array if not np . all ( new_shape = = kernel_shape ) : big_kernel = np . zeros ( new_shape , dtype = np . complex ) big_kernel[kernel_slices] = kernel else : big_kernel = kernel array_fft = np . fft . fftn ( big_array ) kernel_fft = np . fft . fftn ( np . fft . ifftshift ( big_kernel ) ) rifft = np . fft . ifftn ( array_fft * kernel_fft ) return rifft[array_slices] . real": 3457,
 "def Parse ( text ) : precondition . AssertType ( text , Text ) if compatibility . PY2 : text = text . encode ( \" utf-8 \" ) return yaml . safe_load ( text ) ": 3458,
 "def pad_cells ( table ) : col_sizes = [max ( map ( len , col ) ) for col in zip ( *table ) ] for row in table : for cell_num , cell in enumerate ( row ) : row[cell_num] = pad_to ( cell , col_sizes[cell_num] ) return table": 3459,
 "def ungzip_data ( input_data ) : buf = StringIO ( input_data ) f = gzip . GzipFile ( fileobj = buf ) return f": 3460,
 "def notin ( arg , values ) : op = ops . NotContains ( arg , values ) return op . to_expr ( ) ": 3461,
 "def string_presenter ( self , dumper , data ) : if ' \\n ' in data : return dumper . represent_scalar ( ' tag : yaml . org , 2002 : str ' , data , style = ' | ' ) else : return dumper . represent_scalar ( ' tag : yaml . org , 2002 : str ' , data ) ": 3462,
 "def bytes_base64 ( x ) : if six . PY2 : return base64 . encodestring ( x ) . replace ( ' \\n ' , ' ' ) return base64 . encodebytes ( bytes_encode ( x ) ) . replace ( b ' \\n ' , b ' ' ) ": 3463,
 "def normalize_enum_constant ( s ) : if s . islower ( ) : return s if s . isupper ( ) : return s . lower ( ) return \" \" . join ( ch if ch . islower ( ) else \" _ \" + ch . lower ( ) for ch in s ) . strip ( \" _ \" ) ": 3464,
 "def array ( self ) : return numpy . array ( [self[sid] . array for sid in sorted ( self ) ] ) ": 3465,
 "def line_line_intersect ( x , y ) : A = x[0] * y[1] - y[0] * x[1] B = x[2] * y[3] - y[2] * x[4] C = ( x[0] - x[1] ) * ( y[2] - y[3] ) - ( y[0] - y[1] ) * ( x[2] - x[3] ) Ix = ( A * ( x[2] - x[3] ) - ( x[0] - x[1] ) * B ) / C Iy = ( A * ( y[2] - y[3] ) - ( y[0] - y[1] ) * B ) / C return Ix , Iy": 3466,
 "def from_series ( series ) : result = PercentRankTransform ( ) result . cdf = series . values result . bin_edges = series . index . values[1 : -1] return result": 3467,
 "def fix ( h , i ) : down ( h , i , h . size ( ) ) up ( h , i ) ": 3468,
 "def get_cursor ( self ) : return self . grid . GetGridCursorRow ( ) , self . grid . GetGridCursorCol ( ) , \\ self . grid . current_table": 3469,
 "def _increment_numeric_suffix ( s ) : if re . match ( r \" . *\\d+$ \" , s ) : return re . sub ( r \" \\d+$ \" , lambda n : str ( int ( n . group ( 0 ) ) + 1 ) , s ) return s + \" _2 \" ": 3470,
 "def get_ntobj ( self ) : if self . nts : return cx . namedtuple ( \" ntgoea \" , \" \" . join ( vars ( next ( iter ( self . nts ) ) ) . keys ( ) ) ) ": 3471,
 "def to_index ( self , index_type , index_name , includes = None ) : return IndexField ( self . name , self . data_type , index_type , index_name , includes ) ": 3472,
 "def array_sha256 ( a ) : dtype = str ( a . dtype ) . encode ( ) shape = numpy . array ( a . shape ) sha = hashlib . sha256 ( ) sha . update ( dtype ) sha . update ( shape ) sha . update ( a . tobytes ( ) ) return sha . hexdigest ( ) ": 3473,
 "def create_run_logfile ( folder ) : with open ( os . path . join ( folder , \" run . log \" ) , \" w \" ) as f : datestring = datetime . datetime . utcnow ( ) . strftime ( \" %Y-%m-%d %H : %M : %S \" ) f . write ( \" timestamp : ' %s ' \" % datestring ) ": 3474,
 "def construct_from_string ( cls , string ) : if string = = cls . name : return cls ( ) raise TypeError ( \" Cannot construct a ' {} ' from \" \" ' {} ' \" . format ( cls , string ) ) ": 3475,
 "def be_array_from_bytes ( fmt , data ) : arr = array . array ( str ( fmt ) , data ) return fix_byteorder ( arr ) ": 3476,
 "def to_dict ( self ) : return { ' schema ' : self . schema , ' table ' : self . table , ' name ' : self . name , ' type ' : self . type}": 3477,
 "def deep_update ( d , u ) : for k , v in u . items ( ) : if isinstance ( v , Mapping ) : d[k] = deep_update ( d . get ( k , {} ) , v ) elif isinstance ( v , list ) : existing_elements = d . get ( k , [] ) d[k] = existing_elements + [ele for ele in v if ele not in existing_elements] else : d[k] = v return d": 3478,
 "def indent ( s , spaces = 4 ) : new = re . sub ( ' ( \\n+ ) ' , ' \\\\1%s ' % ( ' ' * spaces ) , s ) return ( ' ' * spaces ) + new . strip ( ) ": 3479,
 "def CreateVertices ( self , points ) : gr = digraph ( ) for z , x , Q in points : node = ( z , x , Q ) gr . add_nodes ( [node] ) return gr": 3480,
 "def transformer_ae_a3 ( ) : hparams = transformer_ae_base ( ) hparams . batch_size = 4096 hparams . layer_prepostprocess_dropout = 0 . 3 hparams . optimizer = \" Adafactor \" hparams . learning_rate = 0 . 25 hparams . learning_rate_warmup_steps = 10000 return hparams": 3481,
 "def to_linspace ( self ) : if hasattr ( self . shape , ' __len__ ' ) : raise NotImplementedError ( \" can only convert flat Full arrays to linspace \" ) return Linspace ( self . fill_value , self . fill_value , self . shape ) ": 3482,
 "def rex_assert ( self , rex , byte = False ) : self . rex_search ( rex , byte = byte ) ": 3483,
 "def _monitor_callback_wrapper ( callback ) : def callback_handle ( name , array , _ ) : \" \" \" ctypes function \" \" \" callback ( name , array ) return callback_handle": 3484,
 "def _open ( file , mode = ' r ' , buffering = -1 , encoding = None , errors = None , newline = None , closefd = True , opener = None , * , loop = None , executor = None ) : if loop is None : loop = asyncio . get_event_loop ( ) cb = partial ( sync_open , file , mode = mode , buffering = buffering , encoding = encoding , errors = errors , newline = newline , closefd = closefd , opener = opener ) f = yield from loop . run_in_executor ( executor , cb ) return wrap ( f , loop = loop , executor = executor ) ": 3485,
 "def destroy ( self ) : \t\t\t\tif self . session_type = = ' bash ' : \t\t\t # TODO : does this work/handle already being logged out/logged in deep OK?\t\t\tself . logout ( ) \t\telif self . session_type = = ' vagrant ' : \t\t\t # TODO : does this work/handle already being logged out/logged in deep OK?\t\t\tself . logout ( ) ": 3486,
 "def accel_prev ( self , *args ) : if self . get_notebook ( ) . get_current_page ( ) = = 0 : self . get_notebook ( ) . set_current_page ( self . get_notebook ( ) . get_n_pages ( ) - 1 ) else : self . get_notebook ( ) . prev_page ( ) return True": 3487,
 "def get_files ( client , bucket , prefix = ' ' ) : bucket = client . get_bucket ( bucket ) files = list ( bucket . list_blobs ( prefix = prefix ) ) return files": 3488,
 "def get_capture_dimensions ( capture ) : width = int ( capture . get ( cv2 . CAP_PROP_FRAME_WIDTH ) ) height = int ( capture . get ( cv2 . CAP_PROP_FRAME_HEIGHT ) ) return width , height": 3489,
 "def exists ( self , digest ) : return self . conn . client . blob_exists ( self . container_name , digest ) ": 3490,
 "def today ( year = None ) : return datetime . date ( int ( year ) , _date . month , _date . day ) if year else _date": 3491,
 "def get_bucket_page ( page ) : key_list = page . get ( ' Contents ' , [] ) logger . debug ( \" Retrieving page with {} keys \" . format ( len ( key_list ) , ) ) return dict ( ( k . get ( ' Key ' ) , k ) for k in key_list ) ": 3492,
 "def check_dependencies_remote ( args ) : cmd = [args . python , ' -m ' , ' depends ' , args . requirement] env = dict ( PYTHONPATH = os . path . dirname ( __file__ ) ) return subprocess . check_call ( cmd , env = env ) ": 3493,
 "def error_rate ( predictions , labels ) : return 100 . 0 - ( 100 . 0 * np . sum ( np . argmax ( predictions , 1 ) = = np . argmax ( labels , 1 ) ) / predictions . shape[0] ) ": 3494,
 "def average_price ( quantity_1 , price_1 , quantity_2 , price_2 ) : return ( quantity_1 * price_1 + quantity_2 * price_2 ) / \\ ( quantity_1 + quantity_2 ) ": 3495,
 "def human__decision_tree ( ) : # build data N = 1000000 M = 3 X = np . zeros ( ( N , M ) ) X . shape y = np . zeros ( N ) X[0 , 0] = 1 y[0] = 8 X[1 , 1] = 1 y[1] = 8 X[2 , 0 : 2] = 1 y[2] = 4 # fit model xor_model = sklearn . tree . DecisionTreeRegressor ( max_depth = 2 ) xor_model . fit ( X , y ) return xor_model": 3496,
 "def read_string ( cls , string ) : if PY3 and not isinstance ( string , byte_types ) : string = string . encode ( ) return cls . decode ( string ) ": 3497,
 "def get_python ( self ) : if self . multiselect : return super ( MultiSelectField , self ) . get_python ( ) return self . _get ( ) ": 3498,
 "def camel_to_under ( name ) : s1 = re . sub ( \" ( . ) ( [A-Z][a-z]+ ) \" , r \" \\1_\\2 \" , name ) return re . sub ( \" ( [a-z0-9] ) ( [A-Z] ) \" , r \" \\1_\\2 \" , s1 ) . lower ( ) ": 3499,
 "def ndarr2str ( arr , encoding = ' ascii ' ) : # be fast , don ' t check - just assume ' arr ' is a numpy array - the tostring # call will fail anyway if not retval = arr . tostring ( ) # would rather check \" if isinstance ( retval , bytes ) \" , but support 2 . 5 . # could rm the if PY3K check , but it makes this faster on 2 . x . if PY3K and not isinstance ( retval , str ) : return retval . decode ( encoding ) else : # is str return retval": 3500,
 "def uninstall ( cls ) : if os . path . exists ( cls . home ) : shutil . rmtree ( cls . home ) ": 3501,
 "def getTuple ( self ) : return ( self . x , self . y , self . w , self . h ) ": 3502,
 "def first_unique_char ( s ) : if ( len ( s ) = = 1 ) : return 0 ban = [] for i in range ( len ( s ) ) : if all ( s[i] ! = s[k] for k in range ( i + 1 , len ( s ) ) ) = = True and s[i] not in ban : return i else : ban . append ( s[i] ) return -1": 3503,
 "def ask_folder ( message = ' Select folder . ' , default = ' ' , title = ' ' ) : return backend_api . opendialog ( \" ask_folder \" , dict ( message = message , default = default , title = title ) ) ": 3504,
 "def parse_date ( s ) : try : return datetime . date ( int ( s[ : 4] ) , int ( s[5 : 7] ) , int ( s[8 : 10] ) ) except ValueError : # other accepted format used in one-day data set return datetime . datetime . strptime ( s , ' %d %B %Y ' ) . date ( ) ": 3505,
 "def get_single_value ( d ) : assert len ( d ) = = 1 , ' Single-item dict must have just one item , not %d . ' % len ( d ) return next ( six . itervalues ( d ) ) ": 3506,
 "def data ( self , data ) : self . _data = {det : d . copy ( ) for ( det , d ) in data . items ( ) }": 3507,
 "def _renamer ( self , tre ) : # # get the tre with numbered tree tip labels names = tre . get_leaves ( ) # # replace numbered names with snames for name in names : name . name = self . samples[int ( name . name ) ] # # return with only topology and leaf labels return tre . write ( format = 9 ) ": 3508,
 "def with_tz ( request ) : dt = datetime . now ( ) t = Template ( ' {% load tz %}{% localtime on %}{% get_current_timezone as TIME_ZONE %}{{ TIME_ZONE }}{% endlocaltime %} ' ) c = RequestContext ( request ) response = t . render ( c ) return HttpResponse ( response ) ": 3509,
 "def name2rgb ( hue ) : r , g , b = colorsys . hsv_to_rgb ( hue / 360 . 0 , . 8 , . 7 ) return tuple ( int ( x * 256 ) for x in [r , g , b] ) ": 3510,
 "def get_static_url ( ) : path = getattr ( settings , ' STATIC_URL ' , None ) if not path : path = getattr ( settings , ' MEDIA_URL ' , None ) if not path : path = ' / ' return path": 3511,
 "def convert_str_to_datetime ( df , * , column : str , format : str ) : df[column] = pd . to_datetime ( df[column] , format = format ) return df": 3512,
 "def is_interactive ( self ) : # The Python interpreter sets sys . flags correctly , so use them! if sys . flags . interactive : return True # IPython does not set sys . flags when -i is specified , so first # check it if it is already imported . if ' __IPYTHON__ ' not in dir ( six . moves . builtins ) : return False # Then we check the application singleton and determine based on # a variable it sets . try : from IPython . config . application import Application as App return App . initialized ( ) and App . instance ( ) . interact except ( ImportError , AttributeError ) : return False": 3513,
 "def format_doc_text ( text ) : return ' \\n ' . join ( textwrap . fill ( line , width = 99 , initial_indent = ' ' , subsequent_indent = ' ' ) for line in inspect . cleandoc ( text ) . splitlines ( ) ) ": 3514,
 "def inline_inputs ( self ) : self . text = texutils . inline ( self . text , os . path . dirname ( self . _filepath ) ) # Remove children self . _children = {}": 3515,
 "def downsample_with_striding ( array , factor ) : return array[tuple ( np . s_[ : : f] for f in factor ) ]": 3516,
 "def delete_collection ( mongo_uri , database_name , collection_name ) : client = pymongo . MongoClient ( mongo_uri ) db = client[database_name] db . drop_collection ( collection_name ) ": 3517,
 "def command ( name , mode ) : def decorator ( fn ) : commands[name] = fn . __name__ _Client . _addMethod ( fn . __name__ , name , mode ) return fn return decorator": 3518,
 "def _is_initialized ( self , entity ) : return ( not self . _required or ( ( self . _has_value ( entity ) or self . _default is not None ) and self . _get_value ( entity ) is not None ) ) ": 3519,
 "def is_punctuation ( text ) : return not ( text . lower ( ) in config . AVRO_VOWELS or text . lower ( ) in config . AVRO_CONSONANTS ) ": 3520,
 "def _is_expired_response ( self , response ) : if response . status_code ! = 401 : return False challenge = response . headers . get ( ' www-authenticate ' , ' ' ) return ' error = \" invalid_token \" ' in challenge": 3521,
 "def _is_valid_url ( url ) : try : parsed = urlparse ( url ) mandatory_parts = [parsed . scheme , parsed . netloc] return all ( mandatory_parts ) except : return False": 3522,
 "def is_int_type ( val ) : try : # Python 2 return isinstance ( val , ( int , long ) ) except NameError : # Python 3 return isinstance ( val , int ) ": 3523,
 "def expandpath ( path ) : return os . path . expandvars ( os . path . expanduser ( path ) ) . replace ( \" // \" , \" / \" ) ": 3524,
 "def _relpath ( name ) : return os . path . normpath ( os . path . splitdrive ( name ) [1] ) . lstrip ( _allsep ) ": 3525,
 "def logv ( msg , *args , **kwargs ) : if settings . VERBOSE : log ( msg , *args , **kwargs ) ": 3526,
 "def computeFactorial ( n ) : sleep_walk ( 10 ) ret = 1 for i in range ( n ) : ret = ret * ( i + 1 ) return ret": 3527,
 "def filter_greys_using_image ( image , target ) : maskbase = numpy . array ( range ( 256 ) , dtype = numpy . uint8 ) mask = numpy . where ( numpy . in1d ( maskbase , numpy . unique ( image ) ) , maskbase , 0 ) return mask[target]": 3528,
 "def get_url_nofollow ( url ) : \t\ttry : \t\tresponse = urlopen ( url ) \t\tcode = response . getcode ( ) \t\treturn code\texcept HTTPError as e : \t\treturn e . code\texcept : \t\treturn 0": 3529,
 "def _clear ( self ) : draw = ImageDraw . Draw ( self . _background_image ) draw . rectangle ( self . _device . bounding_box , fill = \" black \" ) del draw": 3530,
 "def _finish ( self ) : if self . _process . returncode is None : self . _process . stdin . flush ( ) self . _process . stdin . close ( ) self . _process . wait ( ) self . closed = True": 3531,
 "def apply_filters ( df , filters ) : idx = pd . Series ( [True]*df . shape[0] ) for k , v in list ( filters . items ( ) ) : if k not in df . columns : continue idx & = ( df[k] = = v ) return df . loc[idx]": 3532,
 "def file_matches ( filename , patterns ) : return any ( fnmatch . fnmatch ( filename , pat ) for pat in patterns ) ": 3533,
 "def docannotate ( func ) : func = annotated ( func ) func . metadata . load_from_doc = True if func . decorated : return func func . decorated = True return decorate ( func , _check_and_execute ) ": 3534,
 "def touch_project ( ) : r = Response ( ) project = cd . project . get_internal_project ( ) if project : project . refresh ( ) else : r . fail ( code = ' NO_PROJECT ' , message = ' No open project to refresh ' ) return r . update ( sync_time = sync_status . get ( ' time ' , 0 ) ) . flask_serialize ( ) ": 3535,
 "def add_url_rule ( self , route , endpoint , handler ) : self . app . add_url_rule ( route , endpoint , handler ) ": 3536,
 "def _linepoint ( self , t , x0 , y0 , x1 , y1 ) : # Originally from nodebox-gl out_x = x0 + t * ( x1 - x0 ) out_y = y0 + t * ( y1 - y0 ) return ( out_x , out_y ) ": 3537,
 "def _loadf ( ins ) : output = _float_oper ( ins . quad[2] ) output . extend ( _fpush ( ) ) return output": 3538,
 "def serialize ( self , value ) : if isinstance ( value , str ) : return value return value . strftime ( DATETIME_FORMAT ) ": 3539,
 "def index_all ( self , index_name ) : oks = 0 notoks = 0 for ok , item in streaming_bulk ( self . es_client , self . _iter_documents ( index_name ) ) : if ok : oks + = 1 else : notoks + = 1 logging . info ( \" Import results : %d ok , %d not ok \" , oks , notoks ) ": 3540,
 "def empty_line_count_at_the_end ( self ) : count = 0 for line in self . lines[ : : -1] : if not line or line . isspace ( ) : count + = 1 else : break return count": 3541,
 "def string_format_func ( s ) : \t\treturn u \" \\ \" %s\\ \" \" % unicode ( s ) . replace ( u \" \\\\ \" , u \" \\\\\\\\ \" ) . replace ( u \" \\ \" \" , u \" \\\\\\ \" \" ) ": 3542,
 "def method_name ( func ) : @wraps ( func ) def _method_name ( *args , **kwargs ) : name = to_pascal_case ( func . __name__ ) return func ( name = name , *args , **kwargs ) return _method_name": 3543,
 "def Timestamp ( year , month , day , hour , minute , second ) : return datetime . datetime ( year , month , day , hour , minute , second ) ": 3544,
 "def ceil_nearest ( x , dx = 1 ) : precision = get_sig_digits ( dx ) return round ( math . ceil ( float ( x ) / dx ) * dx , precision ) ": 3545,
 "def get_item_from_queue ( Q , timeout = 0 . 01 ) : try : item = Q . get ( True , 0 . 01 ) except Queue . Empty : return None return item": 3546,
 "def fileopenbox ( msg = None , title = None , argInitialFile = None ) : return psidialogs . ask_file ( message = msg , title = title , default = argInitialFile ) ": 3547,
 "def remove_hop_by_hop_headers ( headers ) : headers[ : ] = [ ( key , value ) for key , value in headers if not is_hop_by_hop_header ( key ) ]": 3548,
 "def create_db ( app , appbuilder ) : from flask_appbuilder . models . sqla import Base _appbuilder = import_application ( app , appbuilder ) engine = _appbuilder . get_session . get_bind ( mapper = None , clause = None ) Base . metadata . create_all ( engine ) click . echo ( click . style ( \" DB objects created \" , fg = \" green \" ) ) ": 3549,
 "def intersect ( self , other ) : return DataFrame ( self . _jdf . intersect ( other . _jdf ) , self . sql_ctx ) ": 3550,
 "def _to_java_object_rdd ( rdd ) : rdd = rdd . _reserialize ( AutoBatchedSerializer ( PickleSerializer ( ) ) ) return rdd . ctx . _jvm . org . apache . spark . mllib . api . python . SerDe . pythonToJava ( rdd . _jrdd , True ) ": 3551,
 "def as_dict ( df , ix = ' : ' ) : if isinstance ( df . index , pd . DatetimeIndex ) : df[ ' datetime ' ] = df . index return df . to_dict ( orient = ' records ' ) [ix]": 3552,
 "def remove_from_string ( string , values ) : for v in values : string = string . replace ( v , ' ' ) return string": 3553,
 "def get_function ( function_name ) : module , basename = str ( function_name ) . rsplit ( ' . ' , 1 ) try : return getattr ( __import__ ( module , fromlist = [basename] ) , basename ) except ( ImportError , AttributeError ) : raise FunctionNotFound ( function_name ) ": 3554,
 "def add ( self , name , desc , func = None , args = None , krgs = None ) : self . entries . append ( MenuEntry ( name , desc , func , args or [] , krgs or {} ) ) ": 3555,
 "def register_logging_factories ( loader ) : loader . register_factory ( logging . Logger , LoggerFactory ) loader . register_factory ( logging . Handler , LoggingHandlerFactory ) ": 3556,
 "def reraise ( error ) : if hasattr ( error , \" _type_ \" ) : six . reraise ( type ( error ) , error , error . _traceback ) raise error": 3557,
 "def bbox ( self ) : # ( stop - 1 ) to return the max pixel location , not the slice index return ( self . _slice[0] . start , self . _slice[1] . start , self . _slice[0] . stop - 1 , self . _slice[1] . stop - 1 ) * u . pix": 3558,
 "def _matrix3_to_dcm_array ( self , m ) : assert ( isinstance ( m , Matrix3 ) ) return np . array ( [[m . a . x , m . a . y , m . a . z] , [m . b . x , m . b . y , m . b . z] , [m . c . x , m . c . y , m . c . z]] ) ": 3559,
 "def base_path ( self ) : return os . path . join ( self . container . base_path , self . name ) ": 3560,
 "def delete ( filething ) : f = FLAC ( filething ) filething . fileobj . seek ( 0 ) f . delete ( filething ) ": 3561,
 "def parse_func_kwarg_keys ( func , with_vals = False ) : sourcecode = get_func_sourcecode ( func , strip_docstr = True , strip_comments = True ) kwkeys = parse_kwarg_keys ( sourcecode , with_vals = with_vals ) # ut . get_func_kwargs TODO return kwkeys": 3562,
 "def pingback_url ( self , server_name , target_url ) : try : server = ServerProxy ( server_name ) reply = server . pingback . ping ( self . entry_url , target_url ) except ( Error , socket . error ) : reply = ' %s cannot be pinged . ' % target_url return reply": 3563,
 "def get_last_commit_line ( git_path = None ) : if git_path is None : git_path = GIT_PATH output = check_output ( [git_path , \" log \" , \" --pretty = format : ' %ad %h %s ' \" , \" --date = short \" , \" -n1 \" ] ) return output . strip ( ) [1 : -1]": 3564,
 "def multidict_to_dict ( d ) : return dict ( ( k , v[0] if len ( v ) = = 1 else v ) for k , v in iterlists ( d ) ) ": 3565,
 "def _get_gid ( name ) : if getgrnam is None or name is None : return None try : result = getgrnam ( name ) except KeyError : result = None if result is not None : return result[2] return None": 3566,
 "async def delete ( self ) : return await self . bot . delete_message ( self . chat . id , self . message_id ) ": 3567,
 "def border ( self ) : border_array = self . bitmap - self . inner . bitmap return Region ( border_array ) ": 3568,
 "def strip_comments ( string , comment_symbols = frozenset ( ( ' # ' , ' // ' ) ) ) : lines = string . splitlines ( ) for k in range ( len ( lines ) ) : for symbol in comment_symbols : lines[k] = strip_comment_line_with_symbol ( lines[k] , start = symbol ) return ' \\n ' . join ( lines ) ": 3569,
 "def getScreenDims ( self ) : width = ale_lib . getScreenWidth ( self . obj ) height = ale_lib . getScreenHeight ( self . obj ) return ( width , height ) ": 3570,
 "def get_keys_from_shelve ( file_name , file_location ) : temp_list = list ( ) file = __os . path . join ( file_location , file_name ) shelve_store = __shelve . open ( file ) for key in shelve_store : temp_list . append ( key ) shelve_store . close ( ) return temp_list": 3571,
 "def Output ( self ) : self . Open ( ) self . Header ( ) self . Body ( ) self . Footer ( ) ": 3572,
 "def hamming_distance ( str1 , str2 ) : if len ( str1 ) ! = len ( str2 ) : raise VisualizationError ( ' Strings not same length . ' ) return sum ( s1 ! = s2 for s1 , s2 in zip ( str1 , str2 ) ) ": 3573,
 "def max ( self ) : if len ( self . regions ) ! = 1 : raise ClaripyVSAOperationError ( \" ' max ( ) ' onlly works on single-region value-sets . \" ) return self . get_si ( next ( iter ( self . regions ) ) ) . max": 3574,
 "def rollback ( name , database = None , directory = None , verbose = None ) : router = get_router ( directory , database , verbose ) router . rollback ( name ) ": 3575,
 "def _get_closest_week ( self , metric_date ) : # find the offset to the closest monday days_after_monday = metric_date . isoweekday ( ) - 1 return metric_date - datetime . timedelta ( days = days_after_monday ) ": 3576,
 "def get_creation_datetime ( filepath ) : if platform . system ( ) = = ' Windows ' : return datetime . fromtimestamp ( os . path . getctime ( filepath ) ) else : stat = os . stat ( filepath ) try : return datetime . fromtimestamp ( stat . st_birthtime ) except AttributeError : # We ' re probably on Linux . No easy way to get creation dates here , # so we ' ll settle for when its content was last modified . return None": 3577,
 "def get_grid_spatial_dimensions ( self , variable ) : data = self . open_dataset ( self . service ) . variables[variable . variable] dimensions = list ( data . dimensions ) return data . shape[dimensions . index ( variable . x_dimension ) ] , data . shape[dimensions . index ( variable . y_dimension ) ]": 3578,
 "def _force_float ( v ) : try : return float ( v ) except Exception as exc : return float ( ' nan ' ) logger . warning ( ' Failed to convert {} to float with {} error . Using 0 instead . ' . format ( v , exc ) ) ": 3579,
 "def end_of_history ( event ) : event . current_buffer . history_forward ( count = 10**100 ) buff = event . current_buffer buff . go_to_history ( len ( buff . _working_lines ) - 1 ) ": 3580,
 "def dot_v2 ( vec1 , vec2 ) : return vec1 . x * vec2 . x + vec1 . y * vec2 . y": 3581,
 "def batch_get_item ( self , batch_list ) : request_items = self . dynamize_request_items ( batch_list ) return self . layer1 . batch_get_item ( request_items , object_hook = item_object_hook ) ": 3582,
 "def validate_email ( email ) : from django . core . validators import validate_email from django . core . exceptions import ValidationError try : validate_email ( email ) return True except ValidationError : return False": 3583,
 "def printheader ( h = None ) : writer = csv . writer ( sys . stdout ) writer . writerow ( header_fields ( h ) ) ": 3584,
 "def normalize_job_id ( job_id ) : \t\tif not isinstance ( job_id , uuid . UUID ) : \t\tjob_id = uuid . UUID ( job_id ) \treturn job_id": 3585,
 "def load_streams ( chunks ) : chunks = peekable ( chunks ) while chunks : if six . PY3 : dc = zlib . decompressobj ( wbits = zlib . MAX_WBITS | 16 ) else : dc = zlib . decompressobj ( zlib . MAX_WBITS | 16 ) yield load_stream ( dc , chunks ) if dc . unused_data : chunks = peekable ( itertools . chain ( ( dc . unused_data , ) , chunks ) ) ": 3586,
 "def hclust_linearize ( U ) : from scipy . cluster import hierarchy Z = hierarchy . ward ( U ) return hierarchy . leaves_list ( hierarchy . optimal_leaf_ordering ( Z , U ) ) ": 3587,
 "def main ( argv = sys . argv , stream = sys . stderr ) : args = parse_args ( argv ) suite = build_suite ( args ) runner = unittest . TextTestRunner ( verbosity = args . verbose , stream = stream ) result = runner . run ( suite ) return get_status ( result ) ": 3588,
 "def activate ( self ) : add_builtin = self . add_builtin for name , func in self . auto_builtins . iteritems ( ) : add_builtin ( name , func ) ": 3589,
 "def _loop_timeout_cb ( self , main_loop ) : self . _anything_done = True logger . debug ( \" _loop_timeout_cb ( ) called \" ) main_loop . quit ( ) ": 3590,
 "def sets_are_rooted_compat ( one_set , other ) : if one_set . issubset ( other ) or other . issubset ( one_set ) : return True return not intersection_not_empty ( one_set , other ) ": 3591,
 "def ip_address_list ( ips ) : # first , try it as a single IP address try : return ip_address ( ips ) except ValueError : pass # then , consider it as an ipaddress . IPv[4|6]Network instance and expand it return list ( ipaddress . ip_network ( u ( ips ) ) . hosts ( ) ) ": 3592,
 "def check_auth ( email , password ) : try : user = User . get ( User . email = = email ) except User . DoesNotExist : return False return password = = user . password": 3593,
 "def chunked_list ( _list , _chunk_size = 50 ) : for i in range ( 0 , len ( _list ) , _chunk_size ) : yield _list[i : i + _chunk_size]": 3594,
 "def is_running ( self ) : return self . state in [self . STATE_IDLE , self . STATE_ACTIVE , self . STATE_SLEEPING]": 3595,
 "def _get_var_from_string ( item ) : modname , varname = _split_mod_var_names ( item ) if modname : mod = __import__ ( modname , globals ( ) , locals ( ) , [varname] , -1 ) return getattr ( mod , varname ) else : return globals ( ) [varname]": 3596,
 "def struct2dict ( struct ) : return {x : getattr ( struct , x ) for x in dict ( struct . _fields_ ) . keys ( ) }": 3597,
 "def filter_set ( input , **params ) : PARAM_WHERE = ' where ' return Converter . df2list ( pd . DataFrame . from_records ( input ) . query ( params . get ( PARAM_WHERE ) ) ) ": 3598,
 "def _py_ex_argtype ( executable ) : result = [] for p in executable . ordered_parameters : atypes = p . argtypes if atypes is not None : result . extend ( p . argtypes ) else : print ( ( \" No argtypes for : {} \" . format ( p . definition ( ) ) ) ) if type ( executable ) . __name__ = = \" Function \" : result . extend ( executable . argtypes ) return result": 3599,
 "def properties ( self ) : properties = { ' id ' : self . _id} if self . _name is not None : properties[ ' name ' ] = self . _name return properties": 3600,
 "def indexTupleFromItem ( self , treeItem ) : # TODO : move to BaseTreeItem? if not treeItem : return ( QtCore . QModelIndex ( ) , QtCore . QModelIndex ( ) ) if not treeItem . parentItem : # TODO : only necessary because of childNumber? return ( QtCore . QModelIndex ( ) , QtCore . QModelIndex ( ) ) # Is there a bug in Qt in QStandardItemModel : : indexFromItem? # It passes the parent in createIndex . TODO : investigate row = treeItem . childNumber ( ) return ( self . createIndex ( row , 0 , treeItem ) , self . createIndex ( row , self . columnCount ( ) - 1 , treeItem ) ) ": 3601,
 "def locate ( command , on ) : location = find_page_location ( command , on ) click . echo ( location ) ": 3602,
 "def find_centroid ( region ) : x , y = center_of_mass ( region ) w = np . argwhere ( region ) i , j = w[np . argmin ( np . linalg . norm ( w - ( x , y ) , axis = 1 ) ) ] return i , j": 3603,
 "def distL1 ( x1 , y1 , x2 , y2 ) : return int ( abs ( x2-x1 ) + abs ( y2-y1 ) + . 5 ) ": 3604,
 "def find ( self , node , path ) : return node . find ( path , namespaces = self . namespaces ) ": 3605,
 "def deprecated ( operation = None ) : def inner ( o ) : o . deprecated = True return o return inner ( operation ) if operation else inner": 3606,
 "def es_field_sort ( fld_name ) : parts = fld_name . split ( \" . \" ) if \" _ \" not in parts[-1] : parts[-1] = \" _ \" + parts[-1] return \" . \" . join ( parts ) ": 3607,
 "def _make_proxy_property ( bind_attr , attr_name ) : def proxy_property ( self ) : bind = getattr ( self , bind_attr ) return getattr ( bind , attr_name ) return property ( proxy_property ) ": 3608,
 "def find_ge ( a , x ) : i = bs . bisect_left ( a , x ) if i ! = len ( a ) : return i raise ValueError": 3609,
 "def fixed ( ctx , number , decimals = 2 , no_commas = False ) : value = _round ( ctx , number , decimals ) format_str = ' { : f} ' if no_commas else ' { : , f} ' return format_str . format ( value ) ": 3610,
 "def list_backends ( _ ) : backends = [b . __name__ for b in available_backends ( ) ] print ( ' \\n ' . join ( backends ) ) ": 3611,
 "def fourier_series ( x , f , n = 0 ) : # Make the parameter objects for all the terms a0 , *cos_a = parameters ( ' , ' . join ( [ ' a{} ' . format ( i ) for i in range ( 0 , n + 1 ) ] ) ) sin_b = parameters ( ' , ' . join ( [ ' b{} ' . format ( i ) for i in range ( 1 , n + 1 ) ] ) ) # Construct the series series = a0 + sum ( ai * cos ( i * f * x ) + bi * sin ( i * f * x ) for i , ( ai , bi ) in enumerate ( zip ( cos_a , sin_b ) , start = 1 ) ) return series": 3612,
 "def _convert_latitude ( self , latitude ) : return int ( ( 180 - ( 180 / pi * log ( tan ( pi / 4 + latitude * pi / 360 ) ) ) ) * ( 2 ** self . _zoom ) * self . _size / 360 ) ": 3613,
 "def frombits ( cls , bits ) : return cls . frombitsets ( map ( cls . BitSet . frombits , bits ) ) ": 3614,
 "def set_logxticks_for_all ( self , row_column_list = None , logticks = None ) : if row_column_list is None : self . ticks[ ' x ' ] = [ ' 1e%d ' % u for u in logticks] else : for row , column in row_column_list : self . set_logxticks ( row , column , logticks ) ": 3615,
 "def remove_rows_matching ( df , column , match ) : df = df . copy ( ) mask = df[column] . values ! = match return df . iloc[mask , : ]": 3616,
 "def get_kind ( self , value ) : if isinstance ( value , float ) : return ' f ' elif isinstance ( value , int ) : return ' i ' else : raise ValueError ( \" Only integer or floating point values can be stored . \" ) ": 3617,
 "def exit_if_missing_graphviz ( self ) : ( out , err ) = utils . capture_shell ( \" which dot \" ) if \" dot \" not in out : ui . error ( c . MESSAGES[ \" dot_missing \" ] ) ": 3618,
 "def __grid_widgets ( self ) : scrollbar_column = 0 if self . __compound is tk . LEFT else 2 self . _canvas . grid ( row = 0 , column = 1 , sticky = \" nswe \" ) self . _scrollbar . grid ( row = 0 , column = scrollbar_column , sticky = \" ns \" ) ": 3619,
 "def _uniqueid ( n = 30 ) : return ' ' . join ( random . SystemRandom ( ) . choice ( string . ascii_uppercase + string . ascii_lowercase ) for _ in range ( n ) ) ": 3620,
 "def _gaps_from ( intervals ) : sliding_window = zip ( intervals , intervals[1 : ] ) gaps = [b[0] - a[1] for a , b in sliding_window] return gaps": 3621,
 "def add_header ( self , name , value ) : self . _headers . setdefault ( _hkey ( name ) , [] ) . append ( _hval ( value ) ) ": 3622,
 "def test ( ) : dns = ReverseDNS ( ) print ( dns . lookup ( ' 192 . 168 . 0 . 1 ' ) ) print ( dns . lookup ( ' 8 . 8 . 8 . 8 ' ) ) # Test cache print ( dns . lookup ( ' 8 . 8 . 8 . 8 ' ) ) ": 3623,
 "def random_alphanum ( length ) : charset = string . ascii_letters + string . digits return random_string ( length , charset ) ": 3624,
 "def _is_name_used_as_variadic ( name , variadics ) : return any ( variadic . value = = name or variadic . value . parent_of ( name ) for variadic in variadics ) ": 3625,
 "def ancestors ( self , node ) : if isinstance ( node , int ) : warnings . warn ( ' Calling ancestors ( ) with a node id is deprecated , ' ' use a DAGNode instead ' , DeprecationWarning , 2 ) node = self . _id_to_node[node] return nx . ancestors ( self . _multi_graph , node ) ": 3626,
 "def show ( data , negate = False ) : from PIL import Image as pil data = np . array ( ( data - data . min ( ) ) * 255 . 0 / ( data . max ( ) - data . min ( ) ) , np . uint8 ) if negate : data = 255 - data img = pil . fromarray ( data ) img . show ( ) ": 3627,
 "def get_active_ajax_datatable ( self ) : data = getattr ( self . request , self . request . method ) datatables_dict = self . get_datatables ( only = data[ ' datatable ' ] ) return list ( datatables_dict . values ( ) ) [0]": 3628,
 "def last_modified_time ( path ) : return pd . Timestamp ( os . path . getmtime ( path ) , unit = ' s ' , tz = ' UTC ' ) ": 3629,
 "def normalize_vector ( v ) : norm = np . linalg . norm ( v ) return v/norm if not norm = = 0 else v": 3630,
 "def remove_index ( self ) : self . index_client . close ( self . index_name ) self . index_client . delete ( self . index_name ) ": 3631,
 "def input ( self , prompt , default = None , show_default = True ) : return click . prompt ( prompt , default = default , show_default = show_default ) ": 3632,
 "def _ipv4_text_to_int ( self , ip_text ) : if ip_text is None : return None assert isinstance ( ip_text , str ) return struct . unpack ( ' !I ' , addrconv . ipv4 . text_to_bin ( ip_text ) ) [0]": 3633,
 "def _lookup_parent ( self , cls ) : codeobj = self . parent while codeobj is not None and not isinstance ( codeobj , cls ) : codeobj = codeobj . parent return codeobj": 3634,
 "def get_week_start_end_day ( ) : t = date . today ( ) wd = t . weekday ( ) return ( t - timedelta ( wd ) , t + timedelta ( 6 - wd ) ) ": 3635,
 "def pop_row ( self , idr = None , tags = False ) : idr = idr if idr is not None else len ( self . body ) - 1 row = self . body . pop ( idr ) return row if tags else [cell . childs[0] for cell in row]": 3636,
 "def _nth ( arr , n ) : try : return arr . iloc[n] except ( KeyError , IndexError ) : return np . nan": 3637,
 "def record_diff ( old , new ) : old , new = _norm_json_params ( old , new ) return json_delta . diff ( new , old , verbose = False ) ": 3638,
 "def setLib ( self , lib ) : for name , item in lib . items ( ) : self . font . lib[name] = item": 3639,
 "def is_numeric ( value ) : return type ( value ) in [ int , float , np . int8 , np . int16 , np . int32 , np . int64 , np . float16 , np . float32 , np . float64 , np . float128 ]": 3640,
 "def is_identity ( ) : for index , row in enumerate ( self . dta ) : if row[index] = = 1 : for num , element in enumerate ( row ) : if num ! = index : if element ! = 0 : return False else : return False return True": 3641,
 "def bounding_box ( img ) : r locations = numpy . argwhere ( img ) mins = locations . min ( 0 ) maxs = locations . max ( 0 ) + 1 return [slice ( x , y ) for x , y in zip ( mins , maxs ) ]": 3642,
 "def do_files_exist ( filenames ) : preexisting = [tf . io . gfile . exists ( f ) for f in filenames] return any ( preexisting ) ": 3643,
 "def one_hot_encoding ( input_tensor , num_labels ) : xview = input_tensor . view ( -1 , 1 ) . to ( torch . long ) onehot = torch . zeros ( xview . size ( 0 ) , num_labels , device = input_tensor . device , dtype = torch . float ) onehot . scatter_ ( 1 , xview , 1 ) return onehot . view ( list ( input_tensor . shape ) + [-1] ) ": 3644,
 "def compare ( self , dn , attr , value ) : return self . connection . compare_s ( dn , attr , value ) = = 1": 3645,
 "def _one_exists ( input_files ) : for f in input_files : if os . path . exists ( f ) : return True return False": 3646,
 "def days_in_month ( year , month ) : eom = _days_per_month[month - 1] if is_leap_year ( year ) and month = = 2 : eom + = 1 return eom": 3647,
 "def on_binop ( self , node ) : # ( ' left ' , ' op ' , ' right ' ) return op2func ( node . op ) ( self . run ( node . left ) , self . run ( node . right ) ) ": 3648,
 "def print_item_with_children ( ac , classes , level ) : print_row ( ac . id , ac . name , f \" {ac . allocation : , . 2f} \" , level ) print_children_recursively ( classes , ac , level + 1 ) ": 3649,
 "def _scaleSinglePoint ( point , scale = 1 , convertToInteger = True ) : x , y = point if convertToInteger : return int ( round ( x * scale ) ) , int ( round ( y * scale ) ) else : return ( x * scale , y * scale ) ": 3650,
 "def l2_norm ( params ) : flattened , _ = flatten ( params ) return np . dot ( flattened , flattened ) ": 3651,
 "def get_extract_value_function ( column_identifier ) : def extract_value ( run_result ) : pos = None for i , column in enumerate ( run_result . columns ) : if column . title = = column_identifier : pos = i break if pos is None : sys . exit ( ' CPU time missing for task {0} . ' . format ( run_result . task_id[0] ) ) return Util . to_decimal ( run_result . values[pos] ) return extract_value": 3652,
 "def items_to_dict ( items ) : res = collections . defaultdict ( list ) for k , v in items : res[k] . append ( v ) return normalize_dict ( dict ( res ) ) ": 3653,
 "def vars_ ( self ) : return [x for x in self[self . current_scope] . values ( ) if x . class_ = = CLASS . var]": 3654,
 "def deduplicate ( list_object ) : new = [] for item in list_object : if item not in new : new . append ( item ) return new": 3655,
 "def log ( x ) : if isinstance ( x , UncertainFunction ) : mcpts = np . log ( x . _mcpts ) return UncertainFunction ( mcpts ) else : return np . log ( x ) ": 3656,
 "def hdf5_to_dict ( filepath , group = ' / ' ) : if not h5py . is_hdf5 ( filepath ) : raise RuntimeError ( filepath , ' is not a valid HDF5 file . ' ) with h5py . File ( filepath , ' r ' ) as handler : dic = walk_hdf5_to_dict ( handler[group] ) return dic": 3657,
 "def __deepcopy__ ( self , memo ) : # noinspection PyArgumentList return self . __class__ ( **{key : deepcopy ( getattr ( self , key ) , memo ) for key in self . keys} ) ": 3658,
 "def from_file ( filename ) : f = open ( filename , ' r ' ) j = json . load ( f ) f . close ( ) return from_dict ( j ) ": 3659,
 "def pause ( ) : \t\tif not settings . platformCompatible ( ) : \t\treturn False\t ( output , error ) = subprocess . Popen ( [ \" osascript \" , \" -e \" , PAUSE] , stdout = subprocess . PIPE ) . communicate ( ) ": 3660,
 "def get_frame_locals ( stepback = 0 ) : with Frame ( stepback = stepback ) as frame : locals_dict = frame . f_locals return locals_dict": 3661,
 "def do_file_show ( client , args ) : for src_uri in args . uris : client . download_file ( src_uri , sys . stdout . buffer ) return True": 3662,
 "def getLinesFromLogFile ( stream ) : stream . flush ( ) stream . seek ( 0 ) lines = stream . readlines ( ) return lines": 3663,
 "def input_validate_yubikey_secret ( data , name = ' data ' ) : if isinstance ( data , pyhsm . aead_cmd . YHSM_YubiKeySecret ) : data = data . pack ( ) return input_validate_str ( data , name ) ": 3664,
 "def extract_log_level_from_environment ( k , default ) : return LOG_LEVELS . get ( os . environ . get ( k ) ) or int ( os . environ . get ( k , default ) ) ": 3665,
 "def remove_all_handler ( self ) : for handler in self . logger . handlers[ : ] : self . logger . removeHandler ( handler ) self . _handler_cache . append ( handler ) ": 3666,
 "def log_all ( self , file ) : global rflink_log if file = = None : rflink_log = None else : log . debug ( ' logging to : %s ' , file ) rflink_log = open ( file , ' a ' ) ": 3667,
 "def adjust_bounding_box ( bbox ) : for i in range ( 0 , 4 ) : if i in bounding_box : bbox[i] = bounding_box[i] else : bbox[i] + = delta_bounding_box[i] return bbox": 3668,
 "def _turn_sigterm_into_systemexit ( ) : # pragma : no cover try : import signal except ImportError : return def handle_term ( signo , frame ) : raise SystemExit signal . signal ( signal . SIGTERM , handle_term ) ": 3669,
 "def info ( self , message , *args , **kwargs ) : self . _log ( logging . INFO , message , *args , **kwargs ) ": 3670,
 "def patch_lines ( x ) : for idx in range ( len ( x ) -1 ) : x[idx] = np . vstack ( [x[idx] , x[idx+1][0 , : ]] ) return x": 3671,
 "def add_queue_handler ( queue ) : handler = QueueLogHandler ( queue ) handler . setFormatter ( QueueFormatter ( ) ) handler . setLevel ( DEBUG ) GLOBAL_LOGGER . addHandler ( handler ) ": 3672,
 "def __init__ ( self , min_value , max_value , format = \" % ( bar ) s : % ( percentage ) 6 . 2f%% % ( timeinfo ) s \" , width = 40 , barchar = \" # \" , emptychar = \" - \" , output = sys . stdout ) : \t\t\t\tself . min_value = min_value\t\tself . max_value = max_value\t\tself . format = format\t\tself . width = width\t\tself . barchar = barchar\t\tself . emptychar = emptychar\t\tself . output = output\t\t\t\tself . firsttime = True\t\tself . prevtime = time . time ( ) \t\tself . starttime = self . prevtime\t\tself . prevfraction = 0\t\tself . firsttimedone = False\t\tself . value = self . min_value": 3673,
 "def consts ( self ) : # We cannot use a set comprehension because consts do not need # to be hashable . consts = [] append_const = consts . append for instr in self . instrs : if isinstance ( instr , LOAD_CONST ) and instr . arg not in consts : append_const ( instr . arg ) return tuple ( consts ) ": 3674,
 "def __add__ ( self , other ) : return chaospy . poly . collection . arithmetics . add ( self , other ) ": 3675,
 "def gaussian_noise ( x , severity = 1 ) : c = [ . 08 , . 12 , 0 . 18 , 0 . 26 , 0 . 38][severity - 1] x = np . array ( x ) / 255 . x_clip = np . clip ( x + np . random . normal ( size = x . shape , scale = c ) , 0 , 1 ) * 255 return around_and_astype ( x_clip ) ": 3676,
 "def decode_mysql_string_literal ( text ) : assert text . startswith ( \" ' \" ) assert text . endswith ( \" ' \" ) # Ditch quotes from the string literal . text = text[1 : -1] return MYSQL_STRING_ESCAPE_SEQUENCE_PATTERN . sub ( unescape_single_character , text , ) ": 3677,
 "def ensure_dir ( f ) : d = os . path . dirname ( f ) if not os . path . exists ( d ) : os . makedirs ( d ) ": 3678,
 "def calculate_bbox_area ( bbox , rows , cols ) : bbox = denormalize_bbox ( bbox , rows , cols ) x_min , y_min , x_max , y_max = bbox[ : 4] area = ( x_max - x_min ) * ( y_max - y_min ) return area": 3679,
 "def tearDown ( self ) : if self . sdkobject and self . sdkobject . id : self . sdkobject . delete ( ) self . sdkobject . id = None": 3680,
 "def _get_log_prior_cl_func ( self ) : return SimpleCLFunction . from_string ( ' ' ' mot_float_type _computeLogPrior ( local const mot_float_type* x , void* data ) { return ' ' ' + self . _log_prior_func . get_cl_function_name ( ) + ' ' ' ( x , data ) ; } ' ' ' , dependencies = [self . _log_prior_func] ) ": 3681,
 "def datetime_match ( data , dts ) : dts = dts if islistable ( dts ) else [dts] if any ( [not isinstance ( i , datetime . datetime ) for i in dts] ) : error_msg = ( \" `time` can only be filtered by datetimes \" ) raise TypeError ( error_msg ) return data . isin ( dts ) ": 3682,
 "def to_camel ( s ) : # r ' ( ?!^ ) _ ( [a-zA-Z] ) original regex wasn ' t process first groups return re . sub ( r ' _ ( [a-zA-Z] ) ' , lambda m : m . group ( 1 ) . upper ( ) , ' _ ' + s ) ": 3683,
 "def _process_legend ( self ) : for l in self . handles[ ' plot ' ] . legend : l . items[ : ] = [] l . border_line_alpha = 0 l . background_fill_alpha = 0": 3684,
 "def snake_to_camel ( name ) : ret = \" \" . join ( x . title ( ) for x in name . split ( \" _ \" ) ) ret = ret[0] . lower ( ) + ret[1 : ] return ret": 3685,
 "def set_scale ( self , scale , no_reset = False ) : return self . scale_to ( *scale[ : 2] , no_reset = no_reset ) ": 3686,
 "def nested_update ( d , u ) : for k , v in list ( u . items ( ) ) : if isinstance ( v , collections . Mapping ) : r = nested_update ( d . get ( k , {} ) , v ) d[k] = r else : d[k] = u[k] return d": 3687,
 "def std_datestr ( self , datestr ) : return date . strftime ( self . str2date ( datestr ) , self . std_dateformat ) ": 3688,
 "def from_string ( cls , s ) : for num , text in cls . _STATUS2STR . items ( ) : if text = = s : return cls ( num ) else : raise ValueError ( \" Wrong string %s \" % s ) ": 3689,
 "def update ( self , dictionary = None , **kwargs ) : if not dictionary = = None : kwargs . update ( dictionary ) for k in list ( kwargs . keys ( ) ) : self[k] = kwargs[k]": 3690,
 "def create_cursor ( self , name = None ) : return Cursor ( self . client_connection , self . connection , self . djongo_connection ) ": 3691,
 "def _possibly_convert_objects ( values ) : return np . asarray ( pd . Series ( values . ravel ( ) ) ) . reshape ( values . shape ) ": 3692,
 "def plot3d_init ( fignum ) : from mpl_toolkits . mplot3d import Axes3D fig = plt . figure ( fignum ) ax = fig . add_subplot ( 111 , projection = ' 3d ' ) return ax": 3693,
 "def apply ( self , func , workers = 1 , job_size = 10000 ) : if workers = = 1 : for lines in self . iter_chunks ( job_size ) : yield func ( lines ) else : with ProcessPoolExecutor ( max_workers = workers ) as executor : for result in executor . map ( func , self . iter_chunks ( job_size ) ) : yield result": 3694,
 "def multiprocess_mapping ( func , iterable ) : if os . name = = ' nt ' : # In Windows there is no fork . return list ( map ( func , iterable ) ) try : p = multiprocessing . Pool ( ) return_data = list ( p . imap ( func , iterable ) ) p . close ( ) p . join ( ) return return_data except OSError : return list ( map ( func , iterable ) ) ": 3695,
 "def imapchain ( *a , **kwa ) : imap_results = map ( *a , **kwa ) return itertools . chain ( *imap_results ) ": 3696,
 "def get ( self , queue_get ) : if isinstance ( queue_get , ( tuple , list ) ) : self . result . extend ( queue_get ) ": 3697,
 "def match_empty ( self , el ) : is_empty = True for child in self . get_children ( el , tags = False ) : if self . is_tag ( child ) : is_empty = False break elif self . is_content_string ( child ) and RE_NOT_EMPTY . search ( child ) : is_empty = False break return is_empty": 3698,
 "def issubset ( self , other ) : self . _binary_sanity_check ( other ) return set . issubset ( self , other ) ": 3699,
 "def __neg__ ( self ) : return self . __class__ ( self[0] , self . _curve . p ( ) -self[1] , self . _curve ) ": 3700,
 "def str_is_well_formed ( xml_str ) : try : str_to_etree ( xml_str ) except xml . etree . ElementTree . ParseError : return False else : return True": 3701,
 "def to_dotfile ( G : nx . DiGraph , filename : str ) : A = to_agraph ( G ) A . write ( filename ) ": 3702,
 "def are_in_interval ( s , l , r , border = ' included ' ) : return numpy . all ( [IntensityRangeStandardization . is_in_interval ( x , l , r , border ) for x in s] ) ": 3703,
 "def is_unix_like ( platform = None ) : platform = platform or sys . platform platform = platform . lower ( ) return platform . startswith ( \" linux \" ) or platform . startswith ( \" darwin \" ) or \\ platform . startswith ( \" cygwin \" ) ": 3704,
 "def normalize ( name ) : # Name should not contain some specials chars ( issue # 1068 ) ret = name . replace ( ' : ' , ' ' ) ret = ret . replace ( ' % ' , ' ' ) ret = ret . replace ( ' ' , ' _ ' ) return ret": 3705,
 "def accel_next ( self , *args ) : if self . get_notebook ( ) . get_current_page ( ) + 1 = = self . get_notebook ( ) . get_n_pages ( ) : self . get_notebook ( ) . set_current_page ( 0 ) else : self . get_notebook ( ) . next_page ( ) return True": 3706,
 "def _arrayFromBytes ( dataBytes , metadata ) : array = numpy . fromstring ( dataBytes , dtype = numpy . typeDict[metadata[ ' dtype ' ]] ) if ' shape ' in metadata : array = array . reshape ( metadata[ ' shape ' ] ) return array": 3707,
 "def _read_stream_for_size ( stream , buf_size = 65536 ) : size = 0 while True : buf = stream . read ( buf_size ) size + = len ( buf ) if not buf : break return size": 3708,
 "def setupLogFile ( self ) : \t\t\t\tself . logWrite ( \" \\n # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \" ) \t\tself . logWrite ( \" calcpkg . py log from \" + str ( datetime . datetime . now ( ) ) ) \t\tself . changeLogging ( True ) ": 3709,
 "def get_oauth_token ( ) : url = \" {0}/token \" . format ( DEFAULT_ORIGIN[ \" Origin \" ] ) r = s . get ( url = url ) return r . json ( ) [ \" t \" ]": 3710,
 "def connected_socket ( address , timeout = 3 ) : sock = socket . create_connection ( address , timeout ) yield sock sock . close ( ) ": 3711,
 "def delete_index ( index ) : logger . info ( \" Deleting search index : ' %s ' \" , index ) client = get_client ( ) return client . indices . delete ( index = index ) ": 3712,
 "def time2seconds ( t ) : return t . hour * 3600 + t . minute * 60 + t . second + float ( t . microsecond ) / 1e6": 3713,
 "def clear ( self ) : self . adj . clear ( ) self . node . clear ( ) self . graph . clear ( ) ": 3714,
 "def mouse_get_pos ( ) : p = POINT ( ) AUTO_IT . AU3_MouseGetPos ( ctypes . byref ( p ) ) return p . x , p . y": 3715,
 "def Date ( value ) : from datetime import datetime try : return datetime ( *reversed ( [int ( val ) for val in value . split ( ' / ' ) ] ) ) except Exception as err : raise argparse . ArgumentTypeError ( \" invalid date ' %s ' \" % value ) ": 3716,
 "def pad_hex ( value , bit_size ) : value = remove_0x_prefix ( value ) return add_0x_prefix ( value . zfill ( int ( bit_size / 4 ) ) ) ": 3717,
 "def parse_host_port ( host_port ) : host , port = urllib . splitport ( host_port . strip ( ) ) if port is not None : if urlutil . is_numeric_port ( port ) : port = int ( port ) return host , port": 3718,
 "def get_in_samples ( samples , fn ) : for sample in samples : sample = to_single_data ( sample ) if fn ( sample , None ) : return fn ( sample ) return None": 3719,
 "def clean_markdown ( text ) : result = text if isinstance ( text , str ) : result = ' ' . join ( BeautifulSoup ( markdown ( text ) , ' lxml ' ) . findAll ( text = True ) ) return result": 3720,
 "def _connection_failed ( self , error = \" Error not specified! \" ) : if not self . _error : LOG . error ( \" Connection failed : %s \" , str ( error ) ) self . _error = error": 3721,
 "def read_proto_object ( fobj , klass ) : log . debug ( ' %s chunk ' , klass . __name__ ) obj = klass ( ) obj . ParseFromString ( read_block ( fobj ) ) log . debug ( ' Header : %s ' , str ( obj ) ) return obj": 3722,
 "def run_command ( cmd , *args ) : command = ' ' . join ( ( cmd , args ) ) p = Popen ( command , shell = True , stdout = PIPE , stderr = PIPE ) stdout , stderr = p . communicate ( ) return p . retcode , stdout , stderr": 3723,
 "def _render_table ( data , fields = None ) : return IPython . core . display . HTML ( datalab . utils . commands . HtmlBuilder . render_table ( data , fields ) ) ": 3724,
 "def _value_to_color ( value , cmap ) : cm = plt . get_cmap ( cmap ) rgba = cm ( value ) return [int ( round ( 255*v ) ) for v in rgba[0 : 3]]": 3725,
 "def register ( linter ) : linter . register_reporter ( TextReporter ) linter . register_reporter ( ParseableTextReporter ) linter . register_reporter ( VSTextReporter ) linter . register_reporter ( ColorizedTextReporter ) ": 3726,
 "def _put_header ( self ) : self . session . _out ( ' %%PDF-%s ' % self . pdf_version ) if self . session . compression : self . session . buffer + = ' % ' + chr ( 235 ) + chr ( 236 ) + chr ( 237 ) + chr ( 238 ) + \" \\n \" ": 3727,
 "def fix_call ( callable , *args , **kw ) : try : val = callable ( *args , **kw ) except TypeError : exc_info = fix_type_error ( None , callable , args , kw ) reraise ( *exc_info ) return val": 3728,
 "def topk ( arg , k , by = None ) : op = ops . TopK ( arg , k , by = by ) return op . to_expr ( ) ": 3729,
 "def flatten ( iterables ) : for it in iterables : if isinstance ( it , str ) : yield it else : for element in it : yield element": 3730,
 "def read ( self ) : stream = BytesIO ( ) self . cam . capture ( stream , format = ' png ' ) # \" Rewind \" the stream to the beginning so we can read its content stream . seek ( 0 ) return Image . open ( stream ) ": 3731,
 "def focus ( self ) : self . _has_focus = True self . _frame . move_to ( self . _x , self . _y , self . _h ) if self . _on_focus is not None : self . _on_focus ( ) ": 3732,
 "def random_numbers ( n ) : return ' ' . join ( random . SystemRandom ( ) . choice ( string . digits ) for _ in range ( n ) ) ": 3733,
 "def generate_uuid ( ) : r_uuid = base64 . urlsafe_b64encode ( uuid . uuid4 ( ) . bytes ) return r_uuid . decode ( ) . replace ( ' = ' , ' ' ) ": 3734,
 "def oplot ( self , x , y , **kw ) : self . panel . oplot ( x , y , **kw ) ": 3735,
 "def pprint ( self , stream = None , indent = 1 , width = 80 , depth = None ) : pp . pprint ( to_literal ( self ) , stream , indent , width , depth ) ": 3736,
 "def get_base_dir ( ) : return os . path . split ( os . path . abspath ( os . path . dirname ( __file__ ) ) ) [0]": 3737,
 "def diff ( file_ , imports ) : modules_not_imported = compare_modules ( file_ , imports ) logging . info ( \" The following modules are in {} but do not seem to be imported : \" \" {} \" . format ( file_ , \" , \" . join ( x for x in modules_not_imported ) ) ) ": 3738,
 "def get_combined_size ( tiles ) : # TODO : Refactor calculating layout to avoid repetition . columns , rows = calc_columns_rows ( len ( tiles ) ) tile_size = tiles[0] . image . size return ( tile_size[0] * columns , tile_size[1] * rows ) ": 3739,
 "def cli ( env ) : settings = config . get_settings_from_client ( env . client ) env . fout ( config . config_table ( settings ) ) ": 3740,
 "def show ( ) : env = get_environment ( ) for key , val in sorted ( env . env . items ( ) , key = lambda item : item[0] ) : click . secho ( ' %s = %s ' % ( key , val ) ) ": 3741,
 "def _prtstr ( self , obj , dashes ) : self . prt . write ( ' {DASHES : {N}} ' . format ( DASHES = self . fmt_dashes . format ( DASHES = dashes , ID = obj . item_id ) , N = self . dash_len ) ) self . prt . write ( \" {INFO}\\n \" . format ( INFO = str ( obj ) ) ) ": 3742,
 "def globlookup ( pattern , root ) : for subdir , dirnames , filenames in os . walk ( root ) : d = subdir[len ( root ) + 1 : ] files = ( os . path . join ( d , f ) for f in filenames ) for f in fnmatch . filter ( files , pattern ) : yield f": 3743,
 "def debug ( ftn , txt ) : if debug_p : sys . stdout . write ( \" {0} . {1} : {2}\\n \" . format ( modname , ftn , txt ) ) sys . stdout . flush ( ) ": 3744,
 "def _prtfmt ( self , item_id , dashes ) : ntprt = self . id2nt[item_id] dct = ntprt . _asdict ( ) self . prt . write ( ' {DASHES : {N}} ' . format ( DASHES = self . fmt_dashes . format ( DASHES = dashes , ID = self . nm2prtfmt[ ' ID ' ] . format ( **dct ) ) , N = self . dash_len ) ) self . prt . write ( \" {INFO}\\n \" . format ( INFO = self . nm2prtfmt[ ' ITEM ' ] . format ( **dct ) ) ) ": 3745,
 "def imp_print ( self , text , end ) : \t\t\t\tsys . stdout . write ( ( text + end ) . encode ( \" utf-8 \" ) ) ": 3746,
 "def _strip_namespace ( self , xml ) : p = re . compile ( b \" xmlns = *[\\ \" \\ \" ][^\\ \" \\ \" ]*[\\ \" \\ \" ] \" ) allmatches = p . finditer ( xml ) for match in allmatches : xml = xml . replace ( match . group ( ) , b \" \" ) return xml": 3747,
 "def ave_list_v3 ( vec_list ) : vec = Vec3 ( 0 , 0 , 0 ) for v in vec_list : vec + = v num_vecs = float ( len ( vec_list ) ) vec = Vec3 ( vec . x / num_vecs , vec . y / num_vecs , vec . z / num_vecs ) return vec": 3748,
 "def lastmod ( self , author ) : lastitems = EntryModel . objects . published ( ) . order_by ( ' -modification_date ' ) . filter ( author = author ) . only ( ' modification_date ' ) return lastitems[0] . modification_date": 3749,
 "def calculate_size ( name , data_list ) : data_size = 0 data_size + = calculate_size_str ( name ) data_size + = INT_SIZE_IN_BYTES for data_list_item in data_list : data_size + = calculate_size_data ( data_list_item ) return data_size": 3750,
 "def message_from_string ( s , *args , **kws ) : from future . backports . email . parser import Parser return Parser ( *args , **kws ) . parsestr ( s ) ": 3751,
 "def IsErrorSuppressedByNolint ( category , linenum ) : return ( linenum in _error_suppressions . get ( category , set ( ) ) or linenum in _error_suppressions . get ( None , set ( ) ) ) ": 3752,
 "def _raise_if_wrong_file_signature ( stream ) : file_sig = stream . read ( len ( headers . LAS_FILE_SIGNATURE ) ) if file_sig ! = headers . LAS_FILE_SIGNATURE : raise errors . PylasError ( \" File Signature ( {} ) is not {} \" . format ( file_sig , headers . LAS_FILE_SIGNATURE ) ) ": 3753,
 "def loss ( loss_value ) : total_loss = tf . Variable ( 0 . 0 , False ) loss_count = tf . Variable ( 0 , False ) total_loss_update = tf . assign_add ( total_loss , loss_value ) loss_count_update = tf . assign_add ( loss_count , 1 ) loss_op = total_loss / tf . cast ( loss_count , tf . float32 ) return [total_loss_update , loss_count_update] , loss_op": 3754,
 "def create_app ( ) : global QT_APP QT_APP = QApplication . instance ( ) if QT_APP is None : # pragma : no cover QT_APP = QApplication ( sys . argv ) return QT_APP": 3755,
 "def get_last_or_frame_exception ( ) : try : if inspect . istraceback ( sys . last_traceback ) : # We do have a traceback so prefer that . return sys . last_type , sys . last_value , sys . last_traceback except AttributeError : pass return sys . exc_info ( ) ": 3756,
 "def dt_to_qdatetime ( dt ) : return QtCore . QDateTime ( QtCore . QDate ( dt . year , dt . month , dt . day ) , QtCore . QTime ( dt . hour , dt . minute , dt . second ) ) ": 3757,
 "def done ( self , result ) : self . _geometry = self . geometry ( ) QtWidgets . QDialog . done ( self , result ) ": 3758,
 "def resize ( self , width , height ) : if not self . fbo : return # pyqt reports sizes in actual buffer size self . width = width // self . widget . devicePixelRatio ( ) self . height = height // self . widget . devicePixelRatio ( ) self . buffer_width = width self . buffer_height = height super ( ) . resize ( width , height ) ": 3759,
 "def unique_ ( self , col ) : try : df = self . df . drop_duplicates ( subset = [col] , inplace = False ) return list ( df[col] ) except Exception as e : self . err ( e , \" Can not select unique data \" ) ": 3760,
 "def deinit ( self ) : # Clean up after ourselves self . _process . terminate ( ) procs . remove ( self . _process ) self . _mq . remove ( ) queues . remove ( self . _mq ) ": 3761,
 "def exec_rabbitmqctl ( self , command , args = [] , rabbitmqctl_opts = [ ' -q ' ] ) : cmd = [ ' rabbitmqctl ' ] + rabbitmqctl_opts + [command] + args return self . inner ( ) . exec_run ( cmd ) ": 3762,
 "def gen_random_string ( str_len ) : return ' ' . join ( random . choice ( string . ascii_letters + string . digits ) for _ in range ( str_len ) ) ": 3763,
 "def uniform_noise ( points ) : return np . random . rand ( 1 ) * np . random . uniform ( points , 1 ) \\ + random . sample ( [2 , -2] , 1 ) ": 3764,
 "def SampleSum ( dists , n ) : pmf = MakePmfFromList ( RandomSum ( dists ) for i in xrange ( n ) ) return pmf": 3765,
 "def highlight_words ( string , keywords , cls_name = ' highlighted ' ) : if not keywords : return string if not string : return ' ' include , exclude = get_text_tokenizer ( keywords ) highlighted = highlight_text ( include , string , cls_name , words = True ) return highlighted": 3766,
 "def get_env_default ( self , variable , default ) : if variable in os . environ : env_var = os . environ[variable] else : env_var = default return env_var": 3767,
 "def api_home ( request , key = None , hproPk = None ) : if not check_api_key ( request , key , hproPk ) : return HttpResponseForbidden return render_to_response ( ' plugIt/api . html ' , {} , context_instance = RequestContext ( request ) ) ": 3768,
 "def get_as_string ( self , s3_path , encoding = ' utf-8 ' ) : content = self . get_as_bytes ( s3_path ) return content . decode ( encoding ) ": 3769,
 "def backward_delete_word ( self , e ) : # ( Control-Rubout ) u self . l_buffer . backward_delete_word ( self . argument_reset ) self . finalize ( ) ": 3770,
 "def load_tiff ( file ) : ndv , xsize , ysize , geot , projection , datatype = get_geo_info ( file ) data = gdalnumeric . LoadFile ( file ) data = np . ma . masked_array ( data , mask = data = = ndv , fill_value = ndv ) return data": 3771,
 "def do_EOF ( self , args ) : if _debug : ConsoleCmd . _debug ( \" do_EOF %r \" , args ) return self . do_exit ( args ) ": 3772,
 "def stats ( self ) : printDebug ( \" Classes . . . . . : %d \" % len ( self . all_classes ) ) printDebug ( \" Properties . . : %d \" % len ( self . all_properties ) ) ": 3773,
 "def kwargs_to_string ( kwargs ) : outstr = ' ' for arg in kwargs : outstr + = ' -{} {} ' . format ( arg , kwargs[arg] ) return outstr": 3774,
 "def as_dict ( self ) : dicts = [x . as_dict for x in self . children] return { ' {0} {1} ' . format ( self . name , self . value ) : dicts}": 3775,
 "def get ( self , key ) : value = redis_conn . get ( key ) if value is not None : value = pickle . loads ( value ) return value": 3776,
 "def __contains__ ( self , key ) : pickled_key = self . _pickle_key ( key ) return bool ( self . redis . hexists ( self . key , pickled_key ) ) ": 3777,
 "def get_instance ( key , expire = None ) : global _instances try : instance = _instances[key] except KeyError : instance = RedisSet ( key , _redis , expire = expire ) _instances[key] = instance return instance": 3778,
 "def tag ( self , nerdoc ) : labels = [] for snt in nerdoc . sentences : xseq = [t . feature_list ( ) for t in snt] yseq = self . tagger . tag ( xseq ) labels . append ( yseq ) return labels": 3779,
 "def on_IOError ( self , e ) : sys . stderr . write ( \" Error : %s : \\ \" %s\\ \" \\n \" % ( e . strerror , e . filename ) ) ": 3780,
 "def _namematcher ( regex ) : matcher = re_compile ( regex ) def match ( target ) : target_name = getattr ( target , ' __name__ ' , ' ' ) result = matcher . match ( target_name ) return result return match": 3781,
 "def error ( self , text ) : \t\t\t\tself . logger . error ( \" {}{} \" . format ( self . message_prefix , text ) ) ": 3782,
 "def select_from_array ( cls , array , identifier ) : base_array = np . zeros ( array . shape ) array_coords = np . where ( array = = identifier ) base_array[array_coords] = 1 return cls ( base_array ) ": 3783,
 "def register_service ( self , service ) : if service not in self . services : self . services . append ( service ) ": 3784,
 "def separator ( self , menu = None ) : self . gui . get_menu ( menu or self . menu ) . addSeparator ( ) ": 3785,
 "def as_list ( callable ) : @wraps ( callable ) def wrapper ( value_iter ) : return [callable ( value ) for value in value_iter] return wrapper": 3786,
 "def _listify ( collection ) : new_list = [] for index in range ( len ( collection ) ) : new_list . append ( collection[index] ) return new_list": 3787,
 "def log_leave ( event , nick , channel ) : \t\tif channel not in pmxbot . config . log_channels : \t\treturn\tParticipantLogger . store . log ( nick , channel , event . type ) ": 3788,
 "def not_matching_list ( self ) : pre_result = comp ( self . regex ) return [x for x in self . data if not pre_result . search ( str ( x ) ) ]": 3789,
 "def guess_title ( basename ) : base , _ = os . path . splitext ( basename ) return re . sub ( r ' [ _-]+ ' , r ' ' , base ) . title ( ) ": 3790,
 "def cast_int ( x ) : try : x = int ( x ) except ValueError : try : x = x . strip ( ) except AttributeError as e : logger_misc . warn ( \" parse_str : AttributeError : String not number or word , {} , {} \" . format ( x , e ) ) return x": 3791,
 "def do_striptags ( value ) : if hasattr ( value , ' __html__ ' ) : value = value . __html__ ( ) return Markup ( unicode ( value ) ) . striptags ( ) ": 3792,
 "def reduce_multiline ( string ) : string = str ( string ) return \" \" . join ( [item . strip ( ) for item in string . split ( \" \\n \" ) if item . strip ( ) ] ) ": 3793,
 "def scatterplot_matrix ( df , features , downsample_frac = None , figsize = ( 15 , 15 ) ) : if downsample_frac : df = df . sample ( frac = downsample_frac ) plt . figure ( figsize = figsize ) sns . pairplot ( df[features] , hue = ' target ' ) plt . show ( ) ": 3794,
 "def cleanup ( self ) : for instance in self . context : del ( instance ) for plugin in self . plugins : del ( plugin ) ": 3795,
 "def clean_strings ( iterable ) : retval = [] for val in iterable : try : retval . append ( val . strip ( ) ) except ( AttributeError ) : retval . append ( val ) return retval": 3796,
 "def __call__ ( self , factory_name , *args , **kwargs ) : return self . factories[factory_name] ( *args , **kwargs ) ": 3797,
 "def get_language_parameter ( request , query_language_key = ' language ' , object = None , default = None ) : # This is the same logic as the django-admin uses . # The only difference is the origin of the request parameter . if not is_multilingual_project ( ) : # By default , the objects are stored in a single static language . # This makes the transition to multilingual easier as well . # The default language can operate as fallback language too . return default or appsettings . PARLER_LANGUAGES . get_default_language ( ) else : # In multilingual mode , take the provided language of the request . code = request . GET . get ( query_language_key ) if not code : # forms : show first tab by default code = default or appsettings . PARLER_LANGUAGES . get_first_language ( ) return normalize_language_code ( code ) ": 3798,
 "def replaceNewlines ( string , newlineChar ) : \t\tif newlineChar in string : \t\tsegments = string . split ( newlineChar ) \t\tstring = \" \" \t\tfor segment in segments : \t\t\tstring + = segment\treturn string": 3799,
 "def onRightUp ( self , event = None ) : if event is None : return self . cursor_mode_action ( ' rightup ' , event = event ) self . ForwardEvent ( event = event . guiEvent ) ": 3800,
 "def geturl ( self ) : if self . retries is not None and len ( self . retries . history ) : return self . retries . history[-1] . redirect_location else : return self . _request_url": 3801,
 "def rest_put_stream ( self , url , stream , headers = None , session = None , verify = True , cert = None ) : res = session . put ( url , headers = headers , data = stream , verify = verify , cert = cert ) return res . text , res . status_code": 3802,
 "def from_file ( cls , path , encoding , dialect , fields , converters , field_index ) : return cls ( open ( path , ' r ' , encoding = encoding ) , dialect , fields , converters , field_index ) ": 3803,
 "def _reset_bind ( self ) : self . binded = False self . _buckets = {} self . _curr_module = None self . _curr_bucket_key = None": 3804,
 "def reset_params ( self ) : self . __params = dict ( [p , None] for p in self . param_names ) self . set_params ( self . param_defaults ) ": 3805,
 "def _parse_return ( cls , result ) : return_value = None success = result[ ' result ' ] context = result[ ' context ' ] if ' return_value ' in result : return_value = result[ ' return_value ' ] return success , return_value , context": 3806,
 "def unbroadcast_numpy_to ( array , shape ) : axis = create_unbroadcast_axis ( shape , numpy . shape ( array ) ) return numpy . reshape ( numpy . sum ( array , axis = axis ) , shape ) ": 3807,
 "def do_stc_disconnectall ( self , s ) : if self . _not_joined ( ) : return try : self . _stc . disconnectall ( ) except resthttp . RestHttpError as e : print ( e ) return print ( ' OK ' ) ": 3808,
 "def _get_data ( self ) : cookie = self . adapter . cookies . get ( self . name ) return self . _deserialize ( cookie ) if cookie else {}": 3809,
 "def grandparent_path ( self ) : return os . path . basename ( os . path . join ( self . path , ' . . / . . ' ) ) ": 3810,
 "def print_err ( *args , end = ' \\n ' ) : print ( *args , end = end , file = sys . stderr ) sys . stderr . flush ( ) ": 3811,
 "def ensure_newline ( self ) : DECTCEM_SHOW = ' \\033[?25h ' # show cursor AT_END = DECTCEM_SHOW + ' \\n ' if not self . _cursor_at_newline : self . write ( AT_END ) self . _cursor_at_newline = True": 3812,
 "def _run_parallel_process_with_profiling ( self , start_path , stop_path , queue , filename ) : runctx ( ' Engine . _run_parallel_process ( self , start_path , stop_path , queue ) ' , globals ( ) , locals ( ) , filename ) ": 3813,
 "def round_sig ( x , sig ) : return round ( x , sig - int ( floor ( log10 ( abs ( x ) ) ) ) - 1 ) ": 3814,
 "def sleep ( self , time ) : try : task = asyncio . ensure_future ( self . core . sleep ( time ) ) self . loop . run_until_complete ( task ) except asyncio . CancelledError : pass except RuntimeError : pass": 3815,
 "def _power ( ctx , number , power ) : return decimal_pow ( conversions . to_decimal ( number , ctx ) , conversions . to_decimal ( power , ctx ) ) ": 3816,
 "def safe_mkdir_for ( path , clean = False ) : safe_mkdir ( os . path . dirname ( path ) , clean = clean ) ": 3817,
 "def save_cache ( data , filename ) : with open ( filename , ' wb ' ) as handle : pickle . dump ( data , handle ) ": 3818,
 "def path ( self ) : path = super ( WindowsPath2 , self ) . path if path . startswith ( \" \\\\\\\\?\\\\ \" ) : return path[4 : ] return path": 3819,
 "def date ( start , end ) : stime = date_to_timestamp ( start ) etime = date_to_timestamp ( end ) ptime = stime + random . random ( ) * ( etime - stime ) return datetime . date . fromtimestamp ( ptime ) ": 3820,
 "def _pick_attrs ( attrs , keys ) : return dict ( ( k , v ) for k , v in attrs . items ( ) if k in keys ) ": 3821,
 "def fix_dashes ( string ) : string = string . replace ( u ' \\u05BE ' , ' - ' ) string = string . replace ( u ' \\u1806 ' , ' - ' ) string = string . replace ( u ' \\u2E3A ' , ' - ' ) string = string . replace ( u ' \\u2E3B ' , ' - ' ) string = unidecode ( string ) return re . sub ( r ' --+ ' , ' - ' , string ) ": 3822,
 "def _indexes ( arr ) : myarr = np . array ( arr ) if myarr . ndim = = 1 : return list ( range ( len ( myarr ) ) ) elif myarr . ndim = = 2 : return tuple ( itertools . product ( list ( range ( arr . shape[0] ) ) , list ( range ( arr . shape[1] ) ) ) ) else : raise NotImplementedError ( ' Only supporting arrays of dimension 1 and 2 as yet . ' ) ": 3823,
 "def copy ( self ) : result = self . space . element ( ) result . assign ( self ) return result": 3824,
 "async def send ( self , data ) : self . writer . write ( data ) await self . writer . drain ( ) ": 3825,
 "def cli ( yamlfile , format , output ) : print ( OwlSchemaGenerator ( yamlfile , format ) . serialize ( output = output ) ) ": 3826,
 "def serialize ( self , value , **kwargs ) : return [self . item_type . serialize ( val , **kwargs ) for val in value]": 3827,
 "def to_monthly ( series , method = ' ffill ' , how = ' end ' ) : return series . asfreq_actual ( ' M ' , method = method , how = how ) ": 3828,
 "def dispatch ( self ) : try : webapp2 . RequestHandler . dispatch ( self ) finally : self . session_store . save_sessions ( self . response ) ": 3829,
 "def restart_program ( ) : python = sys . executable os . execl ( python , python , * sys . argv ) ": 3830,
 "def _cpu ( self ) : value = int ( psutil . cpu_percent ( ) ) set_metric ( \" cpu \" , value , category = self . category ) gauge ( \" cpu \" , value ) ": 3831,
 "def roundClosestValid ( val , res , decimals = None ) : if decimals is None and \" . \" in str ( res ) : decimals = len ( str ( res ) . split ( ' . ' ) [1] ) return round ( round ( val / res ) * res , decimals ) ": 3832,
 "def unpack2D ( _x ) : _x = np . atleast_2d ( _x ) x = _x[ : , 0] y = _x[ : , 1] return x , y": 3833,
 "def set_xlimits ( self , min = None , max = None ) : self . limits[ ' xmin ' ] = min self . limits[ ' xmax ' ] = max": 3834,
 "def open ( self , flag = \" c \" ) : return shelve . open ( os . path . join ( gettempdir ( ) , self . index ) , flag = flag , protocol = 2 ) ": 3835,
 "def normalise_key ( self , key ) : key = key . replace ( ' - ' , ' _ ' ) if key . startswith ( \" noy_ \" ) : key = key[4 : ] return key": 3836,
 "def getFieldsColumnLengths ( self ) : nameLen = 0 descLen = 0 for f in self . fields : nameLen = max ( nameLen , len ( f[ ' title ' ] ) ) descLen = max ( descLen , len ( f[ ' description ' ] ) ) return ( nameLen , descLen ) ": 3837,
 "def close ( self , wait = False ) : self . session . close ( ) self . pool . shutdown ( wait = wait ) ": 3838,
 "def rand_elem ( seq , n = None ) : return map ( random . choice , repeat ( seq , n ) if n is not None else repeat ( seq ) ) ": 3839,
 "def impute_data ( self , x ) : imp = Imputer ( missing_values = ' NaN ' , strategy = ' mean ' , axis = 0 ) return imp . fit_transform ( x ) ": 3840,
 "def pwm ( host , seq , m1 , m2 , m3 , m4 ) : at ( host , ' PWM ' , seq , [m1 , m2 , m3 , m4] ) ": 3841,
 "def _return_comma_list ( self , l ) : if isinstance ( l , ( text_type , int ) ) : return l if not isinstance ( l , list ) : raise TypeError ( l , ' should be a list of integers , \\not {0} ' . format ( type ( l ) ) ) str_ids = ' , ' . join ( str ( i ) for i in l ) return str_ids": 3842,
 "def symmetrise ( matrix , tri = ' upper ' ) : if tri = = ' upper ' : tri_fn = np . triu_indices else : tri_fn = np . tril_indices size = matrix . shape[0] matrix[tri_fn ( size ) [ : : -1]] = matrix[tri_fn ( size ) ] return matrix": 3843,
 "def main ( ) : time . sleep ( 1 ) with Input ( ) as input_generator : for e in input_generator : print ( repr ( e ) ) ": 3844,
 "def sort_key ( val ) : return numpy . sum ( ( max ( val ) +1 ) **numpy . arange ( len ( val ) -1 , -1 , -1 ) *val ) ": 3845,
 "def setDictDefaults ( d , defaults ) : for key , val in defaults . items ( ) : d . setdefault ( key , val ) return d": 3846,
 "def set_proxy ( proxy_url , transport_proxy = None ) : global proxy , PYPI_URL PYPI_URL = proxy_url proxy = xmlrpc . ServerProxy ( proxy_url , transport = RequestsTransport ( proxy_url . startswith ( ' https : // ' ) ) , allow_none = True ) ": 3847,
 "def value_to_python ( self , value ) : if not isinstance ( value , bytes ) : raise tldap . exceptions . ValidationError ( \" should be a bytes \" ) value = value . decode ( \" utf_8 \" ) return value": 3848,
 "def show ( self , title = ' ' ) : self . render ( title = title ) if self . fig : plt . show ( self . fig ) ": 3849,
 "def _split ( value ) : if isinstance ( value , str ) : # iterable , but not meant for splitting return value , value try : invalue , outvalue = value except TypeError : invalue = outvalue = value except ValueError : raise ValueError ( \" Only single values and pairs are allowed \" ) return invalue , outvalue": 3850,
 "def _split_batches ( self , data , batch_size ) : for i in range ( 0 , len ( data ) , batch_size ) : yield data[i : i + batch_size]": 3851,
 "def solve ( A , x ) : # https : //stackoverflow . com/a/48387507/353337 x = numpy . asarray ( x ) return numpy . linalg . solve ( A , x . reshape ( x . shape[0] , -1 ) ) . reshape ( x . shape ) ": 3852,
 "def callproc ( self , name , params , param_types = None ) : if param_types : placeholders = [self . sql_writer . typecast ( self . sql_writer . to_placeholder ( ) , t ) for t in param_types] else : placeholders = [self . sql_writer . to_placeholder ( ) for p in params] # TODO : This may be Postgres specific . . . qs = \" select * from {0} ( {1} ) ; \" . format ( name , \" , \" . join ( placeholders ) ) return self . execute ( qs , params ) , params": 3853,
 "def clear_all ( self ) : logger . info ( \" Clearing ALL Labels and LabelKeys . \" ) self . session . query ( Label ) . delete ( synchronize_session = \" fetch \" ) self . session . query ( LabelKey ) . delete ( synchronize_session = \" fetch \" ) ": 3854,
 "def primary_keys_full ( cls ) : mapper = cls . __mapper__ return [ mapper . get_property_by_column ( column ) for column in mapper . primary_key ]": 3855,
 "def has_permission ( user , permission_name ) : if user and user . is_superuser : return True return permission_name in available_perm_names ( user ) ": 3856,
 "def save ( self , *args , **kwargs ) : self . timeline . index - = 1 # required for proper starting point for save self . animation . save ( *args , **kwargs ) ": 3857,
 "def println ( msg ) : sys . stdout . write ( msg ) sys . stdout . flush ( ) sys . stdout . write ( ' \\x08 ' * len ( msg ) ) sys . stdout . flush ( ) ": 3858,
 "def nothread_quit ( self , arg ) : self . debugger . core . stop ( ) self . debugger . core . execution_status = ' Quit command ' raise Mexcept . DebuggerQuit": 3859,
 "def exit ( self ) : if self . _server is not None : self . _server . shutdown ( ) self . _server . server_close ( ) self . _server = None": 3860,
 "def graph_key_from_tag ( tag , entity_index ) : start_token = tag . get ( ' start_token ' ) entity = tag . get ( ' entities ' , [] ) [entity_index] return str ( start_token ) + ' - ' + entity . get ( ' key ' ) + ' - ' + str ( entity . get ( ' confidence ' ) ) ": 3861,
 "def measure_string ( self , text , fontname , fontsize , encoding = 0 ) : return _fitz . Tools_measure_string ( self , text , fontname , fontsize , encoding ) ": 3862,
 "def __is__ ( cls , s ) : return s . startswith ( cls . delims ( ) [0] ) and s . endswith ( cls . delims ( ) [1] ) ": 3863,
 "def _print ( self , msg , flush = False , end = \" \\n \" ) : if self . _verbose : print2 ( msg , end = end , flush = flush ) ": 3864,
 "def info ( self , text ) : \t\t\t\tself . logger . info ( \" {}{} \" . format ( self . message_prefix , text ) ) ": 3865,
 "def write_document ( doc , fnm ) : with codecs . open ( fnm , ' wb ' , ' ascii ' ) as f : f . write ( json . dumps ( doc , indent = 2 ) ) ": 3866,
 "def highpass ( cutoff ) : R = thub ( exp ( cutoff - pi ) , 2 ) return ( 1 - R ) / ( 1 + R * z ** -1 ) ": 3867,
 "def exists ( self ) : client = self . _instance . _client try : client . instance_admin_client . get_cluster ( name = self . name ) return True # NOTE : There could be other exceptions that are returned to the user . except NotFound : return False": 3868,
 "def get_path_from_query_string ( req ) : if req . args . get ( ' path ' ) is None : raise exceptions . UserError ( ' Path not found in query string ' ) return req . args . get ( ' path ' ) ": 3869,
 "def _squeeze ( x , axis ) : x = tf . convert_to_tensor ( value = x , name = ' x ' ) if axis is None : return tf . squeeze ( x , axis = None ) axis = tf . convert_to_tensor ( value = axis , name = ' axis ' , dtype = tf . int32 ) axis + = tf . zeros ( [1] , dtype = axis . dtype ) # Make axis at least 1d . keep_axis , _ = tf . compat . v1 . setdiff1d ( tf . range ( 0 , tf . rank ( x ) ) , axis ) return tf . reshape ( x , tf . gather ( tf . shape ( input = x ) , keep_axis ) ) ": 3870,
 "def _handle_authentication_error ( self ) : response = make_response ( ' Access Denied ' ) response . headers[ ' WWW-Authenticate ' ] = self . auth . get_authenticate_header ( ) response . status_code = 401 return response": 3871,
 "def argmax ( attrs , inputs , proto_obj ) : axis = attrs . get ( ' axis ' , 0 ) keepdims = attrs . get ( ' keepdims ' , 1 ) argmax_op = symbol . argmax ( inputs[0] , axis = axis , keepdims = keepdims ) # onnx argmax operator always expects int64 as output type cast_attrs = { ' dtype ' : ' int64 ' } return ' cast ' , cast_attrs , argmax_op": 3872,
 "def predict ( self , X ) : Xt , _ , _ = self . _transform ( X ) return self . _final_estimator . predict ( Xt ) ": 3873,
 "def uniqify ( cls , seq ) : seen = set ( ) seen_add = seen . add return [ x for x in seq if x not in seen and not seen_add ( x ) ]": 3874,
 "def vline ( self , x , y , height , color ) : self . rect ( x , y , 1 , height , color , fill = True ) ": 3875,
 "def is_closed ( self ) : closed = all ( i = = 2 for i in dict ( self . vertex_graph . degree ( ) ) . values ( ) ) return closed": 3876,
 "def get_cell ( self , index ) : i = sorted_index ( self . _index , index ) if self . _sort else self . _index . index ( index ) return self . _data[i]": 3877,
 "def __exit__ ( self , *exc_info ) : self . _loop . create_task ( self . _close ( Client . CLOSED , True ) ) ": 3878,
 "def mcc ( y , z ) : tp , tn , fp , fn = contingency_table ( y , z ) return ( tp * tn - fp * fn ) / K . sqrt ( ( tp + fp ) * ( tp + fn ) * ( tn + fp ) * ( tn + fn ) ) ": 3879,
 "def Binary ( x ) : if isinstance ( x , text_type ) and not ( JYTHON or IRONPYTHON ) : return x . encode ( ) return bytes ( x ) ": 3880,
 "def value ( self , progress_indicator ) : return interpolate . interpolate_linear_single ( self . initial_value , self . final_value , progress_indicator ) ": 3881,
 "def focusNext ( self , event ) : try : event . widget . tk_focusNext ( ) . focus_set ( ) except TypeError : # see tkinter equivalent code for tk_focusNext to see # commented original version name = event . widget . tk . call ( ' tk_focusNext ' , event . widget . _w ) event . widget . _nametowidget ( str ( name ) ) . focus_set ( ) ": 3882,
 "def get_all_items ( self ) : return [self . _widget . itemText ( k ) for k in range ( self . _widget . count ( ) ) ]": 3883,
 "def find_if_expression_as_statement ( node ) : return ( isinstance ( node , ast . Expr ) and isinstance ( node . value , ast . IfExp ) ) ": 3884,
 "def nonlocal_check ( self , original , loc , tokens ) : return self . check_py ( \" 3 \" , \" nonlocal statement \" , original , loc , tokens ) ": 3885,
 "def add_bundled_jars ( ) : # determine lib directory with jars rootdir = os . path . split ( os . path . dirname ( __file__ ) ) [0] libdir = rootdir + os . sep + \" lib \" # add jars from lib directory for l in glob . glob ( libdir + os . sep + \" * . jar \" ) : if l . lower ( ) . find ( \" -src . \" ) = = -1 : javabridge . JARS . append ( str ( l ) ) ": 3886,
 "def xyz2lonlat ( x , y , z ) : lon = xu . rad2deg ( xu . arctan2 ( y , x ) ) lat = xu . rad2deg ( xu . arctan2 ( z , xu . sqrt ( x**2 + y**2 ) ) ) return lon , lat": 3887,
 "def jupytext_cli ( args = None ) : try : jupytext ( args ) except ( ValueError , TypeError , IOError ) as err : sys . stderr . write ( ' [jupytext] Error : ' + str ( err ) + ' \\n ' ) exit ( 1 ) ": 3888,
 "def load_jsonf ( fpath , encoding ) : with codecs . open ( fpath , encoding = encoding ) as f : return json . load ( f ) ": 3889,
 "def pprint ( self , ind ) : pp = pprint . PrettyPrinter ( indent = ind ) pp . pprint ( self . tree ) ": 3890,
 "def _trim ( self , somestr ) : tmp = RE_LSPACES . sub ( \" \" , somestr ) tmp = RE_TSPACES . sub ( \" \" , tmp ) return str ( tmp ) ": 3891,
 "def keyPressEvent ( self , event ) : self . keyboard_event ( event . key ( ) , self . keys . ACTION_PRESS , 0 ) ": 3892,
 "def _try_join_cancelled_thread ( thread ) : thread . join ( 10 ) if thread . is_alive ( ) : logging . warning ( \" Thread %s did not terminate within grace period after cancellation \" , thread . name ) ": 3893,
 "def fit ( self , X ) : self . centers_ , self . labels_ , self . sse_arr_ , self . n_iter_ = \\ _kmeans ( X , self . n_clusters , self . max_iter , self . n_trials , self . tol ) ": 3894,
 "def projR ( gamma , p ) : return np . multiply ( gamma . T , p / np . maximum ( np . sum ( gamma , axis = 1 ) , 1e-10 ) ) . T": 3895,
 "def json_to_initkwargs ( self , json_data , kwargs ) : if isinstance ( json_data , basestring ) : json_data = json . loads ( json_data ) return json_to_initkwargs ( self , json_data , kwargs ) ": 3896,
 "def delayed_close ( self ) : self . state = SESSION_STATE . CLOSING reactor . callLater ( 0 , self . close ) ": 3897,
 "def urlize_twitter ( text ) : html = TwitterText ( text ) . autolink . auto_link ( ) return mark_safe ( html . replace ( ' twitter . com/search?q = ' , ' twitter . com/search/realtime/ ' ) ) ": 3898,
 "def decode_example ( self , example ) : img = tf . image . decode_image ( example , channels = self . _shape[-1] , dtype = tf . uint8 ) img . set_shape ( self . _shape ) return img": 3899,
 "def load_db ( file , db , verbose = True ) : db_data = json . load ( file , verbose = verbose ) return _load ( db_data , db ) ": 3900,
 "def get_time ( ) : time_request = ' \\x1b ' + 47 * ' \\0 ' now = struct . unpack ( \" !12I \" , ntp_service . request ( time_request , timeout = 5 . 0 ) . data . read ( ) ) [10] return time . ctime ( now - EPOCH_START ) ": 3901,
 "def plfit_lsq ( x , y ) : n = len ( x ) btop = n * ( log ( x ) *log ( y ) ) . sum ( ) - ( log ( x ) ) . sum ( ) * ( log ( y ) ) . sum ( ) bbottom = n* ( log ( x ) **2 ) . sum ( ) - ( log ( x ) . sum ( ) ) **2 b = btop / bbottom a = ( log ( y ) . sum ( ) - b * log ( x ) . sum ( ) ) / n A = exp ( a ) return A , b": 3902,
 "def open_usb_handle ( self , port_num ) : serial = self . get_usb_serial ( port_num ) return local_usb . LibUsbHandle . open ( serial_number = serial ) ": 3903,
 "def survival ( value = t , lam = lam , f = failure ) : return sum ( f * log ( lam ) - lam * value ) ": 3904,
 "def put_pidfile ( pidfile_path , pid ) : with open ( pidfile_path , \" w \" ) as f : f . write ( \" %s \" % pid ) os . fsync ( f . fileno ( ) ) return": 3905,
 "def _log_multivariate_normal_density_tied ( X , means , covars ) : cv = np . tile ( covars , ( means . shape[0] , 1 , 1 ) ) return _log_multivariate_normal_density_full ( X , means , cv ) ": 3906,
 "def _eq ( self , other ) : return ( self . type , self . value ) = = ( other . type , other . value ) ": 3907,
 "def get_all_files ( folder ) : for path , dirlist , filelist in os . walk ( folder ) : for fn in filelist : yield op . join ( path , fn ) ": 3908,
 "def _adjust_offset ( self , real_wave_mfcc , algo_parameters ) : self . log ( u \" Called _adjust_offset \" ) self . _apply_offset ( offset = algo_parameters[0] ) ": 3909,
 "def cols_str ( columns ) : cols = \" \" for c in columns : cols = cols + wrap ( c ) + ' , ' return cols[ : -2]": 3910,
 "def _ws_on_close ( self , ws : websocket . WebSocketApp ) : self . connected = False self . logger . error ( ' Websocket closed ' ) self . _reconnect_websocket ( ) ": 3911,
 "def house_explosions ( ) : chart = PieChart2D ( int ( settings . width * 1 . 7 ) , settings . height ) chart . add_data ( [10 , 10 , 30 , 200] ) chart . set_pie_labels ( [ ' Budding Chemists ' , ' Propane issues ' , ' Meth Labs ' , ' Attempts to escape morgage ' , ] ) chart . download ( ' pie-house-explosions . png ' ) ": 3912,
 "def RecurseKeys ( self ) : yield self for subkey in self . GetSubkeys ( ) : for key in subkey . RecurseKeys ( ) : yield key": 3913,
 "def matches ( self , s ) : regex_matches = self . compiled_regex . search ( s ) is not None return not regex_matches if self . inverted else regex_matches": 3914,
 "def save_hdf ( self , filename , path = ' ' ) : self . dataframe . to_hdf ( filename , ' {}/df ' . format ( path ) ) ": 3915,
 "def copy_of_xml_element ( elem ) : copyElem = ElementTree . Element ( elem . tag , elem . attrib ) for child in elem : copyElem . append ( child ) return copyElem": 3916,
 "def __ror__ ( self , other ) : \t\t\t\t\t\treturn self . callable ( * ( self . args + ( other , ) ) , **self . kwargs ) ": 3917,
 "def _flush ( self , buffer ) : container , obj = self . _client_args with _handle_client_exception ( ) : self . _client . put_object ( container , obj , buffer ) ": 3918,
 "def transformer_tall_pretrain_lm_tpu_adafactor ( ) : hparams = transformer_tall_pretrain_lm ( ) update_hparams_for_tpu ( hparams ) hparams . max_length = 1024 # For multi-problem on TPU we need it in absolute examples . hparams . batch_size = 8 hparams . multiproblem_vocab_size = 2**16 return hparams": 3919,
 "def api_test ( method = ' GET ' , **response_kwargs ) : method = method . lower ( ) def api_test_factory ( fn ) : @functools . wraps ( fn ) @mock . patch ( ' requests . {} ' . format ( method ) ) def execute_test ( method_func , *args , **kwargs ) : method_func . return_value = MockResponse ( **response_kwargs ) expected_url , response = fn ( *args , **kwargs ) method_func . assert_called_once ( ) assert_valid_api_call ( method_func , expected_url ) assert isinstance ( response , JSONAPIParser ) assert response . json_data is method_func . return_value . data return execute_test return api_test_factory": 3920,
 "def vertical_percent ( plot , percent = 0 . 1 ) : plot_bottom , plot_top = plot . get_ylim ( ) return percent * ( plot_top - plot_bottom ) ": 3921,
 "def _ParseYamlFromFile ( filedesc ) : content = filedesc . read ( ) return yaml . Parse ( content ) or collections . OrderedDict ( ) ": 3922,
 "def get_axis ( array , axis , slice_num ) : slice_list = [slice ( None ) ] * array . ndim slice_list[axis] = slice_num slice_data = array[tuple ( slice_list ) ] . T # transpose for proper orientation return slice_data": 3923,
 "def __init__ ( self , stream_start ) : self . _decompressor = zlib_decompressor . DeflateDecompressor ( ) self . last_read = stream_start self . uncompressed_offset = 0 self . _compressed_data = b ' ' ": 3924,
 "def changed ( self , *value ) : if self . _last_checked_value ! = value : self . _last_checked_value = value return True return False": 3925,
 "def get_server ( address = None ) : if address : domain = address . split ( \" @ \" ) [1] try : return SMTP_SERVERS[domain] except KeyError : return ( \" smtp . \" + domain , 465 ) return ( None , None ) ": 3926,
 "def nlevels ( self ) : levels = self . levels ( ) return [len ( l ) for l in levels] if levels else 0": 3927,
 "def get_from_human_key ( self , key ) : if key in self . _identifier_map : return self . _identifier_map[key] raise KeyError ( key ) ": 3928,
 "def find_path ( self , start , end , grid ) : start . g = 0 start . f = 0 return super ( AStarFinder , self ) . find_path ( start , end , grid ) ": 3929,
 "def parent_widget ( self ) : parent = self . parent ( ) if parent is not None and isinstance ( parent , QtGraphicsItem ) : return parent . widget": 3930,
 "def reconnect ( self ) : import pika import pika . exceptions self . connection = pika . BlockingConnection ( pika . URLParameters ( self . amqp_url ) ) self . channel = self . connection . channel ( ) try : self . channel . queue_declare ( self . name ) except pika . exceptions . ChannelClosed : self . connection = pika . BlockingConnection ( pika . URLParameters ( self . amqp_url ) ) self . channel = self . connection . channel ( ) ": 3931,
 "def indent ( block , spaces ) : new_block = ' ' for line in block . split ( ' \\n ' ) : new_block + = spaces + line + ' \\n ' return new_block": 3932,
 "def __getattr__ ( self , name ) : return functools . partial ( self . _obj . request , self . _api_prefix + name ) ": 3933,
 "def minus ( *args ) : if len ( args ) = = 1 : return -to_numeric ( args[0] ) return to_numeric ( args[0] ) - to_numeric ( args[1] ) ": 3934,
 "def _remove_nonascii ( self , df ) : df_copy = df . copy ( deep = True ) for col in df_copy . columns : if ( df_copy[col] . dtype = = np . dtype ( ' O ' ) ) : df_copy[col] = df[col] . apply ( lambda x : re . sub ( r ' [^\\x00-\\x7f] ' , r ' ' , x ) if isinstance ( x , six . string_types ) else x ) return df_copy": 3935,
 "def read_numpy ( fh , byteorder , dtype , count , offsetsize ) : dtype = ' b ' if dtype[-1] = = ' s ' else byteorder+dtype[-1] return fh . read_array ( dtype , count ) ": 3936,
 "def makeAnimation ( self ) : aclip = mpy . AudioFileClip ( \" sound . wav \" ) self . iS = self . iS . set_audio ( aclip ) self . iS . write_videofile ( \" mixedVideo . webm \" , 15 , audio = True ) print ( \" wrote \" + \" mixedVideo . webm \" ) ": 3937,
 "def getTopRight ( self ) : return ( float ( self . get_cx ( ) ) + float ( self . get_rx ( ) ) , float ( self . get_cy ( ) ) + float ( self . get_ry ( ) ) ) ": 3938,
 "def dfs_recursive ( graph , node , seen ) : seen[node] = True for neighbor in graph[node] : if not seen[neighbor] : dfs_recursive ( graph , neighbor , seen ) ": 3939,
 "def llen ( self , name ) : with self . pipe as pipe : return pipe . llen ( self . redis_key ( name ) ) ": 3940,
 "def mad ( v ) : return np . median ( np . abs ( v - np . median ( v ) ) ) ": 3941,
 "def build ( self , **kwargs ) : self . lexer = ply . lex . lex ( object = self , **kwargs ) ": 3942,
 "def _get_printable_columns ( columns , row ) : if not columns : return row # Extract the column values , in the order specified . return tuple ( row[c] for c in columns ) ": 3943,
 "def parse_json ( filename ) : # Regular expression for comments comment_re = re . compile ( ' ( ^ ) ?[^\\S\\n]*/ ( ? : \\* ( . *? ) \\*/[^\\S\\n]*|/[^\\n]* ) ( $ ) ? ' , re . DOTALL | re . MULTILINE ) with open ( filename ) as f : content = ' ' . join ( f . readlines ( ) ) # # Looking for comments match = comment_re . search ( content ) while match : # single line comment content = content[ : match . start ( ) ] + content[match . end ( ) : ] match = comment_re . search ( content ) # Return json file return json . loads ( content ) ": 3944,
 "def file_remove ( self , path , filename ) : if os . path . isfile ( path + filename ) : os . remove ( path + filename ) ": 3945,
 "def strip_line ( line , sep = os . linesep ) : try : return line . strip ( sep ) except TypeError : return line . decode ( ' utf-8 ' ) . strip ( sep ) ": 3946,
 "def EvalBinomialPmf ( k , n , p ) : return scipy . stats . binom . pmf ( k , n , p ) ": 3947,
 "def format_docstring ( *args , **kwargs ) : def decorator ( func ) : func . __doc__ = getdoc ( func ) . format ( *args , **kwargs ) return func return decorator": 3948,
 "def _tab ( content ) : response = _data_frame ( content ) . to_csv ( index = False , sep = ' \\t ' ) return response": 3949,
 "def is_iterable ( obj ) : return ( hasattr ( obj , \" __iter__ \" ) and not isinstance ( obj , str ) and not isinstance ( obj , tuple ) ) ": 3950,
 "def _get_set ( self , key , operation , create = False ) : return self . _get_by_type ( key , operation , create , b ' set ' , set ( ) ) ": 3951,
 "def replace ( table , field , a , b , **kwargs ) : return convert ( table , field , {a : b} , **kwargs ) ": 3952,
 "def submit_the_only_form ( self ) : form = ElementSelector ( world . browser , str ( ' //form ' ) ) assert form , \" Cannot find a form on the page . \" form . submit ( ) ": 3953,
 "def get_args ( method_or_func ) : try : # Python 3 . 0+ args = list ( inspect . signature ( method_or_func ) . parameters . keys ( ) ) except AttributeError : # Python 2 . 7 args = inspect . getargspec ( method_or_func ) . args return args": 3954,
 "def new_iteration ( self , prefix ) : # Flush data for the current iteration self . flush ( ) # Fix prefix self . prefix[-1] = prefix self . reset_formatter ( ) ": 3955,
 "def askopenfilename ( **kwargs ) : try : from Tkinter import Tk import tkFileDialog as filedialog except ImportError : from tkinter import Tk , filedialog root = Tk ( ) root . withdraw ( ) root . update ( ) filenames = filedialog . askopenfilename ( **kwargs ) root . destroy ( ) return filenames": 3956,
 "def serialisasi ( self ) : return { \" kelas \" : self . kelas , \" submakna \" : self . submakna , \" info \" : self . info , \" contoh \" : self . contoh }": 3957,
 "def accuracy ( conf_matrix ) : total , correct = 0 . 0 , 0 . 0 for true_response , guess_dict in conf_matrix . items ( ) : for guess , count in guess_dict . items ( ) : if true_response = = guess : correct + = count total + = count return correct/total": 3958,
 "def reversed_lines ( path ) : with open ( path , ' r ' ) as handle : part = ' ' for block in reversed_blocks ( handle ) : for c in reversed ( block ) : if c = = ' \\n ' and part : yield part[ : : -1] part = ' ' part + = c if part : yield part[ : : -1]": 3959,
 "def chunk_sequence ( sequence , chunk_length ) : for index in range ( 0 , len ( sequence ) , chunk_length ) : yield sequence[index : index + chunk_length]": 3960,
 "def __round_time ( self , dt ) : round_to = self . _resolution . total_seconds ( ) seconds = ( dt - dt . min ) . seconds rounding = ( seconds + round_to / 2 ) // round_to * round_to return dt + timedelta ( 0 , rounding - seconds , -dt . microsecond ) ": 3961,
 "def apply ( self , node ) : new_node = self . run ( node ) return self . update , new_node": 3962,
 "def find_all ( self , string , callback ) : \t\t\t\tfor index , output in self . iter ( string ) : \t\t\tcallback ( index , output ) ": 3963,
 "def compose ( func_list ) : def f ( G , bim ) : for func in func_list : G , bim = func ( G , bim ) return G , bim return f": 3964,
 "def Dump ( obj ) : text = yaml . safe_dump ( obj , default_flow_style = False , allow_unicode = True ) if compatibility . PY2 : text = text . decode ( \" utf-8 \" ) return text": 3965,
 "def parser ( ) : parser = argparse . ArgumentParser ( ) parser . add_argument ( ' -c ' , ' --config_paths ' , default = [] , action = ' append ' , help = ' path to a configuration directory ' ) return parser": 3966,
 "def on_pause ( self ) : self . engine . commit ( ) self . strings . save ( ) self . funcs . save ( ) self . config . write ( ) ": 3967,
 "def createArgumentParser ( description ) : parser = argparse . ArgumentParser ( description = description , formatter_class = SortedHelpFormatter ) return parser": 3968,
 "def select_if ( df , fun ) : def _filter_f ( col ) : try : return fun ( df[col] ) except : return False cols = list ( filter ( _filter_f , df . columns ) ) return df[cols]": 3969,
 "def mouseMoveEvent ( self , event ) : self . declaration . mouse_move_event ( event ) super ( QtGraphicsView , self ) . mouseMoveEvent ( event ) ": 3970,
 "def Diag ( a ) : r = np . zeros ( 2 * a . shape , dtype = a . dtype ) for idx , v in np . ndenumerate ( a ) : r[2 * idx] = v return r , ": 3971,
 "def contains ( self , element ) : self . _run ( unittest_case . assertIn , ( element , self . _subject ) ) return ChainInspector ( self . _subject ) ": 3972,
 "def setup ( self , proxystr = ' ' , prompting = True ) : self . prompting = prompting proxy = self . get_proxy ( proxystr ) if proxy : proxy_support = urllib2 . ProxyHandler ( { \" http \" : proxy , \" ftp \" : proxy} ) opener = urllib2 . build_opener ( proxy_support , urllib2 . CacheFTPHandler ) urllib2 . install_opener ( opener ) ": 3973,
 "def assert_in ( obj , seq , message = None , extra = None ) : assert obj in seq , _assert_fail_message ( message , obj , seq , \" is not in \" , extra ) ": 3974,
 "def assert_is_instance ( value , types , message = None , extra = None ) : assert isinstance ( value , types ) , _assert_fail_message ( message , value , types , \" is not an instance of \" , extra ) ": 3975,
 "def delegate ( self , fn , *args , **kwargs ) : callback = functools . partial ( fn , *args , **kwargs ) coro = self . loop . run_in_executor ( self . subexecutor , callback ) return asyncio . ensure_future ( coro ) ": 3976,
 "def run_task ( func ) : def _wrapped ( *a , **k ) : loop = asyncio . get_event_loop ( ) return loop . run_until_complete ( func ( *a , **k ) ) return _wrapped": 3977,
 "def safe_repr ( obj ) : name = getattr ( obj , ' __name__ ' , getattr ( obj . __class__ , ' __name__ ' ) ) if name = = ' ndict ' : name = ' dict ' return name or repr ( obj ) ": 3978,
 "async def smap ( source , func , *more_sources ) : if more_sources : source = zip ( source , *more_sources ) async with streamcontext ( source ) as streamer : async for item in streamer : yield func ( *item ) if more_sources else func ( item ) ": 3979,
 "def list_rds ( region , filter_by_kwargs ) : conn = boto . rds . connect_to_region ( region ) instances = conn . get_all_dbinstances ( ) return lookup ( instances , filter_by = filter_by_kwargs ) ": 3980,
 "def __init__ ( self , enumtype , index , key ) : self . _enumtype = enumtype self . _index = index self . _key = key": 3981,
 "def get_url ( self , routename , **kargs ) : return ' / ' + self . routes . build ( routename , **kargs ) . split ( ' ; ' , 1 ) [1]": 3982,
 "def mean_cl_boot ( series , n_samples = 1000 , confidence_interval = 0 . 95 , random_state = None ) : return bootstrap_statistics ( series , np . mean , n_samples = n_samples , confidence_interval = confidence_interval , random_state = random_state ) ": 3983,
 "def get_http_method ( self , method ) : return self . http_methods[method] ( self . url , **self . http_method_args ) ": 3984,
 "def __sort_up ( self ) : if self . __do_need_sort_up : self . __up_objects . sort ( key = cmp_to_key ( self . __up_cmp ) ) self . __do_need_sort_up = False": 3985,
 "def _get_memoized_value ( func , args , kwargs ) : key = ( repr ( args ) , repr ( kwargs ) ) if not key in func . _cache_dict : ret = func ( *args , **kwargs ) func . _cache_dict[key] = ret return func . _cache_dict[key]": 3986,
 "def locked_delete ( self ) : filters = {self . key_name : self . key_value} self . session . query ( self . model_class ) . filter_by ( **filters ) . delete ( ) ": 3987,
 "def triangle_normal ( a , b , c ) : normal = np . cross ( a - c , b - c ) norm = np . linalg . norm ( normal ) return normal/norm": 3988,
 "def distance_to_line ( a , b , p ) : return distance ( closest_point ( a , b , p ) , p ) ": 3989,
 "def post_ratelimited ( protocol , session , url , headers , data , allow_redirects = False , stream = False ) : thread_id = get_ident ( ) wait = 10 # seconds retry = 0 redirects = 0 # In Python 2 , we want this to be a ' str ' object so logging doesn ' t break ( all formatting arguments are ' str ' ) . # We activated ' unicode_literals ' at the top of this file , so it would be a ' unicode ' object unless we convert # to ' str ' explicitly . This is a no-op for Python 3 . log_msg = str ( ' ' ' \\Retry : % ( retry ) sWaited : % ( wait ) sTimeout : % ( timeout ) sSession : % ( session_id ) sThread : % ( thread_id ) sAuth type : % ( auth ) sURL : % ( url ) sHTTP adapter : % ( adapter ) sAllow redirects : % ( allow_redirects ) sStreaming : % ( stream ) sResponse time : % ( response_time ) sStatus code : % ( status_code ) sRequest headers : % ( request_headers ) sResponse headers : % ( response_headers ) sRequest data : % ( xml_request ) sResponse data : % ( xml_response ) s ' ' ' ) log_vals = dict ( retry = retry , wait = wait , timeout = protocol . TIMEOUT , session_id = session . session_id , thread_id = thread_id , auth = session . auth , url = url , adapter = session . get_adapter ( url ) , allow_redirects = allow_redirects , stream = stream , response_time = None , status_code = None , request_headers = headers , response_headers = None , xml_request = data , xml_response = None , ) try : while True : _back_off_if_needed ( protocol . credentials . back_off_until ) log . debug ( ' Session %s thread %s : retry %s timeout %s POST\\ ' ing to %s after %ss wait ' , session . session_id , thread_id , retry , protocol . TIMEOUT , url , wait ) d_start = time_func ( ) # Always create a dummy response for logging purposes , in case we fail in the following r = DummyResponse ( url = url , headers = {} , request_headers = headers ) try : r = session . post ( url = url , headers = headers , data = data , allow_redirects = False , timeout = protocol . TIMEOUT , stream = stream ) except CONNECTION_ERRORS as e : log . debug ( ' Session %s thread %s : connection error POST\\ ' ing to %s ' , session . session_id , thread_id , url ) r = DummyResponse ( url = url , headers = { ' TimeoutException ' : e} , request_headers = headers ) finally : log_vals . update ( retry = retry , wait = wait , session_id = session . session_id , url = str ( r . url ) , response_time = time_func ( ) - d_start , status_code = r . status_code , request_headers = r . request . headers , response_headers = r . headers , xml_response = ' [STREAMING] ' if stream else r . content , ) log . debug ( log_msg , log_vals ) if _may_retry_on_error ( r , protocol , wait ) : log . info ( \" Session %s thread %s : Connection error on URL %s ( code %s ) . Cool down %s secs \" , session . session_id , thread_id , r . url , r . status_code , wait ) time . sleep ( wait ) # Increase delay for every retry retry + = 1 wait * = 2 session = protocol . renew_session ( session ) continue if r . status_code in ( 301 , 302 ) : if stream : r . close ( ) url , redirects = _redirect_or_fail ( r , redirects , allow_redirects ) continue break except ( RateLimitError , RedirectError ) as e : log . warning ( e . value ) protocol . retire_session ( session ) raise except Exception as e : # Let higher layers handle this . Add full context for better debugging . log . error ( str ( ' %s : %s\\n%s ' ) , e . __class__ . __name__ , str ( e ) , log_msg % log_vals ) protocol . retire_session ( session ) raise if r . status_code = = 500 and r . content and is_xml ( r . content ) : # Some genius at Microsoft thinks it ' s OK to send a valid SOAP response as an HTTP 500 log . debug ( ' Got status code %s but trying to parse content anyway ' , r . status_code ) elif r . status_code ! = 200 : protocol . retire_session ( session ) try : _raise_response_errors ( r , protocol , log_msg , log_vals ) # Always raises an exception finally : if stream : r . close ( ) log . debug ( ' Session %s thread %s : Useful response from %s ' , session . session_id , thread_id , url ) return r , session": 3990,
 "def get_previous_month ( self ) : end = utils . get_month_start ( ) - relativedelta ( days = 1 ) end = utils . to_datetime ( end ) start = utils . get_month_start ( end ) return start , end": 3991,
 "def _hue ( color , **kwargs ) : h = colorsys . rgb_to_hls ( *[x / 255 . 0 for x in color . value[ : 3]] ) [0] return NumberValue ( h * 360 . 0 ) ": 3992,
 "def stop ( self ) : \t\t\t\tlogger . debug ( \" Stopping playback \" ) \t\t # Stop the clock\t\tself . clock . stop ( ) \t\t # Set plauyer status to ready\t\tself . status = READY": 3993,
 "def get_login_credentials ( args ) : if not args . username : args . username = raw_input ( \" Enter Username : \" ) if not args . password : args . password = getpass . getpass ( \" Enter Password : \" ) ": 3994,
 "def angle_to_cartesian ( lon , lat ) : theta = np . array ( np . pi / 2 . - lat ) return np . vstack ( ( np . sin ( theta ) * np . cos ( lon ) , np . sin ( theta ) * np . sin ( lon ) , np . cos ( theta ) ) ) . T": 3995,
 "def get_title ( soup ) : if soup . title : return soup . title . string if soup . h1 : return soup . h1 . string return ' ' ": 3996,
 "def pad_image ( arr , max_size = 400 ) : dim = np . max ( arr . shape ) img = np . zeros ( ( dim , dim , 3 ) , dtype = arr . dtype ) xl = ( dim - arr . shape[0] ) // 2 yl = ( dim - arr . shape[1] ) // 2 img[xl : arr . shape[0]+xl , yl : arr . shape[1]+yl , : ] = arr return resample_image ( img , max_size = max_size ) ": 3997,
 "def _strptime ( self , time_str ) : if time_str : # Parse UTC string into naive datetime , then add timezone dt = datetime . strptime ( time_str , __timeformat__ ) return dt . replace ( tzinfo = UTC ( ) ) return None": 3998,
 "def _svd ( cls , matrix , num_concepts = 5 ) : u , s , v = svds ( matrix , k = num_concepts ) return u , s , v": 3999,
 "def writer_acquire ( self ) : self . _order_mutex . acquire ( ) self . _access_mutex . acquire ( ) self . _order_mutex . release ( ) ": 4000,
 "def _check_key ( self , key ) : if not len ( key ) = = 2 : raise TypeError ( ' invalid key : %r ' % key ) elif key[1] not in TYPES : raise TypeError ( ' invalid datatype : %s ' % key[1] ) ": 4001,
 "def required_attributes ( element , *attributes ) : if not reduce ( lambda still_valid , param : still_valid and param in element . attrib , attributes , True ) : raise NotValidXmlException ( msg_err_missing_attributes ( element . tag , *attributes ) ) ": 4002,
 "def _is_already_configured ( configuration_details ) : path = Path ( configuration_details . path ) . expanduser ( ) with path . open ( ' r ' ) as shell_config : return configuration_details . content in shell_config . read ( ) ": 4003,
 "def _is_one_arg_pos_call ( call ) : return isinstance ( call , astroid . Call ) and len ( call . args ) = = 1 and not call . keywords": 4004,
 "def wait_and_join ( self , task ) : while not task . has_started : time . sleep ( self . _polling_time ) task . thread . join ( ) ": 4005,
 "def url_syntax_check ( url ) : # pragma : no cover if url and isinstance ( url , str ) : # The given URL is not empty nor None . # and # * The given URL is a string . # We silently load the configuration . load_config ( True ) return Check ( url ) . is_url_valid ( ) # We return None , there is nothing to check . return None": 4006,
 "def print_ldamodel_topic_words ( topic_word_distrib , vocab , n_top = 10 , row_labels = DEFAULT_TOPIC_NAME_FMT ) : print_ldamodel_distribution ( topic_word_distrib , row_labels = row_labels , val_labels = vocab , top_n = n_top ) ": 4007,
 "def drop_trailing_zeros ( num ) : txt = ' %f ' % ( num ) txt = txt . rstrip ( ' 0 ' ) if txt . endswith ( ' . ' ) : txt = txt[ : -1] return txt": 4008,
 "def str_check ( *args , func = None ) : func = func or inspect . stack ( ) [2][3] for var in args : if not isinstance ( var , ( str , collections . UserString , collections . abc . Sequence ) ) : name = type ( var ) . __name__ raise StringError ( f ' Function {func} expected str , {name} got instead . ' ) ": 4009,
 "def set_scrollbars_cb ( self , w , tf ) : scrollbars = ' on ' if tf else ' off ' self . t_ . set ( scrollbars = scrollbars ) ": 4010,
 "def is_closed ( self ) : return ( self . state = = SESSION_STATE . CLOSED or self . state = = SESSION_STATE . CLOSING ) ": 4011,
 "def _lookup_enum_in_ns ( namespace , value ) : for attribute in dir ( namespace ) : if getattr ( namespace , attribute ) = = value : return attribute": 4012,
 "def getConnectionStats ( self ) : cur = self . _conn . cursor ( ) cur . execute ( \" \" \" SELECT datname , numbackends FROM pg_stat_database; \" \" \" ) rows = cur . fetchall ( ) if rows : return dict ( rows ) else : return {}": 4013,
 "def _check_model ( obj , models = None ) : return isinstance ( obj , type ) and issubclass ( obj , pw . Model ) and hasattr ( obj , ' _meta ' ) ": 4014,
 "def setVolume ( self , volume ) : val = float ( val ) cmd = \" volume %s \" % val self . _execute ( cmd ) ": 4015,
 "def pool_args ( function , sequence , kwargs ) : return zip ( itertools . repeat ( function ) , sequence , itertools . repeat ( kwargs ) ) ": 4016,
 "def serve_dtool_directory ( directory , port ) : os . chdir ( directory ) server_address = ( \" localhost \" , port ) httpd = DtoolHTTPServer ( server_address , DtoolHTTPRequestHandler ) httpd . serve_forever ( ) ": 4017,
 "def get_last_week_range ( weekday_start = \" Sunday \" ) : today = date . today ( ) # Get the first day of the past complete week . start_of_week = snap_to_beginning_of_week ( today , weekday_start ) - timedelta ( weeks = 1 ) end_of_week = start_of_week + timedelta ( days = 6 ) return ( start_of_week , end_of_week ) ": 4018,
 "def __check_success ( resp ) : if \" success \" not in resp . keys ( ) : try : raise APIError ( ' 200 ' , ' Operation Failed ' , resp[ \" error \" ] ) except KeyError : raise APIError ( ' 200 ' , ' Operation Failed ' , str ( resp ) ) return resp[ \" success \" ]": 4019,
 "def s3_connect ( bucket_name , s3_access_key_id , s3_secret_key ) : conn = connect_s3 ( s3_access_key_id , s3_secret_key ) try : return conn . get_bucket ( bucket_name ) except S3ResponseError as e : if e . status = = 403 : raise Exception ( \" Bad Amazon S3 credentials . \" ) raise": 4020,
 "def short_action_string ( self ) : output = \" {0} \" . format ( self . actor ) if self . override_string : output + = self . override_string else : output + = self . verb return output": 4021,
 "def _check_fields ( self , x , y ) : \t\t\t\tif x is None : \t\t\tif self . x is None : \t\t\t\tself . err ( \t\t\t\t\tself . _check_fields , \t\t\t\t\t \" X field is not set : please specify a parameter \" ) \t\t\t\treturn\t\t\tx = self . x\t\tif y is None : \t\t\tif self . y is None : \t\t\t\tself . err ( \t\t\t\t\tself . _check_fields , \t\t\t\t\t \" Y field is not set : please specify a parameter \" ) \t\t\t\treturn\t\t\ty = self . y\t\treturn x , y": 4022,
 "def _trace_full ( frame , event , arg ) : if event = = \" line \" : _trace_line ( frame , event , arg ) else : _trace ( frame , event , arg ) return _trace_full": 4023,
 "def _remove_empty_items ( d , required ) : new_dict = {} for k , v in d . items ( ) : if k in required : new_dict[k] = v elif isinstance ( v , int ) or v : # \" if v \" would suppress emitting int ( 0 ) new_dict[k] = v return new_dict": 4024,
 "def previous_key ( tuple_of_tuples , key ) : for i , t in enumerate ( tuple_of_tuples ) : if t[0] = = key : try : return tuple_of_tuples[i - 1][0] except IndexError : return None": 4025,
 "def translation ( language ) : global _translations if language not in _translations : _translations[language] = Translations ( language ) return _translations[language]": 4026,
 "def get_common_elements ( list1 , list2 ) : # result = [] # for item in list1 : # if item in list2 : # result . append ( item ) # Return list ( set ( list1 ) . intersection ( set ( list2 ) ) ) set2 = set ( list2 ) result = [item for item in list1 if item in set2] return result": 4027,
 "def cancel ( self , event = None ) : if self . parent ! = None : self . parent . focus_set ( ) self . destroy ( ) ": 4028,
 "def on_close ( self , ws ) : log . debug ( \" Closing WebSocket connection with {} \" . format ( self . url ) ) if self . keepalive and self . keepalive . is_alive ( ) : self . keepalive . do_run = False self . keepalive . join ( ) ": 4029,
 "def close_database_session ( session ) : try : session . close ( ) except OperationalError as e : raise DatabaseError ( error = e . orig . args[1] , code = e . orig . args[0] ) ": 4030,
 "def query_collision ( collision_object ) : global collidable_objects # Note that we use a Brute Force approach for the time being . # It performs horribly under heavy loads , but it meets # our needs for the time being . for obj in collidable_objects : # Make sure we don ' t check ourself against ourself . if obj . obj_id is not collision_object . obj_id : if collision_object . is_colliding ( obj ) : # A collision has been detected . Return the object that we are colliding with . return obj # No collision was noticed . Return None . return None": 4031,
 "def has_edit_permission ( self , request ) : return request . user . is_authenticated and request . user . is_active and request . user . is_staff": 4032,
 "def get_labels ( labels ) : label_u = unique_labels ( labels ) label_u_line = [i + \" _line \" for i in label_u] return label_u , label_u_line": 4033,
 "def _stop_instance ( self ) : instance = self . _get_instance ( ) instance . stop ( ) self . _wait_on_instance ( ' stopped ' , self . timeout ) ": 4034,
 "def get_codeblock ( language , text ) : rst = \" \\n\\n . . code-block : : \" + language + \" \\n\\n \" for line in text . splitlines ( ) : rst + = \" \\t \" + line + \" \\n \" rst + = \" \\n \" return rst": 4035,
 "def xor ( a , b ) : return bytearray ( i ^ j for i , j in zip ( a , b ) ) ": 4036,
 "def compare ( string1 , string2 ) : if len ( string1 ) ! = len ( string2 ) : return False result = True for c1 , c2 in izip ( string1 , string2 ) : result & = c1 = = c2 return result": 4037,
 "def register ( ) : signals . article_generator_finalized . connect ( link_source_files ) signals . page_generator_finalized . connect ( link_source_files ) signals . page_writer_finalized . connect ( write_source_files ) ": 4038,
 "def quit ( self ) : try : RemoteWebDriver . quit ( self ) except http_client . BadStatusLine : pass finally : self . service . stop ( ) ": 4039,
 "def shannon_entropy ( p ) : return -np . sum ( np . where ( p! = 0 , p * np . log2 ( p ) , 0 ) ) ": 4040,
 "def yum_install ( self , packages , ignore_error = False ) : return self . run ( ' yum install -y --quiet ' + ' ' . join ( packages ) , ignore_error = ignore_error , retry = 5 ) ": 4041,
 "def obj_to_string ( obj , top = True ) : obj = prepare_for_json_encoding ( obj ) if type ( obj ) = = six . text_type : return obj return json . dumps ( obj ) ": 4042,
 "def _get_session ( ) : session = getattr ( g , ' _session ' , None ) if session is None : session = g . _session = db . session ( ) return session": 4043,
 "def writeCSV ( data , headers , csvFile ) : with open ( csvFile , \" wb \" ) as f : writer = csv . writer ( f , delimiter = \" , \" ) writer . writerow ( headers ) writer . writerows ( data ) ": 4044,
 "def _MakeExecutable ( self , metadata_script ) : mode = os . stat ( metadata_script ) . st_mode os . chmod ( metadata_script , mode | stat . S_IEXEC ) ": 4045,
 "def build_code ( self , lang , body ) : self . out . append ( \" ``` \" + lang ) self . build_markdown ( lang , body ) self . out . append ( \" ``` \" ) ": 4046,
 "def default_diff ( latest_config , current_config ) : # Pop off the fields we don ' t care about : pop_no_diff_fields ( latest_config , current_config ) diff = DeepDiff ( latest_config , current_config , ignore_order = True ) return diff": 4047,
 "def load_model_from_package ( name , **overrides ) : cls = importlib . import_module ( name ) return cls . load ( **overrides ) ": 4048,
 "def types ( self ) : output = set ( ) for var in self . values ( ) : if var . has_value ( ) : output . update ( var . types ( ) ) return list ( output ) ": 4049,
 "def index ( ) : global productpage table = json2html . convert ( json = json . dumps ( productpage ) , table_attributes = \" class = \\ \" table table-condensed table-bordered table-hover\\ \" \" ) return render_template ( ' index . html ' , serviceTable = table ) ": 4050,
 "def send_request ( self , *args , **kwargs ) : try : return self . session . request ( *args , **kwargs ) except ConnectionError : self . session . close ( ) return self . session . request ( *args , **kwargs ) ": 4051,
 "def _windowsLdmodTargets ( target , source , env , for_signature ) : return _dllTargets ( target , source , env , for_signature , ' LDMODULE ' ) ": 4052,
 "def enbw ( wnd ) : return sum ( el ** 2 for el in wnd ) / sum ( wnd ) ** 2 * len ( wnd ) ": 4053,
 "def __init__ ( self , collection , index_type_obj ) : self . collection = collection self . index_type_obj = index_type_obj": 4054,
 "def setup ( app ) : from . patches import patch_django_for_autodoc # When running , make sure Django doesn ' t execute querysets patch_django_for_autodoc ( ) # Generate docstrings for Django model fields # Register the docstring processor with sphinx app . connect ( ' autodoc-process-docstring ' , improve_model_docstring ) # influence skip rules app . connect ( \" autodoc-skip-member \" , autodoc_skip ) ": 4055,
 "def convertDatetime ( t ) : epoch = datetime . datetime . utcfromtimestamp ( 0 ) delta = t - epoch millis = delta . total_seconds ( ) * 1000 return int ( millis ) ": 4056,
 "def coords_string_parser ( self , coords ) : lat , lon = coords . split ( ' , ' ) return { \" lat \" : lat . strip ( ) , \" lon \" : lon . strip ( ) , \" bounds \" : {}}": 4057,
 "def _iterable_to_varargs_method ( func ) : def wrapped ( self , *args , **kwargs ) : return func ( self , args , **kwargs ) return wrapped": 4058,
 "def to_bin ( data , width ) : data_str = bin ( data & ( 2**width-1 ) ) [2 : ] . zfill ( width ) return [int ( x ) for x in tuple ( data_str ) ]": 4059,
 "def __deepcopy__ ( self , memo ) : return type ( self ) ( value = self . _value , enum_ref = self . enum_ref ) ": 4060,
 "def url ( self , action , **kwargs ) : # TODO : should be static method ? return self . URLS[ ' BASE ' ] % self . URLS[action] % kwargs": 4061,
 "def __delitem__ ( self , key ) : \t\t\t\tindex , value = self . _dict . pop ( key ) \t\tkey2 , value2 = self . _list . pop ( index ) \t\tassert key = = key2\t\tassert value is value2\t\tself . _fix_indices_after_delete ( index ) ": 4062,
 "def restore_button_state ( self ) : self . parent . pbnNext . setEnabled ( self . next_button_state ) self . parent . pbnBack . setEnabled ( self . back_button_state ) ": 4063,
 "def remove_this_tlink ( self , tlink_id ) : for tlink in self . get_tlinks ( ) : if tlink . get_id ( ) = = tlink_id : self . node . remove ( tlink . get_node ( ) ) break": 4064,
 "def normalized_distance ( self , image ) : return self . __distance ( self . __original_image_for_distance , image , bounds = self . bounds ( ) ) ": 4065,
 "def _distance ( coord1 , coord2 ) : xdist = coord1[0] - coord2[0] ydist = coord1[1] - coord2[1] return sqrt ( xdist*xdist + ydist*ydist ) ": 4066,
 "def _decode ( self , obj , context ) : return b ' ' . join ( map ( int2byte , [c + 0x60 for c in bytearray ( obj ) ] ) ) . decode ( \" utf8 \" ) ": 4067,
 "def tpr ( y , z ) : tp , tn , fp , fn = contingency_table ( y , z ) return tp / ( tp + fn ) ": 4068,
 "def is_descriptor_class ( desc , include_abstract = False ) : r return ( isinstance ( desc , type ) and issubclass ( desc , Descriptor ) and ( True if include_abstract else not inspect . isabstract ( desc ) ) ) ": 4069,
 "def set_terminate_listeners ( stream ) : def stop ( signum , frame ) : terminate ( stream . listener ) # Installs signal handlers for handling SIGINT and SIGTERM # gracefully . signal . signal ( signal . SIGINT , stop ) signal . signal ( signal . SIGTERM , stop ) ": 4070,
 "def register ( self , target ) : for rule , options in self . url_rules : target . add_url_rule ( rule , self . name , self . dispatch_request , **options ) ": 4071,
 "def check_hash_key ( query_on , key ) : return ( isinstance ( key , BaseCondition ) and ( key . operation = = \" = = \" ) and ( key . column is query_on . hash_key ) ) ": 4072,
 "def load_files ( files ) : for py_file in files : LOG . debug ( \" exec %s \" , py_file ) execfile ( py_file , globals ( ) , locals ( ) ) ": 4073,
 "def typescript_compile ( source ) : with open ( TS_COMPILER , ' r ' ) as tsservices_js : return evaljs ( ( tsservices_js . read ( ) , ' ts . transpile ( dukpy . tscode , {options} ) ; ' . format ( options = TSC_OPTIONS ) ) , tscode = source ) ": 4074,
 "def __init__ ( self ) : self . state = self . STATE_INITIALIZING self . state_start = time . time ( ) ": 4075,
 "def is_break_tag ( self , el ) : name = el . name return name in self . break_tags or name in self . user_break_tags": 4076,
 "def ignored_regions ( source ) : return [ ( match . start ( ) , match . end ( ) ) for match in _str . finditer ( source ) ]": 4077,
 "def install_plugin ( username , repo ) : print ( \" Installing plugin from \" + username + \" / \" + repo ) pip . main ( [ ' install ' , ' -U ' , \" git+git : //github . com/ \" + username + \" / \" + repo + \" . git \" ] ) ": 4078,
 "def run_cmd ( command , verbose = True , shell = ' /bin/bash ' ) : process = Popen ( command , shell = True , stdout = PIPE , stderr = STDOUT , executable = shell ) output = process . stdout . read ( ) . decode ( ) . strip ( ) . split ( ' \\n ' ) if verbose : # return full output including empty lines return output return [line for line in output if line . strip ( ) ]": 4079,
 "def gauss_box_model ( x , amplitude = 1 . 0 , mean = 0 . 0 , stddev = 1 . 0 , hpix = 0 . 5 ) : z = ( x - mean ) / stddev z2 = z + hpix / stddev z1 = z - hpix / stddev return amplitude * ( norm . cdf ( z2 ) - norm . cdf ( z1 ) ) ": 4080,
 "def safe_dump_all ( documents , stream = None , **kwds ) : return dump_all ( documents , stream , Dumper = SafeDumper , **kwds ) ": 4081,
 "async def vc_check ( ctx : commands . Context ) : # pylint : disable = unused-argument if not discord . voice_client . has_nacl : raise commands . CheckFailure ( \" voice cannot be used because PyNaCl is not loaded \" ) if not discord . opus . is_loaded ( ) : raise commands . CheckFailure ( \" voice cannot be used because libopus is not loaded \" ) return True": 4082,
 "def parse_value ( self , value ) : parsed = super ( BoolField , self ) . parse_value ( value ) return bool ( parsed ) if parsed is not None else None": 4083,
 "def __del__ ( self ) : if self . _hConv : DDE . Disconnect ( self . _hConv ) if self . _idInst : DDE . Uninitialize ( self . _idInst ) ": 4084,
 "def _init_glyph ( self , plot , mapping , properties ) : properties = mpl_to_bokeh ( properties ) plot_method = self . _plot_methods . get ( ' batched ' if self . batched else ' single ' ) if isinstance ( plot_method , tuple ) : # Handle alternative plot method for flipped axes plot_method = plot_method[int ( self . invert_axes ) ] renderer = getattr ( plot , plot_method ) ( **dict ( properties , **mapping ) ) return renderer , renderer . glyph": 4085,
 "def duplicated_rows ( df , col_name ) : _check_cols ( df , [col_name] ) dups = df[pd . notnull ( df[col_name] ) & df . duplicated ( subset = [col_name] ) ] return dups": 4086,
 "def determine_types ( self ) : from nefertari . elasticsearch import ES collections = self . get_collections ( ) resources = self . get_resources ( collections ) models = set ( [res . view . Model for res in resources] ) es_models = [mdl for mdl in models if mdl and getattr ( mdl , ' _index_enabled ' , False ) ] types = [ES . src2type ( mdl . __name__ ) for mdl in es_models] return types": 4087,
 "def is_vector ( inp ) : inp = np . asarray ( inp ) nr_dim = np . ndim ( inp ) if nr_dim = = 1 : return True elif ( nr_dim = = 2 ) and ( 1 in inp . shape ) : return True else : return False": 4088,
 "def mutating_method ( func ) : def wrapper ( self , *__args , **__kwargs ) : old_mutable = self . _mutable self . _mutable = True try : # Call the wrapped function return func ( self , *__args , **__kwargs ) finally : self . _mutable = old_mutable return wrapper": 4089,
 "def _dump_enum ( self , e , top = ' ' ) : self . _print ( ) self . _print ( ' enum {} {{ ' . format ( e . name ) ) self . defines . append ( ' {} . {} ' . format ( top , e . name ) ) self . tabs+ = 1 for v in e . value : self . _print ( ' {} = {}; ' . format ( v . name , v . number ) ) self . tabs- = 1 self . _print ( ' } ' ) ": 4090,
 "def get_enum_from_name ( self , enum_name ) : return next ( ( e for e in self . enums if e . name = = enum_name ) , None ) ": 4091,
 "def sed ( match , replacement , path , modifiers = \" \" ) : cmd = \" sed -r -i ' s/%s/%s/%s ' %s \" % ( match , replacement , modifiers , path ) process = Subprocess ( cmd , shell = True ) ret , out , err = process . run ( timeout = 60 ) if ret : raise SubprocessError ( \" Sed command failed! \" ) ": 4092,
 "def euler ( self ) : e_xyz = transformations . euler_from_matrix ( self . rotation , ' sxyz ' ) return np . array ( [180 . 0 / np . pi * a for a in e_xyz] ) ": 4093,
 "def cleanup ( ) : if _output_dir and os . path . exists ( _output_dir ) : log . msg_warn ( \" Cleaning up output directory at ' {output_dir} ' . . . \" . format ( output_dir = _output_dir ) ) if not _dry_run : shutil . rmtree ( _output_dir ) ": 4094,
 "def paste ( cmd = paste_cmd , stdout = PIPE ) : return Popen ( cmd , stdout = stdout ) . communicate ( ) [0] . decode ( ' utf-8 ' ) ": 4095,
 "def apply_to_field_if_exists ( effect , field_name , fn , default ) : value = getattr ( effect , field_name , None ) if value is None : return default else : return fn ( value ) ": 4096,
 "def fuzzy_get_tuple ( dict_obj , approximate_key , dict_keys = None , key_and_value = False , similarity = 0 . 6 , default = None ) : return fuzzy_get ( dict ( ( ' | ' . join ( str ( k2 ) for k2 in k ) , v ) for ( k , v ) in viewitems ( dict_obj ) ) , ' | ' . join ( str ( k ) for k in approximate_key ) , dict_keys = dict_keys , key_and_value = key_and_value , similarity = similarity , default = default ) ": 4097,
 "def get_typecast_value ( self , value , type ) : if type = = entities . Variable . Type . BOOLEAN : return value = = ' true ' elif type = = entities . Variable . Type . INTEGER : return int ( value ) elif type = = entities . Variable . Type . DOUBLE : return float ( value ) else : return value": 4098,
 "def get_scalar_product ( self , other ) : return self . x*other . x+self . y*other . y": 4099,
 "def get_long_description ( ) : with open ( path . join ( root_path , ' README . md ' ) , encoding = ' utf-8 ' ) as f : long_description = f . read ( ) return long_description": 4100,
 "def main ( argv = None ) : if argv is None : argv = sys . argv[1 : ] cli = CommandLineTool ( ) return cli . run ( argv ) ": 4101,
 "def __init__ ( self , function ) : \t\t\t\tsuper ( filter , self ) . __init__ ( ) \t\tself . function = function": 4102,
 "def make_code_from_py ( filename ) : # Open the source file . try : source_file = open_source ( filename ) except IOError : raise NoSource ( \" No file to run : %r \" % filename ) try : source = source_file . read ( ) finally : source_file . close ( ) # We have the source . `compile` still needs the last line to be clean , # so make sure it is , then compile a code object from it . if not source or source[-1] ! = ' \\n ' : source + = ' \\n ' code = compile ( source , filename , \" exec \" ) return code": 4103,
 "def __init__ ( self ) : super ( FilterObject , self ) . __init__ ( ) self . _filter_expression = None self . _matcher = None": 4104,
 "def parse_fixed_width ( types , lines ) : values = [] line = [] for width , parser in types : if not line : line = lines . pop ( 0 ) . replace ( ' \\n ' , ' ' ) values . append ( parser ( line[ : width] ) ) line = line[width : ] return values": 4105,
 "def handle_request_parsing_error ( err , req , schema , error_status_code , error_headers ) : abort ( error_status_code , errors = err . messages ) ": 4106,
 "def static_url ( path , absolute = False ) : if os . sep ! = ' / ' : path = ' / ' . join ( path . split ( os . sep ) ) return flask . url_for ( ' static ' , filename = path , _external = absolute ) ": 4107,
 "def get_site_name ( request ) : urlparts = request . urlparts return ' : ' . join ( [urlparts . hostname , str ( urlparts . port ) ] ) ": 4108,
 "def jsonify ( resource ) : response = flask . jsonify ( resource . to_dict ( ) ) response = add_link_headers ( response , resource . links ( ) ) return response": 4109,
 "def set_header ( self , name , value ) : self . _headers[_hkey ( name ) ] = [_hval ( value ) ]": 4110,
 "def get_mac_dot_app_dir ( directory ) : return os . path . dirname ( os . path . dirname ( os . path . dirname ( directory ) ) ) ": 4111,
 "def flush ( self ) : if not self . nostdout : self . stdout . flush ( ) if self . file is not None : self . file . flush ( ) ": 4112,
 "def map_parameters ( cls , params ) : d = {} for k , v in six . iteritems ( params ) : d[cls . FIELD_MAP . get ( k . lower ( ) , k ) ] = v return d": 4113,
 "def RunSphinxAPIDoc ( _ ) : current_directory = os . path . abspath ( os . path . dirname ( __file__ ) ) module = os . path . join ( current_directory , ' . . ' , ' plaso ' ) api_directory = os . path . join ( current_directory , ' sources ' , ' api ' ) apidoc . main ( [ ' -o ' , api_directory , module , ' --force ' ] ) ": 4114,
 "def none ( self ) : return EmptyQuerySet ( model = self . model , using = self . _using , connection = self . _connection ) ": 4115,
 "def generate_device_id ( steamid ) : h = hexlify ( sha1_hash ( str ( steamid ) . encode ( ' ascii ' ) ) ) . decode ( ' ascii ' ) return \" android : %s-%s-%s-%s-%s \" % ( h[ : 8] , h[8 : 12] , h[12 : 16] , h[16 : 20] , h[20 : 32] ) ": 4116,
 "def __init__ ( self , token , editor = None ) : self . token = token self . editor = editor self . session = requests . Session ( ) ": 4117,
 "def generate_id ( self ) : if self . use_repeatable_ids : self . repeatable_id_counter + = 1 return ' autobaked-{} ' . format ( self . repeatable_id_counter ) else : return str ( uuid4 ( ) ) ": 4118,
 "def lon_lat_bins ( bb , coord_bin_width ) : west , south , east , north = bb west = numpy . floor ( west / coord_bin_width ) * coord_bin_width east = numpy . ceil ( east / coord_bin_width ) * coord_bin_width lon_extent = get_longitudinal_extent ( west , east ) lon_bins , _ , _ = npoints_between ( west , 0 , 0 , east , 0 , 0 , numpy . round ( lon_extent / coord_bin_width + 1 ) ) lat_bins = coord_bin_width * numpy . arange ( int ( numpy . floor ( south / coord_bin_width ) ) , int ( numpy . ceil ( north / coord_bin_width ) + 1 ) ) return lon_bins , lat_bins": 4119,
 "def object_to_json ( obj ) : if isinstance ( obj , ( datetime . datetime , datetime . date , datetime . time ) ) : return obj . isoformat ( ) return str ( obj ) ": 4120,
 "def get_pid_list ( ) : pids = [int ( x ) for x in os . listdir ( ' /proc ' ) if x . isdigit ( ) ] return pids": 4121,
 "def getRect ( self ) : \t\t\t\treturn ( self . x , self . y , self . w , self . h ) ": 4122,
 "def get_shape ( self ) : \t\t\t\treturn tuple ( int ( c . pcdata ) for c in self . getElementsByTagName ( ligolw . Dim . tagName ) ) [ : : -1]": 4123,
 "def delaunay_2d ( self , tol = 1e-05 , alpha = 0 . 0 , offset = 1 . 0 , bound = False ) : return PolyData ( self . points ) . delaunay_2d ( tol = tol , alpha = alpha , offset = offset , bound = bound ) ": 4124,
 "def forget_canvas ( canvas ) : cc = [c ( ) for c in canvasses if c ( ) is not None] while canvas in cc : cc . remove ( canvas ) canvasses[ : ] = [weakref . ref ( c ) for c in cc]": 4125,
 "def clean ( dry_run = ' n ' ) : file_patterns = [ ' * . pyc ' , ' * . pyo ' , ' *~ ' ] dir_patterns = [ ' __pycache__ ' ] recursive_pattern_delete ( project_paths . root , file_patterns , dir_patterns , dry_run = bool ( dry_run . lower ( ) = = ' y ' ) ) ": 4126,
 "def get_table_pos ( self , tablename ) : _table , ( row , col ) = self . __tables[tablename] return ( row , col ) ": 4127,
 "def parse_text_to_dict ( self , txt ) : op = {} print ( ' TODO - import NLP , split into verbs / nouns ' ) op[ ' nouns ' ] = txt op[ ' verbs ' ] = txt return op": 4128,
 "def off ( self ) : self . win . keypad ( 0 ) curses . nocbreak ( ) curses . echo ( ) try : curses . curs_set ( 1 ) except : pass curses . endwin ( ) ": 4129,
 "def send_text ( self , text ) : return self . client . api . send_message ( self . room_id , text ) ": 4130,
 "def _columns_for_table ( table_name ) : return {cname : col for ( tname , cname ) , col in _COLUMNS . items ( ) if tname = = table_name}": 4131,
 "def cos_sin_deg ( deg ) : deg = deg % 360 . 0 if deg = = 90 . 0 : return 0 . 0 , 1 . 0 elif deg = = 180 . 0 : return -1 . 0 , 0 elif deg = = 270 . 0 : return 0 , -1 . 0 rad = math . radians ( deg ) return math . cos ( rad ) , math . sin ( rad ) ": 4132,
 "def method_header ( method_name , nogil = False , idx_as_arg = False ) : if not config . FASTCYTHON : nogil = False header = ' cpdef inline void %s ( self ' % method_name header + = ' , int idx ) ' if idx_as_arg else ' ) ' header + = ' nogil : ' if nogil else ' : ' return header": 4133,
 "def read_corpus ( file_name ) : with io . open ( file_name , encoding = ' utf-8 ' ) as data_file : return yaml . load ( data_file ) ": 4134,
 "def find_mapping ( es_url , index ) : mapping = None backend = find_perceval_backend ( es_url , index ) if backend : mapping = backend . get_elastic_mappings ( ) if mapping : logging . debug ( \" MAPPING FOUND : \\n%s \" , json . dumps ( json . loads ( mapping[ ' items ' ] ) , indent = True ) ) return mapping": 4135,
 "def _gevent_patch ( ) : try : assert gevent assert grequests except NameError : logger . warn ( ' gevent not exist , fallback to multiprocess . . . ' ) return MULTITHREAD else : monkey . patch_all ( ) # Must patch before get_photos_info return GEVENT": 4136,
 "def get_value ( self , context ) : if self . value : return expressions . eval_string ( self . value , context ) else : # Empty input raises cryptic EOF syntax err , this more human # friendly raise ValueError ( ' !py string expression is empty . It must be a ' ' valid python expression instead . ' ) ": 4137,
 "def _spawn ( self , func , *args , **kwargs ) : gevent . spawn ( func , *args , **kwargs ) ": 4138,
 "def get_code_language ( self ) : js_source = self . get_js_source ( ) if self . options . get ( \" include_html \" , False ) : resources = get_sphinx_resources ( include_bokehjs_api = True ) html_source = BJS_HTML . render ( css_files = resources . css_files , js_files = resources . js_files , bjs_script = js_source ) return [html_source , \" html \" ] else : return [js_source , \" javascript \" ]": 4139,
 "def set ( self ) : glColor4f ( self . r , self . g , self . b , self . a ) ": 4140,
 "def get_h5file ( file_path , mode = ' r ' ) : if not op . exists ( file_path ) : raise IOError ( ' Could not find file {} . ' . format ( file_path ) ) try : h5file = h5py . File ( file_path , mode = mode ) except : raise else : return h5file": 4141,
 "def distance_matrix ( trains1 , trains2 , cos , tau ) : return dissimilarity_matrix ( trains1 , trains2 , cos , tau , \" distance \" ) ": 4142,
 "def save_partial ( self , obj ) : self . save_reduce ( _genpartial , ( obj . func , obj . args , obj . keywords ) ) ": 4143,
 "def _none_value ( self ) : if self . out_type = = int : return 0 elif self . out_type = = float : return 0 . 0 elif self . out_type = = bool : return False elif self . out_type = = six . text_type : return u ' ' ": 4144,
 "def perform_permissions_check ( self , user , obj , perms ) : return self . request . forum_permission_handler . can_download_files ( obj , user ) ": 4145,
 "def serialize ( self ) : data = { ' doc ' : self . doc} if isinstance ( self . query , Query ) : data[ ' query ' ] = self . query . serialize ( ) return data": 4146,
 "def check_if_branch_exist ( db , root_hash , key_prefix ) : validate_is_bytes ( key_prefix ) return _check_if_branch_exist ( db , root_hash , encode_to_bin ( key_prefix ) ) ": 4147,
 "def ensure_dtype_float ( x , default = np . float64 ) : r if isinstance ( x , np . ndarray ) : if x . dtype . kind = = ' f ' : return x elif x . dtype . kind = = ' i ' : return x . astype ( default ) else : raise TypeError ( ' x is of type ' +str ( x . dtype ) + ' that cannot be converted to float ' ) else : raise TypeError ( ' x is not an array ' ) ": 4148,
 "def __str__ ( self ) : return ' Output name : \" %s \" watts : %d type : \" %s \" id : %d ' % ( self . _name , self . _watts , self . _output_type , self . _integration_id ) ": 4149,
 "def _pad ( self ) : if self . _indent : self . whitespace ( self . _indent * len ( self . _open_elements ) ) ": 4150,
 "def start ( self ) : assert not self . has_started ( ) , \" called start ( ) on an active GeventLoop \" self . _stop_event = Event ( ) # note that we don ' t use safe_greenlets . spawn because we take care of it in _loop by ourselves self . _greenlet = gevent . spawn ( self . _loop ) ": 4151,
 "def give_str ( self ) : args = self . _args[ : ] kwargs = self . _kwargs return self . _give_str ( args , kwargs ) ": 4152,
 "def top_level ( url , fix_protocol = True ) : ext = tld . get_tld ( url , fix_protocol = fix_protocol ) toplevel = ' . ' . join ( urlparse ( url ) . netloc . split ( ' . ' ) [-2 : ] ) . split ( ext ) [0] + ext return toplevel": 4153,
 "def gen_api_key ( username ) : salt = str ( os . urandom ( 64 ) ) . encode ( ' utf-8 ' ) return hash_password ( username , salt ) ": 4154,
 "def normalize ( data ) : out_data = data . copy ( ) for i , sample in enumerate ( out_data ) : out_data[i] / = sum ( out_data[i] ) return out_data": 4155,
 "def caller_locals ( ) : import inspect frame = inspect . currentframe ( ) try : return frame . f_back . f_back . f_locals finally : del frame": 4156,
 "def __repr__ ( self ) : return str ( { ' name ' : self . _name , ' watts ' : self . _watts , ' type ' : self . _output_type , ' id ' : self . _integration_id} ) ": 4157,
 "def get_anchor_href ( markup ) : soup = BeautifulSoup ( markup , ' lxml ' ) return [ ' %s ' % link . get ( ' href ' ) for link in soup . find_all ( ' a ' ) ]": 4158,
 "def _file_type ( self , field ) : type = mimetypes . guess_type ( self . _files[field] ) [0] return type . encode ( \" utf-8 \" ) if isinstance ( type , unicode ) else str ( type ) ": 4159,
 "def download_file ( save_path , file_url ) : r = requests . get ( file_url ) # create HTTP response object with open ( save_path , ' wb ' ) as f : f . write ( r . content ) return save_path": 4160,
 "def onkeyup ( self , key , keycode , ctrl , shift , alt ) : return ( key , keycode , ctrl , shift , alt ) ": 4161,
 "def on_train_end ( self , logs ) : duration = timeit . default_timer ( ) - self . train_start print ( ' done , took { : . 3f} seconds ' . format ( duration ) ) ": 4162,
 "def postprocessor ( prediction ) : prediction = prediction . data . numpy ( ) [0] top_predictions = prediction . argsort ( ) [-3 : ][ : : -1] return [labels[prediction] for prediction in top_predictions]": 4163,
 "def stop ( self ) : if self . _progressing : self . _progressing = False self . _thread . join ( ) ": 4164,
 "def size_on_disk ( self ) : return int ( self . connection . query ( \" \" \" SELECT SUM ( data_length + index_length ) FROM information_schema . tables WHERE table_schema = ' {db} ' \" \" \" . format ( db = self . database ) ) . fetchone ( ) [0] ) ": 4165,
 "def stop ( self ) : if self . isPlaying is True : self . _execute ( \" stop \" ) self . _changePlayingState ( False ) ": 4166,
 "def yvals ( self ) : return [ val[1] for serie in self . series for val in serie . values if val[1] is not None ]": 4167,
 "def list_all ( dev : Device ) : for name , service in dev . services . items ( ) : click . echo ( click . style ( \" \\nService %s \" % name , bold = True ) ) for method in service . methods : click . echo ( \" %s \" % method . name ) ": 4168,
 "def yesno ( prompt ) : prompt + = \" [y/n] \" a = \" \" while a not in [ \" y \" , \" n \" ] : a = input ( prompt ) . lower ( ) return a = = \" y \" ": 4169,
 "def get_power ( self ) : power = ( yield from self . handle_int ( self . API . get ( ' power ' ) ) ) return bool ( power ) ": 4170,
 "def datetime_to_year_quarter ( dt ) : year = dt . year quarter = int ( math . ceil ( float ( dt . month ) /3 ) ) return ( year , quarter ) ": 4171,
 "def find_last_sublist ( list_ , sublist ) : for i in reversed ( range ( len ( list_ ) - len ( sublist ) + 1 ) ) : if list_[i] = = sublist[0] and list_[i : i + len ( sublist ) ] = = sublist : return i return None": 4172,
 "def readline ( file , skip_blank = False ) : while 1 : line = file . readline ( ) # print \" every line : %r \" % line if not line : return None if line[0] ! = ' # ' and not ( skip_blank and line . isspace ( ) ) : return line": 4173,
 "def getWindowPID ( self , hwnd ) : pid = ctypes . c_ulong ( ) ctypes . windll . user32 . GetWindowThreadProcessId ( hwnd , ctypes . byref ( pid ) ) return int ( pid . value ) ": 4174,
 "def predecessors ( self , node , graph = None ) : if graph is None : graph = self . graph return [key for key in graph if node in graph[key]]": 4175,
 "def _index_range ( self , version , symbol , from_version = None , **kwargs ) : from_index = None if from_version : from_index = from_version[ ' up_to ' ] return from_index , None": 4176,
 "def upload_file ( token , channel_name , file_name ) : slack = Slacker ( token ) slack . files . upload ( file_name , channels = channel_name ) ": 4177,
 "def loads ( cls , s ) : with closing ( StringIO ( s ) ) as fileobj : return cls . load ( fileobj ) ": 4178,
 "def _module_name_from_previous_frame ( num_frames_back ) : frm = inspect . stack ( ) [num_frames_back + 1] return inspect . getmodule ( frm[0] ) . __name__": 4179,
 "def _multilingual ( function , *args , **kwargs ) : return getattr ( _module ( kwargs . pop ( \" language \" , \" en \" ) ) , function ) ( *args , **kwargs ) ": 4180,
 "def infer_dtype_from ( val , pandas_dtype = False ) : if is_scalar ( val ) : return infer_dtype_from_scalar ( val , pandas_dtype = pandas_dtype ) return infer_dtype_from_array ( val , pandas_dtype = pandas_dtype ) ": 4181,
 "def allele_clusters ( dists , t = 0 . 025 ) : clusters = fcluster ( linkage ( dists ) , 0 . 025 , criterion = ' distance ' ) cluster_idx = defaultdict ( list ) for idx , cl in enumerate ( clusters ) : cluster_idx[cl] . append ( idx ) return cluster_idx": 4182,
 "def nearest_intersection_idx ( a , b ) : # Difference in the two y-value sets difference = a - b # Determine the point just before the intersection of the lines # Will return multiple points for multiple intersections sign_change_idx , = np . nonzero ( np . diff ( np . sign ( difference ) ) ) return sign_change_idx": 4183,
 "def isPackage ( file_path ) : return ( os . path . isdir ( file_path ) and os . path . isfile ( os . path . join ( file_path , ' __init__ . py ' ) ) ) ": 4184,
 "def __sub__ ( self , other ) : \t\t\t\treturn self . __class__ ( [elem for elem in self if elem not in other] ) ": 4185,
 "def add_ul ( text , ul ) : text + = \" \\n \" for li in ul : text + = \" - \" + li + \" \\n \" text + = \" \\n \" return text": 4186,
 "def load ( file_object ) : marshaller = JavaObjectUnmarshaller ( file_object ) marshaller . add_transformer ( DefaultObjectTransformer ( ) ) return marshaller . readObject ( ) ": 4187,
 "def json_get_data ( filename ) : with open ( filename ) as fp : json_data = json . load ( fp ) return json_data return False": 4188,
 "def respond_redirect ( self , location = ' / ' ) : \t\t\t\tself . send_response ( 301 ) \t\tself . send_header ( ' Content-Length ' , 0 ) \t\tself . send_header ( ' Location ' , location ) \t\tself . end_headers ( ) \t\treturn": 4189,
 "def param ( self , param , kwargs , default_value = False ) : if param in kwargs : value = kwargs[param] del kwargs[param] else : value = default_value setattr ( self , param , value ) ": 4190,
 "def prefix_list ( self , prefix , values ) : return list ( map ( lambda value : prefix + \" \" + value , values ) ) ": 4191,
 "def put ( self , entity ) : actual_entity = _normalize_entity ( entity ) if actual_entity is None : return self . ndb_put ( entity ) self . puts . append ( actual_entity ) ": 4192,
 "def _elapsed ( self ) : self . last_time = time . time ( ) return self . last_time - self . start": 4193,
 "def limitReal ( x , max_denominator = 1000000 ) : f = Fraction ( x ) . limit_denominator ( max_denominator ) return Real ( ( f . numerator , f . denominator ) ) ": 4194,
 "def to_bipartite_matrix ( A ) : m , n = A . shape return four_blocks ( zeros ( m , m ) , A , A . T , zeros ( n , n ) ) ": 4195,
 "def vsh ( cmd , *args , **kw ) : args = ' \" \" ' . join ( i . replace ( ' \" ' , r ' \\ \" ' ) for i in args ) easy . sh ( ' \" %s \" \" %s \" ' % ( venv_bin ( cmd ) , args ) ) ": 4196,
 "def str_to_num ( str_value ) : str_value = str ( str_value ) try : return int ( str_value ) except ValueError : return float ( str_value ) ": 4197,
 "def _maybe_cast_to_float64 ( da ) : if da . dtype = = np . float32 : logging . warning ( ' Datapoints were stored using the np . float32 datatype . ' ' For accurate reduction operations using bottleneck , ' ' datapoints are being cast to the np . float64 datatype . ' ' For more information see : https : //github . com/pydata/ ' ' xarray/issues/1346 ' ) return da . astype ( np . float64 ) else : return da": 4198,
 "def dict_self ( self ) : return {k : v for k , v in self . __dict__ . items ( ) if k in FSM_ATTRS}": 4199,
 "def closeEvent ( self , event ) : logger . debug ( \" closeEvent \" ) self . argosApplication . saveSettingsIfNeeded ( ) self . finalize ( ) self . argosApplication . removeMainWindow ( self ) event . accept ( ) logger . debug ( \" closeEvent accepted \" ) ": 4200,
 "def get_tree_type ( tree ) : tree_type = tree . label ( ) assert tree_type in SUBTREE_TYPES , \" tree_type : {} \" . format ( tree_type ) return tree_type": 4201,
 "def from_json ( s ) : d = json . loads ( s ) sbp = SBP . from_json_dict ( d ) return sbp": 4202,
 "def set_interface ( interface , name = ' ' ) : global interfaces if not interface : raise ValueError ( ' interface is empty ' ) # close down the interface before we discard it if name in interfaces : interfaces[name] . close ( ) interfaces[name] = interface": 4203,
 "def _varargs_to_iterable_method ( func ) : def wrapped ( self , iterable , **kwargs ) : return func ( self , *iterable , **kwargs ) return wrapped": 4204,
 "def _iterPoints ( self , **kwargs ) : points = self . points count = len ( points ) index = 0 while count : yield points[index] count - = 1 index + = 1": 4205,
 "def random_filename ( path = None ) : filename = uuid4 ( ) . hex if path is not None : filename = os . path . join ( path , filename ) return filename": 4206,
 "def _begins_with_one_of ( sentence , parts_of_speech ) : doc = nlp ( sentence ) if doc[0] . tag_ in parts_of_speech : return True return False": 4207,
 "def is_element_present ( self , strategy , locator ) : return self . driver_adapter . is_element_present ( strategy , locator , root = self . root ) ": 4208,
 "def OnDoubleClick ( self , event ) : node = HotMapNavigator . findNodeAtPosition ( self . hot_map , event . GetPosition ( ) ) if node : wx . PostEvent ( self , SquareActivationEvent ( node = node , point = event . GetPosition ( ) , map = self ) ) ": 4209,
 "def asMaskedArray ( self ) : return ma . masked_array ( data = self . data , mask = self . mask , fill_value = self . fill_value ) ": 4210,
 "def _is_readable ( self , obj ) : try : read = getattr ( obj , ' read ' ) except AttributeError : return False else : return is_method ( read , max_arity = 1 ) ": 4211,
 "def _axes ( self ) : self . view . _force_vertical = True super ( HorizontalGraph , self ) . _axes ( ) self . view . _force_vertical = False": 4212,
 "def load_library ( version ) : check_version ( version ) module_name = SUPPORTED_LIBRARIES[version] lib = sys . modules . get ( module_name ) if lib is None : lib = importlib . import_module ( module_name ) return lib": 4213,
 "def remove ( self , entry ) : try : list = self . cache[entry . key] list . remove ( entry ) except : pass": 4214,
 "def max_values ( args ) : return Interval ( max ( x . low for x in args ) , max ( x . high for x in args ) ) ": 4215,
 "def stoplog ( self ) : if self . _file_logger : self . logger . removeHandler ( _file_logger ) self . _file_logger = None return 1": 4216,
 "def close_all ( ) : r # Windows can be closed by releasing all references to them so they can be # garbage collected . May not be necessary to call close ( ) . global _qtg_windows for window in _qtg_windows : window . close ( ) _qtg_windows = [] global _qtg_widgets for widget in _qtg_widgets : widget . close ( ) _qtg_widgets = [] global _plt_figures for fig in _plt_figures : _ , plt , _ = _import_plt ( ) plt . close ( fig ) _plt_figures = []": 4217,
 "def __setitem__ ( self , _ignored , return_value ) : self . mock . return_value = return_value self . mock . side_effect = None": 4218,
 "def close ( self ) : if self . pyb and self . pyb . serial : self . pyb . serial . close ( ) self . pyb = None": 4219,
 "def assert_called ( _mock_self ) : self = _mock_self if self . call_count = = 0 : msg = ( \" Expected ' %s ' to have been called . \" % self . _mock_name or ' mock ' ) raise AssertionError ( msg ) ": 4220,
 "def _construct_from_json ( self , rec ) : self . delete ( ) for required_key in [ ' dagobah_id ' , ' created_jobs ' ] : setattr ( self , required_key , rec[required_key] ) for job_json in rec . get ( ' jobs ' , [] ) : self . _add_job_from_spec ( job_json ) self . commit ( cascade = True ) ": 4221,
 "def benchmark ( store , n = 10000 ) : R = Referrer for referred in store . query ( Referred ) : for _reference in store . query ( R , R . reference = = referred ) : pass": 4222,
 "def beautify ( string , *args , **kwargs ) : \t\tparser = Parser ( args , kwargs ) \treturn parser . beautify ( string ) ": 4223,
 "def combine ( self , a , b ) : for l in ( a , b ) : for x in l : yield x": 4224,
 "def zoom_out ( self ) : index = self . _zoom_factors . index ( self . _zoom_factor ) if index = = 0 : # Already zoomed out all the way return self . _zoom_factor = self . _zoom_factors[index - 1] if self . _zoom_factors . index ( self . _zoom_factor ) = = 0 : self . _button_zoom_out . config ( state = tk . DISABLED ) self . _button_zoom_in . config ( state = tk . NORMAL ) self . draw_timeline ( ) ": 4225,
 "def initialize_worker ( self , process_num = None ) : self . initialize ( self . grid , self . num_of_paths , self . seed ) ": 4226,
 "def _unique_id ( self , prefix ) : _id = self . _id_gen self . _id_gen + = 1 return prefix + str ( _id ) ": 4227,
 "def _cell ( x ) : x_no_none = [i if i is not None else \" \" for i in x] return array ( x_no_none , dtype = np_object ) ": 4228,
 "def tick ( self ) : self . current + = 1 if self . current = = self . factor : sys . stdout . write ( ' + ' ) sys . stdout . flush ( ) self . current = 0": 4229,
 "def last_item ( array ) : if array . size = = 0 : # work around for https : //github . com/numpy/numpy/issues/5195 return [] indexer = ( slice ( -1 , None ) , ) * array . ndim return np . ravel ( array[indexer] ) . tolist ( ) ": 4230,
 "def remove_last_line ( self ) : editor = self . _editor text_cursor = editor . textCursor ( ) text_cursor . movePosition ( text_cursor . End , text_cursor . MoveAnchor ) text_cursor . select ( text_cursor . LineUnderCursor ) text_cursor . removeSelectedText ( ) text_cursor . deletePreviousChar ( ) editor . setTextCursor ( text_cursor ) ": 4231,
 "def on_mouse_motion ( self , x , y , dx , dy ) : # Screen coordinates relative to the lower-left corner # so we have to flip the y axis to make this consistent with # other window libraries self . example . mouse_position_event ( x , self . buffer_height - y ) ": 4232,
 "def ComplementEquivalence ( *args , **kwargs ) : return ast . Complement ( ast . Equivalence ( *args , **kwargs ) , **kwargs ) ": 4233,
 "def fit_gaussian ( samples , ddof = 0 ) : if len ( samples . shape ) = = 1 : return np . mean ( samples ) , np . std ( samples , ddof = ddof ) return np . mean ( samples , axis = 1 ) , np . std ( samples , axis = 1 , ddof = ddof ) ": 4234,
 "def get_dates_link ( url ) : urllib . request . urlretrieve ( url , \" temp . txt \" ) dates = get_dates_file ( \" temp . txt \" ) os . remove ( \" temp . txt \" ) return dates": 4235,
 "def sorted_product_set ( array_a , array_b ) : return np . sort ( np . concatenate ( [array_a[i] * array_b for i in xrange ( len ( array_a ) ) ] , axis = 0 ) ) [ : : -1]": 4236,
 "def _tostr ( self , obj ) : if not obj : return ' ' if isinstance ( obj , list ) : return ' , ' . join ( map ( self . _tostr , obj ) ) return str ( obj ) ": 4237,
 "def clear_instance ( cls ) : if not cls . initialized ( ) : return for subclass in cls . _walk_mro ( ) : if isinstance ( subclass . _instance , cls ) : # only clear instances that are instances # of the calling class subclass . _instance = None": 4238,
 "def iterlists ( self ) : for key , values in dict . iteritems ( self ) : yield key , list ( values ) ": 4239,
 "def delete_connection ( ) : if _CON_SYM_ in globals ( ) : con = globals ( ) . pop ( _CON_SYM_ ) if not getattr ( con , ' _session ' ) . start ( ) : con . stop ( ) ": 4240,
 "def PopAttributeContainer ( self ) : try : serialized_data = self . _list . pop ( 0 ) self . data_size - = len ( serialized_data ) return serialized_data except IndexError : return None": 4241,
 "def _ignore_comments ( lines_enum ) : for line_number , line in lines_enum : line = COMMENT_RE . sub ( ' ' , line ) line = line . strip ( ) if line : yield line_number , line": 4242,
 "def delete ( self ) : self . _client . remove_object ( self . _instance , self . _bucket , self . name ) ": 4243,
 "def rpc_fix_code_with_black ( self , source , directory ) : source = get_source ( source ) return fix_code_with_black ( source , directory ) ": 4244,
 "def cursor_up ( self , count = 1 ) : original_column = self . preferred_column or self . document . cursor_position_col self . cursor_position + = self . document . get_cursor_up_position ( count = count , preferred_column = original_column ) # Remember the original column for the next up/down movement . self . preferred_column = original_column": 4245,
 "def _get_pattern ( self , pys_style ) : # Return None if there is no bgcolor if \" bgcolor \" not in pys_style : return pattern = xlwt . Pattern ( ) pattern . pattern = xlwt . Pattern . SOLID_PATTERN bgcolor = wx . Colour ( ) bgcolor . SetRGB ( pys_style[ \" bgcolor \" ] ) pattern . pattern_fore_colour = self . color2idx ( *bgcolor . Get ( ) ) return pattern": 4246,
 "def impad_to_multiple ( img , divisor , pad_val = 0 ) : pad_h = int ( np . ceil ( img . shape[0] / divisor ) ) * divisor pad_w = int ( np . ceil ( img . shape[1] / divisor ) ) * divisor return impad ( img , ( pad_h , pad_w ) , pad_val ) ": 4247,
 "def generate_nonce ( ) : nonce = ' ' . join ( [str ( randint ( 0 , 9 ) ) for i in range ( 8 ) ] ) return HMAC ( nonce . encode ( ) , \" secret \" . encode ( ) , sha1 ) . hexdigest ( ) ": 4248,
 "def rfc3339_to_datetime ( data ) : try : ts = time . strptime ( data , ' %Y-%m-%d ' ) return date ( *ts[ : 3] ) except ValueError : pass try : dt , _ , tz = data . partition ( ' Z ' ) if tz : tz = offset ( tz ) else : tz = offset ( ' 00 : 00 ' ) if ' . ' in dt and dt . rsplit ( ' . ' , 1 ) [-1] . isdigit ( ) : ts = time . strptime ( dt , ' %Y-%m-%dT%H : %M : %S . %f ' ) else : ts = time . strptime ( dt , ' %Y-%m-%dT%H : %M : %S ' ) return datetime ( *ts[ : 6] , tzinfo = tz ) except ValueError : raise ValueError ( ' date-time {!r} is not a valid rfc3339 date representation ' . format ( data ) ) ": 4249,
 "def get_first_lang ( ) : request_lang = request . headers . get ( ' Accept-Language ' ) . split ( ' , ' ) if request_lang : lang = locale . normalize ( request_lang[0] ) . split ( ' . ' ) [0] else : lang = False return lang": 4250,
 "def from_pystr_to_cstr ( data ) : if not isinstance ( data , list ) : raise NotImplementedError pointers = ( ctypes . c_char_p * len ( data ) ) ( ) if PY3 : data = [bytes ( d , ' utf-8 ' ) for d in data] else : data = [d . encode ( ' utf-8 ' ) if isinstance ( d , unicode ) else d # pylint : disable = undefined-variable for d in data] pointers[ : ] = data return pointers": 4251,
 "def document ( schema ) : teleport_schema = from_val ( schema ) return json . dumps ( teleport_schema , sort_keys = True , indent = 2 ) ": 4252,
 "def on_stop ( self ) : LOGGER . debug ( \" zeromq . Publisher . on_stop \" ) self . zmqsocket . close ( ) self . zmqcontext . destroy ( ) ": 4253,
 "def accuracy ( self ) : true_pos = self . matrix[0][0] false_pos = self . matrix[1][0] false_neg = self . matrix[0][1] true_neg = self . matrix[1][1] num = 1 . 0 * ( true_pos + true_neg ) den = true_pos + true_neg + false_pos + false_neg return divide ( num , den ) ": 4254,
 "def git_tag ( tag ) : print ( ' Tagging \" {} \" ' . format ( tag ) ) msg = ' \" Released version {} \" ' . format ( tag ) Popen ( [ ' git ' , ' tag ' , ' -s ' , ' -m ' , msg , tag] ) . wait ( ) ": 4255,
 "def get_from_headers ( request , key ) : value = request . headers . get ( key ) return to_native ( value ) ": 4256,
 "def move_page_bottom ( self ) : self . nav . page_index = self . content . range[1] self . nav . cursor_index = 0 self . nav . inverted = True": 4257,
 "def print_runs ( query ) : if query is None : return for tup in query : print ( ( \" {0} @ {1} - {2} id : {3} group : {4} \" . format ( tup . end , tup . experiment_name , tup . project_name , tup . experiment_group , tup . run_group ) ) ) ": 4258,
 "def wait_for_url ( url , timeout = DEFAULT_TIMEOUT ) : service = ServiceURL ( url , timeout ) return service . wait ( ) ": 4259,
 "def print_float ( self , value , decimal_digits = 2 , justify_right = True ) : format_string = ' {{0 : 0 . {0}F}} ' . format ( decimal_digits ) self . print_number_str ( format_string . format ( value ) , justify_right ) ": 4260,
 "def _stream_docker_logs ( self ) : thread = threading . Thread ( target = self . _stderr_stream_worker ) thread . start ( ) for line in self . docker_client . logs ( self . container , stdout = True , stderr = False , stream = True ) : sys . stdout . write ( line ) thread . join ( ) ": 4261,
 "def detect ( filename , include_confidence = False ) : f = open ( filename ) detection = chardet . detect ( f . read ( ) ) f . close ( ) encoding = detection . get ( ' encoding ' ) confidence = detection . get ( ' confidence ' ) if include_confidence : return ( encoding , confidence ) return encoding": 4262,
 "def define_macro ( self , name , themacro ) : from IPython . core import macro if isinstance ( themacro , basestring ) : themacro = macro . Macro ( themacro ) if not isinstance ( themacro , macro . Macro ) : raise ValueError ( ' A macro must be a string or a Macro instance . ' ) self . user_ns[name] = themacro": 4263,
 "def lazy_property ( function ) : cached_val = [] def _wrapper ( *args ) : try : return cached_val[0] except IndexError : ret_val = function ( *args ) cached_val . append ( ret_val ) return ret_val return _wrapper": 4264,
 "def load ( filename ) : path , name = os . path . split ( filename ) path = path or ' . ' with util . indir ( path ) : return pickle . load ( open ( name , ' rb ' ) ) ": 4265,
 "def indent ( self , message ) : indent = self . indent_char * self . indent_size return indent + message": 4266,
 "def insert_one ( self , mongo_collection , doc , mongo_db = None , **kwargs ) : collection = self . get_collection ( mongo_collection , mongo_db = mongo_db ) return collection . insert_one ( doc , **kwargs ) ": 4267,
 "def assert_called_once ( _mock_self ) : self = _mock_self if not self . call_count = = 1 : msg = ( \" Expected ' %s ' to have been called once . Called %s times . \" % ( self . _mock_name or ' mock ' , self . call_count ) ) raise AssertionError ( msg ) ": 4268,
 "def unique_inverse ( item_list ) : import utool as ut unique_items = ut . unique ( item_list ) inverse = list_alignment ( unique_items , item_list ) return unique_items , inverse": 4269,
 "def generate_random_string ( chars = 7 ) : return u \" \" . join ( random . sample ( string . ascii_letters * 2 + string . digits , chars ) ) ": 4270,
 "def paginate ( self , request , offset = 0 , limit = None ) : return self . collection . offset ( offset ) . limit ( limit ) , self . collection . count ( ) ": 4271,
 "def _generate_plane ( normal , origin ) : plane = vtk . vtkPlane ( ) plane . SetNormal ( normal[0] , normal[1] , normal[2] ) plane . SetOrigin ( origin[0] , origin[1] , origin[2] ) return plane": 4272,
 "def run ( self , forever = True ) : loop = self . create_connection ( ) self . add_signal_handlers ( ) if forever : loop . run_forever ( ) ": 4273,
 "def compute_depth ( self ) : left_depth = self . left_node . compute_depth ( ) if self . left_node else 0 right_depth = self . right_node . compute_depth ( ) if self . right_node else 0 return 1 + max ( left_depth , right_depth ) ": 4274,
 "def convert_to_yaml ( name , value , indentation , indexOfColon , show_multi_line_character ) : strings = [] if isinstance ( value , list ) : # special case for single item lists : if len ( value ) = = 1 \\ and isinstance ( value[0] , str ) : # value = [ \" string \" ] should not be converted to # name : # - string # but to \" name : string \" instead value = value[0] elif len ( value ) = = 1 \\ and isinstance ( value[0] , list ) \\ and len ( value[0] ) = = 1 \\ and isinstance ( value[0][0] , str ) : # same applies to value = [[ \" string \" ]] value = value[0][0] if isinstance ( value , str ) : strings . append ( \" %s%s%s : %s \" % ( ' ' * indentation , name , ' ' * ( indexOfColon-len ( name ) ) , indent_multiline_string ( value , indentation+4 , show_multi_line_character ) ) ) elif isinstance ( value , list ) : strings . append ( \" %s%s%s : \" % ( ' ' * indentation , name , ' ' * ( indexOfColon-len ( name ) ) ) ) for outer in value : # special case for single item sublists if isinstance ( outer , list ) \\ and len ( outer ) = = 1 \\ and isinstance ( outer[0] , str ) : # outer = [ \" string \" ] should not be converted to # - # - string # but to \" - string \" instead outer = outer[0] if isinstance ( outer , str ) : strings . append ( \" %s- %s \" % ( ' ' * ( indentation+4 ) , indent_multiline_string ( outer , indentation+8 , show_multi_line_character ) ) ) elif isinstance ( outer , list ) : strings . append ( \" %s- \" % ( ' ' * ( indentation+4 ) ) ) for inner in outer : if isinstance ( inner , str ) : strings . append ( \" %s- %s \" % ( ' ' * ( indentation+8 ) , indent_multiline_string ( inner , indentation+12 , show_multi_line_character ) ) ) return strings": 4275,
 "def __exit__ ( self , *args ) : sys . stdout = self . _orig self . _devnull . close ( ) ": 4276,
 "def _internal_kv_get ( key ) : worker = ray . worker . get_global_worker ( ) if worker . mode = = ray . worker . LOCAL_MODE : return _local . get ( key ) return worker . redis_client . hget ( key , \" value \" ) ": 4277,
 "def rpop ( self , key ) : redis_list = self . _get_list ( key , ' RPOP ' ) if self . _encode ( key ) not in self . redis : return None try : value = redis_list . pop ( ) if len ( redis_list ) = = 0 : self . delete ( key ) return value except ( IndexError ) : # Redis returns nil if popping from an empty list return None": 4278,
 "def exists ( self ) : r = self . _client . _redis flag = ' {} : flag ' . format ( self . _queue ) return bool ( r . exists ( flag ) ) ": 4279,
 "def disable ( self ) : if not self . _expert : self . config ( state = ' disable ' ) self . _active = False": 4280,
 "def _cached_search_compile ( pattern , re_verbose , re_version , pattern_type ) : return _bregex_parse . _SearchParser ( pattern , re_verbose , re_version ) . parse ( ) ": 4281,
 "def parse_path ( path ) : version , project = path[1 : ] . split ( ' / ' ) return dict ( version = int ( version ) , project = project ) ": 4282,
 "def abfIDfromFname ( fname ) : fname = os . path . abspath ( fname ) basename = os . path . basename ( fname ) return os . path . splitext ( basename ) [0]": 4283,
 "def cleanwrap ( func ) : def enc ( self , *args , **kwargs ) : \" \" \" Send each item to _cleanup ( ) \" \" \" return ( func ( self , item , **kwargs ) for item in args ) return enc": 4284,
 "def remove_from_lib ( self , name ) : self . __remove_path ( os . path . join ( self . root_dir , \" lib \" , name ) ) ": 4285,
 "def _gzip ( self , response ) : bytesio = six . BytesIO ( ) with gzip . GzipFile ( fileobj = bytesio , mode = ' w ' ) as gz : gz . write ( response ) return bytesio . getvalue ( ) ": 4286,
 "def replace_tab_indent ( s , replace = \" \" ) : prefix = get_indent_prefix ( s ) return prefix . replace ( \" \\t \" , replace ) + s[len ( prefix ) : ]": 4287,
 "def stringToDate ( fmt = \" %Y-%m-%d \" ) : import time import datetime def conv_func ( s ) : return datetime . date ( *time . strptime ( s , fmt ) [ : 3] ) return conv_func": 4288,
 "def set_basic_auth ( self , username , password ) : from requests . auth import HTTPBasicAuth self . auth = HTTPBasicAuth ( username , password ) return self": 4289,
 "def localeselector ( ) : # if a user is logged in , use the locale from the user settings user = getattr ( g , \" user \" , None ) if user is not None : locale = getattr ( user , \" locale \" , None ) if locale : return locale # Otherwise , try to guess the language from the user accept header the browser # transmits . By default we support en/fr . The best match wins . return request . accept_languages . best_match ( current_app . config[ \" BABEL_ACCEPT_LANGUAGES \" ] ) ": 4290,
 "def xml ( cls , res , *args , **kwargs ) : return parse_xml ( res . text , *args , **kwargs ) ": 4291,
 "def load_from_file ( cls , filename_prefix ) : filename = cls . _filename ( filename_prefix ) lines , _ = cls . _read_lines_from_file ( filename ) # Strip wrapping single quotes vocab_list = [line[1 : -1] for line in lines] return cls ( vocab_list = vocab_list ) ": 4292,
 "def request ( method , url , **kwargs ) : retries = kwargs . pop ( ' retries ' , None ) with Session ( retries = retries ) as session : return session . request ( method = method , url = url , **kwargs ) ": 4293,
 "def make_file_readable ( filename ) : if not os . path . islink ( filename ) : util . set_mode ( filename , stat . S_IRUSR ) ": 4294,
 "def handle_errors ( resp ) : if resp . status_code = = 400 : raise ApiException ( json . loads ( resp . content ) . get ( ' message ' ) ) return resp": 4295,
 "async def handle ( self , record ) : if ( not self . disabled ) and self . filter ( record ) : await self . callHandlers ( record ) ": 4296,
 "def __print_table ( table ) : col_width = [max ( len ( x ) for x in col ) for col in zip ( *table ) ] print ( \" | \" + \" | \" . join ( \" { : {}} \" . format ( x , col_width[i] ) for i , x in enumerate ( table[0] ) ) + \" | \" ) print ( \" | \" + \" | \" . join ( \" { : {}} \" . format ( ' - ' * col_width[i] , col_width[i] ) for i , x in enumerate ( table[0] ) ) + \" | \" ) for line in table[1 : ] : print ( \" | \" + \" | \" . join ( \" { : {}} \" . format ( x , col_width[i] ) for i , x in enumerate ( line ) ) + \" | \" ) ": 4297,
 "def print_failure_message ( message ) : try : import colorama print ( colorama . Fore . RED + message + colorama . Fore . RESET , file = sys . stderr ) except ImportError : print ( message , file = sys . stderr ) ": 4298,
 "def generate_yaml_file ( filename , contents ) : with open ( filename , ' w ' ) as file : file . write ( yaml . dump ( contents , default_flow_style = False ) ) ": 4299,
 "def get_pull_request ( project , num , auth = False ) : url = \" https : //api . github . com/repos/{project}/pulls/{num} \" . format ( project = project , num = num ) if auth : header = make_auth_header ( ) else : header = None response = requests . get ( url , headers = header ) response . raise_for_status ( ) return json . loads ( response . text , object_hook = Obj ) ": 4300,
 "def list_blobs ( self , prefix = ' ' ) : return [b . name for b in self . bucket . list_blobs ( prefix = prefix ) ]": 4301,
 "def generate_id ( self , obj ) : object_type = type ( obj ) . __name__ . lower ( ) return ' {}_{} ' . format ( object_type , self . get_object_id ( obj ) ) ": 4302,
 "def lengths_offsets ( value ) : values = [] for item in value . split ( ' , ' ) : item = int ( item ) values . append ( item ) return values": 4303,
 "def delete_s3_bucket ( client , resource ) : if dbconfig . get ( ' enable_delete_s3_buckets ' , NS_AUDITOR_REQUIRED_TAGS , False ) : client . delete_bucket ( Bucket = resource . id ) return ActionStatus . SUCCEED , resource . metrics ( ) ": 4304,
 "def escape_link ( url ) : lower_url = url . lower ( ) . strip ( ' \\x00\\x1a \\n\\r\\t ' ) for scheme in _scheme_blacklist : if lower_url . startswith ( scheme ) : return ' ' return escape ( url , quote = True , smart_amp = False ) ": 4305,
 "async def send_files_preconf ( filepaths , config_path = CONFIG_PATH ) : config = read_config ( config_path ) subject = \" PDF files from pdfebc \" message = \" \" await send_with_attachments ( subject , message , filepaths , config ) ": 4306,
 "def remove_item ( self , item ) : self . unindex_item ( item ) self . items . pop ( item . uuid , None ) ": 4307,
 "def _replace ( self , data , replacements ) : for find , repl in replacements : data = data . replace ( find , repl ) return data": 4308,
 "def reset ( self ) : self . _hline_string = None self . _row_size = None self . _header = [] self . _rows = []": 4309,
 "def get_serializable_data_for_fields ( model ) : pk_field = model . _meta . pk # If model is a child via multitable inheritance , use parent ' s pk while pk_field . remote_field and pk_field . remote_field . parent_link : pk_field = pk_field . remote_field . model . _meta . pk obj = { ' pk ' : get_field_value ( pk_field , model ) } for field in model . _meta . fields : if field . serialize : obj[field . name] = get_field_value ( field , model ) return obj": 4310,
 "def RemoveMethod ( self , function ) : self . added_methods = [dm for dm in self . added_methods if not dm . method is function]": 4311,
 "def copy_default_data_file ( filename , module = None ) : if module is None : module = __get_filetypes_module ( ) fullpath = get_default_data_path ( filename , module = module ) shutil . copy ( fullpath , \" . \" ) ": 4312,
 "def set_logging_config ( log_level , handlers ) : logging . basicConfig ( format = ' % ( asctime ) s % ( levelname ) s : % ( name ) s : % ( funcName ) s : % ( message ) s ' , datefmt = ' %Y-%m-%d %H : %M : %S ' , level = log_level , handlers = handlers ) ": 4313,
 "def get_local_image ( self , src ) : return ImageUtils . store_image ( self . fetcher , self . article . link_hash , src , self . config ) ": 4314,
 "def round_data ( filter_data ) : for index , _ in enumerate ( filter_data ) : filter_data[index][0] = round ( filter_data[index][0] / 100 . 0 ) * 100 . 0 return filter_data": 4315,
 "def image_load_time ( self ) : load_times = self . get_load_times ( ' image ' ) return round ( mean ( load_times ) , self . decimal_precision ) ": 4316,
 "def update_token_tempfile ( token ) : with open ( tmp , ' w ' ) as f : f . write ( json . dumps ( token , indent = 4 ) ) ": 4317,
 "def write_wave ( path , audio , sample_rate ) : with contextlib . closing ( wave . open ( path , ' wb ' ) ) as wf : wf . setnchannels ( 1 ) wf . setsampwidth ( 2 ) wf . setframerate ( sample_rate ) wf . writeframes ( audio ) ": 4318,
 "def singleton_per_scope ( _cls , _scope = None , _renew = False , *args , **kwargs ) : result = None singletons = SINGLETONS_PER_SCOPES . setdefault ( _scope , {} ) if _renew or _cls not in singletons : singletons[_cls] = _cls ( *args , **kwargs ) result = singletons[_cls] return result": 4319,
 "def functions ( self ) : return [v for v in self . globals . values ( ) if isinstance ( v , values . Function ) ]": 4320,
 "def all_versions ( req ) : import requests url = \" https : //pypi . python . org/pypi/ \" + req + \" /json \" return tuple ( requests . get ( url ) . json ( ) [ \" releases \" ] . keys ( ) ) ": 4321,
 "def shutdown ( self ) : if self . sock : self . sock . close ( ) self . sock = None self . connected = False": 4322,
 "def sortlevel ( self , level = None , ascending = True , sort_remaining = None ) : return self . sort_values ( return_indexer = True , ascending = ascending ) ": 4323,
 "def set_default ( self_ , param_name , value ) : cls = self_ . cls setattr ( cls , param_name , value ) ": 4324,
 "def _write_separator ( self ) : tmp = self . _page_width - ( ( 4 * self . __indent_level ) + 2 ) self . _write_line ( ' # ' + ( ' - ' * tmp ) ) ": 4325,
 "def run_test ( func , fobj ) : gc . disable ( ) try : begin = time . time ( ) func ( fobj ) end = time . time ( ) finally : gc . enable ( ) return end - begin": 4326,
 "def set_ylim ( self , xlims , dx , xscale , reverse = False ) : self . _set_axis_limits ( ' y ' , xlims , dx , xscale , reverse ) return": 4327,
 "def compile ( expr , params = None ) : from ibis . sql . alchemy import to_sqlalchemy return to_sqlalchemy ( expr , dialect . make_context ( params = params ) ) ": 4328,
 "def set_left_to_right ( self ) : self . displaymode | = LCD_ENTRYLEFT self . write8 ( LCD_ENTRYMODESET | self . displaymode ) ": 4329,
 "def print_error ( msg ) : if IS_POSIX : print ( u \" %s[ERRO] %s%s \" % ( ANSI_ERROR , msg , ANSI_END ) ) else : print ( u \" [ERRO] %s \" % ( msg ) ) ": 4330,
 "def progressbar ( total , pos , msg = \" \" ) : width = get_terminal_size ( ) [0] - 40 rel_pos = int ( float ( pos ) / total * width ) bar = ' ' . join ( [ \" = \" * rel_pos , \" . \" * ( width - rel_pos ) ] ) # Determine how many digits in total ( base 10 ) digits_total = len ( str ( total ) ) fmt_width = \" %0 \" + str ( digits_total ) + \" d \" fmt = \" \\r[ \" + fmt_width + \" / \" + fmt_width + \" ][%s] %s \" progress_stream . write ( fmt % ( pos , total , bar , msg ) ) ": 4331,
 "def info ( docgraph ) : print networkx . info ( docgraph ) , ' \\n ' node_statistics ( docgraph ) print edge_statistics ( docgraph ) ": 4332,
 "def stop_containers ( self ) : while len ( self . _containers ) : container = self . _containers . pop ( ) try : container . kill ( signal . SIGKILL ) except docker . errors . APIError : # probably doesn ' t exist anymore pass": 4333,
 "def natural_sort ( list , key = lambda s : s ) : def get_alphanum_key_func ( key ) : convert = lambda text : int ( text ) if text . isdigit ( ) else text return lambda s : [convert ( c ) for c in re . split ( ' ( [0-9]+ ) ' , key ( s ) ) ] sort_key = get_alphanum_key_func ( key ) list . sort ( key = sort_key ) ": 4334,
 "def get_distance ( F , x ) : n = x . shape[0] square = F . sum ( x ** 2 . 0 , axis = 1 , keepdims = True ) distance_square = square + square . transpose ( ) - ( 2 . 0 * F . dot ( x , x . transpose ( ) ) ) # Adding identity to make sqrt work . return F . sqrt ( distance_square + F . array ( np . identity ( n ) ) ) ": 4335,
 "def escapePathForShell ( path ) : \t\t\t\tif platform . system ( ) = = ' Windows ' : \t\t\treturn ' \" {} \" ' . format ( path . replace ( ' \" ' , ' \" \" ' ) ) \t\telse : \t\t\treturn shellescape . quote ( path ) ": 4336,
 "def chunks ( iterable , size = 1 ) : iterator = iter ( iterable ) for element in iterator : yield chain ( [element] , islice ( iterator , size - 1 ) ) ": 4337,
 "def normalize_array ( lst ) : np_arr = np . array ( lst ) x_normalized = np_arr / np_arr . max ( axis = 0 ) return list ( x_normalized ) ": 4338,
 "def pause ( msg = \" Press Enter to Continue . . . \" ) : print ( ' \\n ' + Fore . YELLOW + msg + Fore . RESET , end = ' ' ) input ( ) ": 4339,
 "def schunk ( string , size ) : return [string[i : i+size] for i in range ( 0 , len ( string ) , size ) ]": 4340,
 "def terminate ( self ) : if self . _pool is not None : self . _pool . terminate ( ) self . _pool . join ( ) self . _pool = None": 4341,
 "def stop ( self ) : if self . stream and self . stream . session . state ! = STATE_STOPPED : self . stream . stop ( ) ": 4342,
 "def get_memory ( self , mode ) : mem = { \" pre \" : self . _translator . get_memory_init ( ) , \" post \" : self . _translator . get_memory_curr ( ) , } return mem[mode]": 4343,
 "def make_slice_strings ( cls , slice_key ) : start = slice_key . start size = slice_key . stop - start return ( str ( start ) , str ( size ) ) ": 4344,
 "def is_callable_tag ( tag ) : return ( isinstance ( tag , six . string_types ) and tag . strip ( ) . startswith ( ' {{ ' ) and tag . strip ( ) . endswith ( ' }} ' ) ) ": 4345,
 "def get_example_features ( example ) : return ( example . features . feature if isinstance ( example , tf . train . Example ) else example . context . feature ) ": 4346,
 "def _safe_db ( num , den ) : if den = = 0 : return np . inf return 10 * np . log10 ( num / den ) ": 4347,
 "def transformer_tpu_1b ( ) : hparams = transformer_tpu ( ) hparams . hidden_size = 2048 hparams . filter_size = 8192 hparams . num_hidden_layers = 8 # smaller batch size to avoid OOM hparams . batch_size = 1024 hparams . activation_dtype = \" bfloat16 \" hparams . weight_dtype = \" bfloat16 \" # maximize number of parameters relative to computation by not sharing . hparams . shared_embedding_and_softmax_weights = False return hparams": 4348,
 "def _float_feature ( value ) : if not isinstance ( value , list ) : value = [value] return tf . train . Feature ( float_list = tf . train . FloatList ( value = value ) ) ": 4349,
 "def assert_valid_input ( cls , tag ) : # Fail on unexpected types . if not cls . is_tag ( tag ) : raise TypeError ( \" Expected a BeautifulSoup ' Tag ' , but instead recieved type {} \" . format ( type ( tag ) ) ) ": 4350,
 "def write_fits ( data , header , file_name ) : hdu = fits . PrimaryHDU ( data ) hdu . header = header hdulist = fits . HDUList ( [hdu] ) hdulist . writeto ( file_name , overwrite = True ) logging . info ( \" Wrote {0} \" . format ( file_name ) ) return": 4351,
 "def stop ( self ) : with self . lock : self . halting = True self . go . clear ( ) ": 4352,
 "def shutdown ( self ) : self . run_clean_thread = False self . cleanup ( True ) if self . cleaner_thread . isAlive ( ) : self . cleaner_thread . join ( ) ": 4353,
 "def delete ( self , id ) : if id in self . _images . keys ( ) : del self . _images[id] self . tk . delete ( id ) ": 4354,
 "def _format_title_string ( self , title_string ) : return self . _title_string_format_text_tag ( title_string . replace ( self . icy_tokkens[0] , self . icy_title_prefix ) ) ": 4355,
 "def call_on_if_def ( obj , attr_name , callable , default , *args , **kwargs ) : try : attr = getattr ( obj , attr_name ) except AttributeError : return default else : return callable ( attr , *args , **kwargs ) ": 4356,
 "def matching_line ( lines , keyword ) : for line in lines : matching = match ( line , keyword ) if matching ! = None : return matching return None": 4357,
 "def form_valid ( self , form ) : auth_login ( self . request , form . get_user ( ) ) return HttpResponseRedirect ( self . get_success_url ( ) ) ": 4358,
 "def str_traceback ( error , tb ) : if not isinstance ( tb , types . TracebackType ) : return tb return ' ' . join ( traceback . format_exception ( error . __class__ , error , tb ) ) ": 4359,
 "def stepBy ( self , steps ) : self . setValue ( self . value ( ) + steps*self . singleStep ( ) ) ": 4360,
 "def is_filelike ( ob ) : if hasattr ( ob , ' read ' ) and callable ( ob . read ) : return True if hasattr ( ob , ' write ' ) and callable ( ob . write ) : return True return False": 4361,
 "def simple_generate ( cls , create , **kwargs ) : strategy = enums . CREATE_STRATEGY if create else enums . BUILD_STRATEGY return cls . generate ( strategy , **kwargs ) ": 4362,
 "def __init__ ( self , scope , parent ) : CodeStatement . __init__ ( self , scope , parent ) self . body = CodeBlock ( scope , self , explicit = True ) self . catches = [] self . finally_body = CodeBlock ( scope , self , explicit = True ) ": 4363,
 "def fval ( self , instance ) : try : val = instance . __dict__[self . instance_field_name] except KeyError as e : # raise AttributeError ( str ( e ) ) val = None return val": 4364,
 "def __init__ ( self , name , flag , **kwargs ) : self . name = name self . flag = flag self . options = kwargs": 4365,
 "def _to_java_object_rdd ( rdd ) : rdd = rdd . _reserialize ( AutoBatchedSerializer ( PickleSerializer ( ) ) ) return rdd . ctx . _jvm . org . apache . spark . ml . python . MLSerDe . pythonToJava ( rdd . _jrdd , True ) ": 4366,
 "def run_func ( self , func_path , *func_args , **kwargs ) : if not self . started : raise ValueError ( ' Session not started , use start ( ) ' ) nargout = kwargs . pop ( ' nargout ' , 1 ) func_args + = tuple ( item for pair in zip ( kwargs . keys ( ) , kwargs . values ( ) ) for item in pair ) dname = os . path . dirname ( func_path ) fname = os . path . basename ( func_path ) func_name , ext = os . path . splitext ( fname ) if ext and not ext = = ' . m ' : raise TypeError ( ' Need to give path to . m file ' ) return self . _json_response ( cmd = ' eval ' , func_name = func_name , func_args = func_args or ' ' , dname = dname , nargout = nargout ) ": 4367,
 "def search_script_directory ( self , path ) : for subdir , dirs , files in os . walk ( path ) : for file_name in files : if file_name . endswith ( \" . py \" ) : self . search_script_file ( subdir , file_name ) ": 4368,
 "def parse_parameter ( value ) : if any ( ( isinstance ( value , float ) , isinstance ( value , int ) , isinstance ( value , bool ) ) ) : return value try : return int ( value ) except ValueError : try : return float ( value ) except ValueError : if value in string_aliases . true_boolean_aliases : return True elif value in string_aliases . false_boolean_aliases : return False else : return str ( value ) ": 4369,
 "def wireshark ( pktlist , *args ) : fname = get_temp_file ( ) wrpcap ( fname , pktlist ) subprocess . Popen ( [conf . prog . wireshark , \" -r \" , fname] + list ( args ) ) ": 4370,
 "def step_impl06 ( context ) : store = context . SingleStore context . st_1 = store ( ) context . st_2 = store ( ) context . st_3 = store ( ) ": 4371,
 "def raises_regex ( self , expected_exception , expected_regexp ) : return unittest_case . assertRaisesRegexp ( expected_exception , expected_regexp , self . _orig_subject , *self . _args , **self . _kwargs ) ": 4372,
 "def import_path ( self ) : return os . path . join ( self . remote_root , self . pkg ) if self . pkg else self . remote_root": 4373,
 "def sbatch_template ( self ) : template = self . sbatch_template_str if template . startswith ( ' # ! ' ) : # script is embedded in YAML return jinja_environment . from_string ( template ) return jinja_environment . get_template ( template ) ": 4374,
 "def timeit ( method ) : def timed ( *args , **kw ) : time_start = time . time ( ) result = method ( *args , **kw ) time_end = time . time ( ) print ( ' timeit : %r %2 . 2f sec ( %r , %r ) ' % ( method . __name__ , time_end-time_start , str ( args ) [ : 20] , kw ) ) return result return timed": 4375,
 "async def stop ( self ) : # negate pid so that signals apply to process group pgid = -self . process . pid try : os . kill ( pgid , signal . SIGTERM ) await asyncio . sleep ( 1 ) os . kill ( pgid , signal . SIGKILL ) except ( OSError , ProcessLookupError ) : return": 4376,
 "def escape ( s ) : if not isinstance ( s , bytes ) : s = s . encode ( ' utf-8 ' ) return quote ( s , safe = ' ~ ' ) ": 4377,
 "def kill_all ( self , kill_signal , kill_shell = False ) : for key in self . processes . keys ( ) : self . kill_process ( key , kill_signal , kill_shell ) ": 4378,
 "def _letter_map ( word ) : lmap = {} for letter in word : try : lmap[letter] + = 1 except KeyError : lmap[letter] = 1 return lmap": 4379,
 "def get_ip_address ( ifname ) : s = socket . socket ( socket . AF_INET , socket . SOCK_DGRAM ) return socket . inet_ntoa ( fcntl . ioctl ( s . fileno ( ) , 0x8915 , # SIOCGIFADDR struct . pack ( ' 256s ' , ifname[ : 15] ) ) [20 : 24] ) ": 4380,
 "def is_valid ( data ) : return bool ( data ) and \\ isinstance ( data , dict ) and \\ bool ( data . get ( \" swagger \" ) ) and \\ isinstance ( data . get ( ' paths ' ) , dict ) ": 4381,
 "def _check_list_len ( row , length ) : if len ( row ) ! = length : raise Exception ( \" row length does not match expected length of \" + str ( length ) + \" \\nrow : \" + str ( row ) ) ": 4382,
 "def getprop ( self , prop_name ) : return self . shell ( [ ' getprop ' , prop_name] , timeout = DEFAULT_GETPROP_TIMEOUT_SEC ) . decode ( ' utf-8 ' ) . strip ( ) ": 4383,
 "def add_input_variable ( self , var ) : assert ( isinstance ( var , Variable ) ) self . input_variable_list . append ( var ) ": 4384,
 "def check_alert ( self , text ) : try : alert = Alert ( world . browser ) if alert . text ! = text : raise AssertionError ( \" Alert text expected to be {!r} , got {!r} . \" . format ( text , alert . text ) ) except WebDriverException : # PhantomJS is kinda poor pass": 4385,
 "def size ( self ) : width = max ( map ( lambda x : x . size ( ) [0] , self . sections . itervalues ( ) ) ) height = sum ( map ( lambda x : x . size ( ) [1] , self . sections . itervalues ( ) ) ) return width , height": 4386,
 "def setAsApplication ( myappid ) : if os . name = = ' nt ' : import ctypes ctypes . windll . shell32 . SetCurrentProcessExplicitAppUserModelID ( myappid ) ": 4387,
 "def _disable_venv ( self , env ) : venv = env . pop ( ' VIRTUAL_ENV ' , None ) if venv : venv_path , sep , env[ ' PATH ' ] = env[ ' PATH ' ] . partition ( os . pathsep ) ": 4388,
 "def attr_cache_clear ( self ) : node = extract_node ( ) return BoundMethod ( proxy = node , bound = self . _instance . parent . scope ( ) ) ": 4389,
 "def submit_by_selector ( self , selector ) : elem = find_element_by_jquery ( world . browser , selector ) elem . submit ( ) ": 4390,
 "def disconnect ( self ) : self . logger . debug ( ' Close connection . . . ' ) self . auto_reconnect = False if self . websocket is not None : self . websocket . close ( ) ": 4391,
 "def settimeout ( self , timeout ) : self . sock_opt . timeout = timeout if self . sock : self . sock . settimeout ( timeout ) ": 4392,
 "def select_random ( engine , table_or_columns , limit = 5 ) : s = select ( table_or_columns ) . order_by ( func . random ( ) ) . limit ( limit ) return engine . execute ( s ) . fetchall ( ) ": 4393,
 "def join_field ( path ) : output = \" . \" . join ( [f . replace ( \" . \" , \" \\\\ . \" ) for f in path if f ! = None] ) return output if output else \" . \" ": 4394,
 "def create_widget ( self ) : d = self . declaration button_type = UIButton . UIButtonTypeSystem if d . flat else UIButton . UIButtonTypeRoundedRect self . widget = UIButton ( buttonWithType = button_type ) ": 4395,
 "def atom_criteria ( *params ) : result = {} for index , param in enumerate ( params ) : if param is None : continue elif isinstance ( param , int ) : result[index] = HasAtomNumber ( param ) else : result[index] = param return result": 4396,
 "def normalize_path ( filename ) : return os . path . normcase ( os . path . realpath ( os . path . normpath ( _cygwin_patch ( filename ) ) ) ) ": 4397,
 "def x_values_ref ( self , series ) : top_row = self . series_table_row_offset ( series ) + 2 bottom_row = top_row + len ( series ) - 1 return \" Sheet1!$A$%d : $A$%d \" % ( top_row , bottom_row ) ": 4398,
 "def _wrap ( text , columns = 80 ) : out = [] for cnt , char in enumerate ( text ) : out . append ( char ) if ( cnt + 1 ) % columns = = 0 : out . append ( \" \\n \" ) return \" \" . join ( out ) ": 4399,
 "def sample_colormap ( cmap_name , n_samples ) : colors = [] colormap = cm . cmap_d[cmap_name] for i in np . linspace ( 0 , 1 , n_samples ) : colors . append ( colormap ( i ) ) return colors": 4400,
 "def write_dict_to_yaml ( dictionary , path , **kwargs ) : with open ( path , ' w ' ) as f : yaml . dump ( dictionary , f , indent = 4 , **kwargs ) ": 4401,
 "def visit_BinOp ( self , node ) : args = [self . visit ( arg ) for arg in ( node . left , node . right ) ] return list ( {frozenset . union ( *x ) for x in itertools . product ( *args ) } ) ": 4402,
 "def get_indentation ( line ) : if line . strip ( ) : non_whitespace_index = len ( line ) - len ( line . lstrip ( ) ) return line[ : non_whitespace_index] else : return ' ' ": 4403,
 "def read_bytes ( fo , writer_schema = None , reader_schema = None ) : size = read_long ( fo ) return fo . read ( size ) ": 4404,
 "def included_length ( self ) : return sum ( [shot . length for shot in self . shots if shot . is_included] ) ": 4405,
 "def upsert_single ( db , collection , object , match_params = None ) : return str ( db[collection] . update_one ( match_params , { \" $set \" : object} , upsert = True ) . upserted_id ) ": 4406,
 "def set_slug ( apps , schema_editor , class_name ) : Cls = apps . get_model ( ' spectator_events ' , class_name ) for obj in Cls . objects . all ( ) : obj . slug = generate_slug ( obj . pk ) obj . save ( update_fields = [ ' slug ' ] ) ": 4407,
 "def moving_average ( a , n ) : ret = np . cumsum ( a , dtype = float ) ret[n : ] = ret[n : ] - ret[ : -n] return ret[n - 1 : ] / n": 4408,
 "def count_words ( file ) : c = Counter ( ) with open ( file , ' r ' ) as f : for l in f : words = l . strip ( ) . split ( ) c . update ( words ) return c": 4409,
 "def word_matches ( s1 , s2 , n = 3 ) : return __matches ( s1 , s2 , word_ngrams , n = n ) ": 4410,
 "def _executemany ( self , cursor , query , parameters ) : try : self . _log ( query ) cursor . executemany ( query , parameters ) except OperationalError as e : # pragma : no cover logging . error ( ' Error connecting to PostgreSQL on %s , e ' , self . host , e ) self . close ( ) raise": 4411,
 "def iso_to_datetime ( date ) : chunks = list ( map ( int , date . split ( ' T ' ) [0] . split ( ' - ' ) ) ) return datetime . datetime ( chunks[0] , chunks[1] , chunks[2] ) ": 4412,
 "def unique_deps ( deps ) : deps . sort ( ) return list ( k for k , _ in itertools . groupby ( deps ) ) ": 4413,
 "def find_one ( cls , *args , **kw ) : \t\t\t\t\t\tif len ( args ) = = 1 and not isinstance ( args[0] , Filter ) : \t\t\targs = ( getattr ( cls , cls . __pk__ ) = = args[0] , ) \t\t\t\tDoc , collection , query , options = cls . _prepare_find ( *args , **kw ) \t\tresult = Doc . from_mongo ( collection . find_one ( query , **options ) ) \t\t\t\treturn result": 4414,
 "def _config_parse ( self ) : res = super ( cfg . ConfigParser , self ) . parse ( Backend . _config_string_io ) return res": 4415,
 "def rpc_fix_code ( self , source , directory ) : source = get_source ( source ) return fix_code ( source , directory ) ": 4416,
 "def overlap ( intv1 , intv2 ) : return max ( 0 , min ( intv1[1] , intv2[1] ) - max ( intv1[0] , intv2[0] ) ) ": 4417,
 "def log ( logger , level , message ) : if logger . parent . name ! = ' root ' : logger . log ( level , message ) else : print ( message , file = sys . stderr ) ": 4418,
 "def filechunk ( f , chunksize ) : while True : chunk = tuple ( itertools . islice ( f , chunksize ) ) if not chunk : return yield np . loadtxt ( iter ( chunk ) , dtype = np . float64 ) ": 4419,
 "def _or ( ctx , *logical ) : for arg in logical : if conversions . to_boolean ( arg , ctx ) : return True return False": 4420,
 "def create_env ( env_file ) : environ = {} with open ( env_file , ' r ' ) as f : for line in f . readlines ( ) : line = line . rstrip ( os . linesep ) if ' = ' not in line : continue if line . startswith ( ' # ' ) : continue key , value = line . split ( ' = ' , 1 ) environ[key] = parse_value ( value ) return environ": 4421,
 "def DeleteIndex ( self , index ) : to_remove = None for i in self . Items : if i . index = = index : to_remove = i if to_remove : self . Items . remove ( to_remove ) ": 4422,
 "def StreamWrite ( stream , *obj ) : stream . Write ( base64 . encodestring ( pickle . dumps ( obj ) ) ) ": 4423,
 "def filter_lines_from_comments ( lines ) : for line_nb , raw_line in enumerate ( lines ) : clean_line = remove_comments_from_line ( raw_line ) if clean_line = = ' ' : continue yield line_nb , clean_line , raw_line": 4424,
 "def mkhead ( repo , path ) : return git . Head ( repo , git . Head . to_full_path ( path ) ) ": 4425,
 "def uncomment_line ( line , prefix ) : if not prefix : return line if line . startswith ( prefix + ' ' ) : return line[len ( prefix ) + 1 : ] if line . startswith ( prefix ) : return line[len ( prefix ) : ] return line": 4426,
 "def draw_tree ( t , df , size = 10 , ratio = 0 . 6 , precision = 0 ) : s = export_graphviz ( t , out_file = None , feature_names = df . columns , filled = True , special_characters = True , rotate = True , precision = precision ) IPython . display . display ( graphviz . Source ( re . sub ( ' Tree { ' , f ' Tree {{ size = {size}; ratio = {ratio} ' , s ) ) ) ": 4427,
 "def _breakRemNewlines ( tag ) : \t\tfor i , c in enumerate ( tag . contents ) : \t\tif type ( c ) ! = bs4 . element . NavigableString : \t\t\tcontinue\t\tc . replace_with ( re . sub ( r ' {2 , } ' , ' ' , c ) . replace ( ' \\n ' , ' ' ) ) ": 4428,
 "def __repr__ ( self ) : return str ( self . __class__ ) + ' ( ' + ' , ' . join ( [list . __repr__ ( d ) for d in self . data] ) + ' ) ' ": 4429,
 "def get_subplot_at ( self , row , column ) : idx = row * self . columns + column return self . subplots[idx]": 4430,
 "def __add_namespaceinfo ( self , ni ) : self . __ns_uri_map[ni . uri] = ni for prefix in ni . prefixes : self . __prefix_map[prefix] = ni": 4431,
 "def request_type ( self ) : if self . static and not self . uses_request : return getattr ( xenon_pb2 , ' Empty ' ) if not self . uses_request : return None return getattr ( xenon_pb2 , self . request_name ) ": 4432,
 "def add_chart ( self , chart , row , col ) : self . __charts . append ( ( chart , ( row , col ) ) ) ": 4433,
 "def vec ( self ) : return np . r_[self . fx , self . fy , self . cx , self . cy , self . skew , self . height , self . width]": 4434,
 "def kindex ( matrix , k ) : ix = ( np . arange ( len ( matrix ) ) , matrix . argsort ( axis = 0 ) [k] ) return ix": 4435,
 "def render_template ( content , context ) : rendered = Template ( content ) . render ( Context ( context ) ) return rendered": 4436,
 "def _get_env ( self , env_var ) : value = os . environ . get ( env_var ) if not value : raise ValueError ( ' Missing environment variable : %s ' % env_var ) return value": 4437,
 "def create ( parallel ) : queue = {k : v for k , v in parallel . items ( ) if k in [ \" queue \" , \" cores_per_job \" , \" mem \" ]} yield queue": 4438,
 "def safe_execute_script ( driver , script ) : try : driver . execute_script ( script ) except Exception : # The likely reason this fails is because : \" jQuery is not defined \" activate_jquery ( driver ) # It ' s a good thing we can define it here driver . execute_script ( script ) ": 4439,
 "def next ( self ) : item = six . next ( self . _item_iter ) result = self . _item_to_value ( self . _parent , item ) # Since we ' ve successfully got the next value from the # iterator , we update the number of remaining . self . _remaining - = 1 return result": 4440,
 "def get_key ( self , key , bucket_name = None ) : if not bucket_name : ( bucket_name , key ) = self . parse_s3_url ( key ) obj = self . get_resource_type ( ' s3 ' ) . Object ( bucket_name , key ) obj . load ( ) return obj": 4441,
 "def save_json ( object , handle , indent = 2 ) : obj_json = json . dumps ( object , indent = indent , cls = NumpyJSONEncoder ) handle . write ( obj_json ) ": 4442,
 "def extend ( self , iterable ) : return super ( Collection , self ) . extend ( self . _ensure_iterable_is_valid ( iterable ) ) ": 4443,
 "def _load_mod_ui_libraries ( self , path ) : path = path / Path ( ' mod ' ) sys . path . append ( str ( path ) ) ": 4444,
 "def find_model_by_table_name ( name ) : for model in ModelBase . _decl_class_registry . values ( ) : if hasattr ( model , ' __table__ ' ) and model . __table__ . fullname = = name : return model return None": 4445,
 "def calculate_bounding_box_from_image ( im , curr_page ) : xMax , y_max = im . size bounding_box = im . getbbox ( ) # note this uses ltrb convention if not bounding_box : # print ( \" \\nWarning : could not calculate a bounding box for this page . \" # \" \\nAn empty page is assumed . \" , file = sys . stderr ) bounding_box = ( xMax/2 , y_max/2 , xMax/2 , y_max/2 ) bounding_box = list ( bounding_box ) # make temporarily mutable # Compensate for reversal of the image y convention versus PDF . bounding_box[1] = y_max - bounding_box[1] bounding_box[3] = y_max - bounding_box[3] full_page_box = curr_page . mediaBox # should have been set already to chosen box # Convert pixel units to PDF ' s bp units . convert_x = float ( full_page_box . getUpperRight_x ( ) - full_page_box . getLowerLeft_x ( ) ) / xMax convert_y = float ( full_page_box . getUpperRight_y ( ) - full_page_box . getLowerLeft_y ( ) ) / y_max # Get final box; note conversion to lower-left point , upper-right point format . final_box = [ bounding_box[0] * convert_x , bounding_box[3] * convert_y , bounding_box[2] * convert_x , bounding_box[1] * convert_y] return final_box": 4446,
 "def server ( request ) : return direct_to_template ( request , ' server/index . html ' , { ' user_url ' : getViewURL ( request , idPage ) , ' server_xrds_url ' : getViewURL ( request , idpXrds ) , } ) ": 4447,
 "def __add__ ( self , other ) : new_table = copy . copy ( self ) for row in other : new_table . Append ( row ) return new_table": 4448,
 "def content_type ( self , data ) : self . _content_type = str ( data ) self . add_header ( ' Content-Type ' , str ( data ) ) ": 4449,
 "def set_default ( self , section , option , default ) : if not self . parser . has_option ( section , option ) : self . parser . set ( section , option , default ) ": 4450,
 "def cli_parse ( parser ) : parser . add_argument ( ' -n ' , ' --samples ' , type = int , required = True , help = ' Number of Samples ' ) return parser": 4451,
 "def args_update ( self ) : for key , value in self . _config_data . items ( ) : setattr ( self . _default_args , key , value ) ": 4452,
 "def toggle_pause ( self ) : self . controller . playing = not self . controller . playing self . music . toggle_pause ( ) ": 4453,
 "def assert_iter ( **kw ) : for name , value in kw . items ( ) : if not isiter ( value ) : raise TypeError ( ' paco : {} must be an iterable object ' . format ( name ) ) ": 4454,
 "def tokenize ( self , s ) : return [s[start : end] for start , end in self . span_tokenize ( s ) ]": 4455,
 "def _resizeColumnsToContents ( self , header , data , limit_ms ) : max_col = data . model ( ) . columnCount ( ) if limit_ms is None : max_col_ms = None else : max_col_ms = limit_ms / max ( 1 , max_col ) for col in range ( max_col ) : self . _resizeColumnToContents ( header , data , col , max_col_ms ) ": 4456,
 "def _load_autoreload_magic ( self ) : from IPython . core . getipython import get_ipython try : get_ipython ( ) . run_line_magic ( ' reload_ext ' , ' autoreload ' ) get_ipython ( ) . run_line_magic ( ' autoreload ' , ' 2 ' ) except Exception : pass": 4457,
 "def _split_python ( python ) : python = _preprocess ( python ) if not python : return [] lexer = PythonSplitLexer ( ) lexer . read ( python ) return lexer . chunks": 4458,
 "def stack_template_url ( bucket_name , blueprint , endpoint ) : key_name = stack_template_key_name ( blueprint ) return \" %s/%s/%s \" % ( endpoint , bucket_name , key_name ) ": 4459,
 "def get_api_url ( self , lambda_name , stage_name ) : api_id = self . get_api_id ( lambda_name ) if api_id : return \" https : //{} . execute-api . {} . amazonaws . com/{} \" . format ( api_id , self . boto_session . region_name , stage_name ) else : return None": 4460,
 "def create_all ( self , check_first : bool = True ) : self . _metadata . create_all ( self . engine , checkfirst = check_first ) ": 4461,
 "def _heapreplace_max ( heap , item ) : returnitem = heap[0] # raises appropriate IndexError if heap is empty heap[0] = item _siftup_max ( heap , 0 ) return returnitem": 4462,
 "def encode_ndarray ( obj ) : shape = obj . shape if len ( shape ) = = 1 : shape = ( 1 , obj . shape[0] ) if obj . flags . c_contiguous : obj = obj . T elif not obj . flags . f_contiguous : obj = asfortranarray ( obj . T ) else : obj = obj . T try : data = obj . astype ( float64 ) . tobytes ( ) except AttributeError : data = obj . astype ( float64 ) . tostring ( ) data = base64 . b64encode ( data ) . decode ( ' utf-8 ' ) return data , shape": 4463,
 "def apply_caching ( response ) : for k , v in config . get ( ' HTTP_HEADERS ' ) . items ( ) : response . headers[k] = v return response": 4464,
 "def slugify_filename ( filename ) : name , ext = os . path . splitext ( filename ) slugified = get_slugified_name ( name ) return slugified + ext": 4465,
 "def to_bytes ( self ) : \t\t\t\tchunks = [PNG_SIGN]\t\tchunks . extend ( c[1] for c in self . chunks ) \t\treturn b \" \" . join ( chunks ) ": 4466,
 "def _get_bokeh_html ( self , chart_obj ) : global bokeh_renderer try : renderer = bokeh_renderer p = renderer . get_plot ( chart_obj ) . state script , div = components ( p ) return script + \" \\n \" + div except Exception as e : self . err ( e , self . _get_bokeh_html , \" Can not get html from the Bokeh rendering engine \" ) ": 4467,
 "def describe_unique_1d ( series ) : return pd . Series ( [base . S_TYPE_UNIQUE] , index = [ ' type ' ] , name = series . name ) ": 4468,
 "def needs_update ( self , cache_key ) : if not self . cacheable ( cache_key ) : # An uncacheable CacheKey is always out of date . return True return self . _read_sha ( cache_key ) ! = cache_key . hash": 4469,
 "def delete_item ( self , item ) : try : self . dynamodb_client . delete_item ( **item ) except botocore . exceptions . ClientError as error : handle_constraint_violation ( error ) ": 4470,
 "def polygon_from_points ( points ) : polygon = [] for pair in points . split ( \" \" ) : x_y = pair . split ( \" , \" ) polygon . append ( [float ( x_y[0] ) , float ( x_y[1] ) ] ) return polygon": 4471,
 "def sync_s3 ( self ) : bucket , key = self . open_s3 ( ) for directory in self . DIRECTORIES : for root , dirs , files in os . walk ( directory ) : self . upload_s3 ( ( bucket , key , self . AWS_BUCKET_NAME , directory ) , root , files , dirs ) ": 4472,
 "def __call__ ( self , obj , *arg , **kw ) : bound_method = self . _manager . __get__ ( obj , obj . __class__ ) return bound_method ( *arg , **kw ) ": 4473,
 "def WriteManyToPath ( objs , filepath ) : with io . open ( filepath , mode = \" w \" , encoding = \" utf-8 \" ) as filedesc : WriteManyToFile ( objs , filedesc ) ": 4474,
 "def add_swagger ( app , json_route , html_route ) : app . router . add_route ( ' GET ' , json_route , create_swagger_json_handler ( app ) ) add_swagger_api_route ( app , html_route , json_route ) ": 4475,
 "def get_bound ( pts ) : ( x0 , y0 , x1 , y1 ) = ( INF , INF , -INF , -INF ) for ( x , y ) in pts : x0 = min ( x0 , x ) y0 = min ( y0 , y ) x1 = max ( x1 , x ) y1 = max ( y1 , y ) return ( x0 , y0 , x1 , y1 ) ": 4476,
 "def hkm_fc ( fdata , Nmax , m , s ) : f = fdata[ : , m] L1 = f . size MM = int ( L1 / 2 ) Q = s . size ff = np . zeros ( Q , dtype = np . complex128 ) for n in xrange ( MM , L1 ) : ff[n] = f[n - MM] for n in xrange ( 0 , MM ) : ff[n] = f[n + MM] # For larger problems , this speeds things up pretty good . F = np . fft . fft ( ff ) S = np . fft . fft ( s ) out = 4 * np . pi * np . fft . ifft ( F * S ) return out[0 : Nmax + 1]": 4477,
 "def text ( value , encoding = \" utf-8 \" , errors = \" strict \" ) : if isinstance ( value , text_type ) : return value elif isinstance ( value , bytes ) : return text_type ( value , encoding , errors ) else : return text_type ( value ) ": 4478,
 "def token_list_len ( tokenlist ) : ZeroWidthEscape = Token . ZeroWidthEscape return sum ( len ( item[1] ) for item in tokenlist if item[0] ! = ZeroWidthEscape ) ": 4479,
 "def filter ( self , func ) : return self . __class__ ( [ i for i in self . res if func ( *i ) ] , name = ' filtered %s ' %self . listname ) ": 4480,
 "def is_SYMBOL ( token , *symbols ) : from symbols . symbol_ import Symbol assert all ( isinstance ( x , Symbol ) for x in symbols ) for sym in symbols : if sym . token ! = token : return False return True": 4481,
 "def wrap ( text , indent = ' ' ) : wrapper = textwrap . TextWrapper ( width = int ( os . environ . get ( ' COLUMNS ' , 80 ) ) , initial_indent = indent , subsequent_indent = indent ) return ' \\n ' . join ( wrapper . wrap ( text ) ) ": 4482,
 "def _update_plot ( self , _ ) : # Since all sliders call this same callback without saying who they are # I need to update the values for all parameters . This can be # circumvented by creating a seperate callback function for each # parameter . for param in self . model . params : param . value = self . _sliders[param] . val for indep_var , dep_var in self . _projections : self . _update_specific_plot ( indep_var , dep_var ) ": 4483,
 "def _maybe_pandas_data ( data , feature_names , feature_types ) : if not isinstance ( data , DataFrame ) : return data , feature_names , feature_types data_dtypes = data . dtypes if not all ( dtype . name in PANDAS_DTYPE_MAPPER for dtype in data_dtypes ) : bad_fields = [data . columns[i] for i , dtype in enumerate ( data_dtypes ) if dtype . name not in PANDAS_DTYPE_MAPPER] msg = \" \" \" DataFrame . dtypes for data must be int , float or bool . Did not expect the data types in fields \" \" \" raise ValueError ( msg + ' , ' . join ( bad_fields ) ) if feature_names is None : if isinstance ( data . columns , MultiIndex ) : feature_names = [ ' ' . join ( [str ( x ) for x in i] ) for i in data . columns ] else : feature_names = data . columns . format ( ) if feature_types is None : feature_types = [PANDAS_DTYPE_MAPPER[dtype . name] for dtype in data_dtypes] data = data . values . astype ( ' float ' ) return data , feature_names , feature_types": 4484,
 "def convert_from_missing_indexer_tuple ( indexer , axes ) : def get_indexer ( _i , _idx ) : return ( axes[_i] . get_loc ( _idx[ ' key ' ] ) if isinstance ( _idx , dict ) else _idx ) return tuple ( get_indexer ( _i , _idx ) for _i , _idx in enumerate ( indexer ) ) ": 4485,
 "def compute_centroid ( points ) : lats = [p[1] for p in points] lons = [p[0] for p in points] return Point ( np . mean ( lats ) , np . mean ( lons ) , None ) ": 4486,
 "def scopes_as ( self , new_scopes ) : old_scopes , self . scopes = self . scopes , new_scopes yield self . scopes = old_scopes": 4487,
 "def any_of ( value , *args ) : if len ( args ) : value = ( value , ) + args return ExpectationAny ( value ) ": 4488,
 "def round_float ( f , digits , rounding = ROUND_HALF_UP ) : return Decimal ( str ( f ) ) . quantize ( Decimal ( 10 ) ** ( -1 * digits ) , rounding = rounding ) ": 4489,
 "def contains_case_insensitive ( adict , akey ) : for key in adict : if key . lower ( ) = = akey . lower ( ) : return True return False": 4490,
 "def exists ( self ) : resp = self . r_session . head ( self . database_url ) if resp . status_code not in [200 , 404] : resp . raise_for_status ( ) return resp . status_code = = 200": 4491,
 "def readable ( path ) : try : st = os . stat ( path ) return 0 ! = st . st_mode & READABLE_MASK except os . error : return None return True": 4492,
 "def imagemagick ( color_count , img , magick_command ) : flags = [ \" -resize \" , \" 25% \" , \" -colors \" , str ( color_count ) , \" -unique-colors \" , \" txt : - \" ] img + = \" [0] \" return subprocess . check_output ( [*magick_command , img , *flags] ) . splitlines ( ) ": 4493,
 "def delete ( args ) : m = RiverManager ( args . hosts ) m . delete ( args . name ) ": 4494,
 "def exists ( self ) : try : return self . metadata is not None except datalab . utils . RequestException : return False except Exception as e : raise e": 4495,
 "def is_valid_file ( parser , arg ) : \t\tif not os . path . exists ( arg ) : \t\tparser . error ( \" File %s not found \" %arg ) \telse : \t \treturn arg": 4496,
 "def isCommaList ( inputFilelist ) : if isinstance ( inputFilelist , int ) or isinstance ( inputFilelist , np . int32 ) : ilist = str ( inputFilelist ) else : ilist = inputFilelist if \" , \" in ilist : return True return False": 4497,
 "def get_category ( self ) : var = self . xmlnode . prop ( \" category \" ) if not var : var = \" ? \" return var . decode ( \" utf-8 \" ) ": 4498,
 "def watched_extension ( extension ) : for ext in hamlpy . VALID_EXTENSIONS : if extension . endswith ( ' . ' + ext ) : return True return False": 4499,
 "def binary_stdout ( ) : # First there is a Python3 issue . try : stdout = sys . stdout . buffer except AttributeError : # Probably Python 2 , where bytes are strings . stdout = sys . stdout # On Windows the C runtime file orientation needs changing . if sys . platform = = \" win32 \" : import msvcrt import os msvcrt . setmode ( sys . stdout . fileno ( ) , os . O_BINARY ) return stdout": 4500,
 "def library ( func ) : @wraps ( func ) def wrapped ( *args , **kwargs ) : \" \" \" Transparent wrapper . \" \" \" return func ( *args , **kwargs ) SINGLES . append ( wrapped ) return wrapped": 4501,
 "def ExpireObject ( self , key ) : node = self . _hash . pop ( key , None ) if node : self . _age . Unlink ( node ) self . KillObject ( node . data ) return node . data": 4502,
 "def WriteToPath ( obj , filepath ) : with io . open ( filepath , mode = \" w \" , encoding = \" utf-8 \" ) as filedesc : WriteToFile ( obj , filedesc ) ": 4503,
 "def do_help ( self , arg ) : print ( self . response_prompt , file = self . stdout ) return cmd . Cmd . do_help ( self , arg ) ": 4504,
 "def linear_variogram_model ( m , d ) : slope = float ( m[0] ) nugget = float ( m[1] ) return slope * d + nugget": 4505,
 "def printcsv ( csvdiffs ) : for row in csvdiffs : print ( ' , ' . join ( [str ( cell ) for cell in row] ) ) ": 4506,
 "def from_json ( cls , s ) : d = json . loads ( s ) return get_dict_handler ( d[ \" type \" ] ) ( d ) ": 4507,
 "def point_in_multipolygon ( point , multipoly ) : coords_array = [multipoly[ ' coordinates ' ]] if multipoly[ ' type ' ] = = \" MultiPolygon \" else multipoly[ ' coordinates ' ] for coords in coords_array : if _point_in_polygon ( point , coords ) : return True return False": 4508,
 "def c2s ( self , p = [0 , 0] ) : return ( ( p[0]-self . canvasx ( self . cx1 ) , p[1]-self . canvasy ( self . cy1 ) ) ) ": 4509,
 "def np2str ( value ) : if hasattr ( value , ' dtype ' ) and \\ issubclass ( value . dtype . type , ( np . string_ , np . object_ ) ) and value . size = = 1 : value = np . asscalar ( value ) if not isinstance ( value , str ) : # python 3 - was scalar numpy array of bytes # otherwise python 2 - scalar numpy array of ' str ' value = value . decode ( ) return value else : raise ValueError ( \" Array is not a string type or is larger than 1 \" ) ": 4510,
 "def register_blueprints ( app ) : app . register_blueprint ( public . public_bp ) app . register_blueprint ( genes . genes_bp ) app . register_blueprint ( cases . cases_bp ) app . register_blueprint ( login . login_bp ) app . register_blueprint ( variants . variants_bp ) app . register_blueprint ( panels . panels_bp ) app . register_blueprint ( dashboard . dashboard_bp ) app . register_blueprint ( api . api_bp ) app . register_blueprint ( alignviewers . alignviewers_bp ) app . register_blueprint ( phenotypes . hpo_bp ) app . register_blueprint ( institutes . overview ) ": 4511,
 "def _clone_properties ( self ) : cls = self . __class__ if self . _properties is cls . _properties : self . _properties = dict ( cls . _properties ) ": 4512,
 "def cross_v2 ( vec1 , vec2 ) : return vec1 . y * vec2 . x - vec1 . x * vec2 . y": 4513,
 "def _get_column_by_db_name ( cls , name ) : return cls . _columns . get ( cls . _db_map . get ( name , name ) ) ": 4514,
 "def init ( ) : print ( yellow ( \" # Setting up environment . . . \\n \" , True ) ) virtualenv . init ( ) virtualenv . update_requirements ( ) print ( green ( \" \\n # DONE . \" , True ) ) print ( green ( \" Type \" ) + green ( \" activate \" , True ) + green ( \" to enable your virtual environment . \" ) ) ": 4515,
 "def token ( name ) : def wrap ( f ) : tokenizers . append ( ( name , f ) ) return f return wrap": 4516,
 "def add_column ( connection , column ) : stmt = alembic . ddl . base . AddColumn ( _State . table . name , column ) connection . execute ( stmt ) _State . reflect_metadata ( ) ": 4517,
 "def unit_ball_L_inf ( shape , precondition = True ) : x = tf . Variable ( tf . zeros ( shape ) ) if precondition : return constrain_L_inf_precondition ( x ) else : return constrain_L_inf ( x ) ": 4518,
 "def save_to_16bit_wave_file ( fname , sig , rate ) : with closing ( wave . open ( fname , \" wb \" ) ) as wave_file : wave_file . setnchannels ( 1 ) wave_file . setsampwidth ( 2 ) wave_file . setframerate ( rate ) for chunk in chunks ( ( clip ( sig ) * 2 ** 15 ) . map ( int ) , dfmt = \" h \" , padval = 0 ) : wave_file . writeframes ( chunk ) ": 4519,
 "def to_bytes_or_none ( value ) : if value = = ffi . NULL : return None elif isinstance ( value , ffi . CData ) : return ffi . string ( value ) else : raise ValueError ( ' Value must be char[] or NULL ' ) ": 4520,
 "def load ( self ) : \t\t\t\tglTexImage3D ( GL_TEXTURE_3D , 0 , GL_LUMINANCE16_ALPHA16 , \t\t\tself . width , self . width , self . width , 0 , GL_LUMINANCE_ALPHA , \t\t\tGL_UNSIGNED_SHORT , ctypes . byref ( self . data ) ) ": 4521,
 "def timestamp_to_datetime ( cls , dt , dt_format = DATETIME_FORMAT ) : return cls . convert_datetime ( cls . get_datetime ( dt ) , dt_format = dt_format ) ": 4522,
 "def get_ips ( self , instance_id ) : instance = self . _load_instance ( instance_id ) IPs = sum ( instance . networks . values ( ) , [] ) return IPs": 4523,
 "def attribute ( func ) : attr = abc . abstractmethod ( func ) attr . __iattribute__ = True attr = _property ( attr ) return attr": 4524,
 "def standardize ( ) : def f ( G , bim ) : G_out = standardize_snps ( G ) return G_out , bim return f": 4525,
 "def get_object_as_string ( obj ) : if isinstance ( obj , str ) : return obj if isinstance ( obj , list ) : return ' \\r\\n\\; ' . join ( [get_object_as_string ( item ) for item in obj] ) attrs = vars ( obj ) as_string = ' , ' . join ( \" %s : %s \" % item for item in attrs . items ( ) ) return as_string": 4526,
 "def isroutine ( object ) : return ( isbuiltin ( object ) or isfunction ( object ) or ismethod ( object ) or ismethoddescriptor ( object ) ) ": 4527,
 "def inFocus ( self ) : previous_flags = self . window . flags ( ) self . window . setFlags ( previous_flags | QtCore . Qt . WindowStaysOnTopHint ) ": 4528,
 "def code ( self ) : return compile ( self . source ( ) , self . full_path , ' exec ' , flags = 0 , dont_inherit = True ) ": 4529,
 "def find_dist_to_centroid ( cvects , idx_list , weights = None ) : centroid = find_centroid ( cvects , idx_list , weights ) dist_vals = np . degrees ( np . arccos ( ( centroid * cvects . T[idx_list] ) . sum ( 1 ) ) ) return dist_vals , centroid": 4530,
 "async def connect ( self ) : await self . node . join_voice_channel ( self . channel . guild . id , self . channel . id ) ": 4531,
 "def dist_sq ( self , other ) : dx = self . x - other . x dy = self . y - other . y return dx**2 + dy**2": 4532,
 "def launch_server ( ) : print ( os . path . dirname ( os . path . abspath ( __file__ ) ) ) cur_dir = os . getcwd ( ) path = os . path . dirname ( os . path . abspath ( __file__ ) ) run = True os . chdir ( path ) os . system ( ' python manage . py runserver --nostatic ' ) os . chdir ( cur_dir ) ": 4533,
 "def add_range ( self , sequence , begin , end ) : sequence . parser_tree = parsing . Range ( self . value ( begin ) . strip ( \" ' \" ) , self . value ( end ) . strip ( \" ' \" ) ) return True": 4534,
 "def url ( viewname , *args , **kwargs ) : return reverse ( viewname , args = args , kwargs = kwargs ) ": 4535,
 "def do ( self ) : self . restore_point = self . obj . copy ( ) return self . do_method ( self . obj , *self . args ) ": 4536,
 "def _image_field ( self ) : for field in self . model . _meta . fields : if isinstance ( field , ImageField ) : return field . name": 4537,
 "def __init__ ( self , function ) : \t\t\t\tsuper ( takewhile , self ) . __init__ ( ) \t\tself . function = function": 4538,
 "def static_urls_js ( ) : if apps . is_installed ( ' django . contrib . staticfiles ' ) : from django . contrib . staticfiles . storage import staticfiles_storage static_base_url = staticfiles_storage . base_url else : static_base_url = PrefixNode . handle_simple ( \" STATIC_URL \" ) transpile_base_url = urljoin ( static_base_url , ' js/transpile/ ' ) return { ' static_base_url ' : static_base_url , ' transpile_base_url ' : transpile_base_url , ' version ' : LAST_RUN[ ' version ' ] }": 4539,
 "def cache ( self ) : if self . _cache is None : self . _cache = django_cache . get_cache ( self . cache_name ) return self . _cache": 4540,
 "def _add_line_segment ( self , x , y ) : self . _drawing_operations . append ( _LineSegment . new ( self , x , y ) ) ": 4541,
 "def can_elasticsearch ( record ) : search = request . _methodview . search_class ( ) search = search . get_record ( str ( record . id ) ) return search . count ( ) = = 1": 4542,
 "def raw ( self ) : es = self . get_es ( ) params = dict ( self . query_params ) mlt_fields = self . mlt_fields or params . pop ( ' mlt_fields ' , [] ) body = self . s . build_search ( ) if self . s else ' ' hits = es . mlt ( index = self . index , doc_type = self . doctype , id = self . id , mlt_fields = mlt_fields , body = body , **params ) log . debug ( hits ) return hits": 4543,
 "def email_user ( self , subject , message , from_email = None ) : send_mail ( subject , message , from_email , [self . email] ) ": 4544,
 "def update_scale ( self , value ) : self . plotter . set_scale ( self . x_slider_group . value , self . y_slider_group . value , self . z_slider_group . value ) ": 4545,
 "def selectin ( table , field , value , complement = False ) : return select ( table , field , lambda v : v in value , complement = complement ) ": 4546,
 "def create_movie ( fig , update_figure , filename , title , fps = 15 , dpi = 100 ) : FFMpegWriter = manimation . writers[ ' ffmpeg ' ] metadata = dict ( title = title ) writer = FFMpegWriter ( fps = fps , metadata = metadata ) with writer . saving ( fig , filename , dpi ) : t = 0 while True : if update_figure ( t ) : writer . grab_frame ( ) t + = 1 else : break": 4547,
 "def is_symbol ( string ) : return ( is_int ( string ) or is_float ( string ) or is_constant ( string ) or is_unary ( string ) or is_binary ( string ) or ( string = = ' ( ' ) or ( string = = ' ) ' ) ) ": 4548,
 "def load ( cls , filename ) : filename = cls . correct_file_extension ( filename ) with open ( filename , ' rb ' ) as f : return pickle . load ( f ) ": 4549,
 "def boxes_intersect ( box1 , box2 ) : xmin1 , xmax1 , ymin1 , ymax1 = box1 xmin2 , xmax2 , ymin2 , ymax2 = box2 if interval_intersection_width ( xmin1 , xmax1 , xmin2 , xmax2 ) and \\ interval_intersection_width ( ymin1 , ymax1 , ymin2 , ymax2 ) : return True else : return False": 4550,
 "def rmfile ( path ) : if osp . isfile ( path ) : if is_win : os . chmod ( path , 0o777 ) os . remove ( path ) ": 4551,
 "def local_minima ( img , min_distance = 4 ) : r # @TODO : Write a unittest for this . fits = numpy . asarray ( img ) minfits = minimum_filter ( fits , size = min_distance ) # default mode is reflect minima_mask = fits = = minfits good_indices = numpy . transpose ( minima_mask . nonzero ( ) ) good_fits = fits[minima_mask] order = good_fits . argsort ( ) return good_indices[order] , good_fits[order]": 4552,
 "def _has_fr_route ( self ) : # 404 ' s , 405 ' s , which might not have a url_rule if self . _should_use_fr_error_handler ( ) : return True # for all other errors , just check if FR dispatched the route if not request . url_rule : return False return self . owns_endpoint ( request . url_rule . endpoint ) ": 4553,
 "def _euclidean_dist ( vector_a , vector_b ) : dist = 0 for ( x , y ) in zip ( vector_a , vector_b ) : dist + = ( x-y ) * ( x-y ) return math . sqrt ( dist ) ": 4554,
 "def enable_writes ( self ) : self . write_buffer = [] self . flush_lock = threading . RLock ( ) self . flush_thread = FlushThread ( self . max_batch_time , self . _flush_writes ) ": 4555,
 "def EvalPoissonPmf ( k , lam ) : # don ' t use the scipy function ( yet ) . for lam = 0 it returns NaN; # should be 0 . 0 # return scipy . stats . poisson . pmf ( k , lam ) return lam ** k * math . exp ( -lam ) / math . factorial ( k ) ": 4556,
 "def _eager_tasklet ( tasklet ) : @utils . wrapping ( tasklet ) def eager_wrapper ( *args , **kwds ) : fut = tasklet ( *args , **kwds ) _run_until_rpc ( ) return fut return eager_wrapper": 4557,
 "def close ( self ) : try : self . _conn . send ( ( self . _CLOSE , None ) ) self . _conn . close ( ) except IOError : # The connection was already closed . pass self . _process . join ( ) ": 4558,
 "def GetIndentLevel ( line ) : indent = Match ( r ' ^ ( * ) \\S ' , line ) if indent : return len ( indent . group ( 1 ) ) else : return 0": 4559,
 "def get_area ( self ) : return ( self . p2 . x-self . p1 . x ) * ( self . p2 . y-self . p1 . y ) ": 4560,
 "def _callable_once ( func ) : def once ( *args , **kwargs ) : if not once . called : once . called = True return func ( *args , **kwargs ) once . called = False return once": 4561,
 "def _dump_spec ( spec ) : with open ( \" spec . yaml \" , \" w \" ) as f : yaml . dump ( spec , f , Dumper = MyDumper , default_flow_style = False ) ": 4562,
 "def AddAccuracy ( model , softmax , label ) : accuracy = brew . accuracy ( model , [softmax , label] , \" accuracy \" ) return accuracy": 4563,
 "def get_selection_owner ( self , selection ) : r = request . GetSelectionOwner ( display = self . display , selection = selection ) return r . owner": 4564,
 "def setup ( self , pin , mode , pull_up_down = PUD_OFF ) : self . rpi_gpio . setup ( pin , self . _dir_mapping[mode] , pull_up_down = self . _pud_mapping[pull_up_down] ) ": 4565,
 "def ruler_line ( self , widths , linetype = ' - ' ) : cells = [] for w in widths : cells . append ( linetype * ( w+2 ) ) return ' + ' + ' + ' . join ( cells ) + ' + ' ": 4566,
 "def check_cv ( self , y ) : y_arr = None if self . stratified : # Try to convert y to numpy for sklearn ' s check_cv; if conversion # doesn ' t work , still try . try : y_arr = to_numpy ( y ) except ( AttributeError , TypeError ) : y_arr = y if self . _is_float ( self . cv ) : return self . _check_cv_float ( ) return self . _check_cv_non_float ( y_arr ) ": 4567,
 "def cov_to_correlation ( cov ) : err = np . sqrt ( np . diag ( cov ) ) errinv = np . ones_like ( err ) * np . nan m = np . isfinite ( err ) & ( err ! = 0 ) errinv[m] = 1 . / err[m] corr = np . array ( cov ) return corr * np . outer ( errinv , errinv ) ": 4568,
 "def random_int ( self , min = 0 , max = 9999 , step = 1 ) : return self . generator . random . randrange ( min , max + 1 , step ) ": 4569,
 "def getcoef ( self ) : global mp_Z_Y1 return np . swapaxes ( mp_Z_Y1 , 0 , self . xstep . cri . axisK+1 ) [0]": 4570,
 "def find_largest_contig ( contig_lengths_dict ) : # Initialise the dictionary longest_contig_dict = dict ( ) for file_name , contig_lengths in contig_lengths_dict . items ( ) : # As the list is sorted in descending order , the largest contig is the first entry in the list longest_contig_dict[file_name] = contig_lengths[0] return longest_contig_dict": 4571,
 "def get_field_by_name ( self , name ) : for f in self . fields : if f . get_name ( ) = = name : return f return None": 4572,
 "def test_value ( self , value ) : if not isinstance ( value , int ) : raise ValueError ( ' expected int value : ' + str ( type ( value ) ) ) ": 4573,
 "def delete ( self , mutagen_file ) : for cover_tag in self . TAG_NAMES . values ( ) : try : del mutagen_file[cover_tag] except KeyError : pass": 4574,
 "def memory_usage ( self , deep = False ) : return self . _codes . nbytes + self . dtype . categories . memory_usage ( deep = deep ) ": 4575,
 "def block ( seed ) : num = SAMPLE_RATE * BLOCK_SIZE rng = RandomState ( seed % 2**32 ) variance = SAMPLE_RATE / 2 return rng . normal ( size = num , scale = variance**0 . 5 ) ": 4576,
 "def get_object_or_child_by_type ( self , *types ) : objects = self . get_objects_or_children_by_type ( *types ) return objects[0] if any ( objects ) else None": 4577,
 "def get_parent_var ( name , global_ok = False , default = None , skip_frames = 0 ) : scope = get_parent_scope_from_var ( name , global_ok = global_ok , skip_frames = skip_frames + 1 ) if not scope : return default if name in scope . locals : return scope . locals . get ( name , default ) return scope . globals . get ( name , default ) ": 4578,
 "def make_coord_dict ( coord ) : return dict ( z = int_if_exact ( coord . zoom ) , x = int_if_exact ( coord . column ) , y = int_if_exact ( coord . row ) , ) ": 4579,
 "def screen_to_latlon ( self , x , y ) : xtile = 1 . * x / TILE_SIZE + self . xtile ytile = 1 . * y / TILE_SIZE + self . ytile return self . num2deg ( xtile , ytile , self . zoom ) ": 4580,
 "def get_querystring ( uri ) : parts = urlparse . urlsplit ( uri ) return urlparse . parse_qs ( parts . query ) ": 4581,
 "def __get_registry_key ( self , key ) : import winreg root = winreg . OpenKey ( winreg . HKEY_CURRENT_USER , r ' SOFTWARE\\GSettings\\org\\gnucash\\general ' , 0 , winreg . KEY_READ ) [pathname , regtype] = ( winreg . QueryValueEx ( root , key ) ) winreg . CloseKey ( root ) return pathname": 4582,
 "def _full_analysis_mp_alias ( br_obj , analysis_set , output_directory , unique_name , verbose , quick_plots ) : return ( br_obj , unique_name , br_obj . full_analysis ( analysis_set , output_directory , verbose = verbose , compile_pdf = verbose , quick_plots = quick_plots ) ) ": 4583,
 "def get_size ( self , m ) : nrow , ncol = 0 , 0 if m[0] = = ' F ' : nrow = self . n elif m[0] = = ' G ' : nrow = self . m if m[1] = = ' x ' : ncol = self . n elif m[1] = = ' y ' : ncol = self . m return nrow , ncol": 4584,
 "def remove_accent_string ( string ) : return utils . join ( [add_accent_char ( c , Accent . NONE ) for c in string] ) ": 4585,
 "def replace_one ( self , replacement ) : self . __bulk . add_replace ( self . __selector , replacement , upsert = True , collation = self . __collation ) ": 4586,
 "def tab ( self , output ) : import csv csvwriter = csv . writer ( self . outfile , dialect = csv . excel_tab ) csvwriter . writerows ( output ) ": 4587,
 "def glpk_read_cplex ( path ) : from swiglpk import glp_create_prob , glp_read_lp problem = glp_create_prob ( ) glp_read_lp ( problem , None , path ) return problem": 4588,
 "def get_builder_toplevel ( self , builder ) : toplevel = builder . get_object ( self . toplevel_name ) if not gobject . type_is_a ( toplevel , gtk . Window ) : toplevel = None if toplevel is None : toplevel = get_first_builder_window ( builder ) return toplevel": 4589,
 "def main ( ) : usage = + Fuse . fusage server = FiocFS ( version = \" %prog \" + fuse . __version__ , usage = usage , dash_s_do = ' setsingle ' ) server . parse ( errex = 1 ) server . main ( ) ": 4590,
 "def unique ( iterable ) : seen = set ( ) for item in iterable : if item not in seen : seen . add ( item ) yield item": 4591,
 "def get_median ( temp_list ) : num = len ( temp_list ) temp_list . sort ( ) print ( temp_list ) if num % 2 = = 0 : median = ( temp_list[int ( num/2 ) ] + temp_list[int ( num/2 ) - 1] ) / 2 else : median = temp_list[int ( num/2 ) ] return median": 4592,
 "def most_even ( number , group ) : count , rest = divmod ( number , group ) counts = zip_longest ( [count] * group , [1] * rest , fillvalue = 0 ) chunks = [sum ( one ) for one in counts] logging . debug ( ' chunks : %s ' , chunks ) return chunks": 4593,
 "def count ( self ) : c = self . main_tab_widget . count ( ) for child in self . child_splitters : c + = child . count ( ) return c": 4594,
 "def _initialize_id ( self ) : self . id = str ( self . db . incr ( self . _key[ ' id ' ] ) ) ": 4595,
 "def call_alias ( self , alias , rest = ' ' ) : cmd = self . transform_alias ( alias , rest ) try : self . shell . system ( cmd ) except : self . shell . showtraceback ( ) ": 4596,
 "def version ( ) : import pkg_resources version = pkg_resources . require ( PROJECT_NAME ) [0] . version floyd_logger . info ( version ) ": 4597,
 "def xor_bytes ( a , b ) : assert len ( a ) = = len ( b ) return bytes ( map ( operator . xor , a , b ) ) ": 4598,
 "def get_method_from_module ( module_path , method_name ) : top_module = __import__ ( module_path ) module = top_module # we tunnel down until we find the module we want for submodule_name in module_path . split ( ' . ' ) [1 : ] : module = getattr ( module , submodule_name ) assert hasattr ( module , method_name ) , \\ \" unable to find method {0} from module {1} . does the method exist? \" . format ( method_name , module_path ) return getattr ( module , method_name ) ": 4599,
 "def to_topojson ( self ) : topojson = self . topojson topojson[ \" objects \" ][ \" points \" ] = { \" type \" : \" GeometryCollection \" , \" geometries \" : [point . to_topojson ( ) for point in self . points . all ( ) ] , } return json . dumps ( topojson ) ": 4600,
 "def get_variables ( args ) : variables_dict = {} if args . variables : for var in args . variables : words = var . split ( ' = ' ) variables_dict[words[0]] = words[1] return variables_dict": 4601,
 "async def create_websocket_server ( sock , filter = None ) : # pylint : disable = W0622 ws = Websocket ( ) await ws . start_server ( sock , filter = filter ) return ws": 4602,
 "def _normalize ( obj ) : if isinstance ( obj , list ) : return [_normalize ( item ) for item in obj] elif isinstance ( obj , dict ) : return {k : _normalize ( v ) for k , v in obj . items ( ) if v is not None} elif hasattr ( obj , ' to_python ' ) : return obj . to_python ( ) return obj": 4603,
 "def ranks ( self , key , value ) : return [normalize_rank ( el ) for el in force_list ( value . get ( ' a ' ) ) ]": 4604,
 "def getRowCurrentIndex ( self ) : curIndex = self . currentIndex ( ) col0Index = curIndex . sibling ( curIndex . row ( ) , 0 ) return col0Index": 4605,
 "def add_todo ( request ) : cur = request . cursor todo = request . json[ \" todo \" ] cur . execute ( , ( todo , ) ) last_id = cur . lastrowid cur . connection . commit ( ) return request . Response ( json = { \" id \" : last_id , \" todo \" : todo} ) ": 4606,
 "def monkey_restore ( ) : for k , v in originals . items ( ) : setattr ( time_mod , k , v ) global epoch epoch = None": 4607,
 "def _normalize_instancemethod ( instance_method ) : if not hasattr ( instance_method , ' im_self ' ) : return instance_method def _func ( *args , **kwargs ) : return instance_method ( *args , **kwargs ) _func . __name__ = repr ( instance_method ) return _func": 4608,
 "def count_rows ( self , table , cols = ' * ' ) : query = ' SELECT COUNT ( {0} ) FROM {1} ' . format ( join_cols ( cols ) , wrap ( table ) ) result = self . fetch ( query ) return result if result is not None else 0": 4609,
 "def log_to_json ( log ) : return [log . timestamp . isoformat ( ) [ : 22] , log . level , log . process , log . message]": 4610,
 "def execute ( self , cmd , *args , **kwargs ) : self . cursor . execute ( cmd , *args , **kwargs ) ": 4611,
 "def upgrade ( directory , sql , tag , x_arg , revision ) : _upgrade ( directory , revision , sql , tag , x_arg ) ": 4612,
 "def get_index_nested ( x , i ) : for ind in range ( len ( x ) ) : if i = = x[ind] : return ind return -1": 4613,
 "def get_table_list ( dbconn ) : cur = dbconn . cursor ( ) cur . execute ( \" SELECT name FROM sqlite_master WHERE type = ' table ' ; \" ) try : return [item[0] for item in cur . fetchall ( ) ] except IndexError : return get_table_list ( dbconn ) ": 4614,
 "def inverse ( self ) : invr = np . linalg . inv ( self . affine_matrix ) return SymmOp ( invr ) ": 4615,
 "def to_networkx ( graph ) : # import here so networkx is not always required . import networkx as nx nodes = graph[ \" nodes \" ] . keys ( ) edges = [[start , end] for start , ends in graph[ \" links \" ] . items ( ) for end in ends] g = nx . Graph ( ) g . add_nodes_from ( nodes ) nx . set_node_attributes ( g , dict ( graph[ \" nodes \" ] ) , \" membership \" ) g . add_edges_from ( edges ) return g": 4616,
 "def _get_col_index ( name ) : index = string . ascii_uppercase . index col = 0 for c in name . upper ( ) : col = col * 26 + index ( c ) + 1 return col": 4617,
 "def widget ( self , f ) : return self . cls ( f , self . opts , **self . kwargs ) ": 4618,
 "def main ( pargs ) : input_file = sys . argv[1] fp = ParseFileLineByLine ( input_file ) for i in fp : print ( i ) ": 4619,
 "def _iterate_flattened_values ( value ) : if isinstance ( value , six . string_types ) : yield value return if isinstance ( value , collections . Mapping ) : value = collections . ValuesView ( value ) if isinstance ( value , collections . Iterable ) : for nested_value in value : for nested_nested_value in _iterate_flattened_values ( nested_value ) : yield nested_nested_value yield value": 4620,
 "def check_github ( self ) : for name , req in list ( self . reqs . items ( ) ) : req_url = req[ \" url \" ] if not req_url : continue req_url = str ( req_url ) if req_url . startswith ( \" git \" ) and \" github . com/ \" not in req_url : continue if req_url . endswith ( ( \" . tar . gz \" , \" . tar . bz2 \" , \" . zip \" ) ) : continue headers = { \" content-type \" : \" application/json \" , } if self . github_api_token : headers[ \" Authorization \" ] = \" token {0} \" . format ( self . github_api_token ) try : path_parts = urlparse ( req_url ) . path . split ( \" # \" , 1 ) [0] . strip ( \" / \" ) . rstrip ( \" / \" ) . split ( \" / \" ) if len ( path_parts ) = = 2 : user , repo = path_parts elif ' archive ' in path_parts : # Supports URL of format : # https : //github . com/django/django/archive/master . tar . gz # egg = Django # https : //github . com/django/django/archive/master . zip # egg = Django user , repo = path_parts[ : 2] repo + = ' @ ' + path_parts[-1] . replace ( ' . tar . gz ' , ' ' ) . replace ( ' . zip ' , ' ' ) else : self . style . ERROR ( \" \\nFailed to parse %r\\n \" % ( req_url , ) ) continue except ( ValueError , IndexError ) as e : self . stdout . write ( self . style . ERROR ( \" \\nFailed to parse %r : %s\\n \" % ( req_url , e ) ) ) continue try : test_auth = requests . get ( \" https : //api . github . com/django/ \" , headers = headers ) . json ( ) except HTTPError as e : self . stdout . write ( \" \\n%s\\n \" % str ( e ) ) return if \" message \" in test_auth and test_auth[ \" message \" ] = = \" Bad credentials \" : self . stdout . write ( self . style . ERROR ( \" \\nGithub API : Bad credentials . Aborting!\\n \" ) ) return elif \" message \" in test_auth and test_auth[ \" message \" ] . startswith ( \" API Rate Limit Exceeded \" ) : self . stdout . write ( self . style . ERROR ( \" \\nGithub API : Rate Limit Exceeded . Aborting!\\n \" ) ) return frozen_commit_sha = None if \" . git \" in repo : repo_name , frozen_commit_full = repo . split ( \" . git \" ) if frozen_commit_full . startswith ( \" @ \" ) : frozen_commit_sha = frozen_commit_full[1 : ] elif \" @ \" in repo : repo_name , frozen_commit_sha = repo . split ( \" @ \" ) if frozen_commit_sha is None : msg = self . style . ERROR ( \" repo is not frozen \" ) if frozen_commit_sha : branch_url = \" https : //api . github . com/repos/{0}/{1}/branches \" . format ( user , repo_name ) branch_data = requests . get ( branch_url , headers = headers ) . json ( ) frozen_commit_url = \" https : //api . github . com/repos/{0}/{1}/commits/{2} \" . format ( user , repo_name , frozen_commit_sha ) frozen_commit_data = requests . get ( frozen_commit_url , headers = headers ) . json ( ) if \" message \" in frozen_commit_data and frozen_commit_data[ \" message \" ] = = \" Not Found \" : msg = self . style . ERROR ( \" {0} not found in {1} . Repo may be private . \" . format ( frozen_commit_sha[ : 10] , name ) ) elif frozen_commit_data[ \" sha \" ] in [branch[ \" commit \" ][ \" sha \" ] for branch in branch_data] : msg = self . style . BOLD ( \" up to date \" ) else : msg = self . style . INFO ( \" {0} is not the head of any branch \" . format ( frozen_commit_data[ \" sha \" ][ : 10] ) ) if \" dist \" in req : pkg_info = \" {dist . project_name} {dist . version} \" . format ( dist = req[ \" dist \" ] ) elif frozen_commit_sha is None : pkg_info = name else : pkg_info = \" {0} {1} \" . format ( name , frozen_commit_sha[ : 10] ) self . stdout . write ( \" {pkg_info : 40} {msg} \" . format ( pkg_info = pkg_info , msg = msg ) ) del self . reqs[name]": 4621,
 "def _query_for_reverse_geocoding ( lat , lng ) : # have to do some stupid f/Decimal/str stuff to ( a ) ensure we get as much # decimal places as the user already specified and ( b ) to ensure we don ' t # get e-5 stuff return \" {0 : f} , {1 : f} \" . format ( Decimal ( str ( lat ) ) , Decimal ( str ( lng ) ) ) ": 4622,
 "def iterparse ( source , events = ( ' end ' , ) , remove_comments = True , **kw ) : return ElementTree . iterparse ( source , events , SourceLineParser ( ) , **kw ) ": 4623,
 "def urljoin ( *urls ) : return reduce ( urlparse . urljoin , [u . strip ( ' / ' ) + ' / ' for u in urls if u . strip ( ' / ' ) ] , ' ' ) . rstrip ( ' / ' ) ": 4624,
 "def complex_check ( *args , func = None ) : func = func or inspect . stack ( ) [2][3] for var in args : if not isinstance ( var , numbers . Complex ) : name = type ( var ) . __name__ raise ComplexError ( f ' Function {func} expected complex number , {name} got instead . ' ) ": 4625,
 "def magic ( self , alias ) : if alias in self . aliases : return self . aliases[alias] else : return \" %%{}\\n \" . format ( alias ) ": 4626,
 "def pprint ( j , no_pretty ) : if not no_pretty : click . echo ( json . dumps ( j , cls = PotionJSONEncoder , sort_keys = True , indent = 4 , separators = ( \" , \" , \" : \" ) ) ) else : click . echo ( j ) ": 4627,
 "def append_query_parameter ( url , parameters , ignore_if_exists = True ) : if ignore_if_exists : for key in parameters . keys ( ) : if key + \" = \" in url : del parameters[key] parameters_str = \" & \" . join ( k + \" = \" + v for k , v in parameters . items ( ) ) append_token = \" & \" if \" ? \" in url else \" ? \" return url + append_token + parameters_str": 4628,
 "def _increment ( arr , indices ) : arr = _as_array ( arr ) indices = _as_array ( indices ) bbins = np . bincount ( indices ) arr[ : len ( bbins ) ] + = bbins return arr": 4629,
 "def plot_kde ( data , ax , title = None , color = ' r ' , fill_bt = True ) : if isinstance ( data , list ) : data = np . asarray ( data ) e = kde . KDEUnivariate ( data . astype ( np . float ) ) e . fit ( ) ax . plot ( e . support , e . density , color = color , alpha = 0 . 9 , linewidth = 2 . 25 ) if fill_bt : ax . fill_between ( e . support , e . density , alpha = . 35 , zorder = 1 , antialiased = True , color = color ) if title is not None : t = ax . set_title ( title ) t . set_y ( 1 . 05 ) ": 4630,
 "def get_long_description ( ) : here = path . abspath ( path . dirname ( __file__ ) ) with open ( path . join ( here , ' README . rst ' ) ) as readme : return readme . read ( ) return None": 4631,
 "def calculate_size ( name , replace_existing_values ) : data_size = 0 data_size + = calculate_size_str ( name ) data_size + = BOOLEAN_SIZE_IN_BYTES return data_size": 4632,
 "def _mid ( string , start , end = None ) : if end is None : end = len ( string ) return string[start : start + end]": 4633,
 "def confirm ( question , default = True ) : valid = { \" \" : default , \" yes \" : True , \" y \" : True , \" no \" : False , \" n \" : False} while 1 : choice = input ( question + ( \" [Y/n] \" if default else \" [y/N] \" ) ) . lower ( ) if choice in valid : return valid[choice] print ( \" Please respond with ' y ' or ' n ' \" ) ": 4634,
 "def ylim ( self , low , high ) : self . chart[ ' yAxis ' ][0][ ' min ' ] = low self . chart[ ' yAxis ' ][0][ ' max ' ] = high return self": 4635,
 "def get_tail ( self ) : node = self . head last_node = self . head while node is not None : last_node = node node = node . next_node return last_node": 4636,
 "def empirical ( X ) : print ( \" Empirical \" ) cov = np . dot ( X . T , X ) / n_samples return cov , np . linalg . inv ( cov ) ": 4637,
 "def dedup ( seq ) : seen = set ( ) for item in seq : if item not in seen : seen . add ( item ) yield item": 4638,
 "def stddev ( values , meanval = None ) : # from AI : A Modern Appproach if meanval = = None : meanval = mean ( values ) return math . sqrt ( sum ( [ ( x - meanval ) **2 for x in values] ) / ( len ( values ) -1 ) ) ": 4639,
 "def __enter__ ( self ) : self . fd = open ( self . filename , ' a ' ) fcntl . lockf ( self . fd , fcntl . LOCK_EX ) return self . fd": 4640,
 "def log_stop ( logger ) : handlers = logger . handlers[ : ] for handler in handlers : handler . close ( ) logger . removeHandler ( handler ) ": 4641,
 "def parse ( self ) : standard_formatters = re . compile ( r ' \\ ( ( . +? ) \\ ) ' , re . IGNORECASE ) return standard_formatters . findall ( self . _fmt ) ": 4642,
 "def _is_retryable_exception ( e ) : if isinstance ( e , urllib3 . exceptions . ProtocolError ) : e = e . args[1] if isinstance ( e , ( socket . gaierror , socket . herror ) ) : return True if isinstance ( e , socket . error ) and e . errno in _RETRYABLE_SOCKET_ERRORS : return True if isinstance ( e , urllib3 . exceptions . NewConnectionError ) : return True return False": 4643,
 "def enableEditing ( self , enabled ) : for button in self . buttons[1 : ] : button . setEnabled ( enabled ) if button . isChecked ( ) : button . setChecked ( False ) model = self . tableView . model ( ) if model is not None : model . enableEditing ( enabled ) ": 4644,
 "def apply_color_map ( name : str , mat : np . ndarray = None ) : def apply_map ( mat ) : return ( cm . get_cmap ( name ) ( _normalize ( mat ) ) [ : , : , : 3] * 255 ) . astype ( np . uint8 ) return apply_map if mat is None else apply_map ( mat ) ": 4645,
 "def check_player_collision ( self ) : player_tiles = r . TileMapManager . active_map . grab_collisions ( self . char . coords ) enemy_tiles = r . TileMapManager . active_map . grab_collisions ( self . coords ) # Check to see if any of the tiles are the same . If so , there is a collision . for ptile in player_tiles : for etile in enemy_tiles : if r . TileMapManager . active_map . pixels_to_tiles ( ptile . coords ) = = r . TileMapManager . active_map . pixels_to_tiles ( etile . coords ) : return True return False": 4646,
 "def read_image ( filepath ) : im_bytes = tf . io . read_file ( filepath ) im = tf . image . decode_image ( im_bytes , channels = CHANNELS ) im = tf . image . convert_image_dtype ( im , tf . float32 ) return im": 4647,
 "def calculate_size ( name , max_size ) : data_size = 0 data_size + = calculate_size_str ( name ) data_size + = INT_SIZE_IN_BYTES return data_size": 4648,
 "def clear_all ( self ) : self . injections . clear_all ( ) for config_file in CONFIG_FILES : self . injections . clear ( os . path . join ( \" ~ \" , config_file ) ) ": 4649,
 "def clear_worker_output ( self ) : self . data_store . clear_worker_output ( ) # Have the plugin manager reload all the plugins self . plugin_manager . load_all_plugins ( ) # Store information about commands and workbench self . _store_information ( ) ": 4650,
 "def tinsel ( to_patch , module_name , decorator = mock_decorator ) : def fn_decorator ( function ) : def wrapper ( *args , **kwargs ) : with patch ( to_patch , decorator ) : m = importlib . import_module ( module_name ) reload ( m ) function ( *args , **kwargs ) reload ( m ) return wrapper return fn_decorator": 4651,
 "def step_table_made ( self ) : try : empty = self . step_table . empty except AttributeError : empty = True return not empty": 4652,
 "def on_modified ( self , event ) : self . _logger . debug ( ' Detected modify event on watched path : %s ' , event . src_path ) self . _process_event ( event ) ": 4653,
 "def _modify ( item , func ) : result = dict ( ) for key in item : result[func ( key ) ] = item[key] return result": 4654,
 "def find_one_by_id ( self , _id ) : document = ( yield self . collection . find_one ( { \" _id \" : ObjectId ( _id ) } ) ) raise Return ( self . _obj_cursor_to_dictionary ( document ) ) ": 4655,
 "def _records_commit ( record_ids ) : for record_id in record_ids : record = Record . get_record ( record_id ) record . commit ( ) ": 4656,
 "def select_up ( self ) : r , c = self . _index self . _select_index ( r-1 , c ) ": 4657,
 "def _cast_to_type ( self , value ) : if isinstance ( value , str ) or value is None : return value return str ( value ) ": 4658,
 "def stop ( self , timeout = None ) : self . stopping = True for process in list ( self . processes ) : self . stop_process ( process , timeout = timeout ) ": 4659,
 "def _intermediary_to_dot ( tables , relationships ) : t = ' \\n ' . join ( t . to_dot ( ) for t in tables ) r = ' \\n ' . join ( r . to_dot ( ) for r in relationships ) return ' {}\\n{}\\n{}\\n}} ' . format ( GRAPH_BEGINNING , t , r ) ": 4660,
 "def getCursor ( self ) : \t\t\t\tif self . connection is None : \t\t\tself . Connect ( ) \t\t\t\t\treturn self . connection . cursor ( MySQLdb . cursors . DictCursor ) ": 4661,
 "def gaussian_distribution ( mean , stdev , num_pts = 50 ) : xstart = mean - ( 4 . 0 * stdev ) xend = mean + ( 4 . 0 * stdev ) x = np . linspace ( xstart , xend , num_pts ) y = ( 1 . 0/np . sqrt ( 2 . 0*np . pi*stdev*stdev ) ) * np . exp ( -1 . 0 * ( ( x - mean ) **2 ) / ( 2 . 0*stdev*stdev ) ) return x , y": 4662,
 "def new ( self , size , fill ) : return Image ( PIL . Image . new ( \" RGB \" , size , fill ) ) ": 4663,
 "def wheel ( delta = 1 ) : location = get_position ( ) e = Quartz . CGEventCreateMouseEvent ( None , Quartz . kCGEventScrollWheel , location , Quartz . kCGMouseButtonLeft ) e2 = Quartz . CGEventCreateScrollWheelEvent ( None , Quartz . kCGScrollEventUnitLine , 1 , delta ) Quartz . CGEventPost ( Quartz . kCGHIDEventTap , e ) Quartz . CGEventPost ( Quartz . kCGHIDEventTap , e2 ) ": 4664,
 "def header_length ( bytearray ) : groups_of_3 , leftover = divmod ( len ( bytearray ) , 3 ) # 4 bytes out for each 3 bytes ( or nonzero fraction thereof ) in . n = groups_of_3 * 4 if leftover : n + = 4 return n": 4665,
 "def setdict ( self , D ) : self . D = np . asarray ( D , dtype = self . dtype ) ": 4666,
 "def zoomed_scaled_array_around_mask ( self , mask , buffer = 1 ) : return self . new_with_array ( array = array_util . extracted_array_2d_from_array_2d_and_coordinates ( array_2d = self , y0 = mask . zoom_region[0]-buffer , y1 = mask . zoom_region[1]+buffer , x0 = mask . zoom_region[2]-buffer , x1 = mask . zoom_region[3]+buffer ) ) ": 4667,
 "def _download ( url ) : fh = StringIO ( ) for line in get ( url ) : fh . write ( line ) fh . seek ( 0 ) return fh": 4668,
 "def new_random_state ( seed = None , fully_random = False ) : if seed is None : if not fully_random : # sample manually a seed instead of just RandomState ( ) , # because the latter one # is way slower . seed = CURRENT_RANDOM_STATE . randint ( SEED_MIN_VALUE , SEED_MAX_VALUE , 1 ) [0] return np . random . RandomState ( seed ) ": 4669,
 "def _strip_empty_keys ( self , params ) : keys = [k for k , v in params . items ( ) if v = = ' ' ] for key in keys : del params[key]": 4670,
 "def click_by_selector ( self , selector ) : # No need for separate button press step with selector style . elem = find_element_by_jquery ( world . browser , selector ) elem . click ( ) ": 4671,
 "def set_attrs ( self ) : self . attrs . encoding = self . encoding self . attrs . errors = self . errors": 4672,
 "def update ( self , **kwargs ) : assert not self . called self . kw . update ( kwargs ) return self": 4673,
 "def stylize ( text , styles , reset = True ) : terminator = attr ( \" reset \" ) if reset else \" \" return \" {}{}{} \" . format ( \" \" . join ( styles ) , text , terminator ) ": 4674,
 "def _covariance_matrix ( self , type = ' noise ' ) : if type = = ' sampling ' : return self . sigma**2/ ( self . n-1 ) elif type = = ' noise ' : return 4*self . sigma*N . var ( self . rotated ( ) , axis = 0 ) ": 4675,
 "def get_all_names ( self ) : result = set ( ) for module in self . names : result . update ( set ( self . names[module] ) ) return result": 4676,
 "def camelcase2list ( s , lower = False ) : s = re . findall ( r ' ( [A-Z][a-z0-9]+ ) ' , s ) return [w . lower ( ) for w in s] if lower else s": 4677,
 "def get_active_window ( self ) : app = get_app ( ) try : return self . _active_window_for_cli[app] except KeyError : self . _active_window_for_cli[app] = self . _last_active_window or self . windows[0] return self . windows[0]": 4678,
 "def trivial_partition ( set_ ) : ensure_countable ( set_ ) result = ( ( x , ) for x in set_ ) return _harmonize_subset_types ( set_ , result ) ": 4679,
 "def inventory ( self , source_id , fetch = False , fmt = ' table ' ) : data_tables = {} t = self . query ( \" SELECT * FROM sqlite_master WHERE type = ' table ' \" , fmt = ' table ' ) all_tables = t[ ' name ' ] . tolist ( ) for table in [ ' sources ' ] + [t for t in all_tables if t not in [ ' sources ' , ' sqlite_sequence ' ]] : try : # Get the columns , pull out redundant ones , and query the table for this source ' s data t = self . query ( \" PRAGMA table_info ( {} ) \" . format ( table ) , fmt = ' table ' ) columns = np . array ( t[ ' name ' ] ) types = np . array ( t[ ' type ' ] ) if table = = ' sources ' or ' source_id ' in columns : # If printing , only get simple data types and exclude redundant ' source_id ' for nicer printing if not fetch : columns = columns[ ( ( types = = ' REAL ' ) | ( types = = ' INTEGER ' ) | ( types = = ' TEXT ' ) ) & ( columns ! = ' source_id ' ) ] # Query the table try : id = ' id ' if table . lower ( ) = = ' sources ' else ' source_id ' data = self . query ( \" SELECT {} FROM {} WHERE {} = {} \" . format ( ' , ' . join ( columns ) , table , id , source_id ) , fmt = ' table ' ) if not data and table . lower ( ) = = ' sources ' : print ( ' No source with id {} . Try db . search ( ) to search the database for a source_id . ' . format ( source_id ) ) except : data = None # If there ' s data for this table , save it if data : if fetch : data_tables[table] = self . query ( \" SELECT {} FROM {} WHERE {} = {} \" . format ( ' , ' . join ( columns ) , table , id , source_id ) , \\ fetch = True , fmt = fmt ) else : data = data[[c . lower ( ) for c in columns]] pprint ( data , title = table . upper ( ) ) else : pass except : print ( ' Could not retrieve data from {} table . ' . format ( table . upper ( ) ) ) if fetch : return data_tables": 4680,
 "def parse ( self , data , lexer = None , *args , **kwargs ) : if lexer is None : lexer = self . lexer return self . parser . parse ( data , lexer = lexer , *args , **kwargs ) ": 4681,
 "def coords_from_query ( query ) : try : coords = json . loads ( query ) except ValueError : vals = re . split ( r ' [ , \\s]+ ' , query . strip ( ) ) coords = [float ( v ) for v in vals] return tuple ( coords[ : 2] ) ": 4682,
 "def _parse_boolean ( value , default = False ) : if value is None : return default try : return bool ( value ) except ValueError : return default": 4683,
 "def ColumnToIndex ( col ) : ndx = 0 for c in col : ndx = ndx * 26 + ord ( c . upper ( ) ) - 64 return ndx": 4684,
 "def smartread ( path ) : with open ( path , \" rb \" ) as f : content = f . read ( ) result = chardet . detect ( content ) return content . decode ( result[ \" encoding \" ] ) ": 4685,
 "def get_data ( ) : # pretend we ' re measuring a noisy resonance at zero y = 1 . 0 / ( 1 . 0 + 1j* ( n_x . get_value ( ) -0 . 002 ) *1000 ) + _n . random . rand ( ) *0 . 1 # and that it takes time to do so _t . sleep ( 0 . 1 ) # return mag phase return abs ( y ) , _n . angle ( y , True ) ": 4686,
 "def _restore_seq_field_pickle ( checked_class , item_type , data ) : type_ = _seq_field_types[checked_class , item_type] return _restore_pickle ( type_ , data ) ": 4687,
 "def save ( self , f ) : return pickle . dump ( ( self . perceptron . weights , self . tagdict , self . classes , self . clusters ) , f , protocol = pickle . HIGHEST_PROTOCOL ) ": 4688,
 "def puts_err ( s = ' ' , newline = True , stream = STDERR ) : puts ( s , newline , stream ) ": 4689,
 "def image_to_texture ( image ) : vtex = vtk . vtkTexture ( ) vtex . SetInputDataObject ( image ) vtex . Update ( ) return vtex": 4690,
 "def write_to_file ( file_path , contents , encoding = \" utf-8 \" ) : with codecs . open ( file_path , \" w \" , encoding ) as f : f . write ( contents ) ": 4691,
 "def as_dict ( self ) : return { \" @module \" : self . __class__ . __module__ , \" @class \" : self . __class__ . __name__ , \" frequencies \" : list ( self . frequencies ) , \" densities \" : list ( self . densities ) }": 4692,
 "def is_floating ( self ) : return ( self . is_numpy_compatible and np . issubdtype ( self . as_numpy_dtype , np . floating ) ) or self . base_dtype = = bfloat16": 4693,
 "def hidden_cursor ( ) : if sys . stdout . isatty ( ) : _LOGGER . debug ( ' Hiding cursor . ' ) print ( ' \\x1B[?25l ' , end = ' ' ) sys . stdout . flush ( ) try : yield finally : if sys . stdout . isatty ( ) : _LOGGER . debug ( ' Showing cursor . ' ) print ( ' \\n\\x1B[?25h ' , end = ' ' ) sys . stdout . flush ( ) ": 4694,
 "def _join_masks_from_masked_array ( data ) : if not isinstance ( data . mask , np . ndarray ) : # workaround to handle mask compressed to single value mask = np . empty ( data . data . shape , dtype = np . bool ) mask . fill ( data . mask ) return mask mask = data . mask[0] . copy ( ) for i in range ( 1 , len ( data . mask ) ) : mask = np . logical_or ( mask , data . mask[i] ) return mask[np . newaxis , : , : ]": 4695,
 "def on_property_change ( self , name , old_value , new_value ) : if self . _registration is not None : # use the registration to trigger the service event self . _registration . set_properties ( {name : new_value} ) ": 4696,
 "def get_property ( self ) : scope = self def fget ( self ) : \" \" \" Call the HasProperties _get method \" \" \" return self . _get ( scope . name ) return property ( fget = fget , doc = scope . sphinx ( ) ) ": 4697,
 "def fopen ( name , mode = ' r ' , buffering = -1 ) : f = _fopen ( name , mode , buffering ) return _FileObjectThreadWithContext ( f , mode , buffering ) ": 4698,
 "def win32_refresh_window ( cls ) : # Get console handle handle = windll . kernel32 . GetConsoleWindow ( ) RDW_INVALIDATE = 0x0001 windll . user32 . RedrawWindow ( handle , None , None , c_uint ( RDW_INVALIDATE ) ) ": 4699,
 "def represented_args ( args , separator = \" \" ) : result = [] if args : for text in args : result . append ( quoted ( short ( text ) ) ) return separator . join ( result ) ": 4700,
 "def err ( msg ) : click . echo ( click . style ( msg , fg = \" red \" , bold = True ) ) ": 4701,
 "async def power ( source , exponent ) : async with streamcontext ( source ) as streamer : async for item in streamer : yield item ** exponent": 4702,
 "def startEdit ( self ) : self . _originalText = self . text ( ) self . scrollWidget ( ) . hide ( ) self . setFocus ( ) self . selectAll ( ) ": 4703,
 "def _clean_workers ( self ) : while self . _bag_collector : self . _bag_collector . popleft ( ) self . _timer_worker_delete . stop ( ) ": 4704,
 "def attach_to_container ( self , container_id ) : sock = self . _docker . containers . get ( container_id ) . attach_socket ( params = { ' stdin ' : 1 , ' stdout ' : 1 , ' stderr ' : 0 , ' stream ' : 1 , } ) # fix a problem with docker-py; we must keep a reference of sock at every time return FixDockerSocket ( sock ) ": 4705,
 "def save_list ( key , *values ) : return json . dumps ( {key : [_get_json ( value ) for value in values]} ) ": 4706,
 "def validate ( schema , data , owner = None ) : schema . _validate ( data = data , owner = owner ) ": 4707,
 "def make_key ( self , key , version = None ) : return ' {} : {} : {} ' . format ( self . prefix , version or self . version , key , ) ": 4708,
 "def confusion_matrix ( links_true , links_pred , total = None ) : links_true = _get_multiindex ( links_true ) links_pred = _get_multiindex ( links_pred ) tp = true_positives ( links_true , links_pred ) fp = false_positives ( links_true , links_pred ) fn = false_negatives ( links_true , links_pred ) if total is None : tn = numpy . nan else : tn = true_negatives ( links_true , links_pred , total ) return numpy . array ( [[tp , fn] , [fp , tn]] ) ": 4709,
 "def lpush ( self , key , *args ) : redis_list = self . _get_list ( key , ' LPUSH ' , create = True ) # Creates the list at this key if it doesn ' t exist , and appends args to its beginning args_reversed = [self . _encode ( arg ) for arg in args] args_reversed . reverse ( ) updated_list = args_reversed + redis_list self . redis[self . _encode ( key ) ] = updated_list # Return the length of the list after the push operation return len ( updated_list ) ": 4710,
 "def connect ( self ) : self . client = redis . Redis ( host = self . host , port = self . port , password = self . password ) ": 4711,
 "def __init__ ( self , node_def , op , message ) : super ( InvalidArgumentError , self ) . __init__ ( node_def , op , message , INVALID_ARGUMENT ) ": 4712,
 "def substitute ( dict_ , source ) : d_esc = ( re . escape ( k ) for k in dict_ . keys ( ) ) pattern = re . compile ( ' | ' . join ( d_esc ) ) return pattern . sub ( lambda x : dict_[x . group ( ) ] , source ) ": 4713,
 "def parse_scale ( x ) : match = re . match ( r ' ^ ( . +? ) : ( \\d+ ) $ ' , x ) if not match : raise ValueError ( ' Invalid scale \" %s \" . ' % x ) return match . group ( 1 ) , int ( match . group ( 2 ) ) ": 4714,
 "def read_raw ( data_path ) : with open ( data_path , ' rb ' ) as f : data = pickle . load ( f ) return data": 4715,
 "def _series_col_letter ( self , series ) : column_number = 1 + series . categories . depth + series . index return self . _column_reference ( column_number ) ": 4716,
 "def __del__ ( self ) : # __del__ can be invoked before __init__ has completed . if hasattr ( self , ' _encoded_stream ' ) : self . _encoded_stream . close ( ) self . _encoded_stream = None super ( EncodedStreamFileEntry , self ) . __del__ ( ) ": 4717,
 "def slugify ( s , delimiter = ' - ' ) : s = unicodedata . normalize ( ' NFKD ' , to_unicode ( s ) ) . encode ( ' ascii ' , ' ignore ' ) . decode ( ' ascii ' ) return RE_SLUG . sub ( delimiter , s ) . strip ( delimiter ) . lower ( ) ": 4718,
 "def dict_keys_without_hyphens ( a_dict ) : return dict ( ( key . replace ( ' - ' , ' _ ' ) , val ) for key , val in a_dict . items ( ) ) ": 4719,
 "def _preprocess ( df ) : df = df . stack ( ) df . index . rename ( [ \" id \" , \" time \" ] , inplace = True ) # . reset_index ( ) df . name = \" value \" df = df . reset_index ( ) return df": 4720,
 "def template_substitute ( text , **kwargs ) : for name , value in kwargs . items ( ) : placeholder_pattern = \" {%s} \" % name if placeholder_pattern in text : text = text . replace ( placeholder_pattern , value ) return text": 4721,
 "def fillna ( series_or_arr , missing_value = 0 . 0 ) : if pandas . notnull ( missing_value ) : if isinstance ( series_or_arr , ( numpy . ndarray ) ) : series_or_arr[numpy . isnan ( series_or_arr ) ] = missing_value else : series_or_arr . fillna ( missing_value , inplace = True ) return series_or_arr": 4722,
 "def reset_namespace ( self ) : self . shellwidget . reset_namespace ( warning = self . reset_warning , message = True ) ": 4723,
 "def input_yn ( conf_mess ) : ui_erase_ln ( ) ui_print ( conf_mess ) with term . cbreak ( ) : input_flush ( ) val = input_by_key ( ) return bool ( val . lower ( ) = = ' y ' ) ": 4724,
 "def _send_cmd ( self , cmd ) : self . _process . stdin . write ( \" {}\\n \" . format ( cmd ) . encode ( \" utf-8 \" ) ) self . _process . stdin . flush ( ) ": 4725,
 "def from_rotation_vector ( rot ) : rot = np . array ( rot , copy = False ) quats = np . zeros ( rot . shape[ : -1]+ ( 4 , ) ) quats[ . . . , 1 : ] = rot[ . . . ]/2 quats = as_quat_array ( quats ) return np . exp ( quats ) ": 4726,
 "def rq_job ( self ) : if not self . rq_id or not self . rq_origin : return try : return RQJob . fetch ( self . rq_id , connection = get_connection ( self . rq_origin ) ) except NoSuchJobError : return": 4727,
 "def set_sig_figs ( n = 4 ) : u . default_format = ' . ' + str ( n ) + ' g ' pd . options . display . float_format = ( ' { : , . ' + str ( n ) + ' } ' ) . format": 4728,
 "def _chunks ( l , n ) : for i in xrange ( 0 , len ( l ) , n ) : yield l[i : i+n]": 4729,
 "def run_hive_script ( script ) : if not os . path . isfile ( script ) : raise RuntimeError ( \" Hive script : {0} does not exist . \" . format ( script ) ) return run_hive ( [ ' -f ' , script] ) ": 4730,
 "def dump_to_log ( self , logger ) : logger . error ( \" Execution ended in %s for cmd %s \" , self . _retcode , self . _cmd ) for line in self . _collected_stdout : logger . error ( STDOUT_LOG_PREFIX + line ) ": 4731,
 "def set_file_mtime ( path , mtime , atime = None ) : if not atime : atime = mtime f = open ( path , ' a ' ) try : os . utime ( path , ( atime , mtime ) ) finally : f . close ( ) ": 4732,
 "def print_verbose ( *args , **kwargs ) : if kwargs . pop ( ' verbose ' , False ) is True : gprint ( *args , **kwargs ) ": 4733,
 "def clean_colnames ( df ) : col_list = [] for index in range ( _dutils . cols ( df ) ) : col_list . append ( df . columns[index] . strip ( ) . lower ( ) . replace ( ' ' , ' _ ' ) ) df . columns = col_list": 4734,
 "def trapz2 ( f , x = None , y = None , dx = 1 . 0 , dy = 1 . 0 ) : return numpy . trapz ( numpy . trapz ( f , x = y , dx = dy ) , x = x , dx = dx ) ": 4735,
 "def set_attr ( self , name , value ) : self . exec_script ( \" node . setAttribute ( %s , %s ) \" % ( repr ( name ) , repr ( value ) ) ) ": 4736,
 "def _set_tab_width ( self , tab_width ) : font_metrics = QtGui . QFontMetrics ( self . font ) self . _control . setTabStopWidth ( tab_width * font_metrics . width ( ' ' ) ) self . _tab_width = tab_width": 4737,
 "def get_shape_mask ( self , shape_obj ) : wd , ht = self . get_size ( ) yi = np . mgrid[ : ht] . reshape ( -1 , 1 ) xi = np . mgrid[ : wd] . reshape ( 1 , -1 ) pts = np . asarray ( ( xi , yi ) ) . T contains = shape_obj . contains_pts ( pts ) return contains": 4738,
 "def move ( self , x , y ) : self . _cursor = self . _normalizePoint ( x , y ) ": 4739,
 "def ignore_comments ( iterator ) : for line in iterator : line = COMMENT_RE . sub ( ' ' , line ) line = line . strip ( ) if line : yield line": 4740,
 "def include_raw_constructor ( self , loader , node ) : path = convert_path ( node . value ) with open ( path , ' r ' ) as f : config = f . read ( ) config = self . inject_include_info ( path , config , include_type = ' include-raw ' ) self . add_file ( path , config ) return config": 4741,
 "def send ( self , *args , **kwargs ) : self . write ( *args , **kwargs ) self . flush ( ) ": 4742,
 "def parsePoint ( line ) : values = [float ( s ) for s in line . split ( ' ' ) ] if values[0] = = -1 : # Convert -1 labels to 0 for MLlib values[0] = 0 return LabeledPoint ( values[0] , values[1 : ] ) ": 4743,
 "def _file_chunks ( self , data , chunk_size ) : for i in xrange ( 0 , len ( data ) , chunk_size ) : yield self . compressor ( data[i : i+chunk_size] ) ": 4744,
 "def update ( table , values , where = ( ) , **kwargs ) : where = dict ( where , **kwargs ) . items ( ) sql , args = makeSQL ( \" UPDATE \" , table , values = values , where = where ) return execute ( sql , args ) . rowcount": 4745,
 "def get_least_distinct_words ( vocab , topic_word_distrib , doc_topic_distrib , doc_lengths , n = None ) : return _words_by_distinctiveness_score ( vocab , topic_word_distrib , doc_topic_distrib , doc_lengths , n , least_to_most = True ) ": 4746,
 "def delete ( self , key_name ) : self . db . remove ( Query ( ) . name = = key_name ) return self . get ( key_name ) = = {}": 4747,
 "def teardown ( self ) : for table_spec in reversed ( self . _table_specs ) : with self . _conn : table_spec . teardown ( self . _conn ) ": 4748,
 "def show_intro ( self ) : from IPython . core . usage import interactive_usage self . main . help . show_rich_text ( interactive_usage ) ": 4749,
 "def is_array ( self , key ) : data = self . model . get_data ( ) return isinstance ( data[key] , ( ndarray , MaskedArray ) ) ": 4750,
 "def stop ( self ) : with self . lock : for dummy in self . threads : self . queue . put ( None ) ": 4751,
 "def _date_to_json ( value ) : if isinstance ( value , datetime . date ) : value = value . isoformat ( ) return value": 4752,
 "def _insert_row ( self , i , index ) : if i = = len ( self . _index ) : self . _add_row ( index ) else : self . _index . insert ( i , index ) self . _data . insert ( i , None ) ": 4753,
 "def unpack_from ( self , data , offset = 0 ) : return tuple ( [v[1] for v in self . unpack_from_any ( data , offset ) ] ) ": 4754,
 "def super_lm_tpu_memtest ( ) : hparams = super_lm_base ( ) hparams . num_model_shards = 1 hparams . layers = \" ffn , \" * 8 hparams . hidden_size = 4096 hparams . filter_size = 12000 hparams . batch_size = 512 return hparams": 4755,
 "def mod ( value , arg ) : try : return valid_numeric ( value ) % valid_numeric ( arg ) except ( ValueError , TypeError ) : try : return value % arg except Exception : return ' ' ": 4756,
 "def excepthook ( self , etype , value , tb ) : self . showtraceback ( ( etype , value , tb ) , tb_offset = 0 ) ": 4757,
 "def if_ ( *args ) : for i in range ( 0 , len ( args ) - 1 , 2 ) : if args[i] : return args[i + 1] if len ( args ) % 2 : return args[-1] else : return None": 4758,
 "def compute_jaccard_index ( x_set , y_set ) : if not x_set or not y_set : return 0 . 0 intersection_cardinal = len ( x_set & y_set ) union_cardinal = len ( x_set | y_set ) return intersection_cardinal / float ( union_cardinal ) ": 4759,
 "def inverse_jacobian ( self , maps ) : m1 = maps[parameters . mass1] m2 = maps[parameters . mass2] mchirp = conversions . mchirp_from_mass1_mass2 ( m1 , m2 ) eta = conversions . eta_from_mass1_mass2 ( m1 , m2 ) return -1 . * mchirp / eta** ( 6 . /5 ) ": 4760,
 "def dimension_size ( x , axis ) : # Since tf . gather isn ' t \" constant-in , constant-out \" , we must first check the # static shape or fallback to dynamic shape . s = tf . compat . dimension_value ( tensorshape_util . with_rank_at_least ( x . shape , np . abs ( axis ) ) [axis] ) if s is not None : return s return tf . shape ( input = x ) [axis]": 4761,
 "def encode_to_shape ( inputs , shape , scope ) : with tf . variable_scope ( scope , reuse = tf . AUTO_REUSE ) : w , h = shape[1] , shape[2] x = inputs x = tfl . flatten ( x ) x = tfl . dense ( x , w * h , activation = None , name = \" enc_dense \" ) x = tf . reshape ( x , ( -1 , w , h , 1 ) ) return x": 4762,
 "def load_parameters ( self , source ) : with open ( source ) as parameters_source : return json . loads ( parameters_source . read ( ) ) ": 4763,
 "def list ( self , table , **kparams ) : result = self . table_api_get ( table , **kparams ) return self . to_records ( result , table ) ": 4764,
 "def join ( self ) : for thread in self . worker_threads : thread . join ( ) WorkerThread . join ( self ) ": 4765,
 "def timedelta_seconds ( timedelta ) : return ( timedelta . total_seconds ( ) if hasattr ( timedelta , \" total_seconds \" ) else timedelta . days * 24 * 3600 + timedelta . seconds + timedelta . microseconds / 1000000 . ) ": 4766,
 "def clean ( self ) : return Text ( self . __text_cleaner . clean ( self[TEXT] ) , **self . __kwargs ) ": 4767,
 "def load_object_at_path ( path ) : with open ( path , ' r ' ) as f : data = _deserialize ( f . read ( ) ) return aadict ( data ) ": 4768,
 "def update_menu ( self ) : self . menu . clear ( ) add_actions ( self . menu , self . create_context_menu_actions ( ) ) ": 4769,
 "def show_tip ( self , tip = \" \" ) : QToolTip . showText ( self . mapToGlobal ( self . pos ( ) ) , tip , self ) ": 4770,
 "def setup_environment ( ) : osinter = ostool . get_interface ( ) pypath = osinter . get_maya_envpath ( ) for p in sys . path : pypath = os . pathsep . join ( ( pypath , p ) ) os . environ[ ' PYTHONPATH ' ] = pypath": 4771,
 "def focusInEvent ( self , event ) : self . focus_changed . emit ( ) return super ( ShellWidget , self ) . focusInEvent ( event ) ": 4772,
 "def get_focused_window_sane ( self ) : window_ret = window_t ( 0 ) _libxdo . xdo_get_focused_window_sane ( self . _xdo , ctypes . byref ( window_ret ) ) return window_ret . value": 4773,
 "def flush_on_close ( self , stream ) : assert get_thread_ident ( ) = = self . ioloop_thread_id # Prevent futher writes stream . KATCPServer_closing = True # Write empty message to get future that resolves when buffer is flushed return stream . write ( ' \\n ' ) ": 4774,
 "def write_json_response ( self , response ) : self . write ( tornado . escape . json_encode ( response ) ) self . set_header ( \" Content-Type \" , \" application/json \" ) ": 4775,
 "def _ndarray_representer ( dumper , data ) : mapping = [ ( ' object ' , data . tolist ( ) ) , ( ' dtype ' , data . dtype . name ) ] return dumper . represent_mapping ( _NUMPY_ARRAY_TAG , mapping ) ": 4776,
 "def tuple ( self , var , cast = None , default = NOTSET ) : return self . get_value ( var , cast = tuple if not cast else ( cast , ) , default = default ) ": 4777,
 "def coverage ( ctx , opts = \" \" ) : return test ( ctx , coverage = True , include_slow = True , opts = opts ) ": 4778,
 "def minify ( path ) : if ' http ' in path : data = requests . get ( path ) . content . decode ( ' ascii ' , errors = ' ignore ' ) else : with open ( path , ' rb ' ) as f : # some of these assholes use unicode spaces -_- data = f . read ( ) . decode ( ' ascii ' , errors = ' ignore ' ) # don ' t re- minify if ' . min . ' in path : return data try : return jsmin . jsmin ( data ) except BaseException : return data": 4779,
 "def _upper ( val_list ) : res = [] for ele in val_list : res . append ( ele . upper ( ) ) return res": 4780,
 "async def write_register ( self , address , value , skip_encode = False ) : await self . _request ( ' write_registers ' , address , value , skip_encode = skip_encode ) ": 4781,
 "def with_args ( self , *args , **kwargs ) : self . args = args self . kwargs = kwargs self . verify_arguments ( ) return self": 4782,
 "def minify_js ( input_files , output_file ) : from . modules import minify , utils if not isinstance ( input_files , ( list , tuple ) ) : raise RuntimeError ( ' JS minifier takes a list of input files . ' ) return { ' dependencies_fn ' : utils . no_dependencies , ' compiler_fn ' : minify . minify_js , ' input ' : input_files , ' output ' : output_file , ' kwargs ' : {} , }": 4783,
 "def get_img_data ( f , maxsize = ( 1200 , 850 ) , first = False ) : img = Image . open ( f ) img . thumbnail ( maxsize ) if first : # tkinter is inactive the first time bio = io . BytesIO ( ) img . save ( bio , format = \" PNG \" ) del img return bio . getvalue ( ) return ImageTk . PhotoImage ( img ) ": 4784,
 "def serve ( application , host = ' 127 . 0 . 0 . 1 ' , port = 8080 , threads = 4 , **kw ) : \t\t\t # Bind and start the server; this is a blocking process . \tserve_ ( application , host = host , port = int ( port ) , threads = int ( threads ) , **kw ) ": 4785,
 "def run_migration ( connection , queries , engine ) : # Execute query with connection . cursor ( ) as cursorMig : # Parse statements queries = parse_statements ( queries , engine ) for query in queries : cursorMig . execute ( query ) connection . commit ( ) return True": 4786,
 "def LogBinomialCoef ( n , k ) : return n * log ( n ) - k * log ( k ) - ( n - k ) * log ( n - k ) ": 4787,
 "def clean_text_by_sentences ( text , language = \" english \" , additional_stopwords = None ) : init_textcleanner ( language , additional_stopwords ) original_sentences = split_sentences ( text ) filtered_sentences = filter_words ( original_sentences ) return merge_syntactic_units ( original_sentences , filtered_sentences ) ": 4788,
 "def return_future ( fn ) : @wraps ( fn ) def decorated ( *args , **kwargs ) : return gen . maybe_future ( fn ( *args , **kwargs ) ) return decorated": 4789,
 "def neo ( graph : BELGraph , connection : str , password : str ) : import py2neo neo_graph = py2neo . Graph ( connection , password = password ) to_neo4j ( graph , neo_graph ) ": 4790,
 "def has_next_async ( self ) : if self . _fut is None : self . _fut = self . _iter . getq ( ) flag = True try : yield self . _fut except EOFError : flag = False raise tasklets . Return ( flag ) ": 4791,
 "def WritePythonFile ( file_descriptor , package , version , printer ) : _WriteFile ( file_descriptor , package , version , _ProtoRpcPrinter ( printer ) ) ": 4792,
 "def dumps ( obj , indent = None , default = None , sort_keys = False , **kw ) : return YAMLEncoder ( indent = indent , default = default , sort_keys = sort_keys , **kw ) . encode ( obj ) ": 4793,
 "def close_session ( self ) : with self . _graph . as_default ( ) : self . _sess . close ( ) self . _sess = None": 4794,
 "def scale_min ( im , targ , interpolation = cv2 . INTER_AREA ) : r , c , *_ = im . shape ratio = targ/min ( r , c ) sz = ( scale_to ( c , ratio , targ ) , scale_to ( r , ratio , targ ) ) return cv2 . resize ( im , sz , interpolation = interpolation ) ": 4795,
 "def json_pretty_dump ( obj , filename ) : with open ( filename , \" wt \" ) as fh : json . dump ( obj , fh , indent = 4 , sort_keys = 4 ) ": 4796,
 "def dump ( self , *args , **kwargs ) : lxml . etree . dump ( self . _obj , *args , **kwargs ) ": 4797,
 "def parse ( text , showToc = True ) : \t\tp = Parser ( show_toc = showToc ) \treturn p . parse ( text ) ": 4798,
 "def clearImg ( self ) : self . img . setImage ( np . array ( [[0]] ) ) self . img . image = None": 4799,
 "def sql ( self , sql : str , *qmark_params , **named_params ) : statement = SingleSqlStatement ( sql ) return self . statement ( statement ) . execute ( *qmark_params , **named_params ) ": 4800,
 "def trigger_installed ( connection : connection , table : str , schema : str = ' public ' ) : installed = False log ( ' Checking if {} . {} trigger installed . . . ' . format ( schema , table ) , logger_name = _LOGGER_NAME ) statement = SELECT_TRIGGER_STATEMENT . format ( table = table , schema = schema ) result = execute ( connection , statement ) if result : installed = True log ( ' . . . {}installed ' . format ( ' ' if installed else ' NOT ' ) , logger_name = _LOGGER_NAME ) return installed": 4801,
 "def stack_as_string ( ) : if sys . version_info . major = = 3 : stack = io . StringIO ( ) else : stack = io . BytesIO ( ) traceback . print_stack ( file = stack ) stack . seek ( 0 ) stack = stack . read ( ) return stack": 4802,
 "def is_standalone ( self ) : return ( not self . args . client and not self . args . browser and not self . args . server and not self . args . webserver ) ": 4803,
 "def reload ( self , save_config = True ) : if save_config : self . device . send ( \" copy running-config startup-config \" ) self . device ( \" reload \" , wait_for_string = \" This command will reboot the system \" ) self . device . ctrl . sendline ( \" y \" ) ": 4804,
 "def addfield ( self , pkt , buf , val ) : self . set_endianess ( pkt ) return self . fld . addfield ( pkt , buf , val ) ": 4805,
 "def MessageToDict ( message , including_default_value_fields = False , preserving_proto_field_name = False ) : printer = _Printer ( including_default_value_fields , preserving_proto_field_name ) # pylint : disable = protected-access return printer . _MessageToJsonObject ( message ) ": 4806,
 "def have_pyrex ( ) : pyrex_impls = ' Cython . Distutils . build_ext ' , ' Pyrex . Distutils . build_ext ' for pyrex_impl in pyrex_impls : try : # from ( pyrex_impl ) import build_ext __import__ ( pyrex_impl , fromlist = [ ' build_ext ' ] ) . build_ext return True except Exception : pass return False": 4807,
 "def reverse_transform ( self , col ) : output = pd . DataFrame ( ) output[self . col_name] = self . get_category ( col[self . col_name] ) return output": 4808,
 "def columnclean ( column ) : cleanedcolumn = str ( column ) \\ . replace ( ' % ' , ' percent ' ) \\ . replace ( ' ( ' , ' _ ' ) \\ . replace ( ' ) ' , ' ' ) \\ . replace ( ' As ' , ' Adenosines ' ) \\ . replace ( ' Cs ' , ' Cytosines ' ) \\ . replace ( ' Gs ' , ' Guanines ' ) \\ . replace ( ' Ts ' , ' Thymines ' ) \\ . replace ( ' Ns ' , ' Unknowns ' ) \\ . replace ( ' index ' , ' adapterIndex ' ) return cleanedcolumn": 4809,
 "def strip_tweet ( text , remove_url = True ) : if remove_url : text = url_pattern . sub ( ' ' , text ) else : text = expand_url ( text ) text = mention_pattern . sub ( ' ' , text ) text = html_parser . unescape ( text ) text = text . strip ( ) return text": 4810,
 "def makeBiDirectional ( d ) : dTmp = d . copy ( ) for k in d : dTmp[d[k]] = k return dTmp": 4811,
 "def fillScreen ( self , color = None ) : md . fill_rect ( self . set , 0 , 0 , self . width , self . height , color ) ": 4812,
 "def __unroll ( self , rolled ) : return np . array ( np . concatenate ( [matrix . flatten ( ) for matrix in rolled] , axis = 1 ) ) . reshape ( -1 ) ": 4813,
 "def downgrade ( ) : op . drop_table ( ' transaction ' ) if op . _proxy . migration_context . dialect . supports_sequences : op . execute ( DropSequence ( Sequence ( ' transaction_id_seq ' ) ) ) ": 4814,
 "def iparallel_progbar ( mapper , iterable , nprocs = None , starmap = False , flatmap = False , shuffle = False , verbose = True , verbose_flatmap = None , max_cache = -1 , **kwargs ) : results = _parallel_progbar_launch ( mapper , iterable , nprocs , starmap , flatmap , shuffle , verbose , verbose_flatmap , max_cache , **kwargs ) return ( x for i , x in results ) ": 4815,
 "def resource_property ( klass , name , **kwargs ) : klass . PROPERTIES[name] = kwargs def getter ( self ) : return getattr ( self , ' _%s ' % name , kwargs . get ( ' default ' , None ) ) if kwargs . get ( ' readonly ' , False ) : setattr ( klass , name , property ( getter ) ) else : def setter ( self , value ) : setattr ( self , ' _%s ' % name , value ) setattr ( klass , name , property ( getter , setter ) ) ": 4816,
 "def get_single_file_info ( self , rel_path ) : f_path = self . get_full_file_path ( rel_path ) return get_single_file_info ( f_path , rel_path ) ": 4817,
 "def __len__ ( self ) : \t\t\t\treturn len ( [i for i in ( set ( dir ( self ) ) - self . _STANDARD_ATTRS ) if i[0] ! = ' _ ' ] ) ": 4818,
 "def str2bool ( value ) : if value . lower ( ) in ( ' yes ' , ' true ' , ' t ' , ' y ' , ' 1 ' ) : return True if value . lower ( ) in ( ' no ' , ' false ' , ' f ' , ' n ' , ' 0 ' ) : return False if value . lower ( ) in ( ' d ' , ' default ' , ' ' ) : return None raise argparse . ArgumentTypeError ( ' Expected : ( Y ) es/ ( T ) rue/ ( N ) o/ ( F ) alse/ ( D ) efault ' ) ": 4819,
 "def add_option ( self , *args , **kwargs ) : if self . parseTool = = ' argparse ' : if args and args[0] = = ' ' : # no short option args = args[1 : ] return self . parser . add_argument ( *args , **kwargs ) else : return self . parser . add_option ( *args , **kwargs ) ": 4820,
 "async def unignore_all ( self , ctx ) : channels = [c for c in ctx . message . server . channels if c . type is discord . ChannelType . text] await ctx . invoke ( self . unignore , *channels ) ": 4821,
 "def async_update ( self , event ) : self . update_attr ( event . get ( ' state ' , {} ) ) super ( ) . async_update ( event ) ": 4822,
 "def resize ( self ) : resized_size = self . get_resized_size ( ) if not resized_size : return self . image = self . image . resize ( resized_size , Image . ANTIALIAS ) ": 4823,
 "def read_full ( stream ) : assert stream , \" stream is required \" chunks = [] chunk = yield stream . read ( ) while chunk : chunks . append ( chunk ) chunk = yield stream . read ( ) raise tornado . gen . Return ( b ' ' . join ( chunks ) ) ": 4824,
 "def list_to_csv ( my_list , csv_file ) : if PY3 : csv_handler = open ( csv_file , ' w ' , newline = ' ' ) else : csv_handler = open ( csv_file , ' wb ' ) try : writer = csv . writer ( csv_handler , delimiter = ' , ' , quoting = csv . QUOTE_ALL ) writer . writerows ( my_list ) finally : csv_handler . close ( ) ": 4825,
 "def set_xticks_for_all ( self , row_column_list = None , ticks = None ) : if row_column_list is None : self . ticks[ ' x ' ] = ticks else : for row , column in row_column_list : self . set_xticks ( row , column , ticks ) ": 4826,
 "def optional ( self , value = None ) : \t\t\t\t # If there ' s no value , this is a getter\t\tif value is None : \t\t\treturn this . _optional\t\t # Else , set the flag\t\telse : \t\t\tthis . _optional = value and True or False": 4827,
 "def into2dBlocks ( arr , n0 , n1 ) : s0 , s1 = arr . shape b = blockshaped ( arr , s0// n0 , s1// n1 ) return b . reshape ( n0 , n1 , *b . shape[1 : ] ) ": 4828,
 "def libpath ( self ) : from os import path return path . join ( self . dirpath , self . libname ) ": 4829,
 "def RandomShuffle ( a , seed ) : if seed : np . random . seed ( seed ) r = a . copy ( ) np . random . shuffle ( r ) return r , ": 4830,
 "def day_to_month ( timeperiod ) : t = datetime . strptime ( timeperiod , SYNERGY_DAILY_PATTERN ) return t . strftime ( SYNERGY_MONTHLY_PATTERN ) ": 4831,
 "def get_cached_data ( datatable , **kwargs ) : cache_key = ' %s%s ' % ( CACHE_PREFIX , datatable . get_cache_key ( **kwargs ) ) data = cache . get ( cache_key ) log . debug ( \" Reading data from cache at %r : %r \" , cache_key , data ) return data": 4832,
 "def _process_and_sort ( s , force_ascii , full_process = True ) : # pull tokens ts = utils . full_process ( s , force_ascii = force_ascii ) if full_process else s tokens = ts . split ( ) # sort tokens and join sorted_string = u \" \" . join ( sorted ( tokens ) ) return sorted_string . strip ( ) ": 4833,
 "def set_primary_key ( self , table , column ) : self . execute ( ' ALTER TABLE {0} ADD PRIMARY KEY ( {1} ) ' . format ( wrap ( table ) , column ) ) self . _printer ( ' \\tAdded primary key to {0} on column {1} ' . format ( wrap ( table ) , column ) ) ": 4834,
 "def is_primary ( self ) : return isinstance ( self . _key , Primary ) and not isinstance ( self . _key , Sub ) ": 4835,
 "def getCenter ( self ) : return Location ( self . x+ ( self . w/2 ) , self . y+ ( self . h/2 ) ) ": 4836,
 "def styles ( self , dictobj ) : \t\t\t\tfor k in dictobj : \t\t\tself . chart_style[k] = dictobj[k]": 4837,
 "def flipwritable ( fn , mode = None ) : if os . access ( fn , os . W_OK ) : return None old_mode = os . stat ( fn ) . st_mode os . chmod ( fn , stat . S_IWRITE | old_mode ) return old_mode": 4838,
 "def synth_hangul ( string ) : raise NotImplementedError return ' ' . join ( [ ' ' . join ( ' ' . join ( jamo_to_hcj ( _ ) ) for _ in string ) ] ) ": 4839,
 "def equal ( x , y ) : x = BigFloat . _implicit_convert ( x ) y = BigFloat . _implicit_convert ( y ) return mpfr . mpfr_equal_p ( x , y ) ": 4840,
 "def load_from_file ( module_path ) : from imp import load_module , PY_SOURCE imported = None if module_path : with open ( module_path , ' r ' ) as openfile : imported = load_module ( ' mod ' , openfile , module_path , ( ' imported ' , ' r ' , PY_SOURCE ) ) return imported": 4841,
 "def qth_pw ( self , q ) : return heapq . nlargest ( q + 2 , self . _T . iteritems ( ) , key = operator . itemgetter ( 1 ) ) [-1]": 4842,
 "def remote_file_exists ( self , url ) : status = requests . head ( url ) . status_code if status ! = 200 : raise RemoteFileDoesntExist": 4843,
 "def do_last ( environment , seq ) : try : return next ( iter ( reversed ( seq ) ) ) except StopIteration : return environment . undefined ( ' No last item , sequence was empty . ' ) ": 4844,
 "def toarray ( self ) : rdd = self . _rdd . map ( lambda x : x . toarray ( ) ) return np . concatenate ( rdd . collect ( ) ) ": 4845,
 "def ishex ( obj ) : return isinstance ( obj , str ) and ( len ( obj ) = = 1 ) and ( obj in string . hexdigits ) ": 4846,
 "def post_tweet ( user_id , message , additional_params = {} ) : url = \" https : //api . twitter . com/1 . 1/statuses/update . json \" params = { \" status \" : message } params . update ( additional_params ) r = make_twitter_request ( url , user_id , params , request_type = ' POST ' ) print ( r . text ) return \" Successfully posted a tweet {} \" . format ( message ) ": 4847,
 "def _config_section ( config , section ) : path = os . path . join ( config . get ( ' config_path ' ) , config . get ( ' config_file ' ) ) conf = _config_ini ( path ) return conf . get ( section ) ": 4848,
 "def setConfigKey ( key , value ) : \t\t\t\tconfigFile = ConfigurationManager . _configFile ( ) \t\treturn JsonDataManager ( configFile ) . setKey ( key , value ) ": 4849,
 "def getBitmap ( self ) : return PlatformManager . getBitmapFromRect ( self . x , self . y , self . w , self . h ) ": 4850,
 "def _removeLru ( self ) : ( dataFile , handle ) = self . _cache . pop ( ) handle . close ( ) return dataFile": 4851,
 "def eval ( e , amplitude , e_0 , alpha , beta ) : ee = e / e_0 eeponent = -alpha - beta * np . log ( ee ) return amplitude * ee ** eeponent": 4852,
 "def visit_ellipsis ( self , node , parent ) : return nodes . Ellipsis ( getattr ( node , \" lineno \" , None ) , getattr ( node , \" col_offset \" , None ) , parent ) ": 4853,
 "def track_update ( self ) : metadata = self . info ( ) metadata . updated_at = dt . datetime . now ( ) self . commit ( ) ": 4854,
 "def strip_comment_marker ( text ) : lines = [] for line in text . splitlines ( ) : lines . append ( line . lstrip ( ' # ' ) ) text = textwrap . dedent ( ' \\n ' . join ( lines ) ) return text": 4855,
 "def is_cyclic ( graph ) : path = set ( ) def visit ( vertex ) : path . add ( vertex ) for neighbour in graph . get ( vertex , ( ) ) : if neighbour in path or visit ( neighbour ) : return True path . remove ( vertex ) return False return any ( visit ( v ) for v in graph ) ": 4856,
 "def scale_v2 ( vec , amount ) : return Vec2 ( vec . x * amount , vec . y * amount ) ": 4857,
 "def is_adb_detectable ( self ) : serials = list_adb_devices ( ) if self . serial in serials : self . log . debug ( ' Is now adb detectable . ' ) return True return False": 4858,
 "def subsystem ( s ) : node_states ( s . state ) cut ( s . cut , s . cut_indices ) if config . VALIDATE_SUBSYSTEM_STATES : state_reachable ( s ) return True": 4859,
 "def _truncate_colormap ( cmap , minval = 0 . 0 , maxval = 1 . 0 , n = 100 ) : new_cmap = LinearSegmentedColormap . from_list ( ' trunc ( {n} , {a : . 2f} , {b : . 2f} ) ' . format ( n = cmap . name , a = minval , b = maxval ) , cmap ( numpy . linspace ( minval , maxval , n ) ) ) return new_cmap": 4860,
 "def _tool_to_dict ( tool ) : out = { \" name \" : _id_to_name ( tool . tool[ \" id \" ] ) , \" baseCommand \" : \" \" . join ( tool . tool[ \" baseCommand \" ] ) , \" arguments \" : [] , \" inputs \" : [_input_to_dict ( i ) for i in tool . tool[ \" inputs \" ]] , \" outputs \" : [_output_to_dict ( o ) for o in tool . tool[ \" outputs \" ]] , \" requirements \" : _requirements_to_dict ( tool . requirements + tool . hints ) , \" stdin \" : None , \" stdout \" : None} return out": 4861,
 "def is_instance_or_subclass ( val , class_ ) : try : return issubclass ( val , class_ ) except TypeError : return isinstance ( val , class_ ) ": 4862,
 "def _compile ( pattern , flags ) : return re . compile ( WcParse ( pattern , flags & FLAG_MASK ) . parse ( ) ) ": 4863,
 "def atlasdb_format_query ( query , values ) : return \" \" . join ( [ \" %s %s \" % ( frag , \" ' %s ' \" % val if type ( val ) in [str , unicode] else val ) for ( frag , val ) in zip ( query . split ( \" ? \" ) , values + ( \" \" , ) ) ] ) ": 4864,
 "def _compress_obj ( obj , level ) : return zlib . compress ( pickle . dumps ( obj , protocol = 2 ) , level ) ": 4865,
 "def loads ( string ) : f = StringIO . StringIO ( string ) marshaller = JavaObjectUnmarshaller ( f ) marshaller . add_transformer ( DefaultObjectTransformer ( ) ) return marshaller . readObject ( ) ": 4866,
 "def mtf_unitransformer_all_layers_tiny ( ) : hparams = mtf_unitransformer_tiny ( ) hparams . moe_num_experts = 4 hparams . moe_expert_x = 4 hparams . moe_expert_y = 4 hparams . moe_hidden_size = 512 hparams . layers = [ \" self_att \" , \" local_self_att \" , \" moe_1d \" , \" moe_2d \" , \" drd \" ] return hparams": 4867,
 "def each_img ( img_dir ) : for fname in utils . each_img ( img_dir ) : fname = os . path . join ( img_dir , fname ) yield cv . imread ( fname ) , fname": 4868,
 "def clean ( ctx , dry_run = False ) : basedir = ctx . sphinx . destdir or \" build/docs \" cleanup_dirs ( [basedir] , dry_run = dry_run ) ": 4869,
 "def convert_date ( date ) : date = convert_month ( date , shorten = False ) clean_string = convert_string ( date ) return datetime . strptime ( clean_string , DATE_FMT . replace ( ' - ' , ' ' ) ) ": 4870,
 "def __init__ ( self , xmin = 0 , ymin = 0 , xmax = 1 , ymax = 1 ) : self . _xmin = xmin self . _ymin = ymin self . _xmax = xmax self . _ymax = ymax": 4871,
 "def set_attached_console_visible ( state ) : flag = {True : SW_SHOW , False : SW_HIDE} return bool ( ShowWindow ( console_window_handle , flag[state] ) ) ": 4872,
 "def delete_environment ( self , environment_name ) : self . ebs . terminate_environment ( environment_name = environment_name , terminate_resources = True ) ": 4873,
 "def __delitem__ ( self , key ) : self . _keys . remove ( key ) super ( ListDict , self ) . __delitem__ ( key ) ": 4874,
 "def _get_node_path ( self , node ) : path = [] while node . up : path . append ( node . name ) node = node . up return list ( reversed ( path ) ) ": 4875,
 "def map_tree ( visitor , tree ) : newn = [map_tree ( visitor , node ) for node in tree . nodes] return visitor ( tree , newn ) ": 4876,
 "def scroll_up ( self , locator ) : driver = self . _current_application ( ) element = self . _element_find ( locator , True , True ) driver . execute_script ( \" mobile : scroll \" , { \" direction \" : ' up ' , ' element ' : element . id} ) ": 4877,
 "def _name_exists ( self , name ) : for i in range ( self . count ( ) ) : if self . tabText ( i ) = = name : return True return False": 4878,
 "def mask_and_flatten ( self ) : self . _check_for_mask ( ) return self . get_data ( smoothed = True , masked = True , safe_copy = False ) [self . get_mask_indices ( ) ] , \\ self . get_mask_indices ( ) , self . mask . shape": 4879,
 "def _convert_dict_to_json ( array ) : return json . dumps ( array , skipkeys = False , allow_nan = False , indent = None , separators = ( \" , \" , \" : \" ) , sort_keys = True , default = lambda o : o . __dict__ , ) ": 4880,
 "async def acquire_async ( self ) : r = self . acquire ( blocking = False ) while not r : await asyncio . sleep ( . 01 ) r = self . acquire ( blocking = False ) ": 4881,
 "def dict_pop_or ( d , key , default = None ) : val = default with suppress ( KeyError ) : val = d . pop ( key ) return val": 4882,
 "def update ( dct , dct_merge ) : for key , value in dct_merge . items ( ) : if key in dct and isinstance ( dct[key] , dict ) : dct[key] = update ( dct[key] , value ) else : dct[key] = value return dct": 4883,
 "def show ( self ) : self . visible = True if self . proxy_is_active : self . proxy . ensure_visible ( ) ": 4884,
 "def total_seconds ( td ) : secs = td . seconds + td . days * 24 * 3600 if td . microseconds : secs + = 1 return secs": 4885,
 "def calculate_delay ( original , delay ) : original = datetime . strptime ( original , ' %H : %M ' ) delayed = datetime . strptime ( delay , ' %H : %M ' ) diff = delayed - original return diff . total_seconds ( ) // 60": 4886,
 "def angle ( vec1 , vec2 ) : dot_vec = dot ( vec1 , vec2 ) mag1 = vec1 . length ( ) mag2 = vec2 . length ( ) result = dot_vec / ( mag1 * mag2 ) return math . acos ( result ) ": 4887,
 "def convert_ajax_data ( self , field_data ) : data = [key for key , val in field_data . items ( ) if val] return data": 4888,
 "def get_future_days ( self ) : today = timezone . now ( ) . date ( ) return Day . objects . filter ( date__gte = today ) ": 4889,
 "def get_enum_documentation ( class_name , module_name , enum_class_object ) : documentation = . format ( module_name = module_name , class_name = class_name , plus = ' + ' * len ( class_name ) , ) if enum_class_object . __doc__ and enum_class_object . __doc__ . strip ( ) : documentation + = ' \\n\\n{} ' . format ( _clean_literals ( inspect . cleandoc ( enum_class_object . __doc__ ) ) ) documentation + = ' \\n\\nConstant Values : \\n ' for e in enum_class_object : documentation + = ' \\n- ``{}`` ( ``{}`` ) ' . format ( e . name , repr ( e . value ) . lstrip ( ' u ' ) ) return documentation": 4890,
 "def uncamel ( name ) : s1 = re . sub ( ' ( . ) ( [A-Z][a-z]+ ) ' , r ' \\1_\\2 ' , name ) return re . sub ( ' ( [a-z0-9] ) ( [A-Z] ) ' , r ' \\1_\\2 ' , s1 ) . lower ( ) ": 4891,
 "def flat_list ( input_list ) : r x = input_list if isinstance ( x , list ) : return [a for i in x for a in flat_list ( i ) ] else : return [x]": 4892,
 "def compress ( obj ) : return json . dumps ( obj , sort_keys = True , separators = ( ' , ' , ' : ' ) , cls = CustomEncoder ) ": 4893,
 "def cell ( self , rowName , columnName ) : return self . matrix[self . rowIndices[rowName] , self . columnIndices[columnName]]": 4894,
 "def convert ( self , value , _type ) : return self . type_convertors . get ( _type , lambda x : x ) ( value ) ": 4895,
 "def get_index ( self , bucket , index , startkey , endkey = None , return_terms = None , max_results = None , continuation = None , timeout = None , term_regex = None ) : raise NotImplementedError": 4896,
 "def class_check ( vector ) : for i in vector : if not isinstance ( i , type ( vector[0] ) ) : return False return True": 4897,
 "def cpp_checker ( code , working_directory ) : return gcc_checker ( code , ' . cpp ' , [os . getenv ( ' CXX ' , ' g++ ' ) , ' -std = c++0x ' ] + INCLUDE_FLAGS , working_directory = working_directory ) ": 4898,
 "def open ( name = None , fileobj = None , closefd = True ) : return Guesser ( ) . open ( name = name , fileobj = fileobj , closefd = closefd ) ": 4899,
 "def label_saves ( name ) : plt . legend ( loc = 0 ) plt . ylim ( [0 , 1 . 025] ) plt . xlabel ( ' $U/D$ ' , fontsize = 20 ) plt . ylabel ( ' $Z$ ' , fontsize = 20 ) plt . savefig ( name , dpi = 300 , format = ' png ' , transparent = False , bbox_inches = ' tight ' , pad_inches = 0 . 05 ) ": 4900,
 "def is_client ( self ) : return ( self . args . client or self . args . browser ) and not self . args . server": 4901,
 "def update_hash ( cls , filelike , digest ) : block_size = digest . block_size * 1024 for chunk in iter ( lambda : filelike . read ( block_size ) , b ' ' ) : digest . update ( chunk ) ": 4902,
 "def _check_surrounded_by_space ( self , tokens , i ) : self . _check_space ( tokens , i , ( _MUST , _MUST ) ) ": 4903,
 "def remove_unsafe_chars ( text ) : if isinstance ( text , six . string_types ) : text = UNSAFE_RE . sub ( ' ' , text ) return text": 4904,
 "def resize ( self , width , height ) : self . _buffer = QtGui . QImage ( width , height , QtGui . QImage . Format_RGB32 ) QtGui . QWidget . resize ( self , width , height ) ": 4905,
 "def _convert ( self , image , output = None ) : with Image . open ( image ) as im : width , height = im . size co = CanvasObjects ( ) co . add ( CanvasImg ( image , 1 . 0 , w = width , h = height ) ) return WatermarkDraw ( co , tempdir = self . tempdir , pagesize = ( width , height ) ) . write ( output ) ": 4906,
 "def _read_indexlist ( self , name ) : setattr ( self , ' _ ' + name , [self . _timeline[int ( i ) ] for i in self . db . lrange ( ' site : {0} ' . format ( name ) , 0 , -1 ) ] ) ": 4907,
 "def __add__ ( self , other ) : return concat ( self , other , copy = True , inplace = False ) ": 4908,
 "def median ( ls ) : ls = sorted ( ls ) return ls[int ( floor ( len ( ls ) /2 . 0 ) ) ]": 4909,
 "def RMS_energy ( frames ) : f = frames . flatten ( ) return N . sqrt ( N . mean ( f * f ) ) ": 4910,
 "def identifierify ( name ) : name = name . lower ( ) name = re . sub ( ' [^a-z0-9] ' , ' _ ' , name ) return name": 4911,
 "def reduce_freqs ( freqlist ) : allfreqs = np . zeros_like ( freqlist[0] ) for f in freqlist : allfreqs + = f return allfreqs": 4912,
 "def create ( self , ami , count , config = None ) : return self . Launcher ( config = config ) . launch ( ami , count ) ": 4913,
 "def load ( cls , tree_path ) : with open ( tree_path ) as f : tree_dict = json . load ( f ) return cls . from_dict ( tree_dict ) ": 4914,
 "def dmap ( fn , record ) : values = ( fn ( v ) for k , v in record . items ( ) ) return dict ( itertools . izip ( record , values ) ) ": 4915,
 "def create_dir_rec ( path : Path ) : if not path . exists ( ) : Path . mkdir ( path , parents = True , exist_ok = True ) ": 4916,
 "def get_the_node_dict ( G , name ) : for node in G . nodes ( data = True ) : if node[0] = = name : return node[1]": 4917,
 "def js_classnameify ( s ) : if not ' _ ' in s : return s return ' ' . join ( w[0] . upper ( ) + w[1 : ] . lower ( ) for w in s . split ( ' _ ' ) ) ": 4918,
 "def to_json ( value , **kwargs ) : serial_list = [ val . serialize ( **kwargs ) if isinstance ( val , HasProperties ) else val for val in value ] return serial_list": 4919,
 "def validate ( self , value , model_instance , **kwargs ) : self . get_choices_form_class ( ) . validate ( value , model_instance , **kwargs ) ": 4920,
 "def snap_to_beginning_of_week ( day , weekday_start = \" Sunday \" ) : delta_days = ( ( day . weekday ( ) + 1 ) % 7 ) if weekday_start is \" Sunday \" else day . weekday ( ) return day - timedelta ( days = delta_days ) ": 4921,
 "def get_current_desktop ( self ) : desktop = ctypes . c_long ( 0 ) _libxdo . xdo_get_current_desktop ( self . _xdo , ctypes . byref ( desktop ) ) return desktop . value": 4922,
 "def empty ( self , name , **kwargs ) : return self . _write_op ( self . _empty_nosync , name , **kwargs ) ": 4923,
 "def get_filetype_icon ( fname ) : ext = osp . splitext ( fname ) [1] if ext . startswith ( ' . ' ) : ext = ext[1 : ] return get_icon ( \" %s . png \" % ext , ima . icon ( ' FileIcon ' ) ) ": 4924,
 "def guess_media_type ( filepath ) : o = subprocess . check_output ( [ ' file ' , ' --mime-type ' , ' -Lb ' , filepath] ) o = o . strip ( ) return o": 4925,
 "def get_hash ( self , handle ) : fpath = self . _fpath_from_handle ( handle ) return DiskStorageBroker . hasher ( fpath ) ": 4926,
 "def on_press_key ( key , callback , suppress = False ) : return hook_key ( key , lambda e : e . event_type = = KEY_UP or callback ( e ) , suppress = suppress ) ": 4927,
 "def get_mtime ( fname ) : try : mtime = os . stat ( fname ) . st_mtime_ns except OSError : # The file might be right in the middle of being written # so sleep time . sleep ( 1 ) mtime = os . stat ( fname ) . st_mtime_ns return mtime": 4928,
 "def _get_current_label ( self ) : if len ( self . _last ) = = 0 : raise StopIteration return self . _last[ : self . _last . find ( \" : \" ) ]": 4929,
 "def splitBy ( data , num ) : return [data[i : i + num] for i in range ( 0 , len ( data ) , num ) ]": 4930,
 "def get_entity_kind ( self , model_obj ) : model_obj_ctype = ContentType . objects . get_for_model ( self . queryset . model ) return ( u ' {0} . {1} ' . format ( model_obj_ctype . app_label , model_obj_ctype . model ) , u ' {0} ' . format ( model_obj_ctype ) ) ": 4931,
 "def get_known_read_position ( fp , buffered = True ) : buffer_size = io . DEFAULT_BUFFER_SIZE if buffered else 0 return max ( fp . tell ( ) - buffer_size , 0 ) ": 4932,
 "def _longest_val_in_column ( self , col ) : try : # +2 is for implicit separator return max ( [len ( x[col] ) for x in self . table if x[col]] ) + 2 except KeyError : logger . error ( \" there is no column %r \" , col ) raise": 4933,
 "def _take_ownership ( self ) : if self : ptr = cast ( self . value , GIBaseInfo ) _UnrefFinalizer . track ( self , ptr ) self . __owns = True": 4934,
 "def get_month_namedays ( self , month = None ) : if month is None : month = datetime . now ( ) . month return self . NAMEDAYS[month-1]": 4935,
 "def get_system_root_directory ( ) : root = os . path . dirname ( __file__ ) root = os . path . dirname ( root ) root = os . path . abspath ( root ) return root": 4936,
 "def _jit_pairwise_distances ( pos1 , pos2 ) : n1 = pos1 . shape[0] n2 = pos2 . shape[0] D = np . empty ( ( n1 , n2 ) ) for i in range ( n1 ) : for j in range ( n2 ) : D[i , j] = np . sqrt ( ( ( pos1[i] - pos2[j] ) **2 ) . sum ( ) ) return D": 4937,
 "def _update_globals ( ) : if not sys . platform . startswith ( ' java ' ) and sys . platform ! = ' cli ' : return incompatible = ' extract_constant ' , ' get_module_constant ' for name in incompatible : del globals ( ) [name] __all__ . remove ( name ) ": 4938,
 "def get_content_type ( headers ) : ptype = headers . get ( ' Content-Type ' , ' application/octet-stream ' ) if \" ; \" in ptype : # split off not needed extension info ptype = ptype . split ( ' ; ' ) [0] return ptype . strip ( ) . lower ( ) ": 4939,
 "def call_with_context ( func , context , *args ) : return make_context_aware ( func , len ( args ) ) ( *args + ( context , ) ) ": 4940,
 "def _extract_traceback ( start ) : tb = sys . exc_info ( ) [2] for i in range ( start ) : tb = tb . tb_next return _parse_traceback ( tb ) ": 4941,
 "def __call__ ( self , *args , **kwargs ) : kwargs[ \" mongokat_collection \" ] = self return self . document_class ( *args , **kwargs ) ": 4942,
 "def restore_image_options ( cli , image , options ) : dockerfile = io . StringIO ( ) dockerfile . write ( u ' FROM {image}\\nCMD {cmd} ' . format ( image = image , cmd = json . dumps ( options[ ' cmd ' ] ) ) ) if options[ ' entrypoint ' ] : dockerfile . write ( ' \\nENTRYPOINT {} ' . format ( json . dumps ( options[ ' entrypoint ' ] ) ) ) cli . build ( tag = image , fileobj = dockerfile ) ": 4943,
 "def get_sparse_matrix_keys ( session , key_table ) : return session . query ( key_table ) . order_by ( key_table . name ) . all ( ) ": 4944,
 "def rdist ( x , y ) : result = 0 . 0 for i in range ( x . shape[0] ) : result + = ( x[i] - y[i] ) ** 2 return result": 4945,
 "def _to_hours_mins_secs ( time_taken ) : mins , secs = divmod ( time_taken , 60 ) hours , mins = divmod ( mins , 60 ) return hours , mins , secs": 4946,
 "def correlation_2D ( image ) : # Take the fourier transform of the image . F1 = fftpack . fft2 ( image ) # Now shift the quadrants around so that low spatial frequencies are in # the center of the 2D fourier transformed image . F2 = fftpack . fftshift ( F1 ) # Calculate a 2D power spectrum psd2D = np . abs ( F2 ) # Calculate the azimuthally averaged 1D power spectrum psd1D = analysis_util . azimuthalAverage ( psd2D ) return psd1D , psd2D": 4947,
 "def open_hdf5 ( filename , mode = ' r ' ) : if isinstance ( filename , ( h5py . Group , h5py . Dataset ) ) : return filename if isinstance ( filename , FILE_LIKE ) : return h5py . File ( filename . name , mode ) return h5py . File ( filename , mode ) ": 4948,
 "def load_fasta_file ( filename ) : with open ( filename , \" r \" ) as handle : records = list ( SeqIO . parse ( handle , \" fasta \" ) ) return records": 4949,
 "def scaled_fft ( fft , scale = 1 . 0 ) : data = np . zeros ( len ( fft ) ) for i , v in enumerate ( fft ) : data[i] = scale * ( i * v ) / NUM_SAMPLES return data": 4950,
 "def _get_file_sha1 ( file ) : bits = file . read ( ) file . seek ( 0 ) h = hashlib . new ( ' sha1 ' , bits ) . hexdigest ( ) return h": 4951,
 "def normalize_field ( self , value ) : if self . default is not None : if value is None or value = = ' ' : value = self . default return value": 4952,
 "def exists ( self , path ) : import hdfs try : self . client . status ( path ) return True except hdfs . util . HdfsError as e : if str ( e ) . startswith ( ' File does not exist : ' ) : return False else : raise e": 4953,
 "def getSize ( self ) : return self . widget . size[0]-self . border[0]*2 , self . widget . size[1]-self . border[1]*2": 4954,
 "def chunks ( dictionary , chunk_size ) : iterable = iter ( dictionary ) for __ in range ( 0 , len ( dictionary ) , chunk_size ) : yield {key : dictionary[key] for key in islice ( iterable , chunk_size ) }": 4955,
 "def extend_with ( func ) : if not func . __name__ in ArgParseInator . _plugins : ArgParseInator . _plugins[func . __name__] = func": 4956,
 "def _transform_col ( self , x , i ) : return x . fillna ( NAN_INT ) . map ( self . label_encoders[i] ) . fillna ( 0 ) ": 4957,
 "def _bind_parameter ( self , parameter , value ) : for ( instr , param_index ) in self . _parameter_table[parameter] : instr . params[param_index] = value": 4958,
 "def check_if_numbers_are_consecutive ( list_ ) : return all ( ( True if second - first = = 1 else False for first , second in zip ( list_[ : -1] , list_[1 : ] ) ) ) ": 4959,
 "def chi_square_calc ( classes , table , TOP , P , POP ) : try : result = 0 for i in classes : for index , j in enumerate ( classes ) : expected = ( TOP[j] * P[i] ) / ( POP[i] ) result + = ( ( table[i][j] - expected ) **2 ) / expected return result except Exception : return \" None \" ": 4960,
 "def auto_update ( cls , function ) : def wrapper ( self , *args , **kwargs ) : f = function ( self , *args , **kwargs ) self . update ( ) return f return wrapper": 4961,
 "def parse_float ( float_str ) : factor = __get_factor ( float_str ) if factor ! = 1 : float_str = float_str[ : -1] try : return float ( float_str . replace ( ' , ' , ' ' ) ) * factor except ValueError : return None": 4962,
 "def cli ( ctx , project_dir ) : exit_code = SCons ( project_dir ) . clean ( ) ctx . exit ( exit_code ) ": 4963,
 "def apply ( self , func , args = ( ) , kwds = dict ( ) ) : return self . apply_async ( func , args , kwds ) . get ( ) ": 4964,
 "def _check_task_id ( self , context ) : ti = context[ ' ti ' ] celery_result = ti . xcom_pull ( task_ids = self . target_task_id ) return celery_result . ready ( ) ": 4965,
 "def to_tree ( self ) : tree = TreeLibTree ( ) for node in self : tree . create_node ( node , node . node_id , parent = node . parent ) return tree": 4966,
 "def gaussian_kernel ( sigma , truncate = 4 . 0 ) : sigma = float ( sigma ) radius = int ( truncate * sigma + 0 . 5 ) x , y = np . mgrid[-radius : radius + 1 , -radius : radius + 1] sigma = sigma ** 2 k = 2 * np . exp ( -0 . 5 * ( x ** 2 + y ** 2 ) / sigma ) k = k / np . sum ( k ) return k": 4967,
 "def mongoqs_to_json ( qs , fields = None ) : l = list ( qs . as_pymongo ( ) ) for element in l : element . pop ( ' _cls ' ) # use DjangoJSONEncoder for transform date data type to datetime json_qs = json . dumps ( l , indent = 2 , ensure_ascii = False , cls = DjangoJSONEncoder ) return json_qs": 4968,
 "def _uniform_phi ( M ) : return np . random . uniform ( -np . pi , np . pi , M ) ": 4969,
 "def set_context ( self , data ) : for key in data : setattr ( self . local_context , key , data[key] ) ": 4970,
 "def shape ( self ) : return tuple ( len ( self . _get_axis ( a ) ) for a in self . _AXIS_ORDERS ) ": 4971,
 "def reopen ( self ) : try : self . _con . reopen ( ) except Exception : if self . _transcation : self . _transaction = False try : self . _con . query ( ' rollback ' ) except Exception : pass else : self . _transaction = False self . _closed = False self . _setsession ( ) self . _usage = 0": 4972,
 "def native_conn ( self ) : if self . __native is None : self . __native = self . _get_connection ( ) return self . __native": 4973,
 "def eval_Rf ( self , Vf ) : return sl . inner ( self . Df , Vf , axis = self . cri . axisM ) - self . Sf": 4974,
 "def is_integer ( dtype ) : dtype = tf . as_dtype ( dtype ) if hasattr ( dtype , ' is_integer ' ) : return dtype . is_integer return np . issubdtype ( np . dtype ( dtype ) , np . integer ) ": 4975,
 "def matches_glob_list ( path , glob_list ) : for glob in glob_list : try : if PurePath ( path ) . match ( glob ) : return True except TypeError : pass return False": 4976,
 "def _find_value ( key , *args ) : for arg in args : v = _get_value ( arg , key ) if v is not None : return v": 4977,
 "def _latest_date ( self , query , datetime_field_name ) : return list ( query . aggregate ( django . db . models . Max ( datetime_field_name ) ) . values ( ) ) [0]": 4978,
 "def _random_x ( self ) : return ( tuple ( random . random ( ) for _ in range ( self . fmodel . dim_x ) ) , ) ": 4979,
 "def model_field_attr ( model , model_field , attr ) : fields = dict ( [ ( field . name , field ) for field in model . _meta . fields] ) return getattr ( fields[model_field] , attr ) ": 4980,
 "def get_next_weekday ( self , including_today = False ) : weekday = self . date_time . weekday ( ) return Weekday . get_next ( weekday , including_today = including_today ) ": 4981,
 "def Unlock ( fd , path ) : try : fcntl . flock ( fd , fcntl . LOCK_UN | fcntl . LOCK_NB ) except IOError as e : if e . errno = = errno . EWOULDBLOCK : raise IOError ( ' Exception unlocking %s . Locked by another process . ' % path ) else : raise IOError ( ' Exception unlocking %s . %s . ' % ( path , str ( e ) ) ) ": 4982,
 "def display_iframe_url ( target , **kwargs ) : txt = iframe_url ( target , **kwargs ) display ( HTML ( txt ) ) ": 4983,
 "def get_points ( self ) : return [ ( k , self . runtime . _ring[k] ) for k in self . runtime . _keys]": 4984,
 "def getheader ( self , name , default = None ) : return self . aiohttp_response . headers . get ( name , default ) ": 4985,
 "def legend_title_header_element ( feature , parent ) : _ = feature , parent # NOQA header = legend_title_header[ ' string_format ' ] return header . capitalize ( ) ": 4986,
 "def calculate_size ( name , count ) : data_size = 0 data_size + = calculate_size_str ( name ) data_size + = INT_SIZE_IN_BYTES return data_size": 4987,
 "def layout ( self , indent = ' ' ) : \t\t\t\tself . __indent ( self . head , indent ) \t\tself . __indent ( self . meta , indent ) \t\tself . __indent ( self . stylesheet , indent ) \t\tself . __indent ( self . header , indent ) \t\tself . __indent ( self . body , indent , initial = 3 ) \t\tself . __indent ( self . footer , indent ) \t\tself . __indent ( self . body_pre_docinfo , indent , initial = 3 ) \t\tself . __indent ( self . docinfo , indent ) ": 4988,
 "def pagerank_limit_push ( s , r , w_i , a_i , push_node , rho ) : # Calculate the A and B quantities to infinity A_inf = rho*r[push_node] B_inf = ( 1-rho ) *r[push_node] # Update approximate Pagerank and residual vectors s[push_node] + = A_inf r[push_node] = 0 . 0 # Update residual vector at push node ' s adjacent nodes r[a_i] + = B_inf * w_i": 4989,
 "def set_clear_color ( self , color = ' black ' , alpha = None ) : self . glir . command ( ' FUNC ' , ' glClearColor ' , *Color ( color , alpha ) . rgba ) ": 4990,
 "def _get_binary_from_ipv4 ( self , ip_addr ) : return struct . unpack ( \" !L \" , socket . inet_pton ( socket . AF_INET , ip_addr ) ) [0]": 4991,
 "def _hess_two_param ( self , funct , p0 , p1 , dl = 2e-5 , rts = False , **kwargs ) : vals0 = self . get_values ( p0 ) vals1 = self . get_values ( p1 ) f00 = funct ( **kwargs ) self . update ( p0 , vals0+dl ) f10 = funct ( **kwargs ) self . update ( p1 , vals1+dl ) f11 = funct ( **kwargs ) self . update ( p0 , vals0 ) f01 = funct ( **kwargs ) if rts : self . update ( p0 , vals0 ) self . update ( p1 , vals1 ) return ( f11 - f10 - f01 + f00 ) / ( dl**2 ) ": 4992,
 "def unique_iter ( seq ) : seen = set ( ) return [x for x in seq if x not in seen and not seen . add ( x ) ]": 4993,
 "def set_mlimits ( self , row , column , min = None , max = None ) : subplot = self . get_subplot_at ( row , column ) subplot . set_mlimits ( min , max ) ": 4994,
 "def _validate_input_data ( self , data , request ) : validator = self . _get_input_validator ( request ) if isinstance ( data , ( list , tuple ) ) : return map ( validator . validate , data ) else : return validator . validate ( data ) ": 4995,
 "def finditer ( self , string , pos = 0 , endpos = sys . maxint ) : scanner = self . scanner ( string , pos , endpos ) return iter ( scanner . search , None ) ": 4996,
 "def set ( cls , color ) : sys . stdout . write ( cls . colors . get ( color , cls . colors[ ' RESET ' ] ) ) ": 4997,
 "def refresh_core ( self ) : self . log . info ( ' Sending out mass query for all attributes ' ) for key in ATTR_CORE : self . query ( key ) ": 4998,
 "def next ( self ) : _LOGGER . debug ( \" reading next \" ) if self . closed : _LOGGER . debug ( \" stream is closed \" ) raise StopIteration ( ) line = self . readline ( ) if not line : _LOGGER . debug ( \" nothing more to read \" ) raise StopIteration ( ) return line": 4999,
 "def __iter__ ( self ) : for bit , mask in zip ( self . _bits , self . _mask ) : yield bit if mask else None": 5000,
 "def purge_cache ( self , object_type ) : if object_type in self . mapping : cache = self . mapping[object_type] log . debug ( \" Purging [{}] cache of {} values . \" . format ( object_type , len ( cache ) ) ) cache . purge ( ) ": 5001,
 "def eval ( self , expression , use_compilation_plan = False ) : code = ' PyJsEvalResult = eval ( %s ) ' % json . dumps ( expression ) self . execute ( code , use_compilation_plan = use_compilation_plan ) return self[ ' PyJsEvalResult ' ]": 5002,
 "def test_security ( self ) : self . assertEqual ( run_example ( examples_folder + \" security . py --generate \" ) , 0 ) self . assertEqual ( run_example ( examples_folder + \" security . py --revoke \" ) , 0 ) ": 5003,
 "def _validate ( data , schema , ac_schema_safe = True , **options ) : try : jsonschema . validate ( data , schema , **options ) except ( jsonschema . ValidationError , jsonschema . SchemaError , Exception ) as exc : if ac_schema_safe : return ( False , str ( exc ) ) # Validation was failed . raise return ( True , ' ' ) ": 5004,
 "def wait ( self , timeout = None ) : if not self . __running : raise RuntimeError ( \" ThreadPool ain ' t running \" ) self . __queue . wait ( timeout ) ": 5005,
 "def vadd ( v1 , v2 ) : v1 = stypes . toDoubleVector ( v1 ) v2 = stypes . toDoubleVector ( v2 ) vout = stypes . emptyDoubleVector ( 3 ) libspice . vadd_c ( v1 , v2 , vout ) return stypes . cVectorToPython ( vout ) ": 5006,
 "def query ( self , base , filterstr , attrlist = None ) : \t\t\t\treturn self . conn . search_s ( base , ldap . SCOPE_SUBTREE , filterstr , attrlist ) ": 5007,
 "def cols_strip ( df , col_list , dest = False ) : if not dest : return _pd . DataFrame ( {col_name : col_strip ( df , col_name ) for col_name in col_list} ) for col_name in col_list : col_strip ( df , col_name , dest ) ": 5008,
 "def get_groups ( self , username ) : username = ldap . filter . escape_filter_chars ( self . _byte_p2 ( username ) ) userdn = self . _get_user ( username , NO_ATTR ) searchfilter = self . group_filter_tmpl % { ' userdn ' : userdn , ' username ' : username } groups = self . _search ( searchfilter , NO_ATTR , self . groupdn ) ret = [] for entry in groups : ret . append ( self . _uni ( entry[0] ) ) return ret": 5009,
 "def _get_xy_scaling_parameters ( self ) : return self . mx , self . bx , self . my , self . by": 5010,
 "def _set_request_cache_if_django_cache_hit ( key , django_cached_response ) : if django_cached_response . is_found : DEFAULT_REQUEST_CACHE . set ( key , django_cached_response . value ) ": 5011,
 "def fgrad_y ( self , y , return_precalc = False ) : d = self . d mpsi = self . psi # vectorized version S = ( mpsi[ : , 1] * ( y[ : , : , None] + mpsi[ : , 2] ) ) . T R = np . tanh ( S ) D = 1 - ( R ** 2 ) GRAD = ( d + ( mpsi[ : , 0 : 1][ : , : , None] * mpsi[ : , 1 : 2][ : , : , None] * D ) . sum ( axis = 0 ) ) . T if return_precalc : return GRAD , S , R , D return GRAD": 5012,
 "def zs ( inlist ) : zscores = [] for item in inlist : zscores . append ( z ( inlist , item ) ) return zscores": 5013,
 "def update ( self , **kwargs ) : self . reload_context ( es_based = False , **kwargs ) return super ( ESCollectionView , self ) . update ( **kwargs ) ": 5014,
 "def handle_test ( self , command , **options ) : # can ' t be async for testing config = { \" async_mode \" : False} for key in ( \" service_name \" , \" secret_token \" ) : if options . get ( key ) : config[key] = options[key] client = DjangoClient ( **config ) client . error_logger = ColoredLogger ( self . stderr ) client . logger = ColoredLogger ( self . stderr ) self . write ( \" Trying to send a test error to APM Server using these settings : \\n\\n \" \" SERVICE_NAME : \\t%s\\n \" \" SECRET_TOKEN : \\t%s\\n \" \" SERVER : \\t\\t%s\\n\\n \" % ( client . config . service_name , client . config . secret_token , client . config . server_url ) ) try : raise TestException ( \" Hi there! \" ) except TestException : client . capture_exception ( ) if not client . error_logger . errors : self . write ( \" Success! We tracked the error successfully! You should be \" \" able to see it in a few seconds at the above URL \" ) finally : client . close ( ) ": 5015,
 "def load ( cls , fp , **kwargs ) : json_obj = json . load ( fp , **kwargs ) return parse ( cls , json_obj ) ": 5016,
 "def assert_lock ( fname ) : if not set_lock ( fname ) : logger . error ( ' File {} is already locked . Terminating . ' . format ( fname ) ) sys . exit ( ) ": 5017,
 "def execute_cast_simple_literal_to_timestamp ( op , data , type , **kwargs ) : return pd . Timestamp ( data , tz = type . timezone ) ": 5018,
 "def _debug_log ( self , msg ) : if not self . debug : return sys . stderr . write ( ' {}\\n ' . format ( msg ) ) ": 5019,
 "def set_verbosity ( verbosity ) : Logger . _verbosity = min ( max ( 0 , WARNING - verbosity ) , 2 ) debug ( \" Verbosity set to %d \" % ( WARNING - Logger . _verbosity ) , ' logging ' ) ": 5020,
 "def count_nulls ( self , field ) : try : n = self . df[field] . isnull ( ) . sum ( ) except KeyError : self . warning ( \" Can not find column \" , field ) return except Exception as e : self . err ( e , \" Can not count nulls \" ) return self . ok ( \" Found \" , n , \" nulls in column \" , field ) ": 5021,
 "def package_in_pypi ( package ) : url = ' http : //pypi . python . org/simple/%s ' % package try : urllib . request . urlopen ( url ) return True except urllib . error . HTTPError as e : logger . debug ( \" Package not found on pypi : %s \" , e ) return False": 5022,
 "def instance_name ( string ) : invalid = ' : /@ ' if set ( string ) . intersection ( invalid ) : msg = ' Invalid instance name {} ' . format ( string ) raise argparse . ArgumentTypeError ( msg ) return string": 5023,
 "def check_update ( ) : logging . info ( ' Check for app updates . ' ) try : update = updater . check_for_app_updates ( ) except Exception : logging . exception ( ' Check for updates failed . ' ) return if update : print ( \" !!! UPDATE AVAILABLE !!!\\n \" \" \" + static_data . PROJECT_URL + \" \\n\\n \" ) logging . info ( \" Update available : \" + static_data . PROJECT_URL ) else : logging . info ( \" No update available . \" ) ": 5024,
 "def get_matrix ( self ) : return np . array ( [ self . get_row_list ( i ) for i in range ( self . row_count ( ) ) ] ) ": 5025,
 "def db_exists ( ) : logger . info ( \" Checking to see if %s already exists \" , repr ( DB[ \" NAME \" ] ) ) try : # Hide stderr since it is confusing here psql ( \" \" , stderr = subprocess . STDOUT ) except subprocess . CalledProcessError : return False return True": 5026,
 "def hmean_int ( a , a_min = 5778 , a_max = 1149851 ) : from scipy . stats import hmean return int ( round ( hmean ( np . clip ( a , a_min , a_max ) ) ) ) ": 5027,
 "def contextMenuEvent ( self , event ) : self . update_menu ( ) self . menu . popup ( event . globalPos ( ) ) ": 5028,
 "def compare ( self , first , second ) : if first . lower ( ) = = second . lower ( ) : return True else : return False": 5029,
 "def comments ( self ) : if self . _comments is None : self . _comments = [c for c in self . grammar . children if c . is_type ( TokenType . comment ) ] return self . _comments": 5030,
 "def tag_to_dict ( html ) : element = document_fromstring ( html ) . xpath ( \" //html/body/child : : * \" ) [0] attributes = dict ( element . attrib ) attributes[ \" text \" ] = element . text_content ( ) return attributes": 5031,
 "def _config_session ( ) : config = tf . ConfigProto ( ) config . gpu_options . allow_growth = True config . gpu_options . visible_device_list = ' 0 ' return tf . Session ( config = config ) ": 5032,
 "def get_object_or_none ( model , *args , **kwargs ) : try : return model . _default_manager . get ( *args , **kwargs ) except model . DoesNotExist : return None": 5033,
 "def write ( self , value ) : self . get_collection ( ) . update_one ( { ' _id ' : self . _document_id} , { ' $set ' : {self . _path : value}} , upsert = True ) ": 5034,
 "def _calc_dir_size ( path ) : dir_size = 0 for ( root , dirs , files ) in os . walk ( path ) : for fn in files : full_fn = os . path . join ( root , fn ) dir_size + = os . path . getsize ( full_fn ) return dir_size": 5035,
 "def create_node ( self , network , participant ) : return self . models . MCMCPAgent ( network = network , participant = participant ) ": 5036,
 "def index_nearest ( array , value ) : idx = ( np . abs ( array-value ) ) . argmin ( ) return idx": 5037,
 "def doc_parser ( ) : parser = argparse . ArgumentParser ( prog = ' ambry ' , description = ' Ambry {} . Management interface for ambry , libraries ' ' and repositories . ' . format ( ambry . _meta . __version__ ) ) return parser": 5038,
 "def has_edge ( self , edge ) : u , v = edge return ( u , v ) in self . edge_properties": 5039,
 "def earth_orientation ( date ) : x_p , y_p , s_prime = np . deg2rad ( _earth_orientation ( date ) ) return rot3 ( -s_prime ) @ rot2 ( x_p ) @ rot1 ( y_p ) ": 5040,
 "def __del__ ( self ) : if self . _delete_file : try : os . remove ( self . name ) except ( OSError , IOError ) : pass": 5041,
 "def request ( self , method , url , body = None , headers = {} ) : self . _send_request ( method , url , body , headers ) ": 5042,
 "def gtype ( n ) : t = type ( n ) . __name__ return str ( t ) if t ! = ' Literal ' else ' Literal , {} ' . format ( n . language ) ": 5043,
 "def __str__ ( self ) : return \" , \" . join ( \" { : 02x}{ : 02x} = { : 02x}{ : 02x} \" . format ( c[0][0] , c[0][1] , c[1][0] , c[1][1] ) for c in self . alias_array_ ) ": 5044,
 "def rgamma ( alpha , beta , size = None ) : return np . random . gamma ( shape = alpha , scale = 1 . / beta , size = size ) ": 5045,
 "def __iter__ ( self ) : return iter ( [v for k , v in sorted ( self . _modes . items ( ) ) ] ) ": 5046,
 "def top_class ( self ) : curr = self parent = self . parent while isinstance ( parent , class_t ) : curr = parent parent = parent . parent return curr": 5047,
 "def load_results ( result_files , options , run_set_id = None , columns = None , columns_relevant_for_diff = set ( ) ) : return parallel . map ( load_result , result_files , itertools . repeat ( options ) , itertools . repeat ( run_set_id ) , itertools . repeat ( columns ) , itertools . repeat ( columns_relevant_for_diff ) ) ": 5048,
 "def screen_to_client ( self , x , y ) : return tuple ( win32 . ScreenToClient ( self . get_handle ( ) , ( x , y ) ) ) ": 5049,
 "def expand_path ( path ) : return os . path . abspath ( os . path . expandvars ( os . path . expanduser ( path ) ) ) ": 5050,
 "def parent ( self , index ) : childItem = self . item ( index ) parentItem = childItem . parent if parentItem = = self . rootItem : parentIndex = QModelIndex ( ) else : parentIndex = self . createIndex ( parentItem . row ( ) , 0 , parentItem ) return parentIndex": 5051,
 "def standardize ( table , with_std = True ) : if isinstance ( table , pandas . DataFrame ) : cat_columns = table . select_dtypes ( include = [ ' category ' ] ) . columns else : cat_columns = [] new_frame = _apply_along_column ( table , standardize_column , with_std = with_std ) # work around for apply converting category dtype to object # https : //github . com/pydata/pandas/issues/9573 for col in cat_columns : new_frame[col] = table[col] . copy ( ) return new_frame": 5052,
 "def PythonPercentFormat ( format_str ) : if format_str . startswith ( ' printf ' ) : fmt = format_str[len ( ' printf ' ) : ] return lambda value : fmt % value else : return None": 5053,
 "def _last_index ( x , default_dim ) : if x . get_shape ( ) . ndims is not None : return len ( x . get_shape ( ) ) - 1 else : return default_dim": 5054,
 "def _async_requests ( urls ) : session = FuturesSession ( max_workers = 30 ) futures = [ session . get ( url ) for url in urls ] return [ future . result ( ) for future in futures ]": 5055,
 "def prompt ( *args , **kwargs ) : try : return click . prompt ( *args , **kwargs ) except click . Abort : return False": 5056,
 "def value_for_key ( membersuite_object_data , key ) : key_value_dicts = { d[ ' Key ' ] : d[ ' Value ' ] for d in membersuite_object_data[ \" Fields \" ][ \" KeyValueOfstringanyType \" ]} return key_value_dicts[key]": 5057,
 "def _baseattrs ( self ) : result = super ( ) . _baseattrs result[ \" params \" ] = \" , \" . join ( self . parameters ) return result": 5058,
 "def _parse_ranges ( ranges ) : for txt in ranges : if ' - ' in txt : low , high = txt . split ( ' - ' ) else : low , high = txt , txt yield int ( low ) , int ( high ) ": 5059,
 "def plot_pauli_transfer_matrix ( self , ax ) : title = \" Estimated process \" ut . plot_pauli_transfer_matrix ( self . r_est , ax , self . pauli_basis . labels , title ) ": 5060,
 "def replace ( self , text ) : for ( pattern , repl ) in self . patterns : text = re . subn ( pattern , repl , text ) [0] return text": 5061,
 "def utcfromtimestamp ( cls , timestamp ) : obj = datetime . datetime . utcfromtimestamp ( timestamp ) obj = pytz . utc . localize ( obj ) return cls ( obj ) ": 5062,
 "def _read_preference_for ( self , session ) : # Override this operation ' s read preference with the transaction ' s . if session : return session . _txn_read_preference ( ) or self . __read_preference return self . __read_preference": 5063,
 "def tuplize ( nested ) : if isinstance ( nested , str ) : return nested try : return tuple ( map ( tuplize , nested ) ) except TypeError : return nested": 5064,
 "def _GetProxies ( self ) : # Detect proxies from the OS environment . result = client_utils . FindProxies ( ) # Also try to connect directly if all proxies fail . result . append ( \" \" ) # Also try all proxies configured in the config system . result . extend ( config . CONFIG[ \" Client . proxy_servers \" ] ) return result": 5065,
 "def _load_ngram ( name ) : module = importlib . import_module ( ' lantern . analysis . english_ngrams . {} ' . format ( name ) ) return getattr ( module , name ) ": 5066,
 "def find_number ( regex , s ) : result = find_string ( regex , s ) if result is None : return None return int ( result ) ": 5067,
 "def detach_index ( self , name ) : assert type ( name ) = = str if name in self . _indexes : del self . _indexes[name]": 5068,
 "def gaussian_kernel ( gstd ) : Nc = np . ceil ( gstd*3 ) *2+1 x = np . linspace ( - ( Nc-1 ) /2 , ( Nc-1 ) /2 , Nc , endpoint = True ) g = np . exp ( - . 5* ( ( x/gstd ) **2 ) ) g = g/np . sum ( g ) return g": 5069,
 "def plot_dot_graph ( graph , filename = None ) : if not plot . pygraphviz_available : logger . error ( \" Pygraphviz is not installed , cannot generate graph plot! \" ) return if not plot . PIL_available : logger . error ( \" PIL is not installed , cannot display graph plot! \" ) return agraph = AGraph ( graph ) agraph . layout ( prog = ' dot ' ) if filename is None : filename = tempfile . mktemp ( suffix = \" . png \" ) agraph . draw ( filename ) image = Image . open ( filename ) image . show ( ) ": 5070,
 "def get_plugin_icon ( self ) : path = osp . join ( self . PLUGIN_PATH , self . IMG_PATH ) return ima . icon ( ' pylint ' , icon_path = path ) ": 5071,
 "def generate_header ( headerfields , oldheader , group_by_field ) : fieldtypes = [ ' peptidefdr ' , ' peptidepep ' , ' nopsms ' , ' proteindata ' , ' precursorquant ' , ' isoquant ' ] return generate_general_header ( headerfields , fieldtypes , peptabledata . HEADER_PEPTIDE , oldheader , group_by_field ) ": 5072,
 "def to_linspace ( self ) : num = int ( ( self . stop-self . start ) / ( self . step ) ) return Linspace ( self . start , self . stop-self . step , num ) ": 5073,
 "def paragraph ( separator = ' \\n\\n ' , wrap_start = ' ' , wrap_end = ' ' , html = False , sentences_quantity = 3 ) : return paragraphs ( quantity = 1 , separator = separator , wrap_start = wrap_start , wrap_end = wrap_end , html = html , sentences_quantity = sentences_quantity ) ": 5074,
 "def trim_trailing_silence ( self ) : length = self . get_active_length ( ) self . pianoroll = self . pianoroll[ : length]": 5075,
 "def list_replace ( subject_list , replacement , string ) : for s in subject_list : string = string . replace ( s , replacement ) return string": 5076,
 "def do_restart ( self , line ) : self . bot . _frame = 0 self . bot . _namespace . clear ( ) self . bot . _namespace . update ( self . bot . _initial_namespace ) ": 5077,
 "def new_figure_manager_given_figure ( num , figure ) : fig = figure frame = FigureFrameWx ( num , fig ) figmgr = frame . get_figure_manager ( ) if matplotlib . is_interactive ( ) : figmgr . frame . Show ( ) return figmgr": 5078,
 "def _prt_line_detail ( self , prt , line , lnum = \" \" ) : data = zip ( self . flds , line . split ( ' \\t ' ) ) txt = [ \" { : 2} ) { : 13} {} \" . format ( i , hdr , val ) for i , ( hdr , val ) in enumerate ( data ) ] prt . write ( \" {LNUM}\\n{TXT}\\n \" . format ( LNUM = lnum , TXT = ' \\n ' . join ( txt ) ) ) ": 5079,
 "def show_partitioning ( rdd , show = True ) : if show : partitionCount = rdd . getNumPartitions ( ) try : valueCount = rdd . countApprox ( 1000 , confidence = 0 . 50 ) except : valueCount = -1 try : name = rdd . name ( ) or None except : pass name = name or \" anonymous \" logging . info ( \" For RDD %s , there are %d partitions with on average %s values \" % ( name , partitionCount , int ( valueCount/float ( partitionCount ) ) ) ) ": 5080,
 "def replacing_symlink ( source , link_name ) : with make_tmp_name ( link_name ) as tmp_link_name : os . symlink ( source , tmp_link_name ) replace_file_or_dir ( link_name , tmp_link_name ) ": 5081,
 "def home_lib ( home ) : if hasattr ( sys , ' pypy_version_info ' ) : lib = ' site-packages ' else : lib = os . path . join ( ' lib ' , ' python ' ) return os . path . join ( home , lib ) ": 5082,
 "def selectnotin ( table , field , value , complement = False ) : return select ( table , field , lambda v : v not in value , complement = complement ) ": 5083,
 "def _send ( self , data ) : if not self . _sock : self . connect ( ) self . _do_send ( data ) ": 5084,
 "def send ( self , data ) : self . stdin . write ( data ) self . stdin . flush ( ) ": 5085,
 "def serialize_me ( self , account , bucket_details ) : return self . dumps ( { \" account \" : account , \" detail \" : { \" request_parameters \" : { \" bucket_name \" : bucket_details[ \" Name \" ] , \" creation_date \" : bucket_details[ \" CreationDate \" ] . replace ( tzinfo = None , microsecond = 0 ) . isoformat ( ) + \" Z \" } } } ) . data": 5086,
 "def _updateTabStopWidth ( self ) : self . setTabStopWidth ( self . fontMetrics ( ) . width ( ' ' * self . _indenter . width ) ) ": 5087,
 "def print_fatal_results ( results , level = 0 ) : print_level ( logger . critical , _RED + \" [X] Fatal Error : %s \" , level , results . error ) ": 5088,
 "def set_limits ( self , min_ = None , max_ = None ) : self . _min , self . _max = min_ , max_": 5089,
 "def close ( self ) : if not self . closed : self . closed = True self . _flush ( finish = True ) self . _buffer = None": 5090,
 "def __init__ ( self , iterable ) : self . _values = [] self . _iterable = iterable self . _initialized = False self . _depleted = False self . _offset = 0": 5091,
 "def print_message ( message = None ) : kwargs = { ' stdout ' : sys . stdout , ' stderr ' : sys . stderr , ' shell ' : True} return subprocess . call ( ' echo \" {0} \" ' . format ( message or ' ' ) , **kwargs ) ": 5092,
 "def segments_to_numpy ( segments ) : segments = numpy . array ( segments , dtype = SEGMENT_DATATYPE , ndmin = 2 ) # each segment in a row segments = segments if SEGMENTS_DIRECTION = = 0 else numpy . transpose ( segments ) return segments": 5093,
 "def search_index_file ( ) : from metapack import Downloader from os import environ return environ . get ( ' METAPACK_SEARCH_INDEX ' , Downloader . get_instance ( ) . cache . getsyspath ( ' index . json ' ) ) ": 5094,
 "def _connect ( self , servers ) : self . _do_connect ( servers . split ( ' ' ) ) self . _verify_connection ( verbose = True ) ": 5095,
 "def offsets ( self ) : return np . array ( [self . x_offset , self . y_offset , self . z_offset] ) ": 5096,
 "def cluster_kmeans ( data , n_clusters , **kwargs ) : km = cl . KMeans ( n_clusters , **kwargs ) kmf = km . fit ( data ) labels = kmf . labels_ return labels , [np . nan]": 5097,
 "def ReverseV2 ( a , axes ) : idxs = tuple ( slice ( None , None , 2 * int ( i not in axes ) - 1 ) for i in range ( len ( a . shape ) ) ) return np . copy ( a[idxs] ) , ": 5098,
 "def set_slug ( apps , schema_editor ) : Event = apps . get_model ( ' spectator_events ' , ' Event ' ) for e in Event . objects . all ( ) : e . slug = generate_slug ( e . pk ) e . save ( update_fields = [ ' slug ' ] ) ": 5099,
 "def wait_send ( self , timeout = None ) : \t\t\t\tself . _send_queue_cleared . clear ( ) \t\tself . _send_queue_cleared . wait ( timeout = timeout ) ": 5100,
 "def _rows_sort ( self , rows ) : return sorted ( rows , key = lambda row : ( row[self . _key_start_date] , row[self . _key_end_date] ) ) ": 5101,
 "def to_html ( self , write_to ) : page_html = self . get_html ( ) with open ( write_to , \" wb \" ) as writefile : writefile . write ( page_html . encode ( \" utf-8 \" ) ) ": 5102,
 "def build_columns ( self , X , verbose = False ) : return sp . sparse . csc_matrix ( X[ : , self . feature][ : , np . newaxis] ) ": 5103,
 "def feature_subset ( self , indices ) : if isinstance ( indices , np . ndarray ) : indices = indices . tolist ( ) if not isinstance ( indices , list ) : raise ValueError ( ' Can only index with lists ' ) return [self . features_[i] for i in indices]": 5104,
 "def _request_modify_dns_record ( self , record ) : return self . _request_internal ( \" Modify_DNS_Record \" , domain = self . domain , record = record ) ": 5105,
 "def table_exists ( cursor , tablename , schema = ' public ' ) : query = cursor . execute ( query , ( schema , tablename ) ) res = cursor . fetchone ( ) [0] return res": 5106,
 "def truncate_table ( self , tablename ) : self . get ( tablename ) . remove ( ) self . db . commit ( ) ": 5107,
 "def fix_line_breaks ( s ) : l = s . splitlines ( ) x = [i . strip ( ) for i in l] x = [i for i in x if i] # remove blank lines return \" \\n \" . join ( x ) ": 5108,
 "def do_quit ( self , arg ) : for name , fh in self . _backup : setattr ( sys , name , fh ) self . console . writeline ( ' *** Aborting program ***\\n ' ) self . console . flush ( ) self . console . close ( ) WebPdb . active_instance = None return Pdb . do_quit ( self , arg ) ": 5109,
 "def itemlist ( item , sep , suppress_trailing = True ) : return condense ( item + ZeroOrMore ( addspace ( sep + item ) ) + Optional ( sep . suppress ( ) if suppress_trailing else sep ) ) ": 5110,
 "def subat ( orig , index , replace ) : return \" \" . join ( [ ( orig[x] if x ! = index else replace ) for x in range ( len ( orig ) ) ] ) ": 5111,
 "def bytes_to_bits ( bytes_ ) : res = [] for x in bytes_ : if not isinstance ( x , int ) : x = ord ( x ) res + = byte_to_bits ( x ) return res": 5112,
 "def get_last_filled_cell ( self , table = None ) : maxrow = 0 maxcol = 0 for row , col , tab in self . dict_grid : if table is None or tab = = table : maxrow = max ( row , maxrow ) maxcol = max ( col , maxcol ) return maxrow , maxcol , table": 5113,
 "def run_std_server ( self ) : config = tf . estimator . RunConfig ( ) server = tf . train . Server ( config . cluster_spec , job_name = config . task_type , task_index = config . task_id , protocol = config . protocol ) server . join ( ) ": 5114,
 "def filesavebox ( msg = None , title = None , argInitialFile = None ) : return psidialogs . ask_file ( message = msg , title = title , default = argInitialFile , save = True ) ": 5115,
 "def is_array ( type_ ) : nake_type = remove_alias ( type_ ) nake_type = remove_reference ( nake_type ) nake_type = remove_cv ( nake_type ) return isinstance ( nake_type , cpptypes . array_t ) ": 5116,
 "def colorize ( txt , fg = None , bg = None ) : setting = ' ' setting + = _SET_FG . format ( fg ) if fg else ' ' setting + = _SET_BG . format ( bg ) if bg else ' ' return setting + str ( txt ) + _STYLE_RESET": 5117,
 "def import_public_rsa_key_from_file ( filename ) : with open ( filename , \" rb \" ) as key_file : public_key = serialization . load_pem_public_key ( key_file . read ( ) , backend = default_backend ( ) ) return public_key": 5118,
 "def Join ( self ) : for _ in range ( self . JOIN_TIMEOUT_DECISECONDS ) : if self . _queue . empty ( ) and not self . busy_threads : return time . sleep ( 0 . 1 ) raise ValueError ( \" Timeout during Join ( ) for threadpool %s . \" % self . name ) ": 5119,
 "def seconds_to_time ( x ) : t = int ( x * 10**6 ) ms = t % 10**6 t = t // 10**6 s = t % 60 t = t // 60 m = t % 60 t = t // 60 h = t return time ( h , m , s , ms ) ": 5120,
 "def _make_sql_params ( self , kw ) : return [ ' %s = ? ' %k for k in kw . keys ( ) ] for k , v in kw . iteritems ( ) : vals . append ( ' %s = ? ' %k ) return vals": 5121,
 "def GetRootKey ( self ) : regf_key = self . _regf_file . get_root_key ( ) if not regf_key : return None return REGFWinRegistryKey ( regf_key , key_path = self . _key_path_prefix ) ": 5122,
 "def _grid_widgets ( self ) : scrollbar_column = 0 if self . __compound is tk . LEFT else 2 self . listbox . grid ( row = 0 , column = 1 , sticky = \" nswe \" ) self . scrollbar . grid ( row = 0 , column = scrollbar_column , sticky = \" ns \" ) ": 5123,
 "def value_left ( self , other ) : return other . value if isinstance ( other , self . __class__ ) else other": 5124,
 "def detach ( self , *items ) : self . _visual_drag . detach ( *items ) ttk . Treeview . detach ( self , *items ) ": 5125,
 "def make_prefixed_stack_name ( prefix , template_path ) : parts = os . path . basename ( template_path ) . split ( ' - ' ) parts = parts if len ( parts ) = = 1 else parts[ : -1] return ( ' %s-%s ' % ( prefix , ' - ' . join ( parts ) ) ) . split ( ' . ' ) [0]": 5126,
 "def append_position_to_token_list ( token_list ) : return [PositionToken ( value . content , value . gd , index , index+1 ) for ( index , value ) in enumerate ( token_list ) ]": 5127,
 "def on_success ( self , fn , *args , **kwargs ) : self . _callbacks . append ( ( fn , args , kwargs ) ) result = self . _resulted_in if result is not _NOTHING_YET : self . _succeed ( result = result ) ": 5128,
 "def log ( self , level , msg = None , *args , **kwargs ) : return self . _log ( level , msg , args , kwargs ) ": 5129,
 "def timestamping_validate ( data , schema ) : jsonschema . validate ( data , schema ) data[ ' timestamp ' ] = str ( time . time ( ) ) ": 5130,
 "def assert_error ( text , check , n = 1 ) : assert_error . description = \" No {} error for ' {} ' \" . format ( check , text ) assert ( check in [error[0] for error in lint ( text ) ] ) ": 5131,
 "def send ( self , topic , *args , **kwargs ) : prefix_topic = self . heroku_kafka . prefix_topic ( topic ) return super ( HerokuKafkaProducer , self ) . send ( prefix_topic , *args , **kwargs ) ": 5132,
 "def kubectl ( *args , input = None , **flags ) : # Build command line call . line = [ ' kubectl ' ] + list ( args ) line = line + get_flag_args ( **flags ) if input is not None : line = line + [ ' -f ' , ' - ' ] # Run subprocess output = subprocess . run ( line , input = input , capture_output = True , text = True ) return output": 5133,
 "def _get_context ( argspec , kwargs ) : if argspec . keywords is not None : return kwargs return dict ( ( arg , kwargs[arg] ) for arg in argspec . args if arg in kwargs ) ": 5134,
 "def retry_until_not_none_or_limit_reached ( method , limit , sleep_s = 1 , catch_exceptions = ( ) ) : return retry_until_valid_or_limit_reached ( method , limit , lambda x : x is not None , sleep_s , catch_exceptions ) ": 5135,
 "def increment ( self , amount = 1 ) : self . _primaryProgressBar . setValue ( self . value ( ) + amount ) QApplication . instance ( ) . processEvents ( ) ": 5136,
 "def safe_url ( url ) : parsed = urlparse ( url ) if parsed . password is not None : pwd = ' : %s@ ' % parsed . password url = url . replace ( pwd , ' : *****@ ' ) return url": 5137,
 "def get_services ( ) : with win32 . OpenSCManager ( dwDesiredAccess = win32 . SC_MANAGER_ENUMERATE_SERVICE ) as hSCManager : try : return win32 . EnumServicesStatusEx ( hSCManager ) except AttributeError : return win32 . EnumServicesStatus ( hSCManager ) ": 5138,
 "def addClassKey ( self , klass , key , obj ) : d = self . _getClass ( klass ) d[key] = obj": 5139,
 "def c2u ( name ) : s1 = re . sub ( ' ( . ) ( [A-Z][a-z]+ ) ' , r ' \\1_\\2 ' , name ) s1 = re . sub ( ' ( [a-z0-9] ) ( [A-Z] ) ' , r ' \\1_\\2 ' , s1 ) . lower ( ) return s1": 5140,
 "def clear_caches ( ) : from jinja2 . environment import _spontaneous_environments from jinja2 . lexer import _lexer_cache _spontaneous_environments . clear ( ) _lexer_cache . clear ( ) ": 5141,
 "def __init__ ( self , response ) : self . response = response super ( ResponseException , self ) . __init__ ( \" received {} HTTP response \" . format ( response . status_code ) ) ": 5142,
 "def _group_dict_set ( iterator ) : d = defaultdict ( set ) for key , value in iterator : d[key] . add ( value ) return dict ( d ) ": 5143,
 "def acquire_nix ( lock_file ) : # pragma : no cover fd = os . open ( lock_file , OPEN_MODE ) try : fcntl . flock ( fd , fcntl . LOCK_EX | fcntl . LOCK_NB ) except ( IOError , OSError ) : os . close ( fd ) else : return fd": 5144,
 "def __Logout ( si ) : try : if si : content = si . RetrieveContent ( ) content . sessionManager . Logout ( ) except Exception as e : pass": 5145,
 "def write_string ( value , buff , byteorder = ' big ' ) : data = value . encode ( ' utf-8 ' ) write_numeric ( USHORT , len ( data ) , buff , byteorder ) buff . write ( data ) ": 5146,
 "def start_task ( self , task ) : self . info ( \" Calculating {} . . . \" . format ( task ) ) self . tasks[task] = self . timer ( ) ": 5147,
 "def merge ( self , obj ) : for attribute in dir ( obj ) : if ' __ ' in attribute : continue setattr ( self , attribute , getattr ( obj , attribute ) ) ": 5148,
 "def elXpath ( self , xpath , dom = None ) : if dom is None : dom = self . browser return expect ( dom . is_element_present_by_xpath , args = [xpath] ) ": 5149,
 "def astype ( array , y ) : if isinstance ( y , autograd . core . Node ) : return array . astype ( numpy . array ( y . value ) . dtype ) return array . astype ( numpy . array ( y ) . dtype ) ": 5150,
 "def save ( self ) : if self . path : self . _saveState ( self . path ) else : self . saveAs ( ) ": 5151,
 "def _parse_array ( self , tensor_proto ) : try : from onnx . numpy_helper import to_array except ImportError as e : raise ImportError ( \" Unable to import onnx which is required {} \" . format ( e ) ) np_array = to_array ( tensor_proto ) . reshape ( tuple ( tensor_proto . dims ) ) return mx . nd . array ( np_array ) ": 5152,
 "def filehash ( path ) : with open ( path , \" rU \" ) as f : return md5 ( py3compat . str_to_bytes ( f . read ( ) ) ) . hexdigest ( ) ": 5153,
 "def _is_target_a_directory ( link , rel_target ) : \t\ttarget = os . path . join ( os . path . dirname ( link ) , rel_target ) \treturn os . path . isdir ( target ) ": 5154,
 "def fetch ( self ) : api = self . doapi_manager return api . _domain ( api . request ( self . url ) [ \" domain \" ] ) ": 5155,
 "def _fetch_all_as_dict ( self , cursor ) : desc = cursor . description return [ dict ( zip ( [col[0] for col in desc] , row ) ) for row in cursor . fetchall ( ) ]": 5156,
 "def add_widgets ( self , *widgets_or_spacings ) : layout = self . layout ( ) for widget_or_spacing in widgets_or_spacings : if isinstance ( widget_or_spacing , int ) : layout . addSpacing ( widget_or_spacing ) else : layout . addWidget ( widget_or_spacing ) ": 5157,
 "def _sort_r ( sorted , processed , key , deps , dependency_tree ) : if key in processed : return processed . add ( key ) for dep_key in deps : dep_deps = dependency_tree . get ( dep_key ) if dep_deps is None : log . debug ( ' \" %s \" not found , skipped ' , Repr ( dep_key ) ) continue _sort_r ( sorted , processed , dep_key , dep_deps , dependency_tree ) sorted . append ( ( key , deps ) ) ": 5158,
 "def sinwave ( n = 4 , inc = . 25 ) : \t\t\tx = np . arange ( -n , n , inc ) \ty = np . arange ( -n , n , inc ) \tX , Y = np . meshgrid ( x , y ) \tR = np . sqrt ( X**2 + Y**2 ) \tZ = np . sin ( R ) / ( . 5*R ) \treturn pd . DataFrame ( Z , index = x , columns = y ) ": 5159,
 "def get_serial_number_string ( self ) : self . _check_device_status ( ) str_p = ffi . new ( \" wchar_t[] \" , 255 ) rv = hidapi . hid_get_serial_number_string ( self . _device , str_p , 255 ) if rv = = -1 : raise IOError ( \" Failed to read serial number string from HID \" \" device : {0} \" . format ( self . _get_last_error_string ( ) ) ) return ffi . string ( str_p ) ": 5160,
 "def __PrintEnumDocstringLines ( self , enum_type ) : description = enum_type . description or ' %s enum type . ' % enum_type . name for line in textwrap . wrap ( ' r ' ) ": 5161,
 "def property_as_list ( self , property_name ) : try : res = self . _a_tags[property_name] except KeyError : return [] if type ( res ) = = list : return res else : return [res]": 5162,
 "def reindex_axis ( self , labels , axis = 0 , **kwargs ) : # for compatibility with higher dims if axis ! = 0 : raise ValueError ( \" cannot reindex series on non-zero axis! \" ) msg = ( \" ' . reindex_axis ' is deprecated and will be removed in a future \" \" version . Use ' . reindex ' instead . \" ) warnings . warn ( msg , FutureWarning , stacklevel = 2 ) return self . reindex ( index = labels , **kwargs ) ": 5163,
 "def listen_for_updates ( self ) : self . toredis . subscribe ( self . group_pubsub , callback = self . callback ) ": 5164,
 "def remove_element ( self , e ) : if e . label is not None : self . elementdict . pop ( e . label ) self . elementlist . remove ( e ) ": 5165,
 "def block_view ( arr , block = ( 3 , 3 ) ) : # simple shape and strides computations may seem at first strange # unless one is able to recognize the ' tuple additions ' involved ;- ) shape = ( arr . shape[0] // block[0] , arr . shape[1] // block[1] ) + block strides = ( block[0] * arr . strides[0] , block[1] * arr . strides[1] ) + arr . strides return ast ( arr , shape = shape , strides = strides ) ": 5166,
 "def delete_index ( self ) : es = self . _init_connection ( ) if es . indices . exists ( index = self . index ) : es . indices . delete ( index = self . index ) ": 5167,
 "def preprocess_french ( trans , fr_nlp , remove_brackets_content = True ) : if remove_brackets_content : trans = pangloss . remove_content_in_brackets ( trans , \" [] \" ) # Not sure why I have to split and rejoin , but that fixes a Spacy token # error . trans = fr_nlp ( \" \" . join ( trans . split ( ) [ : ] ) ) # trans = fr_nlp ( trans ) trans = \" \" . join ( [token . lower_ for token in trans if not token . is_punct] ) return trans": 5168,
 "def __init__ ( self , filename , mode , encoding = None ) : FileHandler . __init__ ( self , filename , mode , encoding ) self . mode = mode self . encoding = encoding": 5169,
 "def _create_statusicon ( self ) : statusicon = Gtk . StatusIcon ( ) statusicon . set_from_gicon ( self . _icons . get_gicon ( ' media ' ) ) statusicon . set_tooltip_text ( _ ( \" udiskie \" ) ) return statusicon": 5170,
 "def sort_matrix ( a , n = 0 ) : a = _n . array ( a ) return a[ : , a[n , : ] . argsort ( ) ]": 5171,
 "def add_params_to_url ( url , params ) : url_parts = list ( urlparse . urlparse ( url ) ) # get url parts query = dict ( urlparse . parse_qsl ( url_parts[4] ) ) # get url query query . update ( params ) # add new params url_parts[4] = urlencode ( query ) return urlparse . urlunparse ( url_parts ) ": 5172,
 "def make_aware ( value , timezone ) : if hasattr ( timezone , ' localize ' ) and value not in ( datetime . datetime . min , datetime . datetime . max ) : # available for pytz time zones return timezone . localize ( value , is_dst = None ) else : # may be wrong around DST changes return value . replace ( tzinfo = timezone ) ": 5173,
 "def reset_password ( app , appbuilder , username , password ) : _appbuilder = import_application ( app , appbuilder ) user = _appbuilder . sm . find_user ( username = username ) if not user : click . echo ( \" User {0} not found . \" . format ( username ) ) else : _appbuilder . sm . reset_password ( user . id , password ) click . echo ( click . style ( \" User {0} reseted . \" . format ( username ) , fg = \" green \" ) ) ": 5174,
 "def check ( text ) : err = \" malapropisms . misc \" msg = u \" ' {} ' is a malapropism . \" illogics = [ \" the infinitesimal universe \" , \" a serial experience \" , \" attack my voracity \" , ] return existence_check ( text , illogics , err , msg , offset = 1 ) ": 5175,
 "def apply ( filter ) : def decorator ( callable ) : return lambda *args , **kwargs : filter ( callable ( *args , **kwargs ) ) return decorator": 5176,
 "def create_response ( self , request , content , content_type ) : return HttpResponse ( content = content , content_type = content_type ) ": 5177,
 "def latlng ( arg ) : if is_string ( arg ) : return arg normalized = normalize_lat_lng ( arg ) return \" %s , %s \" % ( format_float ( normalized[0] ) , format_float ( normalized[1] ) ) ": 5178,
 "def delete ( filething ) : t = MP4 ( filething ) filething . fileobj . seek ( 0 ) t . delete ( filething ) ": 5179,
 "def access_ok ( self , access ) : for c in access : if c not in self . perms : return False return True": 5180,
 "def creation_time ( self ) : timestamp = self . _fsntfs_attribute . get_creation_time_as_integer ( ) return dfdatetime_filetime . Filetime ( timestamp = timestamp ) ": 5181,
 "def nmse ( a , b ) : return np . square ( a - b ) . mean ( ) / ( a . mean ( ) * b . mean ( ) ) ": 5182,
 "def _rescale_array ( self , array , scale , zero ) : if scale ! = 1 . 0 : sval = numpy . array ( scale , dtype = array . dtype ) array * = sval if zero ! = 0 . 0 : zval = numpy . array ( zero , dtype = array . dtype ) array + = zval": 5183,
 "def extract_vars_above ( *names ) : callerNS = sys . _getframe ( 2 ) . f_locals return dict ( ( k , callerNS[k] ) for k in names ) ": 5184,
 "def __init__ ( self , name , contained_key ) : self . name = name self . contained_key = contained_key": 5185,
 "def Any ( a , axis , keep_dims ) : return np . any ( a , axis = axis if not isinstance ( axis , np . ndarray ) else tuple ( axis ) , keepdims = keep_dims ) , ": 5186,
 "def uncheck ( self , locator = None , allow_label_click = None , **kwargs ) : self . _check_with_label ( \" checkbox \" , False , locator = locator , allow_label_click = allow_label_click , **kwargs ) ": 5187,
 "def upload_as_json ( name , mylist ) : location = list ( IPList . objects . filter ( name ) ) if location : iplist = location[0] return iplist . upload ( json = mylist , as_type = ' json ' ) ": 5188,
 "def __getattr__ ( self , *args , **kwargs ) : return xmlrpc . client . _Method ( self . __request , *args , **kwargs ) ": 5189,
 "def setRect ( self , rect ) : \t\t\t\tself . x , self . y , self . w , self . h = rect": 5190,
 "def calc_base64 ( s ) : s = compat . to_bytes ( s ) s = compat . base64_encodebytes ( s ) . strip ( ) # return bytestring return compat . to_native ( s ) ": 5191,
 "def prsint ( string ) : string = stypes . stringToCharP ( string ) intval = ctypes . c_int ( ) libspice . prsint_c ( string , ctypes . byref ( intval ) ) return intval . value": 5192,
 "def testable_memoized_property ( func = None , key_factory = per_instance , **kwargs ) : getter = memoized_method ( func = func , key_factory = key_factory , **kwargs ) def setter ( self , val ) : with getter . put ( self ) as putter : putter ( val ) return property ( fget = getter , fset = setter , fdel = lambda self : getter . forget ( self ) ) ": 5193,
 "def is_cached ( self , url ) : try : return True if url in self . cache else False except TypeError : return False": 5194,
 "def add_xlabel ( self , text = None ) : x = self . fit . meta[ ' independent ' ] if not text : text = ' $ ' + x[ ' tex_symbol ' ] + r ' $ $ ( \\si{ ' + x[ ' siunitx ' ] + r ' } ) $ ' self . plt . set_xlabel ( text ) ": 5195,
 "def stft ( func = None , **kwparams ) : from numpy . fft import fft , ifft return stft . base ( transform = fft , inverse_transform = ifft ) ( func , **kwparams ) ": 5196,
 "def sdmethod ( meth ) : sd = singledispatch ( meth ) def wrapper ( obj , *args , **kwargs ) : return sd . dispatch ( args[0] . __class__ ) ( obj , *args , **kwargs ) wrapper . register = sd . register wrapper . dispatch = sd . dispatch wrapper . registry = sd . registry wrapper . _clear_cache = sd . _clear_cache functools . update_wrapper ( wrapper , meth ) return wrapper": 5197,
 "def str_to_boolean ( input_str ) : if not isinstance ( input_str , six . string_types ) : raise ValueError ( input_str ) input_str = str_quote_stripper ( input_str ) return input_str . lower ( ) in ( \" true \" , \" t \" , \" 1 \" , \" y \" , \" yes \" ) ": 5198,
 "def schedule_task ( self ) : from . tasks import publish_task publish_task . apply_async ( kwargs = { ' pk ' : self . pk} , eta = self . scheduled_time ) ": 5199,
 "def force_stop ( self ) : r = self . local_renderer with self . settings ( warn_only = True ) : r . sudo ( ' pkill -9 -f celery ' ) r . sudo ( ' rm -f /tmp/celery* . pid ' ) ": 5200,
 "def has_add_permission ( self , request ) : return request . user . is_authenticated and request . user . is_active and request . user . is_staff": 5201,
 "def do_forceescape ( value ) : if hasattr ( value , ' __html__ ' ) : value = value . __html__ ( ) return escape ( unicode ( value ) ) ": 5202,
 "def fieldstorage ( self ) : if self . _fieldstorage is None : if self . _body is not None : raise ReadBodyTwiceError ( ) self . _fieldstorage = cgi . FieldStorage ( environ = self . _environ , fp = self . _environ[ ' wsgi . input ' ] ) return self . _fieldstorage": 5203,
 "def napoleon_to_sphinx ( docstring , **config_params ) : if \" napoleon_use_param \" not in config_params : config_params[ \" napoleon_use_param \" ] = False if \" napoleon_use_rtype \" not in config_params : config_params[ \" napoleon_use_rtype \" ] = False config = Config ( **config_params ) return str ( GoogleDocstring ( docstring , config ) ) ": 5204,
 "def split_string ( text , chars_per_string ) : return [text[i : i + chars_per_string] for i in range ( 0 , len ( text ) , chars_per_string ) ]": 5205,
 "def get_checkerboard_matrix ( kernel_width ) : return np . vstack ( ( np . hstack ( ( -1 * np . ones ( ( kernel_width , kernel_width ) ) , np . ones ( ( kernel_width , kernel_width ) ) ) ) , np . hstack ( ( np . ones ( ( kernel_width , kernel_width ) ) , -1 * np . ones ( ( kernel_width , kernel_width ) ) ) ) ) ) ": 5206,
 "def cric__lasso ( ) : model = sklearn . linear_model . LogisticRegression ( penalty = \" l1 \" , C = 0 . 002 ) # we want to explain the raw probability outputs of the trees model . predict = lambda X : model . predict_proba ( X ) [ : , 1] return model": 5207,
 "def from_file_url ( url ) : if url . startswith ( ' file : // ' ) : url = url[len ( ' file : // ' ) : ] . replace ( ' / ' , os . path . sep ) return url": 5208,
 "def to_array ( self ) : dt = np . dtype ( list ( zip ( self . labels , ( c . dtype for c in self . columns ) ) ) ) arr = np . empty_like ( self . columns[0] , dt ) for label in self . labels : arr[label] = self[label] return arr": 5209,
 "def _check_valid ( key , val , valid ) : if val not in valid : raise ValueError ( ' %s must be one of %s , not \" %s \" ' % ( key , valid , val ) ) ": 5210,
 "def blueprint_name_to_url ( name ) : if name[-1 : ] = = \" . \" : name = name[ : -1] name = str ( name ) . replace ( \" . \" , \" / \" ) return name": 5211,
 "def is_bytes ( string ) : if six . PY3 and isinstance ( string , ( bytes , memoryview , bytearray ) ) : # noqa return True elif six . PY2 and isinstance ( string , ( buffer , bytearray ) ) : # noqa return True return False": 5212,
 "def closeEvent ( self , e ) : if self . _closed : return res = self . emit ( ' close ' ) # Discard the close event if False is returned by one of the callback # functions . if False in res : # pragma : no cover e . ignore ( ) return super ( GUI , self ) . closeEvent ( e ) self . _closed = True": 5213,
 "def byteswap ( data , word_size = 4 ) : return reduce ( lambda x , y : x+ ' ' . join ( reversed ( y ) ) , chunks ( data , word_size ) , ' ' ) ": 5214,
 "def point8_to_box ( points ) : p = points . reshape ( ( -1 , 4 , 2 ) ) minxy = p . min ( axis = 1 ) # nx2 maxxy = p . max ( axis = 1 ) # nx2 return np . concatenate ( ( minxy , maxxy ) , axis = 1 ) ": 5215,
 "def wrap ( s , width = 80 ) : return ' \\n ' . join ( textwrap . wrap ( str ( s ) , width = width ) ) ": 5216,
 "def mul ( a , b ) : def multiply ( a , b ) : \" \" \" Multiplication \" \" \" return a * b return op_with_scalar_cast ( a , b , multiply ) ": 5217,
 "def is_edge_consistent ( graph , u , v ) : if not graph . has_edge ( u , v ) : raise ValueError ( ' {} does not contain an edge ( {} , {} ) ' . format ( graph , u , v ) ) return 0 = = len ( set ( d[RELATION] for d in graph . edge[u][v] . values ( ) ) ) ": 5218,
 "def isreal ( obj ) : return ( ( obj is not None ) and ( not isinstance ( obj , bool ) ) and isinstance ( obj , ( int , float ) ) ) ": 5219,
 "def irecarray_to_py ( a ) : pytypes = [pyify ( typestr ) for name , typestr in a . dtype . descr] def convert_record ( r ) : return tuple ( [converter ( value ) for converter , value in zip ( pytypes , r ) ] ) return ( convert_record ( r ) for r in a ) ": 5220,
 "def close ( self ) : if not self . _closed : self . __flush ( ) object . __setattr__ ( self , \" _closed \" , True ) ": 5221,
 "def __call__ ( self , actual_value , expect ) : self . _expect = expect if self . expected_value is NO_ARG : return self . asserts ( actual_value ) return self . asserts ( actual_value , self . expected_value ) ": 5222,
 "def matchfieldnames ( field_a , field_b ) : normalised_a = field_a . replace ( ' ' , ' _ ' ) . lower ( ) normalised_b = field_b . replace ( ' ' , ' _ ' ) . lower ( ) return normalised_a = = normalised_b": 5223,
 "def assert_looks_like ( first , second , msg = None ) : first = _re . sub ( \" \\s+ \" , \" \" , first . strip ( ) ) second = _re . sub ( \" \\s+ \" , \" \" , second . strip ( ) ) if first ! = second : raise AssertionError ( msg or \" %r does not look like %r \" % ( first , second ) ) ": 5224,
 "def constraint_range_dict ( self , *args , **kwargs ) : bins = self . bins ( *args , **kwargs ) return [{self . name+ ' __gte ' : a , self . name+ ' __lt ' : b} for a , b in zip ( bins[ : -1] , bins[1 : ] ) ] space = self . space ( *args , **kwargs ) resolution = space[1] - space[0] return [{self . name+ ' __gte ' : s , self . name+ ' __lt ' : s+resolution} for s in space]": 5225,
 "def __similarity ( s1 , s2 , ngrams_fn , n = 3 ) : ngrams1 , ngrams2 = set ( ngrams_fn ( s1 , n = n ) ) , set ( ngrams_fn ( s2 , n = n ) ) matches = ngrams1 . intersection ( ngrams2 ) return 2 * len ( matches ) / ( len ( ngrams1 ) + len ( ngrams2 ) ) ": 5226,
 "def __complex__ ( self ) : if self . _t ! = 99 or self . key ! = [ ' re ' , ' im ' ] : return complex ( float ( self ) ) return complex ( float ( self . re ) , float ( self . im ) ) ": 5227,
 "def extract_pdfminer ( self , filename , **kwargs ) : stdout , _ = self . run ( [ ' pdf2txt . py ' , filename] ) return stdout": 5228,
 "def connect_rds ( aws_access_key_id = None , aws_secret_access_key = None , **kwargs ) : from boto . rds import RDSConnection return RDSConnection ( aws_access_key_id , aws_secret_access_key , **kwargs ) ": 5229,
 "def read ( self ) : for line in self . io . read ( ) : with self . parse_line ( line ) as j : yield j": 5230,
 "def _parse_canonical_int64 ( doc ) : l_str = doc[ ' $numberLong ' ] if len ( doc ) ! = 1 : raise TypeError ( ' Bad $numberLong , extra field ( s ) : %s ' % ( doc , ) ) return Int64 ( l_str ) ": 5231,
 "def find_commons ( lists ) : others = lists[1 : ] return [ val for val in lists[0] if is_in_all ( val , others ) ]": 5232,
 "def not0 ( a ) : return matrix ( list ( map ( lambda x : 1 if x = = 0 else x , a ) ) , a . size ) ": 5233,
 "def link ( self , mu , dist ) : return np . log ( mu ) - np . log ( dist . levels - mu ) ": 5234,
 "def lines ( self ) : if self . _lines is None : self . _lines = self . obj . content . splitlines ( ) return self . _lines": 5235,
 "def vectorsToMatrix ( aa , bb ) : MM = np . zeros ( [3 , 3] , np . float ) for ii in range ( 3 ) : for jj in range ( 3 ) : MM[ii , jj] = aa[ii] * bb[jj] return MM": 5236,
 "def build_service_class ( metadata ) : i = importlib . import_module ( metadata ) service = i . service env = get_jinja_env ( ) service_template = env . get_template ( ' service . py . jinja2 ' ) with open ( api_path ( service . name . lower ( ) ) , ' w ' ) as t : t . write ( service_template . render ( service_md = service ) ) ": 5237,
 "def validate ( self , obj ) : if not isinstance ( obj , self . model_class ) : raise ValidationError ( ' Invalid object ( %s ) for service %s ' % ( type ( obj ) , type ( self ) ) ) LOG . debug ( u ' Object %s state : %s ' , self . model_class , obj . __dict__ ) obj . full_clean ( ) ": 5238,
 "def is_port_open ( port , host = \" 127 . 0 . 0 . 1 \" ) : s = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) try : s . connect ( ( host , int ( port ) ) ) s . shutdown ( 2 ) return True except Exception as e : return False": 5239,
 "def _is_utf_8 ( txt ) : assert isinstance ( txt , six . binary_type ) try : _ = six . text_type ( txt , ' utf-8 ' ) except ( TypeError , UnicodeEncodeError ) : return False else : return True": 5240,
 "def validate ( self , val ) : if val in self . values : return True , None else : return False , \" ' %s ' is not in enum : %s \" % ( val , str ( self . values ) ) ": 5241,
 "def token_accuracy ( labels , outputs ) : weights = tf . to_float ( tf . not_equal ( labels , 0 ) ) return tf . metrics . accuracy ( labels , outputs , weights = weights ) ": 5242,
 "def add_bg ( img , padding , color = COL_WHITE ) : img = gray3 ( img ) h , w , d = img . shape new_img = np . ones ( ( h + 2*padding , w + 2*padding , d ) ) * color[ : d] new_img = new_img . astype ( np . uint8 ) set_img_box ( new_img , ( padding , padding , w , h ) , img ) return new_img": 5243,
 "def clone ( src , **kwargs ) : obj = object . __new__ ( type ( src ) ) obj . __dict__ . update ( src . __dict__ ) obj . __dict__ . update ( kwargs ) return obj": 5244,
 "def activate ( ) : # This is derived from the clone cli = CommandLineInterface ( ) cli . ensure_config ( ) cli . write_dockerfile ( ) cli . build ( ) cli . run ( ) ": 5245,
 "def mimetype ( self ) : return ( self . environment . mimetypes . get ( self . format_extension ) or self . compiler_mimetype or ' application/octet-stream ' ) ": 5246,
 "def ts_func ( f ) : def wrap_func ( df , *args ) : # TODO : should vectorize to apply over all columns? return Chromatogram ( f ( df . values , *args ) , df . index , df . columns ) return wrap_func": 5247,
 "def apply_conditional_styles ( self , cbfct ) : for ridx in range ( self . nrows ) : for cidx in range ( self . ncols ) : fmts = cbfct ( self . actual_values . iloc[ridx , cidx] ) fmts and self . iloc[ridx , cidx] . apply_styles ( fmts ) return self": 5248,
 "def create_alias ( self ) : LOG . info ( ' Creating alias %s ' , self . env ) try : self . lambda_client . create_alias ( FunctionName = self . app_name , Name = self . env , FunctionVersion = ' $LATEST ' , Description = ' Alias for {} ' . format ( self . env ) ) except boto3 . exceptions . botocore . exceptions . ClientError as error : LOG . debug ( ' Create alias error : %s ' , error ) LOG . info ( \" Alias creation failed . Retrying . . . \" ) raise": 5249,
 "def cmyk ( c , m , y , k ) : return Color ( \" cmyk \" , c , m , y , k ) ": 5250,
 "def _merge_meta ( model1 , model2 ) : w1 = _get_meta ( model1 ) w2 = _get_meta ( model2 ) return metadata . merge ( w1 , w2 , metadata_conflicts = ' silent ' ) ": 5251,
 "def fromiterable ( cls , itr ) : x , y , z = itr return cls ( x , y , z ) ": 5252,
 "def normalize ( self , dt , is_dst = False ) : if dt . tzinfo is self : return dt if dt . tzinfo is None : raise ValueError ( ' Naive time - no tzinfo set ' ) return dt . astimezone ( self ) ": 5253,
 "def covariance ( self , pt0 , pt1 ) : x = np . array ( [pt0[0] , pt1[0]] ) y = np . array ( [pt0[1] , pt1[1]] ) names = [ \" n1 \" , \" n2 \" ] return self . covariance_matrix ( x , y , names = names ) . x[0 , 1]": 5254,
 "def build_parser ( ) : parser = argparse . ArgumentParser ( description = \" The IOTile task supervisor \" ) parser . add_argument ( ' -c ' , ' --config ' , help = \" config json with options \" ) parser . add_argument ( ' -v ' , ' --verbose ' , action = \" count \" , default = 0 , help = \" Increase logging verbosity \" ) return parser": 5255,
 "def get_mod_time ( self , path ) : conn = self . get_conn ( ) ftp_mdtm = conn . sendcmd ( ' MDTM ' + path ) time_val = ftp_mdtm[4 : ] # time_val optionally has microseconds try : return datetime . datetime . strptime ( time_val , \" %Y%m%d%H%M%S . %f \" ) except ValueError : return datetime . datetime . strptime ( time_val , ' %Y%m%d%H%M%S ' ) ": 5256,
 "def _update_font_style ( self , font_style ) : toggle_state = font_style & wx . FONTSTYLE_ITALIC = = wx . FONTSTYLE_ITALIC self . ToggleTool ( wx . FONTFLAG_ITALIC , toggle_state ) ": 5257,
 "def expect_comment_end ( self ) : match = self . _expect_match ( ' # } ' , COMMENT_END_PATTERN ) self . advance ( match . end ( ) ) ": 5258,
 "def round_corner ( radius , fill ) : corner = Image . new ( ' L ' , ( radius , radius ) , 0 ) # ( 0 , 0 , 0 , 0 ) ) draw = ImageDraw . Draw ( corner ) draw . pieslice ( ( 0 , 0 , radius * 2 , radius * 2 ) , 180 , 270 , fill = fill ) return corner": 5259,
 "def this_week ( ) : since = TODAY + delta ( weekday = MONDAY ( -1 ) ) until = since + delta ( weeks = 1 ) return Date ( since ) , Date ( until ) ": 5260,
 "def setHSV ( self , pixel , hsv ) : color = conversions . hsv2rgb ( hsv ) self . _set_base ( pixel , color ) ": 5261,
 "def activate_subplot ( numPlot ) : # see http : //www . mail-archive . com/matplotlib-users@lists . sourceforge . net/msg07156 . html from pylab import gcf , axes numPlot - = 1 # index is 0-based , plots are 1-based return axes ( gcf ( ) . get_axes ( ) [numPlot] ) ": 5262,
 "def last_month ( ) : since = TODAY + delta ( day = 1 , months = -1 ) until = since + delta ( months = 1 ) return Date ( since ) , Date ( until ) ": 5263,
 "def select_down ( self ) : r , c = self . _index self . _select_index ( r+1 , c ) ": 5264,
 "def _get_mtime ( ) : return os . path . exists ( RPM_PATH ) and int ( os . path . getmtime ( RPM_PATH ) ) or 0": 5265,
 "def del_object_from_parent ( self ) : if self . parent : self . parent . objects . pop ( self . ref ) ": 5266,
 "def up ( self ) : if self . frame : self . frame = self . frame . f_back return self . frame is None": 5267,
 "def dispose_orm ( ) : log . debug ( \" Disposing DB connection pool ( PID %s ) \" , os . getpid ( ) ) global engine global Session if Session : Session . remove ( ) Session = None if engine : engine . dispose ( ) engine = None": 5268,
 "def _valid_table_name ( name ) : if name[0] not in \" _ \" + string . ascii_letters or not set ( name ) . issubset ( \" _ \" + string . ascii_letters + string . digits ) : return False else : return True": 5269,
 "def has_common ( self , other ) : if not isinstance ( other , WordSet ) : raise ValueError ( ' Can compare only WordSets ' ) return self . term_set & other . term_set": 5270,
 "def timeit ( self , metric , func , *args , **kwargs ) : return metrics . timeit ( metric , func , *args , **kwargs ) ": 5271,
 "def _call_retry ( self , force_retry ) : last_exception = None for i in range ( self . max_attempts ) : try : log . info ( \" Calling %s %s \" % ( self . method , self . url ) ) response = self . requests_method ( self . url , data = self . data , params = self . params , headers = self . headers , timeout = ( self . connect_timeout , self . read_timeout ) , verify = self . verify_ssl , ) if response is None : log . warn ( \" Got response None \" ) if self . _method_is_safe_to_retry ( ) : delay = 0 . 5 + i * 0 . 5 log . info ( \" Waiting %s sec and Retrying since call is a %s \" % ( delay , self . method ) ) time . sleep ( delay ) continue else : raise PyMacaronCoreException ( \" Call %s %s returned empty response \" % ( self . method , self . url ) ) return response except Exception as e : last_exception = e retry = force_retry if isinstance ( e , ReadTimeout ) : # Log enough to help debugging . . . log . warn ( \" Got a ReadTimeout calling %s %s \" % ( self . method , self . url ) ) log . warn ( \" Exception was : %s \" % str ( e ) ) resp = e . response if not resp : log . info ( \" Requests error has no response . \" ) # TODO : retry = True? Is it really safe? else : b = resp . content log . info ( \" Requests has a response with content : \" + pprint . pformat ( b ) ) if self . _method_is_safe_to_retry ( ) : # It is safe to retry log . info ( \" Retrying since call is a %s \" % self . method ) retry = True elif isinstance ( e , ConnectTimeout ) : log . warn ( \" Got a ConnectTimeout calling %s %s \" % ( self . method , self . url ) ) log . warn ( \" Exception was : %s \" % str ( e ) ) # ConnectTimeouts are safe to retry whatever the call . . . retry = True if retry : continue else : raise e # max_attempts has been reached : propagate the last received Exception if not last_exception : last_exception = Exception ( \" Reached max-attempts ( %s ) . Giving up calling %s %s \" % ( self . max_attempts , self . method , self . url ) ) raise last_exception": 5272,
 "def _check_valid_key ( self , key ) : if not isinstance ( key , key_type ) : raise ValueError ( ' %r is not a valid key type ' % key ) if not VALID_KEY_RE . match ( key ) : raise ValueError ( ' %r contains illegal characters ' % key ) ": 5273,
 "def convert_string ( string ) : if is_int ( string ) : return int ( string ) elif is_float ( string ) : return float ( string ) elif convert_bool ( string ) [0] : return convert_bool ( string ) [1] elif string = = ' None ' : return None else : return string": 5274,
 "def get_serialize_format ( self , mimetype ) : \t\t\t\tformat = self . formats . get ( mimetype , None ) \t\tif format is None : \t\t\tformat = formats . get ( mimetype , None ) \t\treturn format": 5275,
 "def tree_render ( request , upy_context , vars_dictionary ) : page = upy_context[ ' PAGE ' ] return render_to_response ( page . template . file_name , vars_dictionary , context_instance = RequestContext ( request ) ) ": 5276,
 "def smartSum ( x , key , value ) : if key not in list ( x . keys ( ) ) : x[key] = value else : x[key]+ = value": 5277,
 "def add ( self , entity ) : \t\t\t\tresult = self . _http_req ( ' connections ' , method = ' POST ' , payload = entity ) \t\tstatus = result[ ' status ' ]\t\tif not status = = 201 : \t\t\traise ServiceRegistryError ( status , \" Couldn ' t add entity \" ) \t\tself . debug ( 0x01 , result ) \t\treturn result[ ' decoded ' ]": 5278,
 "def load_member ( fqn ) : modulename , member_name = split_fqn ( fqn ) module = __import__ ( modulename , globals ( ) , locals ( ) , member_name ) return getattr ( module , member_name ) ": 5279,
 "def encode_list ( dynamizer , value ) : encoded_list = [] dict ( map ( dynamizer . raw_encode , value ) ) for v in value : encoded_type , encoded_value = dynamizer . raw_encode ( v ) encoded_list . append ( { encoded_type : encoded_value , } ) return ' L ' , encoded_list": 5280,
 "def compute_ssim ( image1 , image2 , gaussian_kernel_sigma = 1 . 5 , gaussian_kernel_width = 11 ) : gaussian_kernel_1d = get_gaussian_kernel ( gaussian_kernel_width , gaussian_kernel_sigma ) return SSIM ( image1 , gaussian_kernel_1d ) . ssim_value ( image2 ) ": 5281,
 "def set_strict ( self , value ) : assert isinstance ( value , bool ) self . __settings . set_strict ( value ) ": 5282,
 "def copy ( self ) : \t\t\t\treturn self . __class__ ( self . operations . copy ( ) , self . collection , self . document ) ": 5283,
 "def cli ( yamlfile , directory , out , classname , format ) : DotGenerator ( yamlfile , format ) . serialize ( classname = classname , dirname = directory , filename = out ) ": 5284,
 "def tanimoto_coefficient ( a , b ) : return sum ( map ( lambda ( x , y ) : float ( x ) *float ( y ) , zip ( a , b ) ) ) / sum ( [ -sum ( map ( lambda ( x , y ) : float ( x ) *float ( y ) , zip ( a , b ) ) ) , sum ( map ( lambda x : float ( x ) **2 , a ) ) , sum ( map ( lambda x : float ( x ) **2 , b ) ) ] ) ": 5285,
 "def prt_nts ( data_nts , prtfmt = None , prt = sys . stdout , nt_fields = None , **kws ) : prt_txt ( prt , data_nts , prtfmt , nt_fields , **kws ) ": 5286,
 "def add_column ( filename , column , formula , force = False ) : columns = parse_formula ( formula ) logger . info ( \" Running file : %s \" %filename ) logger . debug ( \" Reading columns : %s \" %columns ) data = fitsio . read ( filename , columns = columns ) logger . debug ( ' Evaluating formula : %s ' %formula ) col = eval ( formula ) col = np . asarray ( col , dtype = [ ( column , col . dtype ) ] ) insert_columns ( filename , col , force = force ) return True": 5287,
 "def from_json ( cls , json_doc ) : try : d = json . load ( json_doc ) except AttributeError : # catch the read ( ) error d = json . loads ( json_doc ) return cls . from_dict ( d ) ": 5288,
 "def lambda_failure_response ( *args ) : response_data = jsonify ( ServiceErrorResponses . _LAMBDA_FAILURE ) return make_response ( response_data , ServiceErrorResponses . HTTP_STATUS_CODE_502 ) ": 5289,
 "def get_handler ( self , *args , **options ) : handler = get_internal_wsgi_application ( ) from django . contrib . staticfiles . handlers import StaticFilesHandler return StaticFilesHandler ( handler ) ": 5290,
 "def _enter_plotting ( self , fontsize = 9 ) : # interactive_status = matplotlib . is_interactive ( ) self . original_fontsize = pyplot . rcParams[ ' font . size ' ] pyplot . rcParams[ ' font . size ' ] = fontsize pyplot . hold ( False ) # opens a figure window , if non exists pyplot . ioff ( ) ": 5291,
 "def count_levels ( value ) : if not isinstance ( value , dict ) or len ( value ) = = 0 : return 0 elif len ( value ) = = 0 : return 0 # An emptu dict has 0 else : nextval = list ( value . values ( ) ) [0] return 1 + count_levels ( nextval ) ": 5292,
 "def list_of ( cls ) : return lambda l : isinstance ( l , list ) and all ( isinstance ( x , cls ) for x in l ) ": 5293,
 "def delete ( self , name ) : if name in self . _cache : del self . _cache[name] self . writeCache ( ) # TODO clean files return True return False": 5294,
 "def rotation_from_quaternion ( q_wxyz ) : q_xyzw = np . array ( [q_wxyz[1] , q_wxyz[2] , q_wxyz[3] , q_wxyz[0]] ) R = transformations . quaternion_matrix ( q_xyzw ) [ : 3 , : 3] return R": 5295,
 "def delete_object_from_file ( file_name , save_key , file_location ) : file = __os . path . join ( file_location , file_name ) shelve_store = __shelve . open ( file ) del shelve_store[save_key] shelve_store . close ( ) ": 5296,
 "def getHeaders ( self ) : headers = self . _impl . getHeaders ( ) return tuple ( headers . getIndex ( i ) for i in range ( self . _impl . getNumCols ( ) ) ) ": 5297,
 "def get_chat_member ( self , user_id ) : return self . bot . api_call ( \" getChatMember \" , chat_id = str ( self . id ) , user_id = str ( user_id ) ) ": 5298,
 "def confirm_credential_display ( force = False ) : if force : return True msg = result = click . confirm ( text = msg ) return result": 5299,
 "def _is_start ( event , node , tagName ) : # pylint : disable = invalid-name return event = = pulldom . START_ELEMENT and node . tagName = = tagName": 5300,
 "def _index2n ( self , index ) : n_float = np . sqrt ( index + 1 ) - 1 n_int = int ( n_float ) if n_int = = n_float : n = n_int else : n = n_int + 1 return n": 5301,
 "def to_basestring ( value ) : if isinstance ( value , _BASESTRING_TYPES ) : return value assert isinstance ( value , bytes ) return value . decode ( \" utf-8 \" ) ": 5302,
 "def draw ( self , mode = \" triangles \" ) : gl . glDepthMask ( 0 ) Collection . draw ( self , mode ) gl . glDepthMask ( 1 ) ": 5303,
 "def fetch ( table , cols = \" * \" , where = ( ) , group = \" \" , order = ( ) , limit = ( ) , **kwargs ) : return select ( table , cols , where , group , order , limit , **kwargs ) . fetchall ( ) ": 5304,
 "def deleteAll ( self ) : for core in self . endpoints : self . _send_solr_command ( self . endpoints[core] , \" {\\ \" delete\\ \" : { \\ \" query\\ \" : \\ \" * : *\\ \" }} \" ) ": 5305,
 "def current_timestamp ( ) : now = datetime . utcnow ( ) timestamp = now . isoformat ( ) [0 : 19] + ' Z ' debug ( \" generated timestamp : {now} \" . format ( now = timestamp ) ) return timestamp": 5306,
 "def hex_to_rgb ( h ) : h = h . lstrip ( ' # ' ) return tuple ( int ( h[i : i+2] , 16 ) /255 . for i in ( 0 , 2 , 4 ) ) ": 5307,
 "def string_to_genomic_range ( rstring ) : m = re . match ( ' ( [^ : ]+ ) : ( \\d+ ) - ( \\d+ ) ' , rstring ) if not m : sys . stderr . write ( \" ERROR : problem with range string \" +rstring+ \" \\n \" ) return GenomicRange ( m . group ( 1 ) , int ( m . group ( 2 ) ) , int ( m . group ( 3 ) ) ) ": 5308,
 "def code_from_ipynb ( nb , markdown = False ) : code = PREAMBLE for cell in nb[ ' cells ' ] : if cell[ ' cell_type ' ] = = ' code ' : # transform the input to executable Python code + = ' ' . join ( cell[ ' source ' ] ) if cell[ ' cell_type ' ] = = ' markdown ' : code + = ' \\n # ' + ' # ' . join ( cell[ ' source ' ] ) # We want a blank newline after each cell ' s output . # And the last line of source doesn ' t have a newline usually . code + = ' \\n\\n ' return code": 5309,
 "def gcall ( func , *args , **kwargs ) : def idle ( ) : with gdk . lock : return bool ( func ( *args , **kwargs ) ) return gobject . idle_add ( idle ) ": 5310,
 "def readline ( self ) : self . lineno + = 1 if self . _buffer : return self . _buffer . pop ( ) else : return self . input . readline ( ) ": 5311,
 "def ratelimit_remaining ( self ) : json = self . _json ( self . _get ( self . _github_url + ' /rate_limit ' ) , 200 ) core = json . get ( ' resources ' , {} ) . get ( ' core ' , {} ) self . _remaining = core . get ( ' remaining ' , 0 ) return self . _remaining": 5312,
 "def rewrap ( s , width = COLS ) : s = ' ' . join ( [l . strip ( ) for l in s . strip ( ) . split ( ' \\n ' ) ] ) return ' \\n ' . join ( textwrap . wrap ( s , width ) ) ": 5313,
 "def has_overlaps ( self ) : sorted_list = sorted ( self ) for i in range ( 0 , len ( sorted_list ) - 1 ) : if sorted_list[i] . overlaps ( sorted_list[i + 1] ) : return True return False": 5314,
 "def login ( self , username , password = None , token = None ) : self . session . basic_auth ( username , password ) ": 5315,
 "def get_year_start ( day = None ) : day = add_timezone ( day or datetime . date . today ( ) ) return day . replace ( month = 1 ) . replace ( day = 1 ) ": 5316,
 "def feature_union_concat ( Xs , nsamples , weights ) : if any ( x is FIT_FAILURE for x in Xs ) : return FIT_FAILURE Xs = [X if w is None else X * w for X , w in zip ( Xs , weights ) if X is not None] if not Xs : return np . zeros ( ( nsamples , 0 ) ) if any ( sparse . issparse ( f ) for f in Xs ) : return sparse . hstack ( Xs ) . tocsr ( ) return np . hstack ( Xs ) ": 5317,
 "def _get_wow64 ( ) : # Try to determine if the debugger itself is running on WOW64 . # On error assume False . if bits = = 64 : wow64 = False else : try : wow64 = IsWow64Process ( GetCurrentProcess ( ) ) except Exception : wow64 = False return wow64": 5318,
 "def _weighted_selection ( l , n ) : cuml = [] items = [] total_weight = 0 . 0 for weight , item in l : total_weight + = weight cuml . append ( total_weight ) items . append ( item ) return [items[bisect . bisect ( cuml , random . random ( ) *total_weight ) ] for _ in range ( n ) ]": 5319,
 "def move_to_start ( self , column_label ) : self . _columns . move_to_end ( column_label , last = False ) return self": 5320,
 "def files_changed ( ) : with chdir ( get_root ( ) ) : result = run_command ( ' git diff --name-only master . . . ' , capture = ' out ' ) changed_files = result . stdout . splitlines ( ) # Remove empty lines return [f for f in changed_files if f]": 5321,
 "def _get_name ( column_like ) : if isinstance ( column_like , Column ) : return column_like . name elif isinstance ( column_like , Cast ) : return column_like . clause . name": 5322,
 "def _reload ( self , force = False ) : self . _config_map = dict ( ) self . _registered_env_keys = set ( ) self . __reload_sources ( force ) self . __load_environment_keys ( ) self . verify ( ) self . _clear_memoization ( ) ": 5323,
 "def commits_with_message ( message ) : output = log ( \" --grep ' %s ' \" % message , oneline = True , quiet = True ) lines = output . splitlines ( ) return [l . split ( ' ' , 1 ) [0] for l in lines]": 5324,
 "def get_winfunc ( libname , funcname , restype = None , argtypes = ( ) , _libcache = {} ) : if libname not in _libcache : _libcache[libname] = windll . LoadLibrary ( libname ) func = getattr ( _libcache[libname] , funcname ) func . argtypes = argtypes func . restype = restype return func": 5325,
 "def terminate ( self ) : # Tear down the Pailgun TCPServer . if self . pailgun : self . pailgun . server_close ( ) super ( PailgunService , self ) . terminate ( ) ": 5326,
 "def _find_first_of ( line , substrings ) : starts = ( ( line . find ( i ) , i ) for i in substrings ) found = [ ( i , sub ) for i , sub in starts if i ! = -1] if found : return min ( found ) else : return -1 , None": 5327,
 "def open_as_pillow ( filename ) : with __sys_open ( filename , ' rb ' ) as f : data = BytesIO ( f . read ( ) ) return Image . open ( data ) ": 5328,
 "async def i2c_write_request ( self , command ) : device_address = int ( command[0] ) params = command[1] params = [int ( i ) for i in params] await self . core . i2c_write_request ( device_address , params ) ": 5329,
 "def ismatch ( text , pattern ) : if hasattr ( pattern , ' search ' ) : return pattern . search ( text ) is not None else : return pattern in text if Config . options . case_sensitive \\ else pattern . lower ( ) in text . lower ( ) ": 5330,
 "def static_get_type_attr ( t , name ) : for type_ in t . mro ( ) : try : return vars ( type_ ) [name] except KeyError : pass raise AttributeError ( name ) ": 5331,
 "def _get_device_id ( self , bus ) : _dbus = bus . get ( SERVICE_BUS , PATH ) devices = _dbus . devices ( ) if self . device is None and self . device_id is None and len ( devices ) = = 1 : return devices[0] for id in devices : self . _dev = bus . get ( SERVICE_BUS , DEVICE_PATH + \" /%s \" % id ) if self . device = = self . _dev . name : return id return None": 5332,
 "def props ( cls ) : return {k : v for ( k , v ) in inspect . getmembers ( cls ) if type ( v ) is Argument}": 5333,
 "def gettext ( self , string , domain = None , **variables ) : t = self . get_translations ( domain ) return t . ugettext ( string ) % variables": 5334,
 "def connect ( self , A , B , distance = 1 ) : self . connect1 ( A , B , distance ) if not self . directed : self . connect1 ( B , A , distance ) ": 5335,
 "def draw_graph ( G : nx . DiGraph , filename : str ) : A = to_agraph ( G ) A . graph_attr[ \" rankdir \" ] = \" LR \" A . draw ( filename , prog = \" dot \" ) ": 5336,
 "def on_windows ( ) : if bjam . variable ( \" NT \" ) : return True elif bjam . variable ( \" UNIX \" ) : uname = bjam . variable ( \" JAMUNAME \" ) if uname and uname[0] . startswith ( \" CYGWIN \" ) : return True return False": 5337,
 "def generate_chunks ( string , num_chars ) : for start in range ( 0 , len ( string ) , num_chars ) : yield string[start : start+num_chars]": 5338,
 "def __iter__ ( self ) : for node in chain ( *imap ( iter , self . children ) ) : yield node yield self": 5339,
 "def _clean_up_name ( self , name ) : for n in self . naughty : name = name . replace ( n , ' _ ' ) return name": 5340,
 "def assert_single_element ( iterable ) : it = iter ( iterable ) first_item = next ( it ) try : next ( it ) except StopIteration : return first_item raise ValueError ( \" iterable {!r} has more than one element . \" . format ( iterable ) ) ": 5341,
 "def _grammatical_join_filter ( l , arg = None ) : if not arg : arg = \" and | , \" try : final_join , initial_joins = arg . split ( \" | \" ) except ValueError : final_join = arg initial_joins = \" , \" return grammatical_join ( l , initial_joins , final_join ) ": 5342,
 "def setup ( ) : print ( \" Simple drive \" ) board . set_pin_mode ( L_CTRL_1 , Constants . OUTPUT ) board . set_pin_mode ( L_CTRL_2 , Constants . OUTPUT ) board . set_pin_mode ( PWM_L , Constants . PWM ) board . set_pin_mode ( R_CTRL_1 , Constants . OUTPUT ) board . set_pin_mode ( R_CTRL_2 , Constants . OUTPUT ) board . set_pin_mode ( PWM_R , Constants . PWM ) ": 5343,
 "def validate ( payload , schema ) : v = jsonschema . Draft4Validator ( schema , format_checker = jsonschema . FormatChecker ( ) ) error_list = [] for error in v . iter_errors ( payload ) : message = error . message location = ' / ' + ' / ' . join ( [str ( c ) for c in error . absolute_path] ) error_list . append ( message + ' at ' + location ) return error_list": 5344,
 "def kill_process ( process ) : logger = logging . getLogger ( ' xenon ' ) logger . info ( ' Terminating Xenon-GRPC server . ' ) os . kill ( process . pid , signal . SIGINT ) process . wait ( ) ": 5345,
 "def register_plugin ( self ) : self . main . restore_scrollbar_position . connect ( self . restore_scrollbar_position ) self . main . add_dockwidget ( self ) ": 5346,
 "def append_text ( self , txt ) : with open ( self . fullname , \" a \" ) as myfile : myfile . write ( txt ) ": 5347,
 "def tree_predict ( x , root , proba = False , regression = False ) : if isinstance ( root , Leaf ) : if proba : return root . probabilities elif regression : return root . mean else : return root . most_frequent if root . question . match ( x ) : return tree_predict ( x , root . true_branch , proba = proba , regression = regression ) else : return tree_predict ( x , root . false_branch , proba = proba , regression = regression ) ": 5348,
 "def minimise_xyz ( xyz ) : x , y , z = xyz m = max ( min ( x , y ) , min ( max ( x , y ) , z ) ) return ( x-m , y-m , z-m ) ": 5349,
 "def should_be_hidden_as_cause ( exc ) : # reduced traceback in case of HasWrongType ( instance_of checks ) from valid8 . validation_lib . types import HasWrongType , IsWrongType return isinstance ( exc , ( HasWrongType , IsWrongType ) ) ": 5350,
 "def getAllTriples ( self ) : return [ ( str ( s ) , str ( p ) , str ( o ) ) for s , p , o in self]": 5351,
 "def _call ( callable_obj , arg_names , namespace ) : arguments = {arg_name : getattr ( namespace , arg_name ) for arg_name in arg_names} return callable_obj ( **arguments ) ": 5352,
 "def load ( obj , cls , default_factory ) : if obj is None : return default_factory ( ) if isinstance ( obj , dict ) : return cls . load ( obj ) return obj": 5353,
 "def datetime_from_str ( string ) : return datetime . datetime ( year = 2000+int ( string[0 : 2] ) , month = int ( string[2 : 4] ) , day = int ( string[4 : 6] ) , hour = int ( string[7 : 9] ) , minute = int ( string[10 : 12] ) , second = int ( string[13 : 15] ) ) ": 5354,
 "def _normalize_numpy_indices ( i ) : if isinstance ( i , np . ndarray ) : if i . dtype = = bool : i = tuple ( j . tolist ( ) for j in i . nonzero ( ) ) elif i . dtype = = int : i = i . tolist ( ) return i": 5355,
 "def convert_types ( cls , value ) : if isinstance ( value , decimal . Decimal ) : return float ( value ) else : return value": 5356,
 "def set_index ( self , index ) : for df in self . get_DataFrame ( data = True , with_population = False ) : df . index = index": 5357,
 "def screen ( self , width , height , colorDepth ) : screenEvent = ScreenEvent ( ) screenEvent . width . value = width screenEvent . height . value = height screenEvent . colorDepth . value = colorDepth self . rec ( screenEvent ) ": 5358,
 "def iflatten ( L ) : for sublist in L : if hasattr ( sublist , ' __iter__ ' ) : for item in iflatten ( sublist ) : yield item else : yield sublist": 5359,
 "def wait_run_in_executor ( func , *args , **kwargs ) : loop = asyncio . get_event_loop ( ) future = loop . run_in_executor ( None , functools . partial ( func , *args , **kwargs ) ) yield from asyncio . wait ( [future] ) return future . result ( ) ": 5360,
 "def is_builtin_css_function ( name ) : name = name . replace ( ' _ ' , ' - ' ) if name in BUILTIN_FUNCTIONS : return True # Vendor-specific functions ( -foo-bar ) are always okay if name[0] = = ' - ' and ' - ' in name[1 : ] : return True return False": 5361,
 "def roots ( self ) : import numpy as np return np . roots ( list ( self . values ( ) ) [ : : -1] ) . tolist ( ) ": 5362,
 "def with_defaults ( method , nparams , defaults = None ) : args = [None] * nparams if not defaults else defaults + max ( nparams - len ( defaults ) , 0 ) * [None] return method ( *args ) ": 5363,
 "def is_same_nick ( self , left , right ) : return self . normalize ( left ) = = self . normalize ( right ) ": 5364,
 "def stop_refresh ( self ) : self . logger . debug ( \" stopping timed refresh \" ) self . rf_flags[ ' done ' ] = True self . rf_timer . clear ( ) ": 5365,
 "def _close ( self ) : if self . connection : with self . wrap_database_errors : self . connection . client . close ( ) ": 5366,
 "def pascal_row ( n ) : result = [1] x , numerator = 1 , n for denominator in range ( 1 , n // 2 + 1 ) : x * = numerator x / = denominator result . append ( x ) numerator - = 1 if n & 1 = = 0 : result . extend ( reversed ( result[ : -1] ) ) else : result . extend ( reversed ( result ) ) return result": 5367,
 "def place ( self ) : self . place_children ( ) self . canvas . append ( self . parent . canvas , float ( self . left ) , float ( self . top ) ) ": 5368,
 "def compute_number_edges ( function ) : n = 0 for node in function . nodes : n + = len ( node . sons ) return n": 5369,
 "def solr_to_date ( d ) : return \" {day} : {m} : {y} \" . format ( y = d[ : 4] , m = d[5 : 7] , day = d[8 : 10] ) if d else d": 5370,
 "def total_regular_pixels_from_mask ( mask ) : total_regular_pixels = 0 for y in range ( mask . shape[0] ) : for x in range ( mask . shape[1] ) : if not mask[y , x] : total_regular_pixels + = 1 return total_regular_pixels": 5371,
 "def make_temp ( text ) : import tempfile ( handle , path ) = tempfile . mkstemp ( text = True ) os . close ( handle ) afile = File ( path ) afile . write ( text ) return afile": 5372,
 "def shader_string ( body , glsl_version = ' 450 core ' ) : line_count = len ( body . split ( ' \\n ' ) ) line_number = inspect . currentframe ( ) . f_back . f_lineno + 1 - line_count return \" \" \" \\ # version %s%s \" \" \" % ( glsl_version , shader_substring ( body , stack_frame = 2 ) ) ": 5373,
 "def perl_cmd ( ) : perl = which ( os . path . join ( get_bcbio_bin ( ) , \" perl \" ) ) if perl : return perl else : return which ( \" perl \" ) ": 5374,
 "def interface_direct_class ( data_class ) : if data_class in ASSET : interface = AssetsInterface ( ) elif data_class in PARTY : interface = PartiesInterface ( ) elif data_class in BOOK : interface = BooksInterface ( ) elif data_class in CORPORATE_ACTION : interface = CorporateActionsInterface ( ) elif data_class in MARKET_DATA : interface = MarketDataInterface ( ) elif data_class in TRANSACTION : interface = TransactionsInterface ( ) else : interface = AssetManagersInterface ( ) return interface": 5375,
 "def dcounts ( self ) : print ( \" WARNING : Distinct value count for all tables can take a long time . . . \" , file = sys . stderr ) sys . stderr . flush ( ) data = [] for t in self . tables ( ) : for c in t . columns ( ) : data . append ( [t . name ( ) , c . name ( ) , c . dcount ( ) , t . size ( ) , c . dcount ( ) / float ( t . size ( ) ) ] ) df = pd . DataFrame ( data , columns = [ \" table \" , \" column \" , \" distinct \" , \" size \" , \" fraction \" ] ) return df": 5376,
 "def ms_panset ( self , viewer , event , data_x , data_y , msg = True ) : if self . canpan and ( event . state = = ' down ' ) : self . _panset ( viewer , data_x , data_y , msg = msg ) return True": 5377,
 "def _parse_single_response ( cls , response_data ) : if not isinstance ( response_data , dict ) : raise errors . RPCInvalidRequest ( \" No valid RPC-package . \" ) if \" id \" not in response_data : raise errors . RPCInvalidRequest ( \" \" \" Invalid Response , \" id \" missing . \" \" \" ) request_id = response_data[ ' id ' ] if \" jsonrpc \" not in response_data : raise errors . RPCInvalidRequest ( \" \" \" Invalid Response , \" jsonrpc \" missing . \" \" \" , request_id ) if not isinstance ( response_data[ \" jsonrpc \" ] , ( str , unicode ) ) : raise errors . RPCInvalidRequest ( \" \" \" Invalid Response , \" jsonrpc \" must be a string . \" \" \" ) if response_data[ \" jsonrpc \" ] ! = \" 2 . 0 \" : raise errors . RPCInvalidRequest ( \" \" \" Invalid jsonrpc version . \" \" \" , request_id ) error = response_data . get ( ' error ' , None ) result = response_data . get ( ' result ' , None ) if error and result : raise errors . RPCInvalidRequest ( \" \" \" Invalid Response , only \" result \" OR \" error \" allowed . \" \" \" , request_id ) if error : if not isinstance ( error , dict ) : raise errors . RPCInvalidRequest ( \" Invalid Response , invalid error-object . \" , request_id ) if not ( \" code \" in error and \" message \" in error ) : raise errors . RPCInvalidRequest ( \" Invalid Response , invalid error-object . \" , request_id ) error_data = error . get ( \" data \" , None ) if error[ ' code ' ] in errors . ERROR_CODE_CLASS_MAP : raise errors . ERROR_CODE_CLASS_MAP[error[ ' code ' ]] ( error_data , request_id ) else : error_object = errors . RPCFault ( error_data , request_id ) error_object . error_code = error[ ' code ' ] error_object . message = error[ ' message ' ] raise error_object return result , request_id": 5378,
 "def _calculate_similarity ( c ) : ma = {} for idc in c : set1 = _get_seqs ( c[idc] ) [ma . update ( { ( idc , idc2 ) : _common ( set1 , _get_seqs ( c[idc2] ) , idc , idc2 ) } ) for idc2 in c if idc ! = idc2 and ( idc2 , idc ) not in ma] # logger . debug ( \" _calculate_similarity_ %s \" % ma ) return ma": 5379,
 "def bundle_dir ( ) : if frozen ( ) : directory = sys . _MEIPASS else : directory = os . path . dirname ( os . path . abspath ( stack ( ) [1][1] ) ) if os . path . exists ( directory ) : return directory": 5380,
 "def plotfft ( s , fmax , doplot = False ) : fs = abs ( numpy . fft . fft ( s ) ) f = numpy . linspace ( 0 , fmax / 2 , len ( s ) / 2 ) if doplot : plot ( list ( f[1 : int ( len ( s ) / 2 ) ] ) , list ( fs[1 : int ( len ( s ) / 2 ) ] ) ) return f[1 : int ( len ( s ) / 2 ) ] . copy ( ) , fs[1 : int ( len ( s ) / 2 ) ] . copy ( ) ": 5381,
 "def psql ( sql , show = True ) : out = postgres ( ' psql -c \" %s \" ' % sql ) if show : print_command ( sql ) return out": 5382,
 "def download_url ( url , filename , headers ) : ensure_dirs ( filename ) response = requests . get ( url , headers = headers , stream = True ) if response . status_code = = 200 : with open ( filename , ' wb ' ) as f : for chunk in response . iter_content ( 16 * 1024 ) : f . write ( chunk ) ": 5383,
 "def destroy ( self ) : with self . _db_conn ( ) as conn : for table_name in self . _tables : conn . execute ( ' DROP TABLE IF EXISTS %s ' % table_name ) return self": 5384,
 "def do_forceescape ( value ) : if hasattr ( value , ' __html__ ' ) : value = value . __html__ ( ) return escape ( text_type ( value ) ) ": 5385,
 "def format_time ( timestamp ) : format_string = ' %Y_%m_%d_%Hh%Mm%Ss ' formatted_time = datetime . datetime . fromtimestamp ( timestamp ) . strftime ( format_string ) return formatted_time": 5386,
 "def _chunk_write ( chunk , local_file , progress ) : local_file . write ( chunk ) progress . update_with_increment_value ( len ( chunk ) ) ": 5387,
 "def write_only_property ( f ) : docstring = f . __doc__ return property ( fset = f , doc = docstring ) ": 5388,
 "def getEdges ( npArr ) : edges = np . concatenate ( ( [0] , npArr[ : , 0] + npArr[ : , 2] ) ) return np . array ( [Decimal ( str ( i ) ) for i in edges] ) ": 5389,
 "def get_callable_documentation ( the_callable ) : return wrap_text_in_a_box ( title = get_callable_signature_as_string ( the_callable ) , body = ( getattr ( the_callable , ' __doc__ ' ) or ' No documentation ' ) . replace ( ' \\n ' , ' \\n\\n ' ) , style = ' ascii_double ' ) ": 5390,
 "def main ( output = None , error = None , verbose = False ) : runner = Runner ( args = [ \" --verbose \" ] if verbose is not False else None ) runner . run ( output , error ) ": 5391,
 "def compose ( *parameter_functions ) : def composed_fn ( var_name , variable , phase ) : for fn in parameter_functions : variable = fn ( var_name , variable , phase ) return variable return composed_fn": 5392,
 "def contextMenuEvent ( self , event ) : self . menu . popup ( event . globalPos ( ) ) event . accept ( ) ": 5393,
 "def remove_parameter ( self , name ) : \t\t\t\tif name in self . __query : \t\t\tself . __query . pop ( name ) ": 5394,
 "def bbox ( self ) : return self . left , self . top , self . right , self . bottom": 5395,
 "def get_offset_topic_partition_count ( kafka_config ) : metadata = get_topic_partition_metadata ( kafka_config . broker_list ) if CONSUMER_OFFSET_TOPIC not in metadata : raise UnknownTopic ( \" Consumer offset topic is missing . \" ) return len ( metadata[CONSUMER_OFFSET_TOPIC] ) ": 5396,
 "def _regex_span ( _regex , _str , case_insensitive = True ) : if case_insensitive : flags = regex . IGNORECASE | regex . FULLCASE | regex . VERSION1 else : flags = regex . VERSION1 comp = regex . compile ( _regex , flags = flags ) matches = comp . finditer ( _str ) for match in matches : yield match": 5397,
 "def GetValueByName ( self , name ) : pyregf_value = self . _pyregf_key . get_value_by_name ( name ) if not pyregf_value : return None return REGFWinRegistryValue ( pyregf_value ) ": 5398,
 "def table_nan_locs ( table ) : ans = [] for rownum , row in enumerate ( table ) : try : if pd . isnull ( row ) . any ( ) : colnums = pd . isnull ( row ) . nonzero ( ) [0] ans + = [ ( rownum , colnum ) for colnum in colnums] except AttributeError : # table is really just a sequence of scalars if pd . isnull ( row ) : ans + = [ ( rownum , 0 ) ] return ans": 5399,
 "def strip_sdist_extras ( filelist ) : return [name for name in filelist if not file_matches ( name , IGNORE ) and not file_matches_regexps ( name , IGNORE_REGEXPS ) ]": 5400,
 "def get_param_names ( cls ) : return [m[0] for m in inspect . getmembers ( cls ) \\ if type ( m[1] ) = = property]": 5401,
 "def PyplotHistogram ( ) : import numpy as np import matplotlib . pyplot as plt np . random . seed ( 0 ) n_bins = 10 x = np . random . randn ( 1000 , 3 ) fig , axes = plt . subplots ( nrows = 2 , ncols = 2 ) ax0 , ax1 , ax2 , ax3 = axes . flatten ( ) colors = [ ' red ' , ' tan ' , ' lime ' ] ax0 . hist ( x , n_bins , normed = 1 , histtype = ' bar ' , color = colors , label = colors ) ax0 . legend ( prop = { ' size ' : 10} ) ax0 . set_title ( ' bars with legend ' ) ax1 . hist ( x , n_bins , normed = 1 , histtype = ' bar ' , stacked = True ) ax1 . set_title ( ' stacked bar ' ) ax2 . hist ( x , n_bins , histtype = ' step ' , stacked = True , fill = False ) ax2 . set_title ( ' stack step ( unfilled ) ' ) # Make a multiple-histogram of data-sets with different length . x_multi = [np . random . randn ( n ) for n in [10000 , 5000 , 2000]] ax3 . hist ( x_multi , n_bins , histtype = ' bar ' ) ax3 . set_title ( ' different sample sizes ' ) fig . tight_layout ( ) return fig": 5402,
 "def dir_exists ( self ) : r = requests . request ( self . method if self . method else ' HEAD ' , self . url , **self . storage_args ) try : r . raise_for_status ( ) except Exception : return False return True": 5403,
 "def print_result_from_timeit ( stmt = ' pass ' , setup = ' pass ' , number = 1000000 ) : units = [ \" s \" , \" ms \" , \" us \" , \" ns \" ] duration = timeit ( stmt , setup , number = int ( number ) ) avg_duration = duration / float ( number ) thousands = int ( math . floor ( math . log ( avg_duration , 1000 ) ) ) print ( \" Total time : %fs . Average run : % . 3f%s . \" % ( duration , avg_duration * ( 1000 ** -thousands ) , units[-thousands] ) ) ": 5404,
 "def rotation_matrix ( sigma ) : radians = sigma * np . pi / 180 . 0 r11 = np . cos ( radians ) r12 = -np . sin ( radians ) r21 = np . sin ( radians ) r22 = np . cos ( radians ) R = np . array ( [[r11 , r12] , [r21 , r22]] ) return R": 5405,
 "def readme ( filename , encoding = ' utf8 ' ) : with io . open ( filename , encoding = encoding ) as source : return source . read ( ) ": 5406,
 "def bin_open ( fname : str ) : if fname . endswith ( \" . gz \" ) : return gzip . open ( fname , \" rb \" ) return open ( fname , \" rb \" ) ": 5407,
 "def pstd ( self , *args , **kwargs ) : kwargs[ ' file ' ] = self . out self . print ( *args , **kwargs ) sys . stdout . flush ( ) ": 5408,
 "def _sslobj ( sock ) : pass if isinstance ( sock . _sslobj , _ssl . _SSLSocket ) : return sock . _sslobj else : return sock . _sslobj . _sslobj": 5409,
 "def _cho_factor ( A , lower = True , check_finite = True ) : return cp . linalg . cholesky ( A ) , True": 5410,
 "def handle_logging ( self ) : configure_logging ( self . get_scrapy_options ( ) ) # Disable duplicates self . __scrapy_options[ \" LOG_ENABLED \" ] = False # Now , after log-level is correctly set , lets log them . for msg in self . log_output : if msg[ \" level \" ] is \" error \" : self . log . error ( msg[ \" msg \" ] ) elif msg[ \" level \" ] is \" info \" : self . log . info ( msg[ \" msg \" ] ) elif msg[ \" level \" ] is \" debug \" : self . log . debug ( msg[ \" msg \" ] ) ": 5411,
 "def __isub__ ( self , other ) : self . _binary_sanity_check ( other ) set . difference_update ( self , other ) return self": 5412,
 "def partial_fit ( self , X , y = None , classes = None , **fit_params ) : if not self . initialized_ : self . initialize ( ) self . notify ( ' on_train_begin ' , X = X , y = y ) try : self . fit_loop ( X , y , **fit_params ) except KeyboardInterrupt : pass self . notify ( ' on_train_end ' , X = X , y = y ) return self": 5413,
 "def returns ( self ) : return_type = self . signature . return_type none_type = type ( None ) if return_type is not None and return_type is not none_type : return return_type . __name__": 5414,
 "def process_docstring ( app , what , name , obj , options , lines ) : result_lines = lines if app . config . napoleon_numpy_docstring : docstring = ExtendedNumpyDocstring ( result_lines , app . config , app , what , name , obj , options ) result_lines = docstring . lines ( ) if app . config . napoleon_google_docstring : docstring = ExtendedGoogleDocstring ( result_lines , app . config , app , what , name , obj , options ) result_lines = docstring . lines ( ) lines[ : ] = result_lines[ : ]": 5415,
 "def prompt_yes_or_no ( message ) : user_input = input ( \" {} [y/n] : \" . format ( message ) ) . lower ( ) if user_input . startswith ( \" y \" ) : return True elif user_input . startswith ( \" n \" ) : return False else : return prompt_yes_or_no ( message ) ": 5416,
 "def get_sql ( query ) : sql = str ( query . statement . compile ( dialect = sqlite . dialect ( ) , compile_kwargs = { \" literal_binds \" : True} ) ) return sql": 5417,
 "def rotate_point ( xorigin , yorigin , x , y , angle ) : rotx = ( x - xorigin ) * np . cos ( angle ) - ( y - yorigin ) * np . sin ( angle ) roty = ( x - yorigin ) * np . sin ( angle ) + ( y - yorigin ) * np . cos ( angle ) return rotx , roty": 5418,
 "def write_json_corpus ( documents , fnm ) : with codecs . open ( fnm , ' wb ' , ' ascii ' ) as f : for document in documents : f . write ( json . dumps ( document ) + ' \\n ' ) return documents": 5419,
 "def get_connection ( self , host , port , db ) : return redis . StrictRedis ( host = host , port = port , db = db , decode_responses = True ) ": 5420,
 "def file_to_png ( fp ) : \t\timport PIL . Image # pylint : disable = import-error\twith io . BytesIO ( ) as dest : \t\tPIL . Image . open ( fp ) . save ( dest , \" PNG \" , optimize = True ) \t\treturn dest . getvalue ( ) ": 5421,
 "def parse_case_snake_to_camel ( snake , upper_first = True ) : \t\tsnake = snake . split ( ' _ ' ) \tfirst_part = snake[0]\tif upper_first : \t\tfirst_part = first_part . title ( ) \treturn first_part + ' ' . join ( word . title ( ) for word in snake[1 : ] ) ": 5422,
 "def set_gradclip_const ( self , min_value , max_value ) : callBigDlFunc ( self . bigdl_type , \" setConstantClip \" , self . value , min_value , max_value ) ": 5423,
 "def connect ( self ) : self . socket = socket . create_connection ( self . address , self . timeout ) ": 5424,
 "def dump_parent ( self , obj ) : if not self . _is_parent ( obj ) : return self . _dump_relative ( obj . pid ) return None": 5425,
 "def test_SVD ( pca ) : _ = pca rec = N . dot ( _ . U , N . dot ( _ . sigma , _ . V ) ) assert N . allclose ( _ . arr , rec ) ": 5426,
 "def set_float ( self , option , value ) : if not isinstance ( value , float ) : raise TypeError ( \" Value must be a float \" ) self . options[option] = value": 5427,
 "def symbols ( ) : symbols = [] for line in symbols_stream ( ) : symbols . append ( line . decode ( ' utf-8 ' ) . strip ( ) ) return symbols": 5428,
 "def fn_abs ( self , value ) : if is_ndarray ( value ) : return numpy . absolute ( value ) else : return abs ( value ) ": 5429,
 "def remove_stopped_threads ( self ) : self . threads = [t for t in self . threads if t . is_alive ( ) ]": 5430,
 "def open_store_variable ( self , name , var ) : data = indexing . LazilyOuterIndexedArray ( CDMArrayWrapper ( name , self ) ) return Variable ( var . dimensions , data , {a : getattr ( var , a ) for a in var . ncattrs ( ) } ) ": 5431,
 "def _shutdown_proc ( p , timeout ) : freq = 10 # how often to check per second for _ in range ( 1 + timeout * freq ) : ret = p . poll ( ) if ret is not None : logging . info ( \" Shutdown gracefully . \" ) return ret time . sleep ( 1 / freq ) logging . warning ( \" Killing the process . \" ) p . kill ( ) return p . wait ( ) ": 5432,
 "def to_unix ( cls , timestamp ) : if not isinstance ( timestamp , datetime . datetime ) : raise TypeError ( ' Time . milliseconds expects a datetime object ' ) base = time . mktime ( timestamp . timetuple ( ) ) return base": 5433,
 "def keyReleaseEvent ( self , event ) : self . keyboard_event ( event . key ( ) , self . keys . ACTION_RELEASE , 0 ) ": 5434,
 "def empty ( self ) : for k in list ( self . children . keys ( ) ) : self . remove_child ( self . children[k] ) ": 5435,
 "def select_default ( self ) : if self . _default is None : if not self . _set_option_by_index ( 0 ) : utils . error_format ( self . description + \" \\n \" + \" Unable to select default option as the Combo is empty \" ) else : if not self . _set_option ( self . _default ) : utils . error_format ( self . description + \" \\n \" + \" Unable to select default option as it doesnt exist in the Combo \" ) ": 5436,
 "def get_host_power_status ( self ) : sushy_system = self . _get_sushy_system ( PROLIANT_SYSTEM_ID ) return GET_POWER_STATE_MAP . get ( sushy_system . power_state ) ": 5437,
 "def eglInitialize ( display ) : majorVersion = ( _c_int*1 ) ( ) minorVersion = ( _c_int*1 ) ( ) res = _lib . eglInitialize ( display , majorVersion , minorVersion ) if res = = EGL_FALSE : raise RuntimeError ( ' Could not initialize ' ) return majorVersion[0] , minorVersion[0]": 5438,
 "def stdout_to_results ( s ) : results = s . strip ( ) . split ( ' \\n ' ) return [BenchmarkResult ( *r . split ( ) ) for r in results]": 5439,
 "def union ( self , other ) : obj = self . _clone ( ) obj . union_update ( other ) return obj": 5440,
 "def tuple_check ( *args , func = None ) : func = func or inspect . stack ( ) [2][3] for var in args : if not isinstance ( var , ( tuple , collections . abc . Sequence ) ) : name = type ( var ) . __name__ raise TupleError ( f ' Function {func} expected tuple , {name} got instead . ' ) ": 5441,
 "def list_of_dict ( self ) : ret = [] for row in self : ret . append ( dict ( [ ( self . _col_names[i] , row[i] ) for i in range ( len ( self . _col_names ) ) ] ) ) return ReprListDict ( ret , col_names = self . _col_names , col_types = self . _col_types , width_limit = self . _width_limit , digits = self . _digits , convert_unicode = self . _convert_unicode ) ": 5442,
 "def uri_to_iri_parts ( path , query , fragment ) : r path = url_unquote ( path , ' %/;? ' ) query = url_unquote ( query , ' %;/? : @& = + , $ # ' ) fragment = url_unquote ( fragment , ' %;/? : @& = + , $ # ' ) return path , query , fragment": 5443,
 "def subscribe ( self , handler ) : assert callable ( handler ) , \" Invalid handler %s \" % handler self . handlers . append ( handler ) ": 5444,
 "def get_form_bound_field ( form , field_name ) : field = form . fields[field_name] field = field . get_bound_field ( form , field_name ) return field": 5445,
 "def flatten_union ( table ) : op = table . op ( ) if isinstance ( op , ops . Union ) : return toolz . concatv ( flatten_union ( op . left ) , [op . distinct] , flatten_union ( op . right ) ) return [table]": 5446,
 "def script_repr ( val , imports , prefix , settings ) : return pprint ( val , imports , prefix , settings , unknown_value = None , qualify = True , separator = \" \\n \" ) ": 5447,
 "def assert_redirect ( self , response , expected_url = None ) : self . assertIn ( response . status_code , self . redirect_codes , self . _get_redirect_assertion_message ( response ) , ) if expected_url : location_header = response . _headers . get ( ' location ' , None ) self . assertEqual ( location_header , ( ' Location ' , str ( expected_url ) ) , ' Response should redirect to {0} , but it redirects to {1} instead ' . format ( expected_url , location_header[1] , ) ) ": 5448,
 "def _keys_to_camel_case ( self , obj ) : return dict ( ( to_camel_case ( key ) , value ) for ( key , value ) in obj . items ( ) ) ": 5449,
 "def update_context ( self , ctx ) : assert isinstance ( ctx , dict ) ctx[str ( self . context_id ) ] = self . value": 5450,
 "def generate_user_token ( self , user , salt = None ) : return self . token_serializer . dumps ( str ( user . id ) , salt = salt ) ": 5451,
 "def random_string ( string_length = 10 ) : random = str ( uuid . uuid4 ( ) ) # Convert UUID format to a Python string . random = random . upper ( ) # Make all characters uppercase . random = random . replace ( \" - \" , \" \" ) # Remove the UUID ' - ' . return random[0 : string_length]": 5452,
 "def bool_str ( string ) : if string not in BOOL_STRS : raise ValueError ( ' Invalid boolean string : \" {} \" ' . format ( string ) ) return True if string = = ' true ' else False": 5453,
 "def _set_lastpage ( self ) : self . last_page = ( len ( self . _page_data ) - 1 ) // self . screen . page_size": 5454,
 "def put_text ( self , key , text ) : with open ( key , \" w \" ) as fh : fh . write ( text ) ": 5455,
 "def destroy_webdriver ( driver ) : # This is some very flaky code in selenium . Hence the retries # and catch-all exceptions try : retry_call ( driver . close , tries = 2 ) except Exception : pass try : driver . quit ( ) except Exception : pass": 5456,
 "def _checkSize ( self ) : if self . _item_height is not None : sz = min ( self . _max_height_items , self . count ( ) ) * self . _item_height + 5 sz = max ( sz , 20 ) self . setMinimumSize ( 0 , sz ) self . setMaximumSize ( 1000000 , sz ) self . resize ( self . width ( ) , sz ) ": 5457,
 "def path_distance ( points ) : vecs = np . diff ( points , axis = 0 ) [ : , : 3] d2 = [np . dot ( p , p ) for p in vecs] return np . sum ( np . sqrt ( d2 ) ) ": 5458,
 "def element_to_string ( element , include_declaration = True , encoding = DEFAULT_ENCODING , method = ' xml ' ) : if isinstance ( element , ElementTree ) : element = element . getroot ( ) elif not isinstance ( element , ElementType ) : element = get_element ( element ) if element is None : return u ' ' element_as_string = tostring ( element , encoding , method ) . decode ( encoding = encoding ) if include_declaration : return element_as_string else : return strip_xml_declaration ( element_as_string ) ": 5459,
 "def _Open ( self , hostname , port ) : try : self . _xmlrpc_server = SimpleXMLRPCServer . SimpleXMLRPCServer ( ( hostname , port ) , logRequests = False , allow_none = True ) except SocketServer . socket . error as exception : logger . warning ( ( ' Unable to bind a RPC server on {0 : s} : {1 : d} with error : ' ' {2!s} ' ) . format ( hostname , port , exception ) ) return False self . _xmlrpc_server . register_function ( self . _callback , self . _RPC_FUNCTION_NAME ) return True": 5460,
 "def predict ( self , X ) : return [self . classes[prediction . argmax ( ) ] for prediction in self . predict_proba ( X ) ]": 5461,
 "def ParseMany ( text ) : precondition . AssertType ( text , Text ) if compatibility . PY2 : text = text . encode ( \" utf-8 \" ) return list ( yaml . safe_load_all ( text ) ) ": 5462,
 "def kill_test_logger ( logger ) : for h in list ( logger . handlers ) : logger . removeHandler ( h ) if isinstance ( h , logging . FileHandler ) : h . close ( ) ": 5463,
 "def trap_exceptions ( results , handler , exceptions = Exception ) : \t\ttry : \t\tfor result in results : \t\t\tyield result\texcept exceptions as exc : \t\tfor result in always_iterable ( handler ( exc ) ) : \t\t\tyield result": 5464,
 "def _return_result ( self , done ) : chain_future ( done , self . _running_future ) self . current_future = done self . current_index = self . _unfinished . pop ( done ) ": 5465,
 "def start ( self , test_connection = True ) : if self . _context is None : self . _logger . debug ( ' Starting Client ' ) self . _context = zmq . Context ( ) self . _poll = zmq . Poller ( ) self . _start_socket ( ) if test_connection : self . test_ping ( ) ": 5466,
 "def _on_text_changed ( self ) : if not self . _cleaning : ln = TextHelper ( self ) . cursor_position ( ) [0] self . _modified_lines . add ( ln ) ": 5467,
 "def display_list_by_prefix ( names_list , starting_spaces = 0 ) : cur_prefix , result_lines = None , [] space = \" \" * starting_spaces for name in sorted ( names_list ) : split = name . split ( \" _ \" , 1 ) prefix = split[0] if cur_prefix ! = prefix : result_lines . append ( space + prefix + \" : \" ) cur_prefix = prefix result_lines . append ( space + \" * \" + name ) return \" \\n \" . join ( result_lines ) ": 5468,
 "def delete_lines ( self ) : cursor = self . textCursor ( ) self . __select_text_under_cursor_blocks ( cursor ) cursor . removeSelectedText ( ) cursor . deleteChar ( ) return True": 5469,
 "def search ( self , filterstr , attrlist ) : return self . _paged_search_ext_s ( self . settings . BASE , ldap . SCOPE_SUBTREE , filterstr = filterstr , attrlist = attrlist , page_size = self . settings . PAGE_SIZE ) ": 5470,
 "def range ( self , chromosome , start , stop , exact = False ) : return self . _clone ( filters = [GenomicFilter ( chromosome , start , stop , exact ) ] ) ": 5471,
 "def hash_producer ( *args , **kwargs ) : return hashlib . md5 ( six . text_type ( uuid . uuid4 ( ) ) . encode ( ' utf-8 ' ) ) . hexdigest ( ) ": 5472,
 "def retrieve_import_alias_mapping ( names_list ) : import_alias_names = dict ( ) for alias in names_list : if alias . asname : import_alias_names[alias . asname] = alias . name return import_alias_names": 5473,
 "def get_unixtime_registered ( self ) : doc = self . _request ( self . ws_prefix + \" . getInfo \" , True ) return int ( doc . getElementsByTagName ( \" registered \" ) [0] . getAttribute ( \" unixtime \" ) ) ": 5474,
 "def input_dir ( self ) : return os . path . abspath ( os . path . dirname ( self . inputs[ ' job_ini ' ] ) ) ": 5475,
 "def forget_xy ( t ) : shape = ( t . shape[0] , None , None , t . shape[3] ) return tf . placeholder_with_default ( t , shape ) ": 5476,
 "def cell_normalize ( data ) : if sparse . issparse ( data ) : data = sparse . csc_matrix ( data . astype ( float ) ) # normalize in-place sparse_cell_normalize ( data . data , data . indices , data . indptr , data . shape[1] , data . shape[0] ) return data data_norm = data . astype ( float ) total_umis = [] for i in range ( data . shape[1] ) : di = data_norm[ : , i] total_umis . append ( di . sum ( ) ) di / = total_umis[i] med = np . median ( total_umis ) data_norm * = med return data_norm": 5477,
 "def phase_correct_first ( spec , freq , k ) : c_factor = np . exp ( -1j * k * freq ) c_factor = c_factor . reshape ( ( len ( spec . shape ) -1 ) * ( 1 , ) + c_factor . shape ) return spec * c_factor": 5478,
 "def device_state ( device_id ) : if device_id not in devices : return jsonify ( success = False ) return jsonify ( state = devices[device_id] . state ) ": 5479,
 "def get_readonly_fields ( self , request , obj = None ) : return list ( self . readonly_fields ) + [field . name for field in obj . _meta . fields]": 5480,
 "def utime ( self , *args , **kwargs ) : os . utime ( self . extended_path , *args , **kwargs ) ": 5481,
 "def render_none ( self , context , result ) : \t\t\t\tcontext . response . body = b ' ' \t\tdel context . response . content_length\t\treturn True": 5482,
 "def get_class_method ( cls_or_inst , method_name ) : cls = cls_or_inst if isinstance ( cls_or_inst , type ) else cls_or_inst . __class__ meth = getattr ( cls , method_name , None ) if isinstance ( meth , property ) : meth = meth . fget elif isinstance ( meth , cached_property ) : meth = meth . func return meth": 5483,
 "def naturalsortkey ( s ) : return [int ( part ) if part . isdigit ( ) else part for part in re . split ( ' ( [0-9]+ ) ' , s ) ]": 5484,
 "def project ( self , other ) : n = other . normalized ( ) return self . dot ( n ) * n": 5485,
 "def preprocess ( string ) : string = unicode ( string , encoding = \" utf-8 \" ) # convert diacritics to simpler forms string = regex1 . sub ( lambda x : accents[x . group ( ) ] , string ) # remove all rest of the unwanted characters return regex2 . sub ( ' ' , string ) . encode ( ' utf-8 ' ) ": 5486,
 "def timestamp ( format = DATEFMT , timezone = ' Africa/Johannesburg ' ) : return formatdate ( datetime . now ( tz = pytz . timezone ( timezone ) ) ) ": 5487,
 "def _try_lookup ( table , value , default = \" \" ) : try : string = table[ value ] except KeyError : string = default return string": 5488,
 "def write_pid_file ( ) : pidfile = os . path . basename ( sys . argv[0] ) [ : -3] + ' . pid ' # strip . py , add . pid with open ( pidfile , ' w ' ) as fh : fh . write ( \" %d\\n \" % os . getpid ( ) ) fh . close ( ) ": 5489,
 "def inverse ( d ) : output = {} for k , v in unwrap ( d ) . items ( ) : output[v] = output . get ( v , [] ) output[v] . append ( k ) return output": 5490,
 "def plot_decision_boundary ( model , X , y , step = 0 . 1 , figsize = ( 10 , 8 ) , alpha = 0 . 4 , size = 20 ) : x_min , x_max = X[ : , 0] . min ( ) - 1 , X[ : , 0] . max ( ) + 1 y_min , y_max = X[ : , 1] . min ( ) - 1 , X[ : , 1] . max ( ) + 1 xx , yy = np . meshgrid ( np . arange ( x_min , x_max , step ) , np . arange ( y_min , y_max , step ) ) f , ax = plt . subplots ( figsize = figsize ) Z = model . predict ( np . c_[xx . ravel ( ) , yy . ravel ( ) ] ) Z = Z . reshape ( xx . shape ) ax . contourf ( xx , yy , Z , alpha = alpha ) ax . scatter ( X[ : , 0] , X[ : , 1] , c = y , s = size , edgecolor = ' k ' ) plt . show ( ) ": 5491,
 "def _deserialize ( cls , key , value , fields ) : converter = cls . _get_converter_for_field ( key , None , fields ) return converter . deserialize ( value ) ": 5492,
 "def zoom ( ax , xy = ' x ' , factor = 1 ) : limits = ax . get_xlim ( ) if xy = = ' x ' else ax . get_ylim ( ) new_limits = ( 0 . 5* ( limits[0] + limits[1] ) + 1 . /factor * np . array ( ( -0 . 5 , 0 . 5 ) ) * ( limits[1] - limits[0] ) ) if xy = = ' x ' : ax . set_xlim ( new_limits ) else : ax . set_ylim ( new_limits ) ": 5493,
 "def rowlenselect ( table , n , complement = False ) : where = lambda row : len ( row ) = = n return select ( table , where , complement = complement ) ": 5494,
 "def gen_text ( env : TextIOBase , package : str , tmpl : str ) : if env : env_args = json_datetime . load ( env ) else : env_args = {} jinja_env = template . setup ( package ) echo ( jinja_env . get_template ( tmpl ) . render ( **env_args ) ) ": 5495,
 "def _GetFieldByName ( message_descriptor , field_name ) : try : return message_descriptor . fields_by_name[field_name] except KeyError : raise ValueError ( ' Protocol message %s has no \" %s \" field . ' % ( message_descriptor . name , field_name ) ) ": 5496,
 "def closeEvent ( self , event ) : if self . closing ( True ) : event . accept ( ) else : event . ignore ( ) ": 5497,
 "def full_s ( self ) : x = np . zeros ( ( self . shape ) , dtype = np . float32 ) x[ : self . s . shape[0] , : self . s . shape[0]] = self . s . as_2d s = Matrix ( x = x , row_names = self . row_names , col_names = self . col_names , isdiagonal = False , autoalign = False ) return s": 5498,
 "def bound_symbols ( self ) : try : lhs_syms = self . lhs . bound_symbols except AttributeError : lhs_syms = set ( ) try : rhs_syms = self . rhs . bound_symbols except AttributeError : rhs_syms = set ( ) return lhs_syms | rhs_syms": 5499,
 "def calculate_size ( name , function ) : data_size = 0 data_size + = calculate_size_str ( name ) data_size + = calculate_size_data ( function ) return data_size": 5500,
 "def _parse_string_to_list_of_pairs ( s , seconds_to_int = False ) : r ret = [] for p in [s . split ( \" : \" ) for s in re . sub ( \" [ , . ;] \" , \" \" , s ) . split ( ) ] : if len ( p ) ! = 2 : raise ValueError ( \" bad input to _parse_string_to_list_of_pairs %s \" % s ) if seconds_to_int : ret . append ( ( p[0] , int ( p[1] ) ) ) else : ret . append ( tuple ( p ) ) return ret": 5501,
 "def calling_logger ( height = 1 ) : stack = inspect . stack ( ) height = min ( len ( stack ) - 1 , height ) caller = stack[height] scope = caller[0] . f_globals path = scope[ ' __name__ ' ] if path = = ' __main__ ' : path = scope[ ' __package__ ' ] or os . path . basename ( sys . argv[0] ) return logging . getLogger ( path ) ": 5502,
 "def wipe ( self ) : query = \" DELETE FROM {} \" . format ( self . __tablename__ ) connection = sqlite3 . connect ( self . sqlite_file ) cursor = connection . cursor ( ) cursor . execute ( query ) connection . commit ( ) ": 5503,
 "def surface ( self , zdata , **kwargs ) : self . _configure_3d ( ) surf = scene . SurfacePlot ( z = zdata , **kwargs ) self . view . add ( surf ) self . view . camera . set_range ( ) return surf": 5504,
 "def stop_logging ( ) : from . import log logger = logging . getLogger ( \" gromacs \" ) logger . info ( \" GromacsWrapper %s STOPPED logging \" , get_version ( ) ) log . clear_handlers ( logger ) ": 5505,
 "def add_to_enum ( self , clsdict ) : super ( XmlMappedEnumMember , self ) . add_to_enum ( clsdict ) self . register_xml_mapping ( clsdict ) ": 5506,
 "def as_dict ( self ) : attrs = vars ( self ) return {key : attrs[key] for key in attrs if not key . startswith ( ' _ ' ) }": 5507,
 "def __run_spark_submit ( lane_yaml , dist_dir , spark_home , spark_args , silent ) : # spark-submit binary cmd = [ ' spark-submit ' if spark_home is None else os . path . join ( spark_home , ' bin/spark-submit ' ) ] # Supplied spark arguments if spark_args : cmd + = spark_args # Packaged App & lane cmd + = [ ' --py-files ' , ' libs . zip , _framework . zip , tasks . zip ' , ' main . py ' ] cmd + = [ ' --lane ' , lane_yaml] logging . info ( ' Submitting to Spark ' ) logging . debug ( str ( cmd ) ) # Submit devnull = open ( os . devnull , ' w ' ) outp = { ' stderr ' : STDOUT , ' stdout ' : devnull} if silent else {} call ( cmd , cwd = dist_dir , env = MY_ENV , **outp ) devnull . close ( ) ": 5508,
 "def write_login ( collector , image , **kwargs ) : docker_api = collector . configuration[ \" harpoon \" ] . docker_api collector . configuration[ \" authentication \" ] . login ( docker_api , image , is_pushing = True , global_docker = True ) ": 5509,
 "def redirect ( cls , request , response ) : if cls . meta . legacy_redirect : if request . method in ( ' GET ' , ' HEAD ' , ) : # A SAFE request is allowed to redirect using a 301 response . status = http . client . MOVED_PERMANENTLY else : # All other requests must use a 307 response . status = http . client . TEMPORARY_REDIRECT else : # Modern redirects are allowed . Let ' s have some fun . # Hopefully you ' re client supports this . # The RFC explicitly discourages UserAgent sniffing . response . status = http . client . PERMANENT_REDIRECT # Terminate the connection . response . close ( ) ": 5510,
 "def _replace_variables ( data , variables ) : formatter = string . Formatter ( ) return [formatter . vformat ( item , [] , variables ) for item in data]": 5511,
 "def register_action ( action ) : sub = _subparsers . add_parser ( action . meta ( ' cmd ' ) , help = action . meta ( ' help ' ) ) sub . set_defaults ( cmd = action . meta ( ' cmd ' ) ) for ( name , arg ) in action . props ( ) . items ( ) : sub . add_argument ( arg . name , arg . flag , **arg . options ) _actions[action . meta ( ' cmd ' ) ] = action": 5512,
 "def process_wait ( process , timeout = 0 ) : ret = AUTO_IT . AU3_ProcessWait ( LPCWSTR ( process ) , INT ( timeout ) ) return ret": 5513,
 "def connection_lost ( self , exc ) : if exc is None : self . log . warning ( ' eof from receiver? ' ) else : self . log . warning ( ' Lost connection to receiver : %s ' , exc ) self . transport = None if self . _connection_lost_callback : self . _loop . call_soon ( self . _connection_lost_callback ) ": 5514,
 "def convert_timezone ( obj , timezone ) : if timezone is None : return obj . replace ( tzinfo = None ) return pytz . timezone ( timezone ) . localize ( obj ) ": 5515,
 "async def write ( self , data ) : await self . wait ( \" write \" ) start = _now ( ) await super ( ) . write ( data ) self . append ( \" write \" , data , start ) ": 5516,
 "def codebox ( msg = \" \" , title = \" \" , text = \" \" ) : return tb . textbox ( msg , title , text , codebox = 1 ) ": 5517,
 "def printComparison ( results , class_or_prop ) : \t\tdata = []\tRow = namedtuple ( ' Row ' , [class_or_prop , ' VALIDATED ' ] ) \tfor k , v in sorted ( results . items ( ) , key = lambda x : x[1] ) : \t\tdata + = [Row ( k , str ( v ) ) ]\tpprinttable ( data ) ": 5518,
 "def split_long_sentence ( sentence , words_per_line ) : words = sentence . split ( ' ' ) split_sentence = ' ' for i in range ( len ( words ) ) : split_sentence = split_sentence + words[i] if ( i+1 ) % words_per_line = = 0 : split_sentence = split_sentence + ' \\n ' elif i ! = len ( words ) - 1 : split_sentence = split_sentence + \" \" return split_sentence": 5519,
 "def hook_focus_events ( self ) : widget = self . widget widget . focusInEvent = self . focusInEvent widget . focusOutEvent = self . focusOutEvent": 5520,
 "async def packets_from_tshark ( self , packet_callback , packet_count = None , close_tshark = True ) : tshark_process = await self . _get_tshark_process ( packet_count = packet_count ) try : await self . _go_through_packets_from_fd ( tshark_process . stdout , packet_callback , packet_count = packet_count ) except StopCapture : pass finally : if close_tshark : await self . _close_async ( ) ": 5521,
 "def cast_bytes ( s , encoding = None ) : if not isinstance ( s , bytes ) : return encode ( s , encoding ) return s": 5522,
 "def getCachedDataKey ( engineVersionHash , key ) : \t\t\t\tcacheFile = CachedDataManager . _cacheFileForHash ( engineVersionHash ) \t\treturn JsonDataManager ( cacheFile ) . getKey ( key ) ": 5523,
 "def remove_duplicates ( seq ) : seen = set ( ) seen_add = seen . add return [x for x in seq if not ( x in seen or seen_add ( x ) ) ]": 5524,
 "def sequence_molecular_weight ( seq ) : if ' X ' in seq : warnings . warn ( _nc_warning_str , NoncanonicalWarning ) return sum ( [residue_mwt[aa] * n for aa , n in Counter ( seq ) . items ( ) ] ) + water_mass": 5525,
 "def python ( string : str ) : return underscore ( singularize ( string ) if Naming . _pluralize ( string ) else string ) ": 5526,
 "def update ( self ) : if not self . canvas : return for visual in self . canvas . visuals : self . update_program ( visual . program ) self . canvas . update ( ) ": 5527,
 "def ask_str ( question : str , default : str = None ) : default_q = \" [default : {0}] : \" . format ( default ) if default is not None else \" \" answer = input ( \" {0} [{1}] : \" . format ( question , default_q ) ) if answer = = \" \" : return default return answer": 5528,
 "def _zeep_to_dict ( cls , obj ) : res = serialize_object ( obj ) res = cls . _get_non_empty_dict ( res ) return res": 5529,
 "def main ( source ) : if source is None : click . echo ( \" You need to supply a file or url to a schema to a swagger schema , for \" \" the validator to work . \" ) return 1 try : load ( source ) click . echo ( \" Validation passed \" ) return 0 except ValidationError as e : raise click . ClickException ( str ( e ) ) ": 5530,
 "def check_for_positional_argument ( kwargs , name , default = False ) : if name in kwargs : if str ( kwargs[name] ) = = \" True \" : return True elif str ( kwargs[name] ) = = \" False \" : return False else : return kwargs[name] return default": 5531,
 "def _validate_simple ( email ) : name , address = parseaddr ( email ) if not re . match ( ' [^@]+@[^@]+\\ . [^@]+ ' , address ) : raise ValueError ( ' Invalid email : {email} ' . format ( email = email ) ) return address": 5532,
 "def is_file_exists_error ( e ) : if six . PY3 : return isinstance ( e , FileExistsError ) # noqa : F821 else : return isinstance ( e , OSError ) and e . errno = = 17": 5533,
 "def set_input_value ( self , selector , value ) : script = ' document . querySelector ( \" %s \" ) . setAttribute ( \" value \" , \" %s \" ) ' script = script % ( selector , value ) self . evaluate ( script ) ": 5534,
 "def can_access ( self , user ) : return self . class_ . is_admin ( user ) or \\ self . is_ready and self . class_ in user . classes": 5535,
 "def check_dependency ( self , dependency_path ) : stored_hash = self . _stamp_file_hashes . get ( dependency_path ) # This file was newly added , or we don ' t have a file # with stored hashes yet . Assume out of date . if not stored_hash : return False return stored_hash = = _sha1_for_file ( dependency_path ) ": 5536,
 "def _startswith ( expr , pat ) : return _string_op ( expr , Startswith , output_type = types . boolean , _pat = pat ) ": 5537,
 "def is_empty ( self ) : return all ( isinstance ( c , ParseNode ) and c . is_empty for c in self . children ) ": 5538,
 "def list_view_changed ( self , widget , event , data = None ) : adj = self . scrolled_window . get_vadjustment ( ) adj . set_value ( adj . get_upper ( ) - adj . get_page_size ( ) ) ": 5539,
 "def is_natural ( x ) : try : is_integer = int ( x ) = = x except ( TypeError , ValueError ) : return False return is_integer and x > = 0": 5540,
 "def string ( value ) -> str : return system_json . dumps ( Json ( value ) . safe_object ( ) , ensure_ascii = False ) ": 5541,
 "def get_period_last_3_months ( ) -> str : today = Datum ( ) today . today ( ) # start_date = today - timedelta ( weeks = 13 ) start_date = today . clone ( ) start_date . subtract_months ( 3 ) period = get_period ( start_date . date , today . date ) return period": 5542,
 "def dictlist_convert_to_float ( dict_list : Iterable[Dict] , key : str ) -> None : for d in dict_list : try : d[key] = float ( d[key] ) except ValueError : d[key] = None": 5543,
 "def method_caller ( method_name , *args , **kwargs ) : \t\tdef call_method ( target ) : \t\tfunc = getattr ( target , method_name ) \t\treturn func ( *args , **kwargs ) \treturn call_method": 5544,
 "def find_first_in_list ( txt : str , str_list : [str] ) -> int : # type : ignore start = len ( txt ) + 1 for item in str_list : if start > txt . find ( item ) > -1 : start = txt . find ( item ) return start if len ( txt ) + 1 > start > -1 else -1": 5545,
 "def previous_workday ( dt ) : dt - = timedelta ( days = 1 ) while dt . weekday ( ) > 4 : # Mon-Fri are 0-4 dt - = timedelta ( days = 1 ) return dt": 5546,
 "def __gt__ ( self , other ) : if isinstance ( other , Address ) : return str ( self ) > str ( other ) raise TypeError": 5547,
 "def batch_split_sentences ( self , texts : List[str] ) -> List[List[str]] : return [self . split_sentences ( text ) for text in texts]": 5548,
 "def listify ( a ) : if a is None : return [] elif not isinstance ( a , ( tuple , list , np . ndarray ) ) : return [a] return list ( a ) ": 5549,
 "def get_column_names ( engine : Engine , tablename : str ) -> List[str] : return [info . name for info in gen_columns_info ( engine , tablename ) ]": 5550,
 "def list_depth ( list_ , func = max , _depth = 0 ) : depth_list = [list_depth ( item , func = func , _depth = _depth + 1 ) for item in list_ if util_type . is_listlike ( item ) ] if len ( depth_list ) > 0 : return func ( depth_list ) else : return _depth": 5551,
 "def get_timezone ( ) -> Tuple[datetime . tzinfo , str] : dt = get_datetime_now ( ) . astimezone ( ) tzstr = dt . strftime ( \" %z \" ) tzstr = tzstr[ : -2] + \" : \" + tzstr[-2 : ] return dt . tzinfo , tzstr": 5552,
 "def inverted_dict ( d ) : return dict ( ( force_hashable ( v ) , k ) for ( k , v ) in viewitems ( dict ( d ) ) ) ": 5553,
 "def read_text_from_file ( path : str ) -> str : with open ( path ) as text_file : content = text_file . read ( ) return content": 5554,
 "def full ( self ) : return self . maxsize and len ( self . list ) > = self . maxsize or False": 5555,
 "def top ( self , topn = 10 ) : return [self[i] for i in argsort ( list ( zip ( *self ) ) [1] ) [ : : -1][ : topn]]": 5556,
 "def remove_empty_text ( utterances : List[Utterance] ) -> List[Utterance] : return [utter for utter in utterances if utter . text . strip ( ) ! = \" \" ]": 5557,
 "def get_pij_matrix ( t , diag , A , A_inv ) : return A . dot ( np . diag ( np . exp ( diag * t ) ) ) . dot ( A_inv ) ": 5558,
 "def flush ( self ) : if self . _cache_modified_count > 0 : self . storage . write ( self . cache ) self . _cache_modified_count = 0": 5559,
 "def _sum_cycles_from_tokens ( self , tokens : List[str] ) -> int : return sum ( ( int ( self . _nonnumber_pattern . sub ( ' ' , t ) ) for t in tokens ) ) ": 5560,
 "def __next__ ( self ) : self . current + = 1 if self . current > self . total : raise StopIteration else : return self . iterable[self . current - 1]": 5561,
 "def get_margin ( length ) : if length > 23 : margin_left = \" \\t \" chars = 1 elif length > 15 : margin_left = \" \\t\\t \" chars = 2 elif length > 7 : margin_left = \" \\t\\t\\t \" chars = 3 else : margin_left = \" \\t\\t\\t\\t \" chars = 4 return margin_left": 5562,
 "def from_file ( file_path ) -> dict : with io . open ( file_path , ' r ' , encoding = ' utf-8 ' ) as json_stream : return Json . parse ( json_stream , True ) ": 5563,
 "def tail ( filename , number_of_bytes ) : with open ( filename , \" rb \" ) as f : if os . stat ( filename ) . st_size > number_of_bytes : f . seek ( -number_of_bytes , 2 ) return f . read ( ) ": 5564,
 "async def executemany ( self , sql : str , parameters : Iterable[Iterable[Any]] ) -> None : await self . _execute ( self . _cursor . executemany , sql , parameters ) ": 5565,
 "def proper_round ( n ) : return int ( n ) + ( n / abs ( n ) ) * int ( abs ( n - int ( n ) ) > = 0 . 5 ) if n ! = 0 else 0": 5566,
 "def is_integer ( value : Any ) -> bool : return ( isinstance ( value , int ) and not isinstance ( value , bool ) ) or ( isinstance ( value , float ) and isfinite ( value ) and int ( value ) = = value ) ": 5567,
 "def getDimensionForImage ( filename , maxsize ) : try : from PIL import Image except ImportError : return None img = Image . open ( filename ) width , height = img . size if width > maxsize[0] or height > maxsize[1] : img . thumbnail ( maxsize ) out . info ( \" Downscaled display size from %s to %s \" % ( ( width , height ) , img . size ) ) return img . size": 5568,
 "def _rindex ( mylist : Sequence[T] , x : T ) -> int : return len ( mylist ) - mylist[ : : -1] . index ( x ) - 1": 5569,
 "def recClearTag ( element ) : children = element . getchildren ( ) if len ( children ) > 0 : for child in children : recClearTag ( child ) element . tag = clearTag ( element . tag ) ": 5570,
 "def split ( text : str ) -> List[str] : return [word for word in SEPARATOR . split ( text ) if word . strip ( ' \\t ' ) ]": 5571,
 "def clean ( ctx , text ) : text = conversions . to_string ( text , ctx ) return ' ' . join ( [c for c in text if ord ( c ) > = 32] ) ": 5572,
 "def indices_to_labels ( self , indices : Sequence[int] ) -> List[str] : return [ ( self . INDEX_TO_LABEL[index] ) for index in indices]": 5573,
 "def has_key ( cls , *args ) : key = args if len ( args ) > 1 else args[0] return key in cls . _instances": 5574,
 "def get_versions ( reporev = True ) : import sys import platform import qtpy import qtpy . QtCore revision = None if reporev : from spyder . utils import vcs revision , branch = vcs . get_git_revision ( os . path . dirname ( __dir__ ) ) if not sys . platform = = ' darwin ' : # To avoid a crash with our Mac app system = platform . system ( ) else : system = ' Darwin ' return { ' spyder ' : __version__ , ' python ' : platform . python_version ( ) , # \" 2 . 7 . 3 \" ' bitness ' : 64 if sys . maxsize > 2**32 else 32 , ' qt ' : qtpy . QtCore . __version__ , ' qt_api ' : qtpy . API_NAME , # PyQt5 ' qt_api_ver ' : qtpy . PYQT_VERSION , ' system ' : system , # Linux , Windows , . . . ' release ' : platform . release ( ) , # XP , 10 . 6 , 2 . 2 . 0 , etc . ' revision ' : revision , # ' 9fdf926eccce ' }": 5575,
 "def _skip_section ( self ) : self . _last = self . _f . readline ( ) while len ( self . _last ) > 0 and len ( self . _last[0] . strip ( ) ) = = 0 : self . _last = self . _f . readline ( ) ": 5576,
 "async def cursor ( self ) -> Cursor : return Cursor ( self , await self . _execute ( self . _conn . cursor ) ) ": 5577,
 "def last_location_of_minimum ( x ) : x = np . asarray ( x ) return 1 . 0 - np . argmin ( x[ : : -1] ) / len ( x ) if len ( x ) > 0 else np . NaN": 5578,
 "def mmap ( func , iterable ) : if sys . version_info[0] > 2 : return [i for i in map ( func , iterable ) ] else : return map ( func , iterable ) ": 5579,
 "def extend ( a : dict , b : dict ) -> dict : res = a . copy ( ) res . update ( b ) return res": 5580,
 "def valid_date ( x : str ) -> bool : try : if x ! = dt . datetime . strptime ( x , DATE_FORMAT ) . strftime ( DATE_FORMAT ) : raise ValueError return True except ValueError : return False": 5581,
 "def iter_lines ( file_like : Iterable[str] ) -> Generator[str , None , None] : for line in file_like : line = line . rstrip ( ' \\r\\n ' ) if line : yield line": 5582,
 "def strtobytes ( input , encoding ) : py_version = sys . version_info[0] if py_version > = 3 : return _strtobytes_py3 ( input , encoding ) return _strtobytes_py2 ( input , encoding ) ": 5583,
 "def indexes_equal ( a : Index , b : Index ) -> bool : return str ( a ) = = str ( b ) ": 5584,
 "def read ( self , count = 0 ) : return self . f . read ( count ) if count > 0 else self . f . read ( ) ": 5585,
 "def bfx ( value , msb , lsb ) : mask = bitmask ( ( msb , lsb ) ) return ( value & mask ) >> lsb": 5586,
 "def obj_in_list_always ( target_list , obj ) : for item in set ( target_list ) : if item is not obj : return False return True": 5587,
 "def lowercase_chars ( string : any ) -> str : return ' ' . join ( [c if c . islower ( ) else ' ' for c in str ( string ) ] ) ": 5588,
 "def is_unicode ( string ) : str_type = str ( type ( string ) ) if str_type . find ( ' str ' ) > 0 or str_type . find ( ' unicode ' ) > 0 : return True return False": 5589,
 "def assert_valid_name ( name : str ) -> str : error = is_valid_name_error ( name ) if error : raise error return name": 5590,
 "def datetime_iso_format ( date ) : return \" {0 : 0>4}-{1 : 0>2}-{2 : 0>2}T{3 : 0>2} : {4 : 0>2} : {5 : 0>2}Z \" . format ( date . year , date . month , date . day , date . hour , date . minute , date . second ) ": 5591,
 "def gen_lower ( x : Iterable[str] ) -> Generator[str , None , None] : for string in x : yield string . lower ( ) ": 5592,
 "def last_commit ( self ) -> Tuple : from libs . repos import git return git . get_last_commit ( repo_path = self . path ) ": 5593,
 "def dictlist_wipe_key ( dict_list : Iterable[Dict] , key : str ) -> None : for d in dict_list : d . pop ( key , None ) ": 5594,
 "def lower_camel_case_from_underscores ( string ) : components = string . split ( ' _ ' ) string = components[0] for component in components[1 : ] : string + = component[0] . upper ( ) + component[1 : ] return string": 5595,
 "def has_synset ( word : str ) -> list : return wn . synsets ( lemmatize ( word , neverstem = True ) ) ": 5596,
 "def is_sqlatype_string ( coltype : Union[TypeEngine , VisitableType] ) -> bool : coltype = _coltype_to_typeengine ( coltype ) return isinstance ( coltype , sqltypes . String ) ": 5597,
 "def list_to_str ( lst ) : if len ( lst ) = = 1 : str_ = lst[0] elif len ( lst ) = = 2 : str_ = ' and ' . join ( lst ) elif len ( lst ) > 2 : str_ = ' , ' . join ( lst[ : -1] ) str_ + = ' , and {0} ' . format ( lst[-1] ) else : raise ValueError ( ' List of length 0 provided . ' ) return str_": 5598,
 "def dotproduct ( X , Y ) : return sum ( [x * y for x , y in zip ( X , Y ) ] ) ": 5599,
 "def cli_run ( ) : parser = argparse . ArgumentParser ( description = ' Stupidly simple code answers from StackOverflow ' ) parser . add_argument ( ' query ' , help = \" What ' s the problem ? \" , type = str , nargs = ' + ' ) parser . add_argument ( ' -t ' , ' --tags ' , help = ' semicolon separated tags -> python;lambda ' ) args = parser . parse_args ( ) main ( args ) ": 5600,
 "def chars ( string : any ) -> str : return ' ' . join ( [c if c . isalpha ( ) else ' ' for c in str ( string ) ] ) ": 5601,
 "def SetCursorPos ( x : int , y : int ) -> bool : return bool ( ctypes . windll . user32 . SetCursorPos ( x , y ) ) ": 5602,
 "def try_cast_int ( s ) : try : temp = re . findall ( ' \\d ' , str ( s ) ) temp = ' ' . join ( temp ) return int ( temp ) except : return s": 5603,
 "def most_significant_bit ( lst : np . ndarray ) -> int : return np . argwhere ( np . asarray ( lst ) = = 1 ) [0][0]": 5604,
 "def rank ( tensor : BKTensor ) -> int : if isinstance ( tensor , np . ndarray ) : return len ( tensor . shape ) return len ( tensor[0] . size ( ) ) ": 5605,
 "def str_to_time ( time_str : str ) -> datetime . datetime : pieces : Any = [int ( piece ) for piece in time_str . split ( ' - ' ) ] return datetime . datetime ( *pieces ) ": 5606,
 "def remove_nans_1D ( *args ) -> tuple : vals = np . isnan ( args[0] ) for a in args : vals | = np . isnan ( a ) return tuple ( np . array ( a ) [~vals] for a in args ) ": 5607,
 "def snake_to_camel ( s : str ) -> str : fragments = s . split ( ' _ ' ) return fragments[0] + ' ' . join ( x . title ( ) for x in fragments[1 : ] ) ": 5608,
 "def _latex_format ( obj : Any ) -> str : if isinstance ( obj , float ) : try : return sympy . latex ( symbolize ( obj ) ) except ValueError : return \" {0 : . 4g} \" . format ( obj ) return str ( obj ) ": 5609,
 "def is_empty_shape ( sh : ShExJ . Shape ) -> bool : return sh . closed is None and sh . expression is None and sh . extra is None and \\ sh . semActs is None": 5610,
 "def read_set_from_file ( filename : str ) -> Set[str] : collection = set ( ) with open ( filename , ' r ' ) as file_ : for line in file_ : collection . add ( line . rstrip ( ) ) return collection": 5611,
 "def get_keys_of_max_n ( dict_obj , n ) : return sorted ( [ item[0] for item in sorted ( dict_obj . items ( ) , key = lambda item : item[1] , reverse = True ) [ : n] ] ) ": 5612,
 "def pmon ( month ) : \t\tyear , month = month . split ( ' - ' ) \treturn ' {month_name} , {year} ' . format ( \t\tmonth_name = calendar . month_name[int ( month ) ] , \t\tyear = year , \t ) ": 5613,
 "def _lower ( string ) : if not string : return \" \" new_string = [string[0] . lower ( ) ] for char in string[1 : ] : if char . isupper ( ) : new_string . append ( \" _ \" ) new_string . append ( char . lower ( ) ) return \" \" . join ( new_string ) ": 5614,
 "def iterate_items ( dictish ) : if hasattr ( dictish , ' iteritems ' ) : return dictish . iteritems ( ) if hasattr ( dictish , ' items ' ) : return dictish . items ( ) return dictish": 5615,
 "def clean_column_names ( df : DataFrame ) -> DataFrame : f = df . copy ( ) f . columns = [col . strip ( ) for col in f . columns] return f": 5616,
 "def area ( self ) : area = 0 . 0 for segment in self . segments ( ) : area + = ( ( segment . p . x * segment . q . y ) - ( segment . q . x * segment . p . y ) ) /2 return area": 5617,
 "def get_day_name ( self ) -> str : weekday = self . value . isoweekday ( ) - 1 return calendar . day_name[weekday]": 5618,
 "def _duplicates ( list_ ) : item_indices = {} for i , item in enumerate ( list_ ) : try : item_indices[item] . append ( i ) except KeyError : # First time seen item_indices[item] = [i] return item_indices": 5619,
 "def recall_score ( y_true , y_pred , average = ' micro ' , suffix = False ) : true_entities = set ( get_entities ( y_true , suffix ) ) pred_entities = set ( get_entities ( y_pred , suffix ) ) nb_correct = len ( true_entities & pred_entities ) nb_true = len ( true_entities ) score = nb_correct / nb_true if nb_true > 0 else 0 return score": 5620,
 "def is_any_type_set ( sett : Set[Type] ) -> bool : return len ( sett ) = = 1 and is_any_type ( min ( sett ) ) ": 5621,
 "def unzoom_all ( self , event = None ) : if len ( self . conf . zoom_lims ) > 0 : self . conf . zoom_lims = [self . conf . zoom_lims[0]] self . unzoom ( event ) ": 5622,
 "def write_text ( filename : str , text : str ) -> None : with open ( filename , ' w ' ) as f : # type : TextIO print ( text , file = f ) ": 5623,
 "def psutil_phymem_usage ( ) : import psutil # This is needed to avoid a deprecation warning error with # newer psutil versions try : percent = psutil . virtual_memory ( ) . percent except : percent = psutil . phymem_usage ( ) . percent return percent": 5624,
 "def right_replace ( string , old , new , count = 1 ) : if not string : return string return new . join ( string . rsplit ( old , count ) ) ": 5625,
 "def debugTreePrint ( node , pfx = \" -> \" ) : print pfx , node . item for c in node . children : debugTreePrint ( c , \" \" +pfx ) ": 5626,
 "def exclude ( self , *args , **kwargs ) -> \" QuerySet \" : return self . _filter_or_exclude ( negate = True , *args , **kwargs ) ": 5627,
 "def camel_to_snake ( s : str ) -> str : return CAMEL_CASE_RE . sub ( r ' _\\1 ' , s ) . strip ( ) . lower ( ) ": 5628,
 "def is_sqlatype_integer ( coltype : Union[TypeEngine , VisitableType] ) -> bool : coltype = _coltype_to_typeengine ( coltype ) return isinstance ( coltype , sqltypes . Integer ) ": 5629,
 "def zfill ( x , width ) : if not isinstance ( x , basestring ) : x = repr ( x ) return x . zfill ( width ) ": 5630,
 "def most_frequent ( lst ) : lst = lst[ : ] highest_freq = 0 most_freq = None for val in unique ( lst ) : if lst . count ( val ) > highest_freq : most_freq = val highest_freq = lst . count ( val ) return most_freq": 5631,
 "def normalize ( numbers ) : total = float ( sum ( numbers ) ) return [n / total for n in numbers]": 5632,
 "def attrname_to_colname_dict ( cls ) -> Dict[str , str] : attr_col = {} # type : Dict[str , str] for attrname , column in gen_columns ( cls ) : attr_col[attrname] = column . name return attr_col": 5633,
 "def stretch ( iterable , n = 2 ) : r times = range ( n ) for item in iterable : for i in times : yield item": 5634,
 "async def parallel_results ( future_map : Sequence[Tuple] ) -> Dict : ctx_methods = OrderedDict ( future_map ) fs = list ( ctx_methods . values ( ) ) results = await asyncio . gather ( *fs ) results = { key : results[idx] for idx , key in enumerate ( ctx_methods . keys ( ) ) } return results": 5635,
 "def __remove_trailing_zeros ( self , collection ) : index = len ( collection ) - 1 while index > = 0 and collection[index] = = 0 : index - = 1 return collection[ : index + 1]": 5636,
 "def __replace_all ( repls : dict , input : str ) -> str : return re . sub ( ' | ' . join ( re . escape ( key ) for key in repls . keys ( ) ) , lambda k : repls[k . group ( 0 ) ] , input ) ": 5637,
 "def maybe_infer_dtype_type ( element ) : tipo = None if hasattr ( element , ' dtype ' ) : tipo = element . dtype elif is_list_like ( element ) : element = np . asarray ( element ) tipo = element . dtype return tipo": 5638,
 "def bytes_hack ( buf ) : ub = None if sys . version_info > ( 3 , ) : ub = buf else : ub = bytes ( buf ) return ub": 5639,
 "def get_prop_value ( name , props , default = None ) : # type : ( str , Dict[str , Any] , Any ) -> Any if not props : return default try : return props[name] except KeyError : return default": 5640,
 "def _my_hash ( arg_list ) : # type : ( List[Any] ) -> int res = 0 for arg in arg_list : res = res * 31 + hash ( arg ) return res": 5641,
 "def create_pie_chart ( self , snapshot , filename = ' ' ) : try : from pylab import figure , title , pie , axes , savefig from pylab import sum as pylab_sum except ImportError : return self . nopylab_msg % ( \" pie_chart \" ) # Don ' t bother illustrating a pie without pieces . if not snapshot . tracked_total : return ' ' classlist = [] sizelist = [] for k , v in list ( snapshot . classes . items ( ) ) : if v[ ' pct ' ] > 3 . 0 : classlist . append ( k ) sizelist . append ( v[ ' sum ' ] ) sizelist . insert ( 0 , snapshot . asizeof_total - pylab_sum ( sizelist ) ) classlist . insert ( 0 , ' Other ' ) # sizelist = [x*0 . 01 for x in sizelist] title ( \" Snapshot ( %s ) Memory Distribution \" % ( snapshot . desc ) ) figure ( figsize = ( 8 , 8 ) ) axes ( [0 . 1 , 0 . 1 , 0 . 8 , 0 . 8] ) pie ( sizelist , labels = classlist ) savefig ( filename , dpi = 50 ) return self . chart_tag % ( self . relative_path ( filename ) ) ": 5642,
 "def strings_to_integers ( strings : Iterable[str] ) -> Iterable[int] : return strings_to_ ( strings , lambda x : int ( float ( x ) ) ) ": 5643,
 "def _ ( f , x ) : return {k : v for k , v in x . items ( ) if f ( k , v ) }": 5644,
 "def get_last_day_of_month ( t : datetime ) -> int : tn = t + timedelta ( days = 32 ) tn = datetime ( year = tn . year , month = tn . month , day = 1 ) tt = tn - timedelta ( hours = 1 ) return tt . day": 5645,
 "def samefile ( a : str , b : str ) -> bool : try : return os . path . samefile ( a , b ) except OSError : return os . path . normpath ( a ) = = os . path . normpath ( b ) ": 5646,
 "def read32 ( bytestream ) : dt = np . dtype ( np . uint32 ) . newbyteorder ( ' > ' ) return np . frombuffer ( bytestream . read ( 4 ) , dtype = dt ) [0]": 5647,
 "def do_quit ( self , _ : argparse . Namespace ) -> bool : self . _should_quit = True return self . _STOP_AND_EXIT": 5648,
 "def astensor ( array : TensorLike ) -> BKTensor : tensor = tf . convert_to_tensor ( value = array , dtype = CTYPE ) return tensor": 5649,
 "def genfirstvalues ( cursor : Cursor , arraysize : int = 1000 ) \\ -> Generator[Any , None , None] : return ( row[0] for row in genrows ( cursor , arraysize ) ) ": 5650,
 "def array2string ( arr : numpy . ndarray ) -> str : shape = str ( arr . shape ) [1 : -1] if shape . endswith ( \" , \" ) : shape = shape[ : -1] return numpy . array2string ( arr , threshold = 11 ) + \" %s[%s] \" % ( arr . dtype , shape ) ": 5651,
 "def _reshuffle ( mat , shape ) : return np . reshape ( np . transpose ( np . reshape ( mat , shape ) , ( 3 , 1 , 2 , 0 ) ) , ( shape[3] * shape[1] , shape[0] * shape[2] ) ) ": 5652,
 "def cpu_count ( ) -> int : if multiprocessing is None : return 1 try : return multiprocessing . cpu_count ( ) except NotImplementedError : pass try : return os . sysconf ( \" SC_NPROCESSORS_CONF \" ) except ( AttributeError , ValueError ) : pass gen_log . error ( \" Could not detect number of processors; assuming 1 \" ) return 1": 5653,
 "def mouse_event ( dwFlags : int , dx : int , dy : int , dwData : int , dwExtraInfo : int ) -> None : ctypes . windll . user32 . mouse_event ( dwFlags , dx , dy , dwData , dwExtraInfo ) ": 5654,
 "def _izip ( *iterables ) : # This izip routine is from itertools # izip ( ' ABCD ' , ' xy ' ) --> Ax By iterators = map ( iter , iterables ) while iterators : yield tuple ( map ( next , iterators ) ) ": 5655,
 "def s3_get ( url : str , temp_file : IO ) -> None : s3_resource = boto3 . resource ( \" s3 \" ) bucket_name , s3_path = split_s3_path ( url ) s3_resource . Bucket ( bucket_name ) . download_fileobj ( s3_path , temp_file ) ": 5656,
 "def decode_value ( stream ) : length = decode_length ( stream ) ( value , ) = unpack_value ( \" >{ : d}s \" . format ( length ) , stream ) return value": 5657,
 "def flatten_list ( x : List[Any] ) -> List[Any] : # noqa return [item for sublist in x for item in sublist]": 5658,
 "def is_not_null ( df : DataFrame , col_name : str ) -> bool : if ( isinstance ( df , pd . DataFrame ) and col_name in df . columns and df[col_name] . notnull ( ) . any ( ) ) : return True else : return False": 5659,
 "def release_lock ( ) : get_lock . n_lock - = 1 assert get_lock . n_lock > = 0 # Only really release lock once all lock requests have ended . if get_lock . lock_is_enabled and get_lock . n_lock = = 0 : get_lock . start_time = None get_lock . unlocker . unlock ( ) ": 5660,
 "def uppercase_chars ( string : any ) -> str : return ' ' . join ( [c if c . isupper ( ) else ' ' for c in str ( string ) ] ) ": 5661,
 "def read ( self , start_position : int , size : int ) -> memoryview : return memoryview ( self . _bytes ) [start_position : start_position + size]": 5662,
 "def min ( self ) : res = self . _qexec ( \" min ( %s ) \" % self . _name ) if len ( res ) > 0 : self . _min = res[0][0] return self . _min": 5663,
 "def append_num_column ( self , text : str , index : int ) : width = self . columns[index][ \" width \" ] return f \" {text : >{width}} \" ": 5664,
 "def check64bit ( current_system = \" python \" ) : if current_system = = \" python \" : return sys . maxsize > 2147483647 elif current_system = = \" os \" : import platform pm = platform . machine ( ) if pm ! = \" . . \" and pm . endswith ( ' 64 ' ) : # recent Python ( not Iron ) return True else : if ' PROCESSOR_ARCHITEW6432 ' in os . environ : return True # 32 bit program running on 64 bit Windows try : # 64 bit Windows 64 bit program return os . environ[ ' PROCESSOR_ARCHITECTURE ' ] . endswith ( ' 64 ' ) except IndexError : pass # not Windows try : # this often works in Linux return ' 64 ' in platform . architecture ( ) [0] except Exception : # is an older version of Python , assume also an older os@ # ( best we can guess ) return False": 5665,
 "def _kbhit_unix ( ) -> bool : dr , dw , de = select . select ( [sys . stdin] , [] , [] , 0 ) return dr ! = []": 5666,
 "def get_last_weekday_in_month ( year , month , weekday ) : day = date ( year , month , monthrange ( year , month ) [1] ) while True : if day . weekday ( ) = = weekday : break day = day - timedelta ( days = 1 ) return day": 5667,
 "def _gaussian_function ( self , datalength : int , values : np . ndarray , height : int , index : int ) -> np . ndarray : return height * np . exp ( - ( 1 / ( self . spread_number * datalength ) ) * ( values - ( ( datalength / self . function_number ) * index ) ) ** 2 ) ": 5668,
 "def _parse_tuple_string ( argument ) : if isinstance ( argument , str ) : return tuple ( int ( p . strip ( ) ) for p in argument . split ( ' , ' ) ) return argument": 5669,
 "def year ( date ) : try : fmt = ' %m/%d/%Y ' return datetime . strptime ( date , fmt ) . timetuple ( ) . tm_year except ValueError : return 0": 5670,
 "def SvcStop ( self ) -> None : # tell the SCM we ' re shutting down # noinspection PyUnresolvedReferences self . ReportServiceStatus ( win32service . SERVICE_STOP_PENDING ) # fire the stop event win32event . SetEvent ( self . h_stop_event ) ": 5671,
 "def _cnx_is_empty ( in_file ) : with open ( in_file ) as in_handle : for i , line in enumerate ( in_handle ) : if i > 0 : return False return True": 5672,
 "def grep ( pattern , filename ) : try : # for line in file # if line matches pattern : # return line return next ( ( L for L in open ( filename ) if L . find ( pattern ) > = 0 ) ) except StopIteration : return ' ' ": 5673,
 "def _newer ( a , b ) : if not os . path . exists ( a ) : return False if not os . path . exists ( b ) : return True return os . path . getmtime ( a ) > = os . path . getmtime ( b ) ": 5674,
 "def remove_prefix ( text , prefix ) : \t\tnull , prefix , rest = text . rpartition ( prefix ) \treturn rest": 5675,
 "def _environment_variables ( ) -> Dict[str , str] : return {key : value for key , value in os . environ . items ( ) if _is_encodable ( value ) }": 5676,
 "def truncate_string ( value , max_width = None ) : if isinstance ( value , text_type ) and max_width is not None and len ( value ) > max_width : return value[ : max_width] return value": 5677,
 "def zoom_out ( self ) : if self . _scalefactor > = self . _sfmin : self . _scalefactor - = 1 self . scale_image ( ) self . _adjust_scrollbar ( 1/self . _scalestep ) self . sig_zoom_changed . emit ( self . get_scaling ( ) ) ": 5678,
 "def __init__ ( self , enum_obj : Any ) -> None : if enum_obj : self . name = enum_obj self . items = ' , ' . join ( [str ( i ) for i in enum_obj] ) else : self . items = ' ' ": 5679,
 "def count ( self , elem ) : return self . _left_list . count ( elem ) + self . _right_list . count ( elem ) ": 5680,
 "def _run_sync ( self , method : Callable , *args , **kwargs ) -> Any : if self . loop . is_running ( ) : raise RuntimeError ( \" Event loop is already running . \" ) if not self . is_connected : self . loop . run_until_complete ( self . connect ( ) ) task = asyncio . Task ( method ( *args , **kwargs ) , loop = self . loop ) result = self . loop . run_until_complete ( task ) self . loop . run_until_complete ( self . quit ( ) ) return result": 5681,
 "def to_bool ( value : Any ) -> bool : return bool ( strtobool ( value ) if isinstance ( value , str ) else value ) ": 5682,
 "def resize ( im , short , max_size ) : im_shape = im . shape im_size_min = np . min ( im_shape[0 : 2] ) im_size_max = np . max ( im_shape[0 : 2] ) im_scale = float ( short ) / float ( im_size_min ) # prevent bigger axis from being more than max_size : if np . round ( im_scale * im_size_max ) > max_size : im_scale = float ( max_size ) / float ( im_size_max ) im = cv2 . resize ( im , None , None , fx = im_scale , fy = im_scale , interpolation = cv2 . INTER_LINEAR ) return im , im_scale": 5683,
 "def memory_full ( ) : current_process = psutil . Process ( os . getpid ( ) ) return ( current_process . memory_percent ( ) > config . MAXIMUM_CACHE_MEMORY_PERCENTAGE ) ": 5684,
 "def sorted_by ( key : Callable[[raw_types . Qid] , Any] ) -> ' QubitOrder ' : return QubitOrder ( lambda qubits : tuple ( sorted ( qubits , key = key ) ) ) ": 5685,
 "def is_finite ( value : Any ) -> bool : return isinstance ( value , int ) or ( isinstance ( value , float ) and isfinite ( value ) ) ": 5686,
 "def rate_limited ( max_per_hour : int , *args : Any ) -> Callable[ . . . , Any] : return util . rate_limited ( max_per_hour , *args ) ": 5687,
 "def dict_to_enum_fn ( d : Dict[str , Any] , enum_class : Type[Enum] ) -> Enum : return enum_class[d[ ' name ' ]]": 5688,
 "def smooth_image ( image , sigma , sigma_in_physical_coordinates = True , FWHM = False , max_kernel_width = 32 ) : if image . components = = 1 : return _smooth_image_helper ( image , sigma , sigma_in_physical_coordinates , FWHM , max_kernel_width ) else : imagelist = utils . split_channels ( image ) newimages = [] for image in imagelist : newimage = _smooth_image_helper ( image , sigma , sigma_in_physical_coordinates , FWHM , max_kernel_width ) newimages . append ( newimage ) return utils . merge_channels ( newimages ) ": 5689,
 "def has_changed ( filename ) : key = os . path . abspath ( filename ) mtime = get_mtime ( key ) if key not in _mtime_cache : _mtime_cache[key] = mtime return True return mtime > _mtime_cache[key]": 5690,
 "def fcast ( value : float ) -> TensorLike : newvalue = tf . cast ( value , FTYPE ) if DEVICE = = ' gpu ' : newvalue = newvalue . gpu ( ) # Why is this needed? # pragma : no cover return newvalue": 5691,
 "def from_buffer ( buffer , mime = False ) : m = _get_magic_type ( mime ) return m . from_buffer ( buffer ) ": 5692,
 "def long_substr ( data ) : substr = ' ' if len ( data ) > 1 and len ( data[0] ) > 0 : for i in range ( len ( data[0] ) ) : for j in range ( len ( data[0] ) -i+1 ) : if j > len ( substr ) and all ( data[0][i : i+j] in x for x in data ) : substr = data[0][i : i+j] elif len ( data ) = = 1 : substr = data[0] return substr": 5693,
 "def url_host ( url : str ) -> str : from urllib . parse import urlparse res = urlparse ( url ) return res . netloc . split ( ' : ' ) [0] if res . netloc else ' ' ": 5694,
 "def suppress_stdout ( ) : save_stdout = sys . stdout sys . stdout = DevNull ( ) yield sys . stdout = save_stdout": 5695,
 "def first_location_of_maximum ( x ) : if not isinstance ( x , ( np . ndarray , pd . Series ) ) : x = np . asarray ( x ) return np . argmax ( x ) / len ( x ) if len ( x ) > 0 else np . NaN": 5696,
 "def impose_legend_limit ( limit = 30 , axes = \" gca \" , **kwargs ) : if axes = = \" gca \" : axes = _pylab . gca ( ) # make these axes current _pylab . axes ( axes ) # loop over all the lines_pylab . for n in range ( 0 , len ( axes . lines ) ) : if n > limit-1 and not n = = len ( axes . lines ) -1 : axes . lines[n] . set_label ( \" _nolegend_ \" ) if n = = limit-1 and not n = = len ( axes . lines ) -1 : axes . lines[n] . set_label ( \" . . . \" ) _pylab . legend ( **kwargs ) ": 5697,
 "def multi_split ( s , split ) : # type : ( S , Iterable[S] ) -> List[S] for r in split : s = s . replace ( r , \" | \" ) return [i for i in s . split ( \" | \" ) if len ( i ) > 0]": 5698,
 "def replace_in_list ( stringlist : Iterable[str] , replacedict : Dict[str , str] ) -> List[str] : newlist = [] for fromstring in stringlist : newlist . append ( multiple_replace ( fromstring , replacedict ) ) return newlist": 5699,
 "def list_to_str ( list , separator = ' , ' ) : list = [str ( x ) for x in list] return separator . join ( list ) ": 5700,
 "def convert_bytes_to_ints ( in_bytes , num ) : dt = numpy . dtype ( ' >i ' + str ( num ) ) return numpy . frombuffer ( in_bytes , dt ) ": 5701,
 "def fetchallfirstvalues ( self , sql : str , *args ) -> List[Any] : rows = self . fetchall ( sql , *args ) return [row[0] for row in rows]": 5702,
 "def read_las ( source , closefd = True ) : with open_las ( source , closefd = closefd ) as reader : return reader . read ( ) ": 5703,
 "def truncate ( value : Decimal , n_digits : int ) -> Decimal : return Decimal ( math . trunc ( value * ( 10 ** n_digits ) ) ) / ( 10 ** n_digits ) ": 5704,
 "def flatten_list ( l : List[list] ) -> list : return [v for inner_l in l for v in inner_l]": 5705,
 "def MoveWindow ( handle : int , x : int , y : int , width : int , height : int , repaint : int = 1 ) -> bool : return bool ( ctypes . windll . user32 . MoveWindow ( ctypes . c_void_p ( handle ) , x , y , width , height , repaint ) ) ": 5706,
 "def is_line_in_file ( filename : str , line : str ) -> bool : assert \" \\n \" not in line with open ( filename , \" r \" ) as file : for fileline in file : if fileline = = line : return True return False": 5707,
 "def to_bytes ( data : Any ) -> bytearray : # noqa if isinstance ( data , int ) : return bytearray ( [data] ) return bytearray ( data , encoding = ' latin-1 ' ) ": 5708,
 "def de_duplicate ( items ) : result = [] for item in items : if item not in result : result . append ( item ) return result": 5709,
 "def stop ( self ) -> None : if self . _stop and not self . _posted_kork : self . _stop ( ) self . _stop = None": 5710,
 "def non_zero_row ( arr ) : if len ( arr ) = = 0 : return False for item in arr : if item = = 0 : return False return True": 5711,
 "def unpackbools ( integers , dtype = ' L ' ) : atoms = ATOMS[dtype] for chunk in integers : for a in atoms : yield not not chunk & a": 5712,
 "def is_done ( self ) : return self . position . is_game_over ( ) or self . position . n > = FLAGS . max_game_length": 5713,
 "def _generate ( self ) : doc_count = 0 for fp in self . all_files : for doc in self . _get_docs_for_path ( fp ) : yield doc doc_count + = 1 if doc_count > = self . max_docs : return": 5714,
 "def call_spellchecker ( cmd , input_text = None , encoding = None ) : process = get_process ( cmd ) # A buffer has been provided if input_text is not None : for line in input_text . splitlines ( ) : # Hunspell truncates lines at `0x1fff` ( at least on Windows this has been observed ) # Avoid truncation by chunking the line on white space and inserting a new line to break it . offset = 0 end = len ( line ) while True : chunk_end = offset + 0x1fff m = None if chunk_end > = end else RE_LAST_SPACE_IN_CHUNK . search ( line , offset , chunk_end ) if m : chunk_end = m . start ( 1 ) chunk = line[offset : m . start ( 1 ) ] offset = m . end ( 1 ) else : chunk = line[offset : chunk_end] offset = chunk_end # Avoid wasted calls to empty strings if chunk and not chunk . isspace ( ) : process . stdin . write ( chunk + b ' \\n ' ) if offset > = end : break return get_process_output ( process , encoding ) ": 5715,
 "def multivariate_normal_tril ( x , dims , layer_fn = tf . compat . v1 . layers . dense , loc_fn = lambda x : x , scale_fn = tril_with_diag_softplus_and_shift , name = None ) : with tf . compat . v1 . name_scope ( name , ' multivariate_normal_tril ' , [x , dims] ) : x = tf . convert_to_tensor ( value = x , name = ' x ' ) x = layer_fn ( x , dims + dims * ( dims + 1 ) // 2 ) return tfd . MultivariateNormalTriL ( loc = loc_fn ( x[ . . . , : dims] ) , scale_tril = scale_fn ( x[ . . . , dims : ] ) ) ": 5716,
 "def binary ( length ) : num = randint ( 1 , 999999 ) mask = ' 0 ' * length return ( mask + ' ' . join ( [str ( num >> i & 1 ) for i in range ( 7 , -1 , -1 ) ] ) ) [-length : ]": 5717,
 "def average_arrays ( arrays : List[mx . nd . NDArray] ) -> mx . nd . NDArray : if not arrays : raise ValueError ( \" arrays is empty . \" ) if len ( arrays ) = = 1 : return arrays[0] check_condition ( all ( arrays[0] . shape = = a . shape for a in arrays ) , \" nd array shapes do not match \" ) return mx . nd . add_n ( *arrays ) / len ( arrays ) ": 5718,
 "def delete ( self , endpoint : str , **kwargs ) -> dict : return self . _request ( ' DELETE ' , endpoint , **kwargs ) ": 5719,
 "def is_running ( process_id : int ) -> bool : pstr = str ( process_id ) encoding = sys . getdefaultencoding ( ) s = subprocess . Popen ( [ \" ps \" , \" -p \" , pstr] , stdout = subprocess . PIPE ) for line in s . stdout : strline = line . decode ( encoding ) if pstr in strline : return True return False": 5720,
 "def butlast ( iterable ) : iterable = iter ( iterable ) try : first = next ( iterable ) except StopIteration : return for second in iterable : yield first first = second": 5721,
 "def issubset ( self , other ) : if len ( self ) > len ( other ) : # Fast check for obvious cases return False return all ( item in other for item in self ) ": 5722,
 "def _str_to_list ( value , separator ) : value_list = [item . strip ( ) for item in value . split ( separator ) ] value_list_sanitized = builtins . list ( filter ( None , value_list ) ) if len ( value_list_sanitized ) > 0 : return value_list_sanitized else : raise ValueError ( ' Invalid list variable . ' ) ": 5723,
 "def flatten_multidict ( multidict ) : return dict ( [ ( key , value if len ( value ) > 1 else value[0] ) for ( key , value ) in multidict . iterlists ( ) ] ) ": 5724,
 "def remove_blank_lines ( string ) : return \" \\n \" . join ( line for line in string . split ( \" \\n \" ) if len ( line . strip ( ) ) ) ": 5725,
 "def incr ( name , value = 1 , rate = 1 , tags = None ) : client ( ) . incr ( name , value , rate , tags ) ": 5726,
 "def name_is_valid ( name ) : # The name can only be 80 characters long . if len ( name ) > MAX_NAME_LENGTH : return False return bool ( NAME_VALID_CHARS_REGEX . match ( name ) ) ": 5727,
 "async def async_run ( self ) -> None : self . main_task = self . loop . create_task ( self . main ( ) ) await self . main_task": 5728,
 "def file_uptodate ( fname , cmp_fname ) : try : return ( file_exists ( fname ) and file_exists ( cmp_fname ) and getmtime ( fname ) > = getmtime ( cmp_fname ) ) except OSError : return False": 5729,
 "def __rmatmul__ ( self , other ) : return self . T . dot ( np . transpose ( other ) ) . T": 5730,
 "def file_exists ( fname ) : try : return fname and os . path . exists ( fname ) and os . path . getsize ( fname ) > 0 except OSError : return False": 5731,
 "def tsv_escape ( x : Any ) -> str : if x is None : return \" \" x = str ( x ) return x . replace ( \" \\t \" , \" \\\\t \" ) . replace ( \" \\n \" , \" \\\\n \" ) ": 5732,
 "def get_system_drives ( ) : drives = [] if os . name = = ' nt ' : import ctypes bitmask = ctypes . windll . kernel32 . GetLogicalDrives ( ) letter = ord ( ' A ' ) while bitmask > 0 : if bitmask & 1 : name = chr ( letter ) + ' : ' + os . sep if os . path . isdir ( name ) : drives . append ( name ) bitmask >> = 1 letter + = 1 else : current_drive = get_drive ( os . getcwd ( ) ) if current_drive : drive = current_drive else : drive = os . sep drives . append ( drive ) return drives": 5733,
 "def is_rate_limited ( response ) : if ( response . status_code = = codes . too_many_requests and ' Retry-After ' in response . headers and int ( response . headers[ ' Retry-After ' ] ) > = 0 ) : return True return False": 5734,
 "def iprotate ( l , steps = 1 ) : r if len ( l ) : steps % = len ( l ) if steps : firstPart = l[ : steps] del l[ : steps] l . extend ( firstPart ) return l": 5735,
 "def to_int64 ( a ) : # build new dtype and replace i4 --> i8 def promote_i4 ( typestr ) : if typestr[1 : ] = = ' i4 ' : typestr = typestr[0]+ ' i8 ' return typestr dtype = [ ( name , promote_i4 ( typestr ) ) for name , typestr in a . dtype . descr] return a . astype ( dtype ) ": 5736,
 "def browse_dialog_dir ( ) : _go_to_package ( ) logger_directory . info ( \" enter browse_dialog \" ) _path_bytes = subprocess . check_output ( [ ' python ' , ' gui_dir_browse . py ' ] , shell = False ) _path = _fix_path_bytes ( _path_bytes , file = False ) if len ( _path ) > = 1 : _path = _path[0] else : _path = \" \" logger_directory . info ( \" chosen path : {} \" . format ( _path ) ) logger_directory . info ( \" exit browse_dialog \" ) return _path": 5737,
 "def interact ( self , container : Container ) -> None : cmd = \" /bin/bash -c ' source / . environment && /bin/bash ' \" cmd = \" docker exec -it {} {} \" . format ( container . id , cmd ) subprocess . call ( cmd , shell = True ) ": 5738,
 "def file_exists ( self ) -> bool : cfg_path = self . file_path assert cfg_path return path . isfile ( cfg_path ) ": 5739,
 "def _short_repr ( obj ) : stringified = pprint . saferepr ( obj ) if len ( stringified ) > 200 : return ' %s . . . ( %d bytes ) ' % ( stringified[ : 200] , len ( stringified ) ) return stringified": 5740,
 "def remove_once ( gset , elem ) : remove = getattr ( gset , ' remove ' , None ) if remove is not None : remove ( elem ) else : del gset[elem] return elem": 5741,
 "def prevPlot ( self ) : if self . stacker . currentIndex ( ) > 0 : self . stacker . setCurrentIndex ( self . stacker . currentIndex ( ) -1 ) ": 5742,
 "def find_duplicates ( l : list ) -> set : return set ( [x for x in l if l . count ( x ) > 1] ) ": 5743,
 "def change_bgcolor_enable ( self , state ) : self . dataModel . bgcolor ( state ) self . bgcolor_global . setEnabled ( not self . is_series and state > 0 ) ": 5744,
 "def sorted_chain ( *ranges : Iterable[Tuple[int , int]] ) -> List[Tuple[int , int]] : return sorted ( itertools . chain ( *ranges ) ) ": 5745,
 "def csv_to_numpy ( string_like , dtype = None ) : # type : ( str ) -> np . array stream = StringIO ( string_like ) return np . genfromtxt ( stream , dtype = dtype , delimiter = ' , ' ) ": 5746,
 "def _check_whitespace ( string ) : if string . count ( ' ' ) + string . count ( ' \\t ' ) + string . count ( ' \\n ' ) > 0 : raise ValueError ( INSTRUCTION_HAS_WHITESPACE ) ": 5747,
 "def clean_map ( obj : Mapping[Any , Any] ) -> Mapping[Any , Any] : return {k : v for k , v in obj . items ( ) if v is not None}": 5748,
 "def get_pylint_options ( config_dir = ' . ' ) : # type : ( str ) -> List[str] if PYLINT_CONFIG_NAME in os . listdir ( config_dir ) : pylint_config_path = PYLINT_CONFIG_NAME else : pylint_config_path = DEFAULT_PYLINT_CONFIG_PATH return [ ' --rcfile = {} ' . format ( pylint_config_path ) ]": 5749,
 "def prin ( *args , **kwargs ) : r print >> kwargs . get ( ' out ' , None ) , \" \" . join ( [str ( arg ) for arg in args] ) ": 5750,
 "def validate_django_compatible_with_python ( ) : python_version = sys . version[ : 5] django_version = django . get_version ( ) if sys . version_info = = ( 2 , 7 ) and django_version > = \" 2 \" : click . BadArgumentUsage ( \" Please install Django v1 . 11 for Python {} , or switch to Python > = v3 . 4 \" . format ( python_version ) ) ": 5751,
 "def memory_usage ( ) : try : import psutil import os except ImportError : return _memory_usage_ps ( ) process = psutil . Process ( os . getpid ( ) ) mem = process . memory_info ( ) [0] / float ( 2 ** 20 ) return mem": 5752,
 "def position ( self ) -> Position : return Position ( self . _index , self . _lineno , self . _col_offset ) ": 5753,
 "def find_column ( token ) : i = token . lexpos input = token . lexer . lexdata while i > 0 : if input[i - 1] = = ' \\n ' : break i - = 1 column = token . lexpos - i + 1 return column": 5754,
 "def numeric_part ( s ) : m = re_numeric_part . match ( s ) if m : return int ( m . group ( 1 ) ) return None": 5755,
 "def numchannels ( samples : np . ndarray ) -> int : if len ( samples . shape ) = = 1 : return 1 else : return samples . shape[1]": 5756,
 "def exponential_backoff ( attempt : int , cap : int = 1200 ) -> timedelta : base = 3 temp = min ( base * 2 ** attempt , cap ) return timedelta ( seconds = temp / 2 + random . randint ( 0 , temp / 2 ) ) ": 5757,
 "def is_relative_url ( url ) : if url . startswith ( \" # \" ) : return None if url . find ( \" : // \" ) > 0 or url . startswith ( \" // \" ) : # either ' http ( s ) : // . . . ' or ' //cdn . . . ' and therefore absolute return False return True": 5758,
 "def check_consistent_length ( *arrays ) : uniques = np . unique ( [_num_samples ( X ) for X in arrays if X is not None] ) if len ( uniques ) > 1 : raise ValueError ( \" Found arrays with inconsistent numbers of samples : %s \" % str ( uniques ) ) ": 5759,
 "def segment_str ( text : str , phoneme_inventory : Set[str] = PHONEMES ) -> str : text = text . lower ( ) text = segment_into_tokens ( text , phoneme_inventory ) return text": 5760,
 "def last_modified ( self ) -> Optional[datetime . datetime] : httpdate = self . _headers . get ( hdrs . LAST_MODIFIED ) if httpdate is not None : timetuple = parsedate ( httpdate ) if timetuple is not None : return datetime . datetime ( *timetuple[ : 6] , tzinfo = datetime . timezone . utc ) return None": 5761,
 "def tofile ( self , fileobj ) : \t\t\t\tfor entry in self : \t\t\tprint >>fileobj , str ( entry ) \t\tfileobj . close ( ) ": 5762,
 "def _brief_print_list ( lst , limit = 7 ) : lst = list ( lst ) if len ( lst ) > limit : return _brief_print_list ( lst[ : limit//2] , limit ) + ' , . . . , ' + \\ _brief_print_list ( lst[-limit//2 : ] , limit ) return ' , ' . join ( [ \" ' %s ' \" %str ( i ) for i in lst] ) ": 5763,
 "def _tree_line ( self , no_type : bool = False ) -> str : return self . _tree_line_prefix ( ) + \" \" + self . iname ( ) ": 5764,
 "def uconcatenate ( arrs , axis = 0 ) : v = np . concatenate ( arrs , axis = axis ) v = _validate_numpy_wrapper_units ( v , arrs ) return v": 5765,
 "def get_from_gnucash26_date ( date_str : str ) -> date : date_format = \" %Y%m%d \" result = datetime . strptime ( date_str , date_format ) . date ( ) return result": 5766,
 "def camel_to_snake_case ( string ) : s = _1 . sub ( r ' \\1_\\2 ' , string ) return _2 . sub ( r ' \\1_\\2 ' , s ) . lower ( ) ": 5767,
 "def count ( args ) : counts = defaultdict ( int ) for arg in args : for item in arg : counts[item] = counts[item] + 1 return counts": 5768,
 "def encode_list ( key , list_ ) : # type : ( str , Iterable ) -> Dict[str , str] if not list_ : return {} return {key : \" \" . join ( str ( i ) for i in list_ ) }": 5769,
 "def natural_sort ( list_to_sort : Iterable[str] ) -> List[str] : return sorted ( list_to_sort , key = natural_keys ) ": 5770,
 "def are_token_parallel ( sequences : Sequence[Sized] ) -> bool : if not sequences or len ( sequences ) = = 1 : return True return all ( len ( s ) = = len ( sequences[0] ) for s in sequences ) ": 5771,
 "def margin ( text ) : r lines = str ( text ) . split ( ' \\n ' ) return ' \\n ' . join ( ' {} ' . format ( l ) for l in lines ) ": 5772,
 "def closest_values ( L ) : assert len ( L ) > = 2 L . sort ( ) valmin , argmin = min ( ( L[i] - L[i - 1] , i ) for i in range ( 1 , len ( L ) ) ) return L[argmin - 1] , L[argmin]": 5773,
 "def is_orthogonal ( matrix : np . ndarray , * , rtol : float = 1e-5 , atol : float = 1e-8 ) -> bool : return ( matrix . shape[0] = = matrix . shape[1] and np . all ( np . imag ( matrix ) = = 0 ) and np . allclose ( matrix . dot ( matrix . T ) , np . eye ( matrix . shape[0] ) , rtol = rtol , atol = atol ) ) ": 5774,
 "def toStringArray ( name , a , width = 0 ) : string = name + \" : \" cnt = 0 for i in a : string + = \" %4 . 2f \" % i if width > 0 and ( cnt + 1 ) % width = = 0 : string + = ' \\n ' cnt + = 1 return string": 5775,
 "def _isint ( string ) : return type ( string ) is int or \\ ( isinstance ( string , _binary_type ) or isinstance ( string , _text_type ) ) and \\ _isconvertible ( int , string ) ": 5776,
 "def text_coords ( string , position ) : r line_start = string . rfind ( ' \\n ' , 0 , position ) + 1 line_end = string . find ( ' \\n ' , position ) lineno = string . count ( ' \\n ' , 0 , position ) columnno = position - line_start line = string[line_start : line_end] return ( lineno , columnno , line ) ": 5777,
 "def highlight ( text : str , color_code : int , bold : bool = False ) -> str : return ' {}\\033[{}m{}\\033[0m ' . format ( ' \\033[1m ' if bold else ' ' , color_code , text , ) ": 5778,
 "def assign_parent ( node : astroid . node_classes . NodeNG ) -> astroid . node_classes . NodeNG : while node and isinstance ( node , ( astroid . AssignName , astroid . Tuple , astroid . List ) ) : node = node . parent return node": 5779,
 "def excel_datetime ( timestamp , epoch = None ) : if epoch is None : epoch = datetime . datetime . fromordinal ( 693594 ) return epoch + datetime . timedelta ( timestamp ) ": 5780,
 "def callable_validator ( v : Any ) -> AnyCallable : if callable ( v ) : return v raise errors . CallableError ( value = v ) ": 5781,
 "def pack_bits ( longbits ) : byte = longbits & ( 0x0101010101010101 ) byte = ( byte | ( byte>>7 ) ) & ( 0x0003000300030003 ) byte = ( byte | ( byte>>14 ) ) & ( 0x0000000f0000000f ) byte = ( byte | ( byte>>28 ) ) & ( 0x00000000000000ff ) return byte": 5782,
 "def enum_mark_last ( iterable , start = 0 ) : it = iter ( iterable ) count = start try : last = next ( it ) except StopIteration : return for val in it : yield count , False , last last = val count + = 1 yield count , True , last": 5783,
 "def to_iso_string ( self ) -> str : assert isinstance ( self . value , datetime ) return datetime . isoformat ( self . value ) ": 5784,
 "def timeit ( func , *args , **kwargs ) : start_time = time . time ( ) res = func ( *args , **kwargs ) timing = time . time ( ) - start_time return res , timing": 5785,
 "def clean_all_buckets ( self ) : bucket_keys = self . redis_object . keys ( pattern = ' nearpy_* ' ) if len ( bucket_keys ) > 0 : self . redis_object . delete ( *bucket_keys ) ": 5786,
 "def output_dir ( self , *args ) -> str : return os . path . join ( self . project_dir , ' output ' , *args ) ": 5787,
 "def writable_stream ( handle ) : if isinstance ( handle , io . IOBase ) and sys . version_info > = ( 3 , 5 ) : return handle . writable ( ) try : handle . write ( b ' ' ) except ( io . UnsupportedOperation , IOError ) : return False else : return True": 5788,
 "def contains ( self , token : str ) -> bool : self . _validate_token ( token ) return token in self": 5789,
 "def detect_model_num ( string ) : match = re . match ( MODEL_NUM_REGEX , string ) if match : return int ( match . group ( ) ) return None": 5790,
 "def shape ( self ) -> Tuple[int , . . . ] : return tuple ( bins . bin_count for bins in self . _binnings ) ": 5791,
 "def simple_eq ( one : Instance , two : Instance , attrs : List[str] ) -> bool : return all ( getattr ( one , a ) = = getattr ( two , a ) for a in attrs ) ": 5792,
 "def imt2tup ( string ) : s = string . strip ( ) if not s . endswith ( ' ) ' ) : # no parenthesis , PGA is considered the same as PGA ( ) return ( s , ) name , rest = s . split ( ' ( ' , 1 ) return ( name , ) + tuple ( float ( x ) for x in ast . literal_eval ( rest[ : -1] + ' , ' ) ) ": 5793,
 "def _store_helper ( model : Action , session : Optional[Session] = None ) -> None : if session is None : session = _make_session ( ) session . add ( model ) session . commit ( ) session . close ( ) ": 5794,
 "def _cursorLeft ( self ) : if self . cursorPos > 0 : self . cursorPos - = 1 sys . stdout . write ( console . CURSOR_LEFT ) sys . stdout . flush ( ) ": 5795,
 "def parse_reading ( val : str ) -> Optional[float] : try : return float ( val ) except ValueError : logging . warning ( ' Reading of \" %s \" is not a number ' , val ) return None": 5796,
 "def datetime_from_isoformat ( value : str ) : if sys . version_info > = ( 3 , 7 ) : return datetime . fromisoformat ( value ) return datetime . strptime ( value , ' %Y-%m-%dT%H : %M : %S . %f ' ) ": 5797,
 "def get_domain ( url ) : parse_result = urlparse ( url ) domain = \" {schema} : //{netloc} \" . format ( schema = parse_result . scheme , netloc = parse_result . netloc ) return domain": 5798,
 "def argmax ( self , rows : List[Row] , column : ComparableColumn ) -> List[Row] : if not rows : return [] value_row_pairs = [ ( row . values[column . name] , row ) for row in rows] if not value_row_pairs : return [] # Returns a list containing the row with the max cell value . return [sorted ( value_row_pairs , key = lambda x : x[0] , reverse = True ) [0][1]]": 5799,
 "def tanimoto_set_similarity ( x : Iterable[X] , y : Iterable[X] ) -> float : a , b = set ( x ) , set ( y ) union = a | b if not union : return 0 . 0 return len ( a & b ) / len ( union ) ": 5800,
 "def reverse_mapping ( mapping ) : \t\tkeys , values = zip ( *mapping . items ( ) ) \treturn dict ( zip ( values , keys ) ) ": 5801,
 "def get_table_names_from_metadata ( metadata : MetaData ) -> List[str] : return [table . name for table in metadata . tables . values ( ) ]": 5802,
 "def dtypes ( self ) : return [ ( str ( f . name ) , f . dataType . simpleString ( ) ) for f in self . schema . fields]": 5803,
 "def almost_hermitian ( gate : Gate ) -> bool : return np . allclose ( asarray ( gate . asoperator ( ) ) , asarray ( gate . H . asoperator ( ) ) ) ": 5804,
 "def sample_normal ( mean , var , rng ) : ret = numpy . sqrt ( var ) * rng . randn ( *mean . shape ) + mean return ret": 5805,
 "def fetchvalue ( self , sql : str , *args ) -> Optional[Any] : row = self . fetchone ( sql , *args ) if row is None : return None return row[0]": 5806,
 "def inject_nulls ( data : Mapping , field_names ) -> dict : record = dict ( ) for field in field_names : record[field] = data . get ( field , None ) return record": 5807,
 "def valid_file ( path : str ) -> bool : path = Path ( path ) . expanduser ( ) log . debug ( \" checking if %s is a valid file \" , path ) return path . exists ( ) and path . is_file ( ) ": 5808,
 "def get_deprecation_reason ( node : Union[EnumValueDefinitionNode , FieldDefinitionNode] ) -> Optional[str] : from . . execution import get_directive_values deprecated = get_directive_values ( GraphQLDeprecatedDirective , node ) return deprecated[ \" reason \" ] if deprecated else None": 5809,
 "def _prm_get_longest_stringsize ( string_list ) : maxlength = 1 for stringar in string_list : if isinstance ( stringar , np . ndarray ) : if stringar . ndim > 0 : for string in stringar . ravel ( ) : maxlength = max ( len ( string ) , maxlength ) else : maxlength = max ( len ( stringar . tolist ( ) ) , maxlength ) else : maxlength = max ( len ( stringar ) , maxlength ) # Make the string Col longer than needed in order to allow later on slightly larger strings return int ( maxlength * 1 . 5 ) ": 5810,
 "def cmd_dot ( conf : Config ) : build_context = BuildContext ( conf ) populate_targets_graph ( build_context , conf ) if conf . output_dot_file is None : write_dot ( build_context , conf , sys . stdout ) else : with open ( conf . output_dot_file , ' w ' ) as out_file : write_dot ( build_context , conf , out_file ) ": 5811,
 "def has_value ( cls , value : int ) -> bool : return any ( value = = item . value for item in cls ) ": 5812,
 "def post ( self , endpoint : str , **kwargs ) -> dict : return self . _request ( ' POST ' , endpoint , **kwargs ) ": 5813,
 "def auto_up ( self , count = 1 , go_to_start_of_line_if_history_changes = False ) : if self . complete_state : self . complete_previous ( count = count ) elif self . document . cursor_position_row > 0 : self . cursor_up ( count = count ) elif not self . selection_state : self . history_backward ( count = count ) # Go to the start of the line? if go_to_start_of_line_if_history_changes : self . cursor_position + = self . document . get_start_of_line_position ( ) ": 5814,
 "def to_0d_array ( value : Any ) -> np . ndarray : if np . isscalar ( value ) or ( isinstance ( value , np . ndarray ) and value . ndim = = 0 ) : return np . array ( value ) else : return to_0d_object_array ( value ) ": 5815,
 "def gcd_float ( numbers , tol = 1e-8 ) : def pair_gcd_tol ( a , b ) : \" \" \" Calculate the Greatest Common Divisor of a and b . Unless b = = 0 , the result will have the same sign as b ( so that when b is divided by it , the result comes out positive ) . \" \" \" while b > tol : a , b = b , a % b return a n = numbers[0] for i in numbers : n = pair_gcd_tol ( n , i ) return n": 5816,
 "def calculate_dimensions ( image , long_side , short_side ) : if image . width > = image . height : return ' {0}x{1} ' . format ( long_side , short_side ) return ' {0}x{1} ' . format ( short_side , long_side ) ": 5817,
 "def fmt_camel ( name ) : words = split_words ( name ) assert len ( words ) > 0 first = words . pop ( 0 ) . lower ( ) return first + ' ' . join ( [word . capitalize ( ) for word in words] ) ": 5818,
 "def from_file ( filename , mime = False ) : m = _get_magic_type ( mime ) return m . from_file ( filename ) ": 5819,
 "def _relative_frequency ( self , word ) : \t\t\t\tcount = self . type_counts . get ( word , 0 ) \t\treturn math . log ( count/len ( self . type_counts ) ) if count > 0 else 0": 5820,
 "def getIndex ( predicateFn : Callable[[T] , bool] , items : List[T] ) -> int : try : return next ( i for i , v in enumerate ( items ) if predicateFn ( v ) ) except StopIteration : return -1": 5821,
 "def isarray ( array , test , dim = 2 ) : if dim > 1 : return all ( isarray ( array[i] , test , dim - 1 ) for i in range ( len ( array ) ) ) return all ( test ( i ) for i in array ) ": 5822,
 "def is_quoted ( arg : str ) -> bool : return len ( arg ) > 1 and arg[0] = = arg[-1] and arg[0] in constants . QUOTES": 5823,
 "def get_language ( ) : from parler import appsettings language = dj_get_language ( ) if language is None and appsettings . PARLER_DEFAULT_ACTIVATE : return appsettings . PARLER_DEFAULT_LANGUAGE_CODE else : return language": 5824,
 "def infer_format ( filename : str ) -> str : _ , ext = os . path . splitext ( filename ) return ext": 5825,
 "def _find_conda ( ) : if ' CONDA_EXE ' in os . environ : conda = os . environ[ ' CONDA_EXE ' ] else : conda = util . which ( ' conda ' ) return conda": 5826,
 "def nTimes ( n , f , *args , **kwargs ) : r for i in xrange ( n ) : f ( *args , **kwargs ) ": 5827,
 "def elmo_loss2ppl ( losses : List[np . ndarray] ) -> float : avg_loss = np . mean ( losses ) return float ( np . exp ( avg_loss ) ) ": 5828,
 "def url_concat ( url , args ) : if not args : return url if url[-1] not in ( ' ? ' , ' & ' ) : url + = ' & ' if ( ' ? ' in url ) else ' ? ' return url + urllib . urlencode ( args ) ": 5829,
 "def pset ( iterable = ( ) , pre_size = 8 ) : if not iterable : return _EMPTY_PSET return PSet . _from_iterable ( iterable , pre_size = pre_size ) ": 5830,
 "def hsv2rgb_spectrum ( hsv ) : h , s , v = hsv return hsv2rgb_raw ( ( ( h * 192 ) >> 8 , s , v ) ) ": 5831,
 "def __as_list ( value : List[JsonObjTypes] ) -> List[JsonTypes] : return [e . _as_dict if isinstance ( e , JsonObj ) else e for e in value]": 5832,
 "def __add_method ( m : lmap . Map , key : T , method : Method ) -> lmap . Map : return m . assoc ( key , method ) ": 5833,
 "def isfile_notempty ( inputfile : str ) -> bool : try : return isfile ( inputfile ) and getsize ( inputfile ) > 0 except TypeError : raise TypeError ( ' inputfile is not a valid type ' ) ": 5834,
 "def __iter__ ( self ) : def generator ( ) : for i , obj in enumerate ( self . _sequence ) : if i > = self . _limit : break yield obj raise StopIteration return generator": 5835,
 "def clean_int ( x ) -> int : try : return int ( x ) except ValueError : raise forms . ValidationError ( \" Cannot convert to integer : {} \" . format ( repr ( x ) ) ) ": 5836,
 "def format_repr ( obj , attributes ) -> str : attribute_repr = ' , ' . join ( ( ' {} = {} ' . format ( attr , repr ( getattr ( obj , attr ) ) ) for attr in attributes ) ) return \" {0} ( {1} ) \" . format ( obj . __class__ . __qualname__ , attribute_repr ) ": 5837,
 "def _read_words ( filename ) : with tf . gfile . GFile ( filename , \" r \" ) as f : if sys . version_info[0] > = 3 : return f . read ( ) . replace ( \" \\n \" , \" %s \" % EOS ) . split ( ) else : return f . read ( ) . decode ( \" utf-8 \" ) . replace ( \" \\n \" , \" %s \" % EOS ) . split ( ) ": 5838,
 "def u16le_list_to_byte_list ( data ) : byteData = [] for h in data : byteData . extend ( [h & 0xff , ( h >> 8 ) & 0xff] ) return byteData": 5839,
 "def sort_by_modified ( files_or_folders : list ) -> list : return sorted ( files_or_folders , key = os . path . getmtime , reverse = True ) ": 5840,
 "def lint ( fmt = ' colorized ' ) : if fmt = = ' html ' : outfile = ' pylint_report . html ' local ( ' pylint -f %s davies > %s || true ' % ( fmt , outfile ) ) local ( ' open %s ' % outfile ) else : local ( ' pylint -f %s davies || true ' % fmt ) ": 5841,
 "def _gauss ( mean : int , sigma : int ) -> int : return int ( random . gauss ( mean , sigma ) ) ": 5842,
 "def rmglob ( pattern : str ) -> None : for f in glob . glob ( pattern ) : os . remove ( f ) ": 5843,
 "def PrintIndented ( self , file , ident , code ) : for entry in code : print >>file , ' %s%s ' % ( ident , entry ) ": 5844,
 "def replace_keys ( record : Mapping , key_map : Mapping ) -> dict : return {key_map[k] : v for k , v in record . items ( ) if k in key_map}": 5845,
 "def valid_substitution ( strlen , index ) : values = index[0] return all ( [strlen > i for i in values] ) ": 5846,
 "def fast_median ( a ) : a = checkma ( a ) # return scoreatpercentile ( a . compressed ( ) , 50 ) if a . count ( ) > 0 : out = np . percentile ( a . compressed ( ) , 50 ) else : out = np . ma . masked return out": 5847,
 "def dict_of_sets_add ( dictionary , key , value ) : # type : ( DictUpperBound , Any , Any ) -> None set_objs = dictionary . get ( key , set ( ) ) set_objs . add ( value ) dictionary[key] = set_objs": 5848,
 "def arcball_map_to_sphere ( point , center , radius ) : v0 = ( point[0] - center[0] ) / radius v1 = ( center[1] - point[1] ) / radius n = v0*v0 + v1*v1 if n > 1 . 0 : # position outside of sphere n = math . sqrt ( n ) return numpy . array ( [v0/n , v1/n , 0 . 0] ) else : return numpy . array ( [v0 , v1 , math . sqrt ( 1 . 0 - n ) ] ) ": 5849,
 "def _create_empty_array ( self , frames , always_2d , dtype ) : import numpy as np if always_2d or self . channels > 1 : shape = frames , self . channels else : shape = frames , return np . empty ( shape , dtype , order = ' C ' ) ": 5850,
 "def assert_equal ( first , second , msg_fmt = \" {msg} \" ) : if isinstance ( first , dict ) and isinstance ( second , dict ) : assert_dict_equal ( first , second , msg_fmt ) elif not first = = second : msg = \" {!r} ! = {!r} \" . format ( first , second ) fail ( msg_fmt . format ( msg = msg , first = first , second = second ) ) ": 5851,
 "def set_cell_value ( cell , value ) : if OPENPYXL_MAJOR_VERSION > 1 : cell . value = value else : cell . internal_value = value": 5852,
 "def _mid ( pt1 , pt2 ) : ( x0 , y0 ) , ( x1 , y1 ) = pt1 , pt2 return 0 . 5 * ( x0 + x1 ) , 0 . 5 * ( y0 + y1 ) ": 5853,
 "def _parse_date ( string : str ) -> datetime . date : return datetime . datetime . strptime ( string , ' %Y-%m-%d ' ) . date ( ) ": 5854,
 "def hash_file ( fileobj ) : hasher = hashlib . md5 ( ) buf = fileobj . read ( 65536 ) while len ( buf ) > 0 : hasher . update ( buf ) buf = fileobj . read ( 65536 ) return hasher . hexdigest ( ) ": 5855,
 "def setup_cache ( app : Flask , cache_config ) -> Optional[Cache] : if cache_config and cache_config . get ( ' CACHE_TYPE ' ) ! = ' null ' : return Cache ( app , config = cache_config ) return None": 5856,
 "def in_transaction ( self ) : if not hasattr ( self . local , ' tx ' ) : return False return len ( self . local . tx ) > 0": 5857,
 "def score_small_straight_yatzy ( dice : List[int] ) -> int : dice_set = set ( dice ) if _are_two_sets_equal ( {1 , 2 , 3 , 4 , 5} , dice_set ) : return sum ( dice ) return 0": 5858,
 "def process_literal_param ( self , value : Optional[List[int]] , dialect : Dialect ) -> str : retval = self . _intlist_to_dbstr ( value ) return retval": 5859,
 "def label_from_bin ( buf ) : mpls_label = type_desc . Int3 . to_user ( six . binary_type ( buf ) ) return mpls_label >> 4 , mpls_label & 1": 5860,
 "def has_table ( self , name ) : return len ( self . sql ( \" SELECT name FROM sqlite_master WHERE type = ' table ' AND name = ? \" , parameters = ( name , ) , asrecarray = False , cache = False ) ) > 0": 5861,
 "def rl_get_point ( ) -> int : # pragma : no cover if rl_type = = RlType . GNU : return ctypes . c_int . in_dll ( readline_lib , \" rl_point \" ) . value elif rl_type = = RlType . PYREADLINE : return readline . rl . mode . l_buffer . point else : return 0": 5862,
 "def is_unitary ( matrix : np . ndarray ) -> bool : rows , cols = matrix . shape if rows ! = cols : return False return np . allclose ( np . eye ( rows ) , matrix . dot ( matrix . T . conj ( ) ) ) ": 5863,
 "def SGT ( self , a , b ) : # http : //gavwood . com/paper . pdf s0 , s1 = to_signed ( a ) , to_signed ( b ) return Operators . ITEBV ( 256 , s0 > s1 , 1 , 0 ) ": 5864,
 "def replaceStrs ( s , *args ) : r if args = = ( ) : return s mapping = dict ( ( frm , to ) for frm , to in args ) return re . sub ( \" | \" . join ( map ( re . escape , mapping . keys ( ) ) ) , lambda match : mapping[match . group ( 0 ) ] , s ) ": 5865,
 "def remove_falsy_values ( counter : Mapping[Any , int] ) -> Mapping[Any , int] : return { label : count for label , count in counter . items ( ) if count }": 5866,
 "def normcdf ( x , log = False ) : y = np . atleast_1d ( x ) . copy ( ) flib . normcdf ( y ) if log : if ( y>0 ) . all ( ) : return np . log ( y ) return -np . inf return y": 5867,
 "def zlib_compress ( data ) : if PY3K : if isinstance ( data , str ) : return zlib . compress ( bytes ( data , ' utf-8 ' ) ) return zlib . compress ( data ) return zlib . compress ( data ) ": 5868,
 "def get_cursor ( self ) : x , y = self . _cursor width , height = self . parent . get_size ( ) while x > = width : x - = width y + = 1 if y > = height and self . scrollMode = = ' scroll ' : y = height - 1 return x , y": 5869,
 "def file_lines ( bblfile : str ) -> iter : with open ( bblfile ) as fd : yield from ( line . rstrip ( ) for line in fd if line . rstrip ( ) ) ": 5870,
 "def getRandomBinaryTreeLeafNode ( binaryTree ) : if binaryTree . internal = = True : if random . random ( ) > 0 . 5 : return getRandomBinaryTreeLeafNode ( binaryTree . left ) else : return getRandomBinaryTreeLeafNode ( binaryTree . right ) else : return binaryTree": 5871,
 "def check_key ( self , key : str ) -> bool : keys = self . get_keys ( ) return key in keys": 5872,
 "def split_unit ( value ) : r = re . search ( ' ^ ( \\-?[\\d\\ . ]+ ) ( . * ) $ ' , str ( value ) ) return r . groups ( ) if r else ( ' ' , ' ' ) ": 5873,
 "def rms ( x ) : try : return ( np . array ( x ) ** 2 ) . mean ( ) ** 0 . 5 except : x = np . array ( dropna ( x ) ) invN = 1 . 0 / len ( x ) return ( sum ( invN * ( x_i ** 2 ) for x_i in x ) ) ** . 5": 5874,
 "def templategetter ( tmpl ) : tmpl = tmpl . replace ( ' { ' , ' % ( ' ) tmpl = tmpl . replace ( ' } ' , ' ) s ' ) return lambda data : tmpl % data": 5875,
 "def to_clipboard ( self , excel = True , sep = None , **kwargs ) : r from pandas . io import clipboards clipboards . to_clipboard ( self , excel = excel , sep = sep , **kwargs ) ": 5876,
 "def get_datatype ( self , table : str , column : str ) -> str : return self . flavour . get_datatype ( self , table , column ) . upper ( ) ": 5877,
 "def SwitchToThisWindow ( handle : int ) -> None : ctypes . windll . user32 . SwitchToThisWindow ( ctypes . c_void_p ( handle ) , 1 ) ": 5878,
 "def pretty_dict ( d ) : return ' {%s} ' % ' , ' . join ( ' %r : %r ' % ( k , v ) for k , v in sorted ( d . items ( ) , key = repr ) ) ": 5879,
 "def array_to_npy ( array_like ) : # type : ( np . array or Iterable or int or float ) -> object buffer = BytesIO ( ) np . save ( buffer , array_like ) return buffer . getvalue ( ) ": 5880,
 "def read_byte_data ( self , addr , cmd ) : self . _set_addr ( addr ) res = SMBUS . i2c_smbus_read_byte_data ( self . _fd , ffi . cast ( \" __u8 \" , cmd ) ) if res = = -1 : raise IOError ( ffi . errno ) return res": 5881,
 "def decode ( self , bytes , raw = False ) : return struct . unpack ( self . format , buffer ( bytes ) ) [0]": 5882,
 "def _parse_property ( self , node ) : # type : ( ElementTree . Element ) -> Tuple[str , Any] # Get information name = node . attrib[ATTR_NAME] vtype = node . attrib . get ( ATTR_VALUE_TYPE , TYPE_STRING ) # Look for a value as a single child node try : value_node = next ( iter ( node ) ) value = self . _parse_value_node ( vtype , value_node ) except StopIteration : # Value is an attribute value = self . _convert_value ( vtype , node . attrib[ATTR_VALUE] ) return name , value": 5883,
 "def is_intersection ( g , n ) : return len ( set ( g . predecessors ( n ) + g . successors ( n ) ) ) > 2": 5884,
 "def interpolate ( f1 : float , f2 : float , factor : float ) -> float : return f1 + ( f2 - f1 ) * factor": 5885,
 "def reduce ( function , initval = None ) : \t\tif initval is None : \t\treturn lambda s : __builtin__ . reduce ( function , s ) \telse : \t\treturn lambda s : __builtin__ . reduce ( function , s , initval ) ": 5886,
 "def _validate_authority_uri_abs_path ( host , path ) : if len ( host ) > 0 and len ( path ) > 0 and not path . startswith ( \" / \" ) : raise ValueError ( \" Path in a URL with authority \" \" should start with a slash ( ' / ' ) if set \" ) ": 5887,
 "def warn_if_nans_exist ( X ) : null_count = count_rows_with_nans ( X ) total = len ( X ) percent = 100 * null_count / total if null_count > 0 : warning_message = \\ ' Warning! Found {} rows of {} ( { : 0 . 2f}% ) with nan values . Only ' \\ ' complete rows will be plotted . ' . format ( null_count , total , percent ) warnings . warn ( warning_message , DataWarning ) ": 5888,
 "def _get_parsing_plan_for_multifile_children ( self , obj_on_fs : PersistedObject , desired_type : Type[Any] , logger : Logger ) -> Dict[str , Any] : raise Exception ( ' This should never happen , since this parser relies on underlying parsers ' ) ": 5889,
 "def sort_key ( x ) : name , ( r , u ) = x return - len ( u ) + u . count ( ' } ' ) * 100": 5890,
 "def inverted_dict_of_lists ( d ) : new_dict = {} for ( old_key , old_value_list ) in viewitems ( dict ( d ) ) : for new_key in listify ( old_value_list ) : new_dict[new_key] = old_key return new_dict": 5891,
 "def copy_without_prompts ( self ) : text = self . get_selected_text ( ) lines = text . split ( os . linesep ) for index , line in enumerate ( lines ) : if line . startswith ( ' >>> ' ) or line . startswith ( ' . . . ' ) : lines[index] = line[4 : ] text = os . linesep . join ( lines ) QApplication . clipboard ( ) . setText ( text ) ": 5892,
 "def hex_to_int ( value ) : if version_info . major > = 3 : return int . from_bytes ( value , \" big \" ) return int ( value . encode ( \" hex \" ) , 16 ) ": 5893,
 "def partition_items ( count , bin_size ) : \t\tnum_bins = int ( math . ceil ( count / float ( bin_size ) ) ) \tbins = [0] * num_bins\tfor i in range ( count ) : \t\tbins[i % num_bins] + = 1\treturn bins": 5894,
 "def _read_section ( self ) : lines = [self . _last[self . _last . find ( \" : \" ) +1 : ]] self . _last = self . _f . readline ( ) while len ( self . _last ) > 0 and len ( self . _last[0] . strip ( ) ) = = 0 : lines . append ( self . _last ) self . _last = self . _f . readline ( ) return lines": 5895,
 "def _get_ipv6_from_binary ( self , bin_addr ) : hi = bin_addr >> 64 lo = bin_addr & 0xFFFFFFFF return socket . inet_ntop ( socket . AF_INET6 , struct . pack ( \" !QQ \" , hi , lo ) ) ": 5896,
 "def connect_to_database_odbc_access ( self , dsn : str , autocommit : bool = True ) -> None : self . connect ( engine = ENGINE_ACCESS , interface = INTERFACE_ODBC , dsn = dsn , autocommit = autocommit ) ": 5897,
 "def has_enumerated_namespace_name ( self , namespace : str , name : str ) -> bool : return self . has_enumerated_namespace ( namespace ) and name in self . namespace_to_terms[namespace]": 5898,
 "def Exit ( msg , code = 1 ) : print >> sys . stderr , msg sys . exit ( code ) ": 5899,
 "def is_iterable ( etype ) -> bool : return type ( etype ) is GenericMeta and issubclass ( etype . __extra__ , Iterable ) ": 5900,
 "async def fetchall ( self ) -> Iterable[sqlite3 . Row] : return await self . _execute ( self . _cursor . fetchall ) ": 5901,
 "def get_line_number ( line_map , offset ) : for lineno , line_offset in enumerate ( line_map , start = 1 ) : if line_offset > offset : return lineno return -1": 5902,
 "def snake_to_camel ( value ) : camel = \" \" . join ( word . title ( ) for word in value . split ( \" _ \" ) ) return value[ : 1] . lower ( ) + camel[1 : ]": 5903,
 "def factorial ( n , mod = None ) : if not ( isinstance ( n , int ) and n > = 0 ) : raise ValueError ( \" ' n ' must be a non-negative integer . \" ) if mod is not None and not ( isinstance ( mod , int ) and mod > 0 ) : raise ValueError ( \" ' mod ' must be a positive integer \" ) result = 1 if n = = 0 : return 1 for i in range ( 2 , n+1 ) : result * = i if mod : result % = mod return result": 5904,
 "def ResetConsoleColor ( ) -> bool : if sys . stdout : sys . stdout . flush ( ) bool ( ctypes . windll . kernel32 . SetConsoleTextAttribute ( _ConsoleOutputHandle , _DefaultConsoleColor ) ) ": 5905,
 "def getCollectDServer ( queue , cfg ) : server = CollectDServerMP if cfg . collectd_workers > 1 else CollectDServer return server ( queue , cfg ) ": 5906,
 "def val_mb ( valstr : Union[int , str] ) -> str : try : return \" { : . 3f} \" . format ( int ( valstr ) / ( 1024 * 1024 ) ) except ( TypeError , ValueError ) : return ' ? ' ": 5907,
 "def moving_average ( iterable , n ) : it = iter ( iterable ) d = collections . deque ( itertools . islice ( it , n - 1 ) ) d . appendleft ( 0 ) s = sum ( d ) for elem in it : s + = elem - d . popleft ( ) d . append ( elem ) yield s / float ( n ) ": 5908,
 "def _close ( self ) : self . _usb_handle . releaseInterface ( ) try : # If we ' re using PyUSB > = 1 . 0 we can re-attach the kernel driver here . self . _usb_handle . dev . attach_kernel_driver ( 0 ) except : pass self . _usb_int = None self . _usb_handle = None return True": 5909,
 "def dag_longest_path ( graph , source , target ) : if source = = target : return [source] allpaths = nx . all_simple_paths ( graph , source , target ) longest_path = [] for l in allpaths : if len ( l ) > len ( longest_path ) : longest_path = l return longest_path": 5910,
 "def __remove_method ( m : lmap . Map , key : T ) -> lmap . Map : return m . dissoc ( key ) ": 5911,
 "def returned ( n ) : \t\t # # `takei` yield lazily so we can short-circuit and avoid computing the rest of the walk\tfor pos in randwalk ( ) >> drop ( 1 ) >> takei ( xrange ( n-1 ) ) : \t\tif pos = = Origin : \t\t\treturn True\treturn False": 5912,
 "def looks_like_url ( url ) : if not isinstance ( url , basestring ) : return False if not isinstance ( url , basestring ) or len ( url ) > = 1024 or not cre_url . match ( url ) : return False return True": 5913,
 "def preconnect ( self , size = -1 ) : if size = = -1 and self . max_size = = -1 : raise ClientError ( \" size = -1 not allowed with pool max_size = -1 \" ) limit = min ( size , self . max_size ) if size ! = -1 else self . max_size clients = yield [self . get_connected_client ( ) for _ in range ( 0 , limit ) ] for client in clients : self . release_client ( client ) ": 5914,
 "def left_zero_pad ( s , blocksize ) : if blocksize > 0 and len ( s ) % blocksize : s = ( blocksize - len ( s ) % blocksize ) * b ( ' \\000 ' ) + s return s": 5915,
 "def str_upper ( x ) : sl = _to_string_sequence ( x ) . upper ( ) return column . ColumnStringArrow ( sl . bytes , sl . indices , sl . length , sl . offset , string_sequence = sl ) ": 5916,
 "def uuid ( self , version : int = None ) -> str : bits = self . random . getrandbits ( 128 ) return str ( uuid . UUID ( int = bits , version = version ) ) ": 5917,
 "def fprint ( expr , print_ascii = False ) : r if print_ascii : pprint ( expr , use_unicode = False , num_columns = 120 ) else : return expr": 5918,
 "def is_none ( string_ , default = ' raise ' ) : none = [ ' none ' , ' undefined ' , ' unknown ' , ' null ' , ' ' ] if string_ . lower ( ) in none : return True elif not default : return False else : raise ValueError ( ' The value \\ ' {}\\ ' cannot be mapped to none . ' . format ( string_ ) ) ": 5919,
 "async def login ( username : str , password : str , brand : str , websession : ClientSession = None ) -> API : api = API ( brand , websession ) await api . authenticate ( username , password ) return api": 5920,
 "def should_rollover ( self , record : LogRecord ) -> bool : t = int ( time . time ( ) ) if t > = self . rollover_at : return True return False": 5921,
 "def _request ( self , method : str , endpoint : str , params : dict = None , data : dict = None , headers : dict = None ) -> dict : ": 5922,
 "def after_epoch ( self , **_ ) -> None : SaveEvery . save_model ( model = self . _model , name_suffix = self . _OUTPUT_NAME , on_failure = self . _on_save_failure ) ": 5923,
 "def last ( self ) : if self . _last is UNDETERMINED : # not necessarily the last one . . . self . _last = self . sdat . tseries . index[-1] return self[self . _last]": 5924,
 "def decodebytes ( input ) : py_version = sys . version_info[0] if py_version > = 3 : return _decodebytes_py3 ( input ) return _decodebytes_py2 ( input ) ": 5925,
 "def is_prime ( n ) : if n % 2 = = 0 and n > 2 : return False return all ( n % i for i in range ( 3 , int ( math . sqrt ( n ) ) + 1 , 2 ) ) ": 5926,
 "def sortBy ( self , keyfunc , ascending = True , numPartitions = None ) : return self . keyBy ( keyfunc ) . sortByKey ( ascending , numPartitions ) . values ( ) ": 5927,
 "def multiple_replace ( string , replacements ) : # type : ( str , Dict[str , str] ) -> str pattern = re . compile ( \" | \" . join ( [re . escape ( k ) for k in sorted ( replacements , key = len , reverse = True ) ] ) , flags = re . DOTALL ) return pattern . sub ( lambda x : replacements[x . group ( 0 ) ] , string ) ": 5928,
 "def uniqued ( iterable ) : seen = set ( ) return [item for item in iterable if item not in seen and not seen . add ( item ) ]": 5929,
 "def _check_samples_nodups ( fnames ) : counts = defaultdict ( int ) for f in fnames : for s in get_samples ( f ) : counts[s] + = 1 duplicates = [s for s , c in counts . items ( ) if c > 1] if duplicates : raise ValueError ( \" Duplicate samples found in inputs %s : %s \" % ( duplicates , fnames ) ) ": 5930,
 "def get_window_dim ( ) : version = sys . version_info if version > = ( 3 , 3 ) : return _size_36 ( ) if platform . system ( ) = = ' Windows ' : return _size_windows ( ) return _size_27 ( ) ": 5931,
 "def decode_base64 ( data : str ) -> bytes : missing_padding = len ( data ) % 4 if missing_padding ! = 0 : data + = \" = \" * ( 4 - missing_padding ) return base64 . decodebytes ( data . encode ( \" utf-8 \" ) ) ": 5932,
 "def is_sqlatype_numeric ( coltype : Union[TypeEngine , VisitableType] ) -> bool : coltype = _coltype_to_typeengine ( coltype ) return isinstance ( coltype , sqltypes . Numeric ) ": 5933,
 "def check_lengths ( *arrays ) : lengths = [len ( array ) for array in arrays] if len ( np . unique ( lengths ) ) > 1 : raise ValueError ( ' Inconsistent data lengths : {} ' . format ( lengths ) ) ": 5934,
 "def isfinite ( data : mx . nd . NDArray ) -> mx . nd . NDArray : is_data_not_nan = data = = data is_data_not_infinite = data . abs ( ) ! = np . inf return mx . nd . logical_and ( is_data_not_infinite , is_data_not_nan ) ": 5935,
 "def set_range ( self , min_val , max_val ) : if min_val > max_val : max_val , min_val = min_val , max_val self . values = ( ( ( self . values * 1 . 0 - self . values . min ( ) ) / ( self . values . max ( ) - self . values . min ( ) ) ) * ( max_val - min_val ) + min_val ) ": 5936,
 "def execute_sql ( self , query ) : c = self . con . cursor ( ) c . execute ( query ) result = [] if c . rowcount > 0 : try : result = c . fetchall ( ) except psycopg2 . ProgrammingError : pass return result": 5937,
 "def non_increasing ( values ) : return all ( x > = y for x , y in zip ( values , values[1 : ] ) ) ": 5938,
 "async def stdout ( self ) -> AsyncGenerator[str , None] : await self . wait_running ( ) async for line in self . _subprocess . stdout : # type : ignore yield line": 5939,
 "def same_network ( atree , btree ) -> bool : return same_hierarchy ( atree , btree ) and same_topology ( atree , btree ) ": 5940,
 "def is_strict_numeric ( n : Node ) -> bool : return is_typed_literal ( n ) and cast ( Literal , n ) . datatype in [XSD . integer , XSD . decimal , XSD . float , XSD . double]": 5941,
 "def b64_decode ( data : bytes ) -> bytes : missing_padding = len ( data ) % 4 if missing_padding ! = 0 : data + = b ' = ' * ( 4 - missing_padding ) return urlsafe_b64decode ( data ) ": 5942,
 "def block_diag ( *blocks : np . ndarray ) -> np . ndarray : for b in blocks : if b . shape[0] ! = b . shape[1] : raise ValueError ( ' Blocks must be square . ' ) if not blocks : return np . zeros ( ( 0 , 0 ) , dtype = np . complex128 ) n = sum ( b . shape[0] for b in blocks ) dtype = functools . reduce ( _merge_dtypes , ( b . dtype for b in blocks ) ) result = np . zeros ( shape = ( n , n ) , dtype = dtype ) i = 0 for b in blocks : j = i + b . shape[0] result[i : j , i : j] = b i = j return result": 5943,
 "def get_now_sql_datetime ( ) : # # > IMPORTS # # from datetime import datetime , date , time now = datetime . now ( ) now = now . strftime ( \" %Y-%m-%dT%H : %M : %S \" ) return now": 5944,
 "def percentile ( sorted_list , percent , key = lambda x : x ) : if not sorted_list : return None if percent = = 1 : return float ( sorted_list[-1] ) if percent = = 0 : return float ( sorted_list[0] ) n = len ( sorted_list ) i = percent * n if ceil ( i ) = = i : i = int ( i ) return ( sorted_list[i-1] + sorted_list[i] ) / 2 return float ( sorted_list[ceil ( i ) -1] ) ": 5945,
 "def fib ( n ) : assert n > 0 a , b = 1 , 1 for i in range ( n - 1 ) : a , b = b , a + b return a": 5946,
 "def try_instance_init ( self , instance , late_start = False ) : try : instance . init_try + = 1 # Maybe it ' s a retry if not late_start and instance . init_try > 1 : # Do not try until too frequently , or it ' s too loopy if instance . last_init_try > time . time ( ) - MODULE_INIT_PERIOD : logger . info ( \" Too early to retry initialization , retry period is %d seconds \" , MODULE_INIT_PERIOD ) # logger . info ( \" %s / %s \" , instance . last_init_try , time . time ( ) ) return False instance . last_init_try = time . time ( ) logger . info ( \" Trying to initialize module : %s \" , instance . name ) # If it ' s an external module , create/update Queues ( ) if instance . is_external : instance . create_queues ( self . daemon . sync_manager ) # The module instance init function says if initialization is ok if not instance . init ( ) : logger . warning ( \" Module %s initialisation failed . \" , instance . name ) return False logger . info ( \" Module %s is initialized . \" , instance . name ) except Exception as exp : # pylint : disable = broad-except # pragma : no cover , simple protection msg = \" The module instance %s raised an exception \" \\ \" on initialization : %s , I remove it! \" % ( instance . name , str ( exp ) ) self . configuration_errors . append ( msg ) logger . error ( msg ) logger . exception ( exp ) return False return True": 5947,
 "def add_colons ( s ) : return ' : ' . join ( [s[i : i + 2] for i in range ( 0 , len ( s ) , 2 ) ] ) ": 5948,
 "def has_jongsung ( letter ) : if len ( letter ) ! = 1 : raise Exception ( ' The target string must be one letter . ' ) if not is_hangul ( letter ) : raise NotHangulException ( ' The target string must be Hangul ' ) code = lt . hangul_index ( letter ) return code % NUM_JONG > 0": 5949,
 "def iso_string_to_python_datetime ( isostring : str ) -> Optional[datetime . datetime] : if not isostring : return None # if you parse ( ) an empty string , you get today ' s date return dateutil . parser . parse ( isostring ) ": 5950,
 "def get_case_insensitive_dict_key ( d : Dict , k : str ) -> Optional[str] : for key in d . keys ( ) : if k . lower ( ) = = key . lower ( ) : return key return None": 5951,
 "def find_index ( segmentation , stroke_id ) : for i , symbol in enumerate ( segmentation ) : for sid in symbol : if sid = = stroke_id : return i return -1": 5952,
 "def check_oneof ( **kwargs ) : # Sanity check : If no keyword arguments were sent , this is fine . if not kwargs : return None not_nones = [val for val in kwargs . values ( ) if val is not None] if len ( not_nones ) > 1 : raise ValueError ( ' Only one of {fields} should be set . ' . format ( fields = ' , ' . join ( sorted ( kwargs . keys ( ) ) ) , ) ) ": 5953,
 "def execute ( cur , *args ) : stmt = args[0] if len ( args ) > 1 : stmt = stmt . replace ( ' % ' , ' %% ' ) . replace ( ' ? ' , ' %r ' ) print ( stmt % ( args[1] ) ) return cur . execute ( *args ) ": 5954,
 "def camelize ( key ) : return ' ' . join ( x . capitalize ( ) if i > 0 else x for i , x in enumerate ( key . split ( ' _ ' ) ) ) ": 5955,
 "def _groups_of_size ( iterable , n , fillvalue = None ) : # _groups_of_size ( ' ABCDEFG ' , 3 , ' x ' ) --> ABC DEF Gxx args = [iter ( iterable ) ] * n return zip_longest ( fillvalue = fillvalue , *args ) ": 5956,
 "def long_substring ( str_a , str_b ) : data = [str_a , str_b] substr = ' ' if len ( data ) > 1 and len ( data[0] ) > 0 : for i in range ( len ( data[0] ) ) : for j in range ( len ( data[0] ) -i+1 ) : if j > len ( substr ) and all ( data[0][i : i+j] in x for x in data ) : substr = data[0][i : i+j] return substr . strip ( ) ": 5957,
 "def squash ( self , a , b ) : return ( ( ' ' . join ( x ) if isinstance ( x , tuple ) else x ) for x in itertools . product ( a , b ) ) ": 5958,
 "def wipe_table ( self , table : str ) -> int : sql = \" DELETE FROM \" + self . delimit ( table ) return self . db_exec ( sql ) ": 5959,
 "def _interface_exists ( self , interface ) : ios_cfg = self . _get_running_config ( ) parse = HTParser ( ios_cfg ) itfcs_raw = parse . find_lines ( \" ^interface \" + interface ) return len ( itfcs_raw ) > 0": 5960,
 "def GetAllPixelColors ( self ) -> ctypes . Array : return self . GetPixelColorsOfRect ( 0 , 0 , self . Width , self . Height ) ": 5961,
 "def calculate_fft ( data , tbin ) : if len ( np . shape ( data ) ) > 1 : n = len ( data[0] ) return np . fft . fftfreq ( n , tbin * 1e-3 ) , np . fft . fft ( data , axis = 1 ) else : n = len ( data ) return np . fft . fftfreq ( n , tbin * 1e-3 ) , np . fft . fft ( data ) ": 5962,
 "def get_commits_modified_file ( self , filepath : str ) -> List[str] : path = str ( Path ( filepath ) ) commits = [] try : commits = self . git . log ( \" --follow \" , \" --format = %H \" , path ) . split ( ' \\n ' ) except GitCommandError : logger . debug ( \" Could not find information of file %s \" , path ) return commits": 5963,
 "def similarity ( word1 : str , word2 : str ) -> float : return _MODEL . similarity ( word1 , word2 ) ": 5964,
 "def snake_case ( a_string ) : partial = re . sub ( ' ( . ) ( [A-Z][a-z]+ ) ' , r ' \\1_\\2 ' , a_string ) return re . sub ( ' ( [a-z0-9] ) ( [A-Z] ) ' , r ' \\1_\\2 ' , partial ) . lower ( ) ": 5965,
 "def get_default_bucket_key ( buckets : List[Tuple[int , int]] ) -> Tuple[int , int] : return max ( buckets ) ": 5966,
 "def product ( *args , **kwargs ) : p = [[]] for iterable in map ( tuple , args ) * kwargs . get ( \" repeat \" , 1 ) : p = [x + [y] for x in p for y in iterable] for p in p : yield tuple ( p ) ": 5967,
 "def file_or_stdin ( ) -> Callable : def parse ( path ) : if path is None or path = = \" - \" : return sys . stdin else : return data_io . smart_open ( path ) return parse": 5968,
 "def running_containers ( name_filter : str ) -> List[str] : return [container . short_id for container in docker_client . containers . list ( filters = { \" name \" : name_filter} ) ]": 5969,
 "def cookies ( self ) -> Dict[str , str] : cookies = SimpleCookie ( ) cookies . load ( self . headers . get ( ' Cookie ' , ' ' ) ) return {key : cookie . value for key , cookie in cookies . items ( ) }": 5970,
 "def docker_environment ( env ) : return ' ' . join ( [ \" -e \\ \" %s = %s\\ \" \" % ( key , value . replace ( \" $ \" , \" \\\\$ \" ) . replace ( \" \\ \" \" , \" \\\\\\ \" \" ) . replace ( \" ` \" , \" \\\\` \" ) ) for key , value in env . items ( ) ] ) ": 5971,
 "def call_api ( self , resource_path , method , path_params = None , query_params = None , header_params = None , body = None , post_params = None , files = None , response_type = None , auth_settings = None , asynchronous = None , _return_http_data_only = None , collection_formats = None , _preload_content = True , _request_timeout = None ) : if not asynchronous : return self . __call_api ( resource_path , method , path_params , query_params , header_params , body , post_params , files , response_type , auth_settings , _return_http_data_only , collection_formats , _preload_content , _request_timeout ) else : thread = self . pool . apply_async ( self . __call_api , ( resource_path , method , path_params , query_params , header_params , body , post_params , files , response_type , auth_settings , _return_http_data_only , collection_formats , _preload_content , _request_timeout ) ) return thread": 5972,
 "def parsehttpdate ( string_ ) : try : t = time . strptime ( string_ , \" %a , %d %b %Y %H : %M : %S %Z \" ) except ValueError : return None return datetime . datetime ( *t[ : 6] ) ": 5973,
 "def translate_dict ( cls , val ) : escaped = ' , ' . join ( [ \" {} -> {} \" . format ( cls . translate_str ( k ) , cls . translate ( v ) ) for k , v in val . items ( ) ] ) return ' Map ( {} ) ' . format ( escaped ) ": 5974,
 "def get_bin_edges_from_axis ( axis ) -> np . ndarray : # Don ' t include over- or underflow bins bins = range ( 1 , axis . GetNbins ( ) + 1 ) # Bin edges bin_edges = np . empty ( len ( bins ) + 1 ) bin_edges[ : -1] = [axis . GetBinLowEdge ( i ) for i in bins] bin_edges[-1] = axis . GetBinUpEdge ( axis . GetNbins ( ) ) return bin_edges": 5975,
 "def get_language ( query : str ) -> str : query = query . lower ( ) for language in LANGUAGES : if query . endswith ( language ) : return language return ' ' ": 5976,
 "def _strip_top_comments ( lines : Sequence[str] , line_separator : str ) -> str : lines = copy . copy ( lines ) while lines and lines[0] . startswith ( \" # \" ) : lines = lines[1 : ] return line_separator . join ( lines ) ": 5977,
 "def scope_logger ( cls ) : cls . log = logging . getLogger ( ' {0} . {1} ' . format ( cls . __module__ , cls . __name__ ) ) return cls": 5978,
 "def read_flat ( self ) : x , y , pixel , meta = self . read ( ) arraycode = ' BH ' [meta[ ' bitdepth ' ] > 8] pixel = array ( arraycode , itertools . chain ( *pixel ) ) return x , y , pixel , meta": 5979,
 "def hex_color_to_tuple ( hex ) : hex = hex[1 : ] length = len ( hex ) // 2 return tuple ( int ( hex[i*2 : i*2+2] , 16 ) for i in range ( length ) ) ": 5980,
 "def capitalize ( string ) : if not string : return string if len ( string ) = = 1 : return string . upper ( ) return string[0] . upper ( ) + string[1 : ] . lower ( ) ": 5981,
 "def export_to_dot ( self , filename : str = ' output ' ) -> None : with open ( filename + ' . dot ' , ' w ' ) as output : output . write ( self . as_dot ( ) ) ": 5982,
 "def from_iso_time ( timestring , use_dateutil = True ) : if not _iso8601_time_re . match ( timestring ) : raise ValueError ( ' Not a valid ISO8601-formatted time string ' ) if dateutil_available and use_dateutil : return parser . parse ( timestring ) . time ( ) else : if len ( timestring ) > 8 : # has microseconds fmt = ' %H : %M : %S . %f ' else : fmt = ' %H : %M : %S ' return datetime . datetime . strptime ( timestring , fmt ) . time ( ) ": 5983,
 "def fix_title_capitalization ( title ) : if re . search ( \" [A-Z] \" , title ) and re . search ( \" [a-z] \" , title ) : return title word_list = re . split ( ' + ' , title ) final = [word_list[0] . capitalize ( ) ] for word in word_list[1 : ] : if word . upper ( ) in COMMON_ACRONYMS : final . append ( word . upper ( ) ) elif len ( word ) > 3 : final . append ( word . capitalize ( ) ) else : final . append ( word . lower ( ) ) return \" \" . join ( final ) ": 5984,
 "def argsort_k_smallest ( x , k ) : if k = = 0 : return np . array ( [] , dtype = np . intp ) if k is None or k > = len ( x ) : return np . argsort ( x ) indices = np . argpartition ( x , k ) [ : k] values = x[indices] return indices[np . argsort ( values ) ]": 5985,
 "def getElementsBy ( self , cond : Callable[[Element] , bool] ) -> NodeList : return getElementsBy ( self , cond ) ": 5986,
 "def uuid2buid ( value ) : if six . PY3 : # pragma : no cover return urlsafe_b64encode ( value . bytes ) . decode ( ' utf-8 ' ) . rstrip ( ' = ' ) else : return six . text_type ( urlsafe_b64encode ( value . bytes ) . rstrip ( ' = ' ) ) ": 5987,
 "def replace ( s , old , new , maxreplace = -1 ) : return s . replace ( old , new , maxreplace ) ": 5988,
 "def get_longest_line_length ( text ) : lines = text . split ( \" \\n \" ) length = 0 for i in range ( len ( lines ) ) : if len ( lines[i] ) > length : length = len ( lines[i] ) return length": 5989,
 "def constant ( times : np . ndarray , amp : complex ) -> np . ndarray : return np . full ( len ( times ) , amp , dtype = np . complex_ ) ": 5990,
 "def strip_codes ( s : Any ) -> str : return codepat . sub ( ' ' , str ( s ) if ( s or ( s = = 0 ) ) else ' ' ) ": 5991,
 "def to_jupyter ( graph : BELGraph , chart : Optional[str] = None ) -> Javascript : with open ( os . path . join ( HERE , ' render_with_javascript . js ' ) , ' rt ' ) as f : js_template = Template ( f . read ( ) ) return Javascript ( js_template . render ( **_get_context ( graph , chart = chart ) ) ) ": 5992,
 "def negate_mask ( mask ) : res = np . ones ( mask . shape , dtype = np . int8 ) res[mask > 0] = 0 return res": 5993,
 "def local_machine_uuid ( ) : result = subprocess . check_output ( ' hal-get-property --udi ' ' /org/freedesktop/Hal/devices/computer ' ' --key system . hardware . uuid ' . split ( ) ) . strip ( ) return uuid . UUID ( hex = result ) ": 5994,
 "def _hash_the_file ( hasher , filename ) : BUF_SIZE = 65536 with open ( filename , ' rb ' ) as f : buf = f . read ( BUF_SIZE ) while len ( buf ) > 0 : hasher . update ( buf ) buf = f . read ( BUF_SIZE ) return hasher": 5995,
 "def get_value ( self ) -> Decimal : quantity = self . get_quantity ( ) price = self . get_last_available_price ( ) if not price : # raise ValueError ( \" no price found for \" , self . full_symbol ) return Decimal ( 0 ) value = quantity * price . value return value": 5996,
 "def is_inside_lambda ( node : astroid . node_classes . NodeNG ) -> bool : parent = node . parent while parent is not None : if isinstance ( parent , astroid . Lambda ) : return True parent = parent . parent return False": 5997,
 "def stdout_encode ( u , default = ' utf-8 ' ) : # from http : //stackoverflow . com/questions/3627793/best-output-type-and- # encoding-practices-for-repr-functions encoding = sys . stdout . encoding or default return u . encode ( encoding , \" replace \" ) . decode ( encoding , \" replace \" ) ": 5998,
 "def revrank_dict ( dict , key = lambda t : t[1] , as_tuple = False ) : sorted_list = sorted ( dict . items ( ) , key = key , reverse = True ) return OrderedDict ( sorted_list ) if not as_tuple else tuple ( sorted_list ) ": 5999,
 "def remove_parenthesis_around_tz ( cls , timestr ) : parenthesis = cls . TIMEZONE_PARENTHESIS . match ( timestr ) if parenthesis is not None : return parenthesis . group ( 1 ) ": 6000,
 "def __repr__ ( self ) -> str : return ' {0} ( {1} ) ' . format ( type ( self ) . __name__ , repr ( self . string ) ) ": 6001,
 "def load_yaml ( yaml_file : str ) -> Any : with open ( yaml_file , ' r ' ) as file : return ruamel . yaml . load ( file , ruamel . yaml . RoundTripLoader ) ": 6002,
 "def quoted_or_list ( items : List[str] ) -> Optional[str] : return or_list ( [f \" ' {item} ' \" for item in items] ) ": 6003,
 "def first_digits ( s , default = 0 ) : s = re . split ( r ' [^0-9]+ ' , str ( s ) . strip ( ) . lstrip ( ' +- ' + charlist . whitespace ) ) if len ( s ) and len ( s[0] ) : return int ( s[0] ) return default": 6004,
 "def run_time ( ) -> timedelta : delta = start_time if start_time else datetime . utcnow ( ) return datetime . utcnow ( ) - delta": 6005,
 "def to_np ( *args ) : if len ( args ) > 1 : return ( cp . asnumpy ( x ) for x in args ) else : return cp . asnumpy ( args[0] ) ": 6006,
 "def _RetryRequest ( self , timeout = None , **request_args ) : while True : try : now = time . time ( ) if not timeout : timeout = config . CONFIG[ \" Client . http_timeout \" ] result = requests . request ( **request_args ) # By default requests doesn ' t raise on HTTP error codes . result . raise_for_status ( ) # Requests does not always raise an exception when an incorrect response # is received . This fixes that behaviour . if not result . ok : raise requests . RequestException ( response = result ) return time . time ( ) - now , result # Catch any exceptions that dont have a code ( e . g . socket . error ) . except IOError as e : self . consecutive_connection_errors + = 1 # Request failed . If we connected successfully before we attempt a few # connections before we determine that it really failed . This might # happen if the front end is loaded and returns a few throttling 500 # messages . if self . active_base_url is not None : # Propagate 406 immediately without retrying , as 406 is a valid # response that indicates a need for enrollment . response = getattr ( e , \" response \" , None ) if getattr ( response , \" status_code \" , None ) = = 406 : raise if self . consecutive_connection_errors > = self . retry_error_limit : # We tried several times but this really did not work , just fail it . logging . info ( \" Too many connection errors to %s , retrying another URL \" , self . active_base_url ) self . active_base_url = None raise e # Back off hard to allow the front end to recover . logging . debug ( \" Unable to connect to frontend . Backing off %s seconds . \" , self . error_poll_min ) self . Wait ( self . error_poll_min ) # We never previously connected , maybe the URL/proxy is wrong? Just fail # right away to allow callers to try a different URL . else : raise e": 6007,
 "def duration_expired ( start_time , duration_seconds ) : if duration_seconds is not None : delta_seconds = datetime_delta_to_seconds ( dt . datetime . now ( ) - start_time ) if delta_seconds > = duration_seconds : return True return False": 6008,
 "def get_valid_filename ( s ) : s = str ( s ) . strip ( ) . replace ( ' ' , ' _ ' ) return re . sub ( r ' ( ?u ) [^-\\w . ] ' , ' ' , s ) ": 6009,
 "async def enter_captcha ( self , url : str , sid : str ) -> str : raise VkCaptchaNeeded ( url , sid ) ": 6010,
 "def wait_for_shutdown_signal ( self , please_stop = False , # ASSIGN SIGNAL TO STOP EARLY allow_exit = False , # ALLOW \" exit \" COMMAND ON CONSOLE TO ALSO STOP THE APP wait_forever = True # IGNORE CHILD THREADS , NEVER EXIT . False = > IF NO CHILD THREADS LEFT , THEN EXIT ) : self_thread = Thread . current ( ) if self_thread ! = MAIN_THREAD or self_thread ! = self : Log . error ( \" Only the main thread can sleep forever ( waiting for KeyboardInterrupt ) \" ) if isinstance ( please_stop , Signal ) : # MUTUAL SIGNALING MAKES THESE TWO EFFECTIVELY THE SAME SIGNAL self . please_stop . on_go ( please_stop . go ) please_stop . on_go ( self . please_stop . go ) else : please_stop = self . please_stop if not wait_forever : # TRIGGER SIGNAL WHEN ALL CHILDREN THEADS ARE DONE with self_thread . child_lock : pending = copy ( self_thread . children ) children_done = AndSignals ( please_stop , len ( pending ) ) children_done . signal . on_go ( self . please_stop . go ) for p in pending : p . stopped . on_go ( children_done . done ) try : if allow_exit : _wait_for_exit ( please_stop ) else : _wait_for_interrupt ( please_stop ) except KeyboardInterrupt as _ : Log . alert ( \" SIGINT Detected! Stopping . . . \" ) except SystemExit as _ : Log . alert ( \" SIGTERM Detected! Stopping . . . \" ) finally : self . stop ( ) ": 6011,
 "def strids2ids ( tokens : Iterable[str] ) -> List[int] : return list ( map ( int , tokens ) ) ": 6012,
 "def to_dict ( self ) : if self . childCount ( ) > 0 : value = {} for index in range ( self . childCount ( ) ) : value . update ( self . child ( index ) . to_dict ( ) ) else : value = self . value return {self . name : value}": 6013,
 "def python_utc_datetime_to_sqlite_strftime_string ( value : datetime . datetime ) -> str : millisec_str = str ( round ( value . microsecond / 1000 ) ) . zfill ( 3 ) return value . strftime ( \" %Y-%m-%d %H : %M : %S \" ) + \" . \" + millisec_str": 6014,
 "def drop_post ( self ) : post_index = self . version . find ( ' . post ' ) if post_index > = 0 : self . version = self . version[ : post_index]": 6015,
 "def safe_pow ( base , exp ) : if exp > MAX_EXPONENT : raise RuntimeError ( \" Invalid exponent , max exponent is {} \" . format ( MAX_EXPONENT ) ) return base ** exp": 6016,
 "def mkdir ( self , target_folder ) : self . printv ( \" Making directory : %s \" % target_folder ) self . k . key = re . sub ( r \" ^/|/$ \" , \" \" , target_folder ) + \" / \" self . k . set_contents_from_string ( ' ' ) self . k . close ( ) ": 6017,
 "def find_first ( pattern : str , path : str ) -> str : try : return find ( pattern , path ) [0] except IndexError : log . critical ( ' ' ' Couldn ' t find \" {} \" in \" {} \" ' ' ' , pattern , path ) raise": 6018,
 "def issuperset ( self , items ) : return all ( _compat . map ( self . _seen . __contains__ , items ) ) ": 6019,
 "def union ( cls , *sets ) : import utool as ut lists_ = ut . flatten ( [list ( s ) for s in sets] ) return cls ( lists_ ) ": 6020,
 "def _cleanup ( path : str ) -> None : if os . path . isdir ( path ) : shutil . rmtree ( path ) ": 6021,
 "def default_parser ( ) -> argparse . ArgumentParser : parser = argparse . ArgumentParser ( prog = CONSOLE_SCRIPT , formatter_class = argparse . ArgumentDefaultsHelpFormatter , ) build_parser ( parser ) return parser": 6022,
 "def add_mark_at ( string , index , mark ) : if index = = -1 : return string # Python can handle the case which index is out of range of given string return string[ : index] + add_mark_char ( string[index] , mark ) + string[index+1 : ]": 6023,
 "def is_up_to_date ( outfile , basedatetime ) : # type : ( AnyStr , datetime ) -> bool if os . path . exists ( outfile ) : if os . path . getmtime ( outfile ) > = basedatetime : return True return False": 6024,
 "def bulk_load_docs ( es , docs ) : chunk_size = 200 try : results = elasticsearch . helpers . bulk ( es , docs , chunk_size = chunk_size ) log . debug ( f \" Elasticsearch documents loaded : {results[0]} \" ) # elasticsearch . helpers . parallel_bulk ( es , terms , chunk_size = chunk_size , thread_count = 4 ) if len ( results[1] ) > 0 : log . error ( \" Bulk load errors {} \" . format ( results ) ) except elasticsearch . ElasticsearchException as e : log . error ( \" Indexing error : {}\\n \" . format ( e ) ) ": 6025,
 "def after_third_friday ( day = None ) : day = day if day is not None else datetime . datetime . now ( ) now = day . replace ( day = 1 , hour = 16 , minute = 0 , second = 0 , microsecond = 0 ) now + = relativedelta . relativedelta ( weeks = 2 , weekday = relativedelta . FR ) return day > now": 6026,
 "def _write_json ( obj , path ) : # type : ( object , str ) -> None with open ( path , ' w ' ) as f : json . dump ( obj , f ) ": 6027,
 "def argmax ( iterable , key = None , both = False ) : if key is not None : it = imap ( key , iterable ) else : it = iter ( iterable ) score , argmax = reduce ( max , izip ( it , count ( ) ) ) if both : return argmax , score return argmax": 6028,
 "def get_system_flags ( ) -> FrozenSet[Flag] : return frozenset ( {Seen , Recent , Deleted , Flagged , Answered , Draft} ) ": 6029,
 "def timestamp_with_tzinfo ( dt ) : utc = tzutc ( ) if dt . tzinfo : dt = dt . astimezone ( utc ) . replace ( tzinfo = None ) return dt . isoformat ( ) + ' Z ' ": 6030,
 "def replace_variables ( self , source : str , variables : dict ) -> str : try : replaced = re . sub ( \" {{ ( . *? ) }} \" , lambda m : variables . get ( m . group ( 1 ) , \" \" ) , source ) except TypeError : replaced = source return replaced": 6031,
 "def duplicates ( coll ) : return list ( set ( x for x in coll if coll . count ( x ) > 1 ) ) ": 6032,
 "def _dfs_cycle_detect ( graph , node , path , visited_nodes ) : visited_nodes . add ( node ) for target in graph[node] : if target in path : # cycle found = > return current path return path + [target] else : return _dfs_cycle_detect ( graph , target , path + [target] , visited_nodes ) return None": 6033,
 "def collect_static ( ) -> bool : from django . core . management import execute_from_command_line # from django . conf import settings # if not os . listdir ( settings . STATIC_ROOT ) : wf ( ' Collecting static files . . . ' , False ) execute_from_command_line ( [ ' . /manage . py ' , ' collectstatic ' , ' -c ' , ' --noinput ' , ' -v0 ' ] ) wf ( ' [+]\\n ' ) return True": 6034,
 "def lsr_pairwise_dense ( comp_mat , alpha = 0 . 0 , initial_params = None ) : n_items = comp_mat . shape[0] ws , chain = _init_lsr ( n_items , alpha , initial_params ) denom = np . tile ( ws , ( n_items , 1 ) ) chain + = comp_mat . T / ( denom + denom . T ) chain - = np . diag ( chain . sum ( axis = 1 ) ) return log_transform ( statdist ( chain ) ) ": 6035,
 "def import_by_path ( path : str ) -> Callable : module_path , _ , class_name = path . rpartition ( ' . ' ) return getattr ( import_module ( module_path ) , class_name ) ": 6036,
 "def ensure_list ( iterable : Iterable[A] ) -> List[A] : if isinstance ( iterable , list ) : return iterable else : return list ( iterable ) ": 6037,
 "def _protected_log ( x1 ) : with np . errstate ( divide = ' ignore ' , invalid = ' ignore ' ) : return np . where ( np . abs ( x1 ) > 0 . 001 , np . log ( np . abs ( x1 ) ) , 0 . ) ": 6038,
 "def load_preprocess_images ( image_paths : List[str] , image_size : tuple ) -> List[np . ndarray] : image_size = image_size[1 : ] # we do not need the number of channels images = [] for image_path in image_paths : images . append ( load_preprocess_image ( image_path , image_size ) ) return images": 6039,
 "def _check_update_ ( self ) : try : data = requests . get ( \" https : //pypi . python . org/pypi/jira/json \" , timeout = 2 . 001 ) . json ( ) released_version = data[ ' info ' ][ ' version ' ] if parse_version ( released_version ) > parse_version ( __version__ ) : warnings . warn ( \" You are running an outdated version of JIRA Python %s . Current version is %s . Do not file any bugs against older versions . \" % ( __version__ , released_version ) ) except requests . RequestException : pass except Exception as e : logging . warning ( e ) ": 6040,
 "def _get_or_default ( mylist , i , default = None ) : if i > = len ( mylist ) : return default else : return mylist[i]": 6041,
 "def version ( ) : OPENJPEG . opj_version . restype = ctypes . c_char_p library_version = OPENJPEG . opj_version ( ) if sys . hexversion > = 0x03000000 : return library_version . decode ( ' utf-8 ' ) else : return library_version": 6042,
 "def is_builtin_object ( node : astroid . node_classes . NodeNG ) -> bool : return node and node . root ( ) . name = = BUILTINS_NAME": 6043,
 "def checksum ( path ) : hasher = hashlib . sha1 ( ) with open ( path , ' rb ' ) as stream : buf = stream . read ( BLOCKSIZE ) while len ( buf ) > 0 : hasher . update ( buf ) buf = stream . read ( BLOCKSIZE ) return hasher . hexdigest ( ) ": 6044,
 "def get_days_in_month ( year : int , month : int ) -> int : month_range = calendar . monthrange ( year , month ) return month_range[1]": 6045,
 "def pairwise ( iterable ) : first , second = tee ( iterable ) next ( second , None ) return zip ( first , second ) ": 6046,
 "def to_graphviz ( graph ) : ret = [ ' digraph g { ' ] vertices = [] node_ids = dict ( [ ( name , ' node ' + idx ) for ( idx , name ) in enumerate ( list ( graph ) ) ] ) for node in list ( graph ) : ret . append ( ' \" %s \" [label = \" %s \" ]; ' % ( node_ids[node] , node ) ) for target in graph[node] : vertices . append ( ' \" %s \" -> \" %s \" ; ' % ( node_ids[node] , node_ids[target] ) ) ret + = vertices ret . append ( ' } ' ) return ' \\n ' . join ( ret ) ": 6047,
 "def get_file_extension ( filename ) : filename_x = filename . split ( ' . ' ) if len ( filename_x ) > 1 : if filename_x[-1] . strip ( ) is not ' ' : return filename_x[-1] return None": 6048,
 "def normalize_column_names ( df ) : r columns = df . columns if hasattr ( df , ' columns ' ) else df columns = [c . lower ( ) . replace ( ' ' , ' _ ' ) for c in columns] return columns": 6049,
 "def _width_is_big_enough ( image , width ) : if width > image . size[0] : raise ImageSizeError ( image . size[0] , width ) ": 6050,
 "def branches ( ) : # type : ( ) -> List[str] out = shell . run ( ' git branch ' , capture = True , never_pretend = True ) . stdout . strip ( ) return [x . strip ( ' * \\t\\n ' ) for x in out . splitlines ( ) ]": 6051,
 "def cache_page ( page_cache , page_hash , cache_size ) : page_cache . append ( page_hash ) if len ( page_cache ) > cache_size : page_cache . pop ( 0 ) ": 6052,
 "def _log_response ( response ) : message = u ' Received HTTP {0} response : {1} ' . format ( response . status_code , response . text ) if response . status_code > = 400 : # pragma : no cover logger . warning ( message ) else : logger . debug ( message ) ": 6053,
 "def empty_wav ( wav_path : Union[Path , str] ) -> bool : with wave . open ( str ( wav_path ) , ' rb ' ) as wav_f : return wav_f . getnframes ( ) = = 0": 6054,
 "def _in_qtconsole ( ) -> bool : try : from IPython import get_ipython try : from ipykernel . zmqshell import ZMQInteractiveShell shell_object = ZMQInteractiveShell except ImportError : from IPython . kernel . zmq import zmqshell shell_object = zmqshell . ZMQInteractiveShell return isinstance ( get_ipython ( ) , shell_object ) except Exception : return False": 6055,
 "def sorted ( self ) : for i in range ( 0 , self . tabs . tabBar ( ) . count ( ) - 1 ) : if ( self . tabs . tabBar ( ) . tabText ( i ) > self . tabs . tabBar ( ) . tabText ( i + 1 ) ) : return False return True": 6056,
 "def ask_bool ( question : str , default : bool = True ) -> bool : default_q = \" Y/n \" if default else \" y/N \" answer = input ( \" {0} [{1}] : \" . format ( question , default_q ) ) lower = answer . lower ( ) if not lower : return default return lower = = \" y \" ": 6057,
 "def parse_dim ( features , check = True ) : # try : dim = features[0] . shape[1] # except IndexError : # dim = 1 if check and not dim > 0 : raise IOError ( ' features dimension must be strictly positive ' ) if check and not all ( [d = = dim for d in [x . shape[1] for x in features]] ) : raise IOError ( ' all files must have the same feature dimension ' ) return dim": 6058,
 "def get_edge_relations ( graph : BELGraph ) -> Mapping[Tuple[BaseEntity , BaseEntity] , Set[str]] : return group_dict_set ( ( ( u , v ) , d[RELATION] ) for u , v , d in graph . edges ( data = True ) ) ": 6059,
 "def __setitem__ ( self , *args , **kwargs ) : super ( History , self ) . __setitem__ ( *args , **kwargs ) if len ( self ) > self . size : self . popitem ( False ) ": 6060,
 "def list_adb_devices_by_usb_id ( ) : out = adb . AdbProxy ( ) . devices ( [ ' -l ' ] ) clean_lines = new_str ( out , ' utf-8 ' ) . strip ( ) . split ( ' \\n ' ) results = [] for line in clean_lines : tokens = line . strip ( ) . split ( ) if len ( tokens ) > 2 and tokens[1] = = ' device ' : results . append ( tokens[2] ) return results": 6061,
 "def returns ( self ) -> T . Optional[DocstringReturns] : try : return next ( DocstringReturns . from_meta ( meta ) for meta in self . meta if meta . args[0] in { \" return \" , \" returns \" , \" yield \" , \" yields \" } ) except StopIteration : return None": 6062,
 "def _infer_interval_breaks ( coord ) : coord = np . asarray ( coord ) deltas = 0 . 5 * ( coord[1 : ] - coord[ : -1] ) first = coord[0] - deltas[0] last = coord[-1] + deltas[-1] return np . r_[[first] , coord[ : -1] + deltas , [last]]": 6063,
 "def check_max_filesize ( chosen_file , max_size ) : if os . path . getsize ( chosen_file ) > max_size : return False else : return True": 6064,
 "def pretty_describe ( object , nestedness = 0 , indent = 2 ) : if not isinstance ( object , dict ) : return str ( object ) sep = f ' \\n{ \" \" * nestedness * indent} ' out = sep . join ( ( f ' {k} : {pretty_describe ( v , nestedness + 1 ) } ' for k , v in object . items ( ) ) ) if nestedness > 0 and out : return f ' {sep}{out} ' return out": 6065,
 "def indent ( text : str , num : int = 2 ) -> str : lines = text . splitlines ( ) return \" \\n \" . join ( indent_iterable ( lines , num = num ) ) ": 6066,
 "def get_view_selection ( self ) : if not self . MODEL_STORAGE_ID : return None , None # avoid selection requests on empty tree views -> case warnings in gtk3 if len ( self . store ) = = 0 : paths = [] else : model , paths = self . _tree_selection . get_selected_rows ( ) # get all related models for selection from respective tree store field selected_model_list = [] for path in paths : model = self . store[path][self . MODEL_STORAGE_ID] selected_model_list . append ( model ) return self . _tree_selection , selected_model_list": 6067,
 "def public ( self ) -> ' PrettyDir ' : return PrettyDir ( self . obj , [pattr for pattr in self . pattrs if not pattr . name . startswith ( ' _ ' ) ] ) ": 6068,
 "def drop_column ( self , tablename : str , fieldname : str ) -> int : sql = \" ALTER TABLE {} DROP COLUMN {} \" . format ( tablename , fieldname ) log . info ( sql ) return self . db_exec_literal ( sql ) ": 6069,
 "def _check_limit ( self ) : # First compress self . _compress ( ) # Then check the max size if len ( self . _store ) > = self . _max_size : self . _store . popitem ( last = False ) ": 6070,
 "def codes_get_size ( handle , key ) : # type : ( cffi . FFI . CData , str ) -> int size = ffi . new ( ' size_t * ' ) _codes_get_size ( handle , key . encode ( ENC ) , size ) return size[0]": 6071,
 "def remove_namespaces ( root ) : for elem in root . getiterator ( ) : if not hasattr ( elem . tag , ' find ' ) : continue i = elem . tag . find ( ' } ' ) if i > = 0 : elem . tag = elem . tag[i + 1 : ] objectify . deannotate ( root , cleanup_namespaces = True ) ": 6072,
 "def update ( self , iterable ) : e = self . evolver ( ) for element in iterable : e . add ( element ) return e . persistent ( ) ": 6073,
 "def _exit ( self , status_code ) : # If there are active threads still running infinite loops , sys . exit # won ' t kill them but os . _exit will . os . _exit skips calling cleanup # handlers , flushing stdio buffers , etc . exit_func = os . _exit if threading . active_count ( ) > 1 else sys . exit exit_func ( status_code ) ": 6074,
 "def update_kwargs ( kwargs , **keyvalues ) : for key , value in keyvalues . items ( ) : if key not in kwargs : kwargs[key] = value": 6075,
 "def head ( self ) -> Any : lambda_list = self . _get_value ( ) return lambda_list ( lambda head , _ : head ) ": 6076,
 "def integer_partition ( size : int , nparts : int ) -> Iterator[List[List[int]]] : for part in algorithm_u ( range ( size ) , nparts ) : yield part": 6077,
 "def filter_float ( n : Node , query : str ) -> float : return _scalariter2item ( n , query , float ) ": 6078,
 "def lcm ( num1 , num2 ) : if num1 > num2 : bigger = num1 else : bigger = num2 while True : if bigger % num1 = = 0 and bigger % num2 = = 0 : return bigger bigger + = 1": 6079,
 "def was_into_check ( self ) -> bool : king = self . king ( not self . turn ) return king is not None and self . is_attacked_by ( self . turn , king ) ": 6080,
 "def find_unit_clause ( clauses , model ) : for clause in clauses : P , value = unit_clause_assign ( clause , model ) if P : return P , value return None , None": 6081,
 "def get_now_utc_notz_datetime ( ) -> datetime . datetime : now = datetime . datetime . utcnow ( ) return now . replace ( tzinfo = None ) ": 6082,
 "def make_dep_graph ( depender ) : \t\tshutit_global . shutit_global_object . yield_to_draw ( ) \tdigraph = ' ' \tfor dependee_id in depender . depends_on : \t\tdigraph = ( digraph + ' \" ' + depender . module_id + ' \" -> \" ' + dependee_id + ' \" ;\\n ' ) \treturn digraph": 6083,
 "def from_uuid ( value : uuid . UUID ) -> ulid . ULID : return ulid . ULID ( value . bytes ) ": 6084,
 "def make_indices_to_labels ( labels : Set[str] ) -> Dict[int , str] : return {index : label for index , label in enumerate ( [ \" pad \" ] + sorted ( list ( labels ) ) ) }": 6085,
 "def get_terminal_width ( ) : # http : //www . brandonrubin . me/2014/03/18/python-snippet-get-terminal-width/ command = [ ' tput ' , ' cols ' ] try : width = int ( subprocess . check_output ( command ) ) except OSError as e : print ( \" Invalid Command ' {0} ' : exit status ( {1} ) \" . format ( command[0] , e . errno ) ) except subprocess . CalledProcessError as e : print ( \" ' {0} ' returned non-zero exit status : ( {1} ) \" . format ( command , e . returncode ) ) else : return width": 6086,
 "def flush ( self ) : if len ( self . _buffer ) > 0 : self . logger . log ( self . level , self . _buffer ) self . _buffer = str ( ) ": 6087,
 "def assert_or_raise ( stmt : bool , exception : Exception , *exception_args , **exception_kwargs ) -> None : if not stmt : raise exception ( *exception_args , **exception_kwargs ) ": 6088,
 "def columns_equal ( a : Column , b : Column ) -> bool : return ( a . name = = b . name and column_types_equal ( a . type , b . type ) and a . nullable = = b . nullable ) ": 6089,
 "def factors ( n ) : return set ( reduce ( list . __add__ , ( [i , n // i] for i in range ( 1 , int ( n ** 0 . 5 ) + 1 ) if n % i = = 0 ) ) ) ": 6090,
 "def get_property_as_float ( self , name : str ) -> float : return float ( self . __instrument . get_property ( name ) ) ": 6091,
 "def rollapply ( data , window , fn ) : res = data . copy ( ) res[ : ] = np . nan n = len ( data ) if window > n : return res for i in range ( window - 1 , n ) : res . iloc[i] = fn ( data . iloc[i - window + 1 : i + 1] ) return res": 6092,
 "def clear ( self ) -> None : self . _headers = httputil . HTTPHeaders ( { \" Server \" : \" TornadoServer/%s \" % tornado . version , \" Content-Type \" : \" text/html; charset = UTF-8 \" , \" Date \" : httputil . format_timestamp ( time . time ( ) ) , } ) self . set_default_headers ( ) self . _write_buffer = [] # type : List[bytes] self . _status_code = 200 self . _reason = httputil . responses[200]": 6093,
 "def is_closing ( self ) -> bool : return self . stream . closed ( ) or self . client_terminated or self . server_terminated": 6094,
 "def DeleteLog ( ) -> None : if os . path . exists ( Logger . FileName ) : os . remove ( Logger . FileName ) ": 6095,
 "def copy_session ( session : requests . Session ) -> requests . Session : new = requests . Session ( ) new . cookies = requests . utils . cookiejar_from_dict ( requests . utils . dict_from_cookiejar ( session . cookies ) ) new . headers = session . headers . copy ( ) return new": 6096,
 "def __getattr__ ( self , item : str ) -> Callable : return functools . partial ( self . call_action , item ) ": 6097,
 "def calculate_single_tanimoto_set_distances ( target : Iterable[X] , dict_of_sets : Mapping[Y , Set[X]] ) -> Mapping[Y , float] : target_set = set ( target ) return { k : tanimoto_set_similarity ( target_set , s ) for k , s in dict_of_sets . items ( ) }": 6098,
 "def quaternion_imag ( quaternion ) : return numpy . array ( quaternion[1 : 4] , dtype = numpy . float64 , copy = True ) ": 6099,
 "def access_token ( self ) : access_token = self . session . get ( self . access_token_key ) if access_token : if not self . expires_at : # user provided access_token , just return it return access_token timestamp = time . time ( ) if self . expires_at - timestamp > 60 : return access_token self . fetch_access_token ( ) return self . session . get ( self . access_token_key ) ": 6100,
 "def join_states ( *states : State ) -> State : vectors = [ket . vec for ket in states] vec = reduce ( outer_product , vectors ) return State ( vec . tensor , vec . qubits ) ": 6101,
 "def blk_coverage_1d ( blk , size ) : rem = size % blk maxpix = size - rem return maxpix , rem": 6102,
 "def header_status ( header ) : status_line = header[ : header . find ( ' \\r ' ) ] # ' HTTP/1 . 1 200 OK ' -> ( 200 , ' OK ' ) fields = status_line . split ( None , 2 ) return int ( fields[1] ) , fields[2]": 6103,
 "def percent_of ( percent , whole ) : percent = float ( percent ) whole = float ( whole ) return ( percent * whole ) / 100": 6104,
 "def guess_mimetype ( filename ) : fn = os . path . basename ( filename ) return mimetypes . guess_type ( fn ) [0] or ' application/octet-stream ' ": 6105,
 "def get_tokens ( line : str ) -> Iterator[str] : for token in line . rstrip ( ) . split ( ) : if len ( token ) > 0 : yield token": 6106,
 "def getElementByWdomId ( id : str ) -> Optional[WebEventTarget] : if not id : return None elif id = = ' document ' : return get_document ( ) elif id = = ' window ' : return get_document ( ) . defaultView elm = WdomElement . _elements_with_wdom_id . get ( id ) return elm": 6107,
 "def viewport_to_screen_space ( framebuffer_size : vec2 , point : vec4 ) -> vec2 : return ( framebuffer_size * point . xy ) / point . w": 6108,
 "def datetime_is_iso ( date_str ) : try : if len ( date_str ) > 10 : dt = isodate . parse_datetime ( date_str ) else : dt = isodate . parse_date ( date_str ) return True , [] except : # Any error qualifies as not ISO format return False , [ ' Datetime provided is not in a valid ISO 8601 format ' ]": 6109,
 "def index_exists ( self , table : str , indexname : str ) -> bool : # MySQL : sql = ( \" SELECT COUNT ( * ) FROM information_schema . statistics \" \" WHERE table_name = ? AND index_name = ? \" ) row = self . fetchone ( sql , table , indexname ) return True if row[0] > = 1 else False": 6110,
 "def moving_average ( arr : np . ndarray , n : int = 3 ) -> np . ndarray : ret = np . cumsum ( arr , dtype = float ) ret[n : ] = ret[n : ] - ret[ : -n] return ret[n - 1 : ] / n": 6111,
 "def exclude_from ( l , containing = [] , equal_to = [] ) : cont = lambda li : any ( c in li for c in containing ) eq = lambda li : any ( e = = li for e in equal_to ) return [li for li in l if not ( cont ( li ) or eq ( li ) ) ]": 6112,
 "def to_dict ( cls ) : return dict ( ( item . name , item . number ) for item in iter ( cls ) ) ": 6113,
 "def is_valid ( cls , arg ) : return ( isinstance ( arg , ( int , long ) ) and ( arg > = 0 ) ) or \\ isinstance ( arg , basestring ) ": 6114,
 "def remove_links ( text ) : tco_link_regex = re . compile ( \" https? : //t . co/[A-z0-9] . * \" ) generic_link_regex = re . compile ( \" ( https? : // ) ? ( \\w*[ . ]\\w+ ) + ( [/? = &]+\\w+ ) * \" ) remove_tco = re . sub ( tco_link_regex , \" \" , text ) remove_generic = re . sub ( generic_link_regex , \" \" , remove_tco ) return remove_generic": 6115,
 "def trade_day ( dt , cal = ' US ' ) : from xone import calendar dt = pd . Timestamp ( dt ) . date ( ) return calendar . trading_dates ( start = dt - pd . Timedelta ( ' 10D ' ) , end = dt , calendar = cal ) [-1]": 6116,
 "def numpy_to_yaml ( representer : Representer , data : np . ndarray ) -> Sequence[Any] : return representer . represent_sequence ( \" !numpy_array \" , data . tolist ( ) ) ": 6117,
 "def is_end_of_month ( self ) -> bool : end_of_month = Datum ( ) # get_end_of_month ( value ) end_of_month . end_of_month ( ) return self . value = = end_of_month . value": 6118,
 "def check_valid ( number , input_base = 10 ) : for n in number : if n in ( \" . \" , \" [ \" , \" ] \" ) : continue elif n > = input_base : if n = = 1 and input_base = = 1 : continue else : return False return True": 6119,
 "def upsert_multi ( db , collection , object , match_params = None ) : if isinstance ( object , list ) and len ( object ) > 0 : return str ( db[collection] . insert_many ( object ) . inserted_ids ) elif isinstance ( object , dict ) : return str ( db[collection] . update_many ( match_params , { \" $set \" : object} , upsert = False ) . upserted_id ) ": 6120,
 "def call_fset ( self , obj , value ) -> None : vars ( obj ) [self . name] = self . fset ( obj , value ) ": 6121,
 "def src2ast ( src : str ) -> Expression : try : return ast . parse ( src , mode = ' eval ' ) except SyntaxError : raise ValueError ( \" Not a valid expression . \" ) from None": 6122,
 "def put ( self , endpoint : str , **kwargs ) -> dict : return self . _request ( ' PUT ' , endpoint , **kwargs ) ": 6123,
 "def signed_distance ( mesh , points ) : # make sure we have a numpy array points = np . asanyarray ( points , dtype = np . float64 ) # find the closest point on the mesh to the queried points closest , distance , triangle_id = closest_point ( mesh , points ) # we only care about nonzero distances nonzero = distance > tol . merge if not nonzero . any ( ) : return distance inside = mesh . ray . contains_points ( points[nonzero] ) sign = ( inside . astype ( int ) * 2 ) - 1 # apply sign to previously computed distance distance[nonzero] * = sign return distance": 6124,
 "def needs_check ( self ) : if self . lastcheck is None : return True return time . time ( ) - self . lastcheck > = self . ipchangedetection_sleep": 6125,
 "def get_creation_date ( self , bucket : str , key : str , ) -> datetime . datetime : blob_obj = self . _get_blob_obj ( bucket , key ) return blob_obj . time_created": 6126,
 "def clip_to_seconds ( m : Union[int , pd . Series] ) -> Union[int , pd . Series] : return m // pd . Timedelta ( 1 , unit = ' s ' ) . value": 6127,
 "def setlocale ( name ) : with LOCALE_LOCK : old_locale = locale . setlocale ( locale . LC_ALL ) try : yield locale . setlocale ( locale . LC_ALL , name ) finally : locale . setlocale ( locale . LC_ALL , old_locale ) ": 6128,
 "def to_javascript_ ( self , table_name : str = \" data \" ) -> str : try : renderer = pytablewriter . JavaScriptTableWriter data = self . _build_export ( renderer , table_name ) return data except Exception as e : self . err ( e , \" Can not convert data to javascript code \" ) ": 6129,
 "def availability_pdf ( ) -> bool : pdftotext = tools[ ' pdftotext ' ] if pdftotext : return True elif pdfminer : log . warning ( \" PDF conversion : pdftotext missing; \" \" using pdfminer ( less efficient ) \" ) return True else : return False": 6130,
 "def build ( ctx ) : return_code = run_sphinx ( ctx . obj[ ' root_dir ' ] ) if return_code > 0 : sys . exit ( return_code ) ": 6131,
 "def dictlist_replace ( dict_list : Iterable[Dict] , key : str , value : Any ) -> None : for d in dict_list : d[key] = value": 6132,
 "def get_account_id_by_fullname ( self , fullname : str ) -> str : account = self . get_by_fullname ( fullname ) return account . guid": 6133,
 "def isFull ( self ) : return ( ( self . _pageSize > 0 and self . _numElements > = self . _pageSize ) or ( self . _bufferSize > = self . _maxBufferSize ) ) ": 6134,
 "def command ( self , cmd , *args ) : self . _serial_interface . command ( cmd ) if len ( args ) > 0 : self . _serial_interface . data ( list ( args ) ) ": 6135,
 "def timeit ( func , log , limit ) : def newfunc ( *args , **kwargs ) : \" \" \" Execute function and print execution time . \" \" \" t = time . time ( ) res = func ( *args , **kwargs ) duration = time . time ( ) - t if duration > limit : print ( func . __name__ , \" took %0 . 2f seconds \" % duration , file = log ) print ( args , file = log ) print ( kwargs , file = log ) return res return update_func_meta ( newfunc , func ) ": 6136,
 "def date_to_datetime ( d ) : if not isinstance ( d , datetime ) : d = datetime . combine ( d , datetime . min . time ( ) ) return d": 6137,
 "def quaternion_imag ( quaternion ) : return np . array ( quaternion[1 : 4] , dtype = np . float64 , copy = True ) ": 6138,
 "def zip_with_index ( rdd ) : starts = [0] if rdd . getNumPartitions ( ) > 1 : nums = rdd . mapPartitions ( lambda it : [sum ( 1 for _ in it ) ] ) . collect ( ) count = sum ( nums ) for i in range ( len ( nums ) - 1 ) : starts . append ( starts[-1] + nums[i] ) else : count = rdd . count ( ) def func ( k , it ) : for i , v in enumerate ( it , starts[k] ) : yield v , i return count , rdd . mapPartitionsWithIndex ( func ) ": 6139,
 "def console_get_background_flag ( con : tcod . console . Console ) -> int : return int ( lib . TCOD_console_get_background_flag ( _console ( con ) ) ) ": 6140,
 "def load_yaml ( file ) : if hasattr ( yaml , \" full_load \" ) : return yaml . full_load ( file ) else : return yaml . load ( file ) ": 6141,
 "def iter_fields ( self , schema : Schema ) -> Iterable[Tuple[str , Field]] : for name in sorted ( schema . fields . keys ( ) ) : field = schema . fields[name] yield field . dump_to or name , field": 6142,
 "def random_name_gen ( size = 6 ) : return ' ' . join ( [random . choice ( string . ascii_uppercase ) ] + [random . choice ( string . ascii_uppercase + string . digits ) for i in range ( size - 1 ) ] ) if size > 0 else ' ' ": 6143,
 "def urljoin ( *args ) : value = \" / \" . join ( map ( lambda x : str ( x ) . strip ( ' / ' ) , args ) ) return \" /{} \" . format ( value ) ": 6144,
 "def stdev ( self ) : return round ( np . std ( self . array ) , self . precision ) \\ if len ( self . array ) else None": 6145,
 "def space_list ( line : str ) -> List[int] : spaces = [] for idx , car in enumerate ( list ( line ) ) : if car = = \" \" : spaces . append ( idx ) return spaces": 6146,
 "def get_property ( self , name ) : # type : ( str ) -> object with self . __properties_lock : return self . __properties . get ( name , os . getenv ( name ) ) ": 6147,
 "def to_bool ( value ) : # type : ( Any ) -> bool if isinstance ( value , _compat . string_types ) : return value . upper ( ) in ( ' Y ' , ' YES ' , ' T ' , ' TRUE ' , ' 1 ' , ' OK ' ) return bool ( value ) ": 6148,
 "def find_editor ( ) -> str : editor = os . environ . get ( ' EDITOR ' ) if not editor : if sys . platform[ : 3] = = ' win ' : editor = ' notepad ' else : # Favor command-line editors first so we don ' t leave the terminal to edit for editor in [ ' vim ' , ' vi ' , ' emacs ' , ' nano ' , ' pico ' , ' gedit ' , ' kate ' , ' subl ' , ' geany ' , ' atom ' ] : if which ( editor ) : break return editor": 6149,
 "def get_pixel ( framebuf , x , y ) : index = ( y >> 3 ) * framebuf . stride + x offset = y & 0x07 return ( framebuf . buf[index] >> offset ) & 0x01": 6150,
 "def is_sqlatype_text_over_one_char ( coltype : Union[TypeEngine , VisitableType] ) -> bool : coltype = _coltype_to_typeengine ( coltype ) return is_sqlatype_text_of_length_at_least ( coltype , 2 ) ": 6151,
 "def is_string_dtype ( arr_or_dtype ) : # TODO : gh-15585 : consider making the checks stricter . def condition ( dtype ) : return dtype . kind in ( ' O ' , ' S ' , ' U ' ) and not is_period_dtype ( dtype ) return _is_dtype ( arr_or_dtype , condition ) ": 6152,
 "def expired ( self ) : if self . timeout is None : return False return monotonic ( ) - self . start_time > self . timeout": 6153,
 "def _extension ( modpath : str ) -> setuptools . Extension : return setuptools . Extension ( modpath , [modpath . replace ( \" . \" , \" / \" ) + \" . py \" ] ) ": 6154,
 "def _skip ( self , cnt ) : while cnt > 0 : if cnt > 8192 : buf = self . read ( 8192 ) else : buf = self . read ( cnt ) if not buf : break cnt - = len ( buf ) ": 6155,
 "def validate ( request : Union[Dict , List] , schema : dict ) -> Union[Dict , List] : jsonschema_validate ( request , schema ) return request": 6156,
 "def format_exp_floats ( decimals ) : threshold = 10 ** 5 return ( lambda n : \" { : . {prec}e} \" . format ( n , prec = decimals ) if n > threshold else \" { : 4 . {prec}f} \" . format ( n , prec = decimals ) ) ": 6157,
 "def login ( self , user : str , passwd : str ) -> None : self . context . login ( user , passwd ) ": 6158,
 "def remove_leading_zeros ( num : str ) -> str : if not num : return num if num . startswith ( ' M ' ) : ret = ' M ' + num[1 : ] . lstrip ( ' 0 ' ) elif num . startswith ( ' - ' ) : ret = ' - ' + num[1 : ] . lstrip ( ' 0 ' ) else : ret = num . lstrip ( ' 0 ' ) return ' 0 ' if ret in ( ' ' , ' M ' , ' - ' ) else ret": 6159,
 "def increment_frame ( self ) : self . current_frame + = 1 if self . current_frame > = self . end_frame : # Wrap back to the beginning of the animation . self . current_frame = 0": 6160,
 "def singularize ( word ) : for inflection in UNCOUNTABLES : if re . search ( r ' ( ?i ) \\b ( %s ) \\Z ' % inflection , word ) : return word for rule , replacement in SINGULARS : if re . search ( rule , word ) : return re . sub ( rule , replacement , word ) return word": 6161,
 "def get_environment_info ( ) -> dict : data = _environ . systems . get_system_data ( ) data[ ' cauldron ' ] = _environ . package_settings . copy ( ) return data": 6162,
 "def pruning ( self , X , y , cost_mat ) : self . tree_ . tree_pruned = copy . deepcopy ( self . tree_ . tree ) if self . tree_ . n_nodes > 0 : self . _pruning ( X , y , cost_mat ) nodes_pruned = self . _nodes ( self . tree_ . tree_pruned ) self . tree_ . n_nodes_pruned = len ( nodes_pruned ) ": 6163,
 "def content_type ( self ) -> ContentType : return self . _ctype if self . _ctype else self . parent . content_type ( ) ": 6164,
 "def fix_missing ( df , col , name , na_dict ) : if is_numeric_dtype ( col ) : if pd . isnull ( col ) . sum ( ) or ( name in na_dict ) : df[name+ ' _na ' ] = pd . isnull ( col ) filler = na_dict[name] if name in na_dict else col . median ( ) df[name] = col . fillna ( filler ) na_dict[name] = filler return na_dict": 6165,
 "def same ( *values ) : if not values : return True first , rest = values[0] , values[1 : ] return all ( value = = first for value in rest ) ": 6166,
 "def trunc ( obj , max , left = 0 ) : s = str ( obj ) s = s . replace ( ' \\n ' , ' | ' ) if len ( s ) > max : if left : return ' . . . ' +s[len ( s ) -max+3 : ] else : return s[ : ( max-3 ) ]+ ' . . . ' else : return s": 6167,
 "def remove_blank_spaces ( syllables : List[str] ) -> List[str] : cleaned = [] for syl in syllables : if syl = = \" \" or syl = = ' ' : pass else : cleaned . append ( syl ) return cleaned": 6168,
 "def dict_to_ddb ( item ) : # type : ( Dict[str , Any] ) -> Dict[str , Any] # TODO : narrow these types down serializer = TypeSerializer ( ) return {key : serializer . serialize ( value ) for key , value in item . items ( ) }": 6169,
 "def input ( prompt = \" \" ) : \t\t\tstring = stdin_decode ( raw_input ( prompt ) ) \t\tcaller_frame = sys . _getframe ( 1 ) \tglobals = caller_frame . f_globals\tlocals = caller_frame . f_locals\t\treturn eval ( string , globals , locals ) ": 6170,
 "def convert_to_int ( x : Any , default : int = None ) -> int : try : return int ( x ) except ( TypeError , ValueError ) : return default": 6171,
 "def filter_bool ( n : Node , query : str ) -> bool : return _scalariter2item ( n , query , bool ) ": 6172,
 "def page_align_content_length ( length ) : # type : ( int ) -> int mod = length % _PAGEBLOB_BOUNDARY if mod ! = 0 : return length + ( _PAGEBLOB_BOUNDARY - mod ) return length": 6173,
 "def getVectorFromType ( self , dtype ) -> Union[bool , None , Tuple[int , int]] : if dtype = = BIT : return False elif isinstance ( dtype , Bits ) : return [evalParam ( dtype . width ) - 1 , hInt ( 0 ) ]": 6174,
 "def use_kwargs ( self , *args , **kwargs ) -> typing . Callable : return super ( ) . use_kwargs ( *args , **kwargs ) ": 6175,
 "def convert_camel_case_string ( name : str ) -> str : string = re . sub ( \" ( . ) ( [A-Z][a-z]+ ) \" , r \" \\1_\\2 \" , name ) return re . sub ( \" ( [a-z0-9] ) ( [A-Z] ) \" , r \" \\1_\\2 \" , string ) . lower ( ) ": 6176,
 "def distinct_permutations ( iterable ) : def make_new_permutations ( permutations , e ) : \" \" \" Internal helper function . The output permutations are built up by adding element *e* to the current *permutations* at every possible position . The key idea is to keep repeated elements ( reverse ) ordered : if e1 = = e2 and e1 is before e2 in the iterable , then all permutations with e1 before e2 are ignored . \" \" \" for permutation in permutations : for j in range ( len ( permutation ) ) : yield permutation[ : j] + [e] + permutation[j : ] if permutation[j] = = e : break else : yield permutation + [e] permutations = [[]] for e in iterable : permutations = make_new_permutations ( permutations , e ) return ( tuple ( t ) for t in permutations ) ": 6177,
 "def text_alignment ( x , y ) : if x = = 0 : ha = \" center \" elif x > 0 : ha = \" left \" else : ha = \" right \" if y = = 0 : va = \" center \" elif y > 0 : va = \" bottom \" else : va = \" top \" return ha , va": 6178,
 "def _validate_image_rank ( self , img_array ) : if img_array . ndim = = 1 or img_array . ndim > 3 : msg = \" {0}D imagery is not allowed . \" . format ( img_array . ndim ) raise IOError ( msg ) ": 6179,
 "def _isbool ( string ) : return isinstance ( string , _bool_type ) or\\ ( isinstance ( string , ( _binary_type , _text_type ) ) and string in ( \" True \" , \" False \" ) ) ": 6180,
 "def __gt__ ( self , other ) : if not isinstance ( other , Key ) : return NotImplemented return self . __tuple ( ) > other . __tuple ( ) ": 6181,
 "def strictly_positive_int_or_none ( val ) : val = positive_int_or_none ( val ) if val is None or val > 0 : return val raise ValueError ( ' \" {} \" must be strictly positive ' . format ( val ) ) ": 6182,
 "def sections ( self ) -> list : self . config . read ( self . filepath ) return self . config . sections ( ) ": 6183,
 "def assert_raises ( ex_type , func , *args , **kwargs ) : r try : func ( *args , **kwargs ) except Exception as ex : assert isinstance ( ex , ex_type ) , ( ' Raised %r but type should have been %r ' % ( ex , ex_type ) ) return True else : raise AssertionError ( ' No error was raised ' ) ": 6184,
 "def _numbers_units ( N ) : lst = range ( 1 , N + 1 ) return \" \" . join ( list ( map ( lambda i : str ( i % 10 ) , lst ) ) ) ": 6185,
 "def insert_ordered ( value , array ) : index = 0 # search for the last array item that value is larger than for n in range ( 0 , len ( array ) ) : if value > = array[n] : index = n+1 array . insert ( index , value ) return index": 6186,
 "def check_python_version ( ) : # Required due to multiple with statements on one line req_version = ( 2 , 7 ) cur_version = sys . version_info if cur_version > = req_version : print ( \" Python version . . . %sOK%s ( found %s , requires %s ) \" % ( Bcolors . OKGREEN , Bcolors . ENDC , str ( platform . python_version ( ) ) , str ( req_version[0] ) + \" . \" + str ( req_version[1] ) ) ) else : print ( \" Python version . . . %sFAIL%s ( found %s , requires %s ) \" % ( Bcolors . FAIL , Bcolors . ENDC , str ( cur_version ) , str ( req_version ) ) ) ": 6187,
 "def get_caller_module ( ) : stack = inspect . stack ( ) assert len ( stack ) > 1 caller = stack[2][0] return caller . f_globals[ ' __name__ ' ]": 6188,
 "def memory_read ( self , start_position : int , size : int ) -> memoryview : return self . _memory . read ( start_position , size ) ": 6189,
 "def pluralize ( word ) : if not word or word . lower ( ) in UNCOUNTABLES : return word else : for rule , replacement in PLURALS : if re . search ( rule , word ) : return re . sub ( rule , replacement , word ) return word": 6190,
 "def positive_int ( val ) : if isinstance ( val , float ) : raise ValueError ( ' \" {} \" must not be a float ' . format ( val ) ) val = int ( val ) if val > = 0 : return val raise ValueError ( ' \" {} \" must be positive ' . format ( val ) ) ": 6191,
 "def signed_area ( coords ) : xs , ys = map ( list , zip ( *coords ) ) xs . append ( xs[1] ) ys . append ( ys[1] ) return sum ( xs[i]* ( ys[i+1]-ys[i-1] ) for i in range ( 1 , len ( coords ) ) ) /2 . 0": 6192,
 "def classify_fit ( fqdn , result , *argl , **argd ) : if len ( argl ) > 2 : # Usually fit is called with fit ( machine , Xtrain , ytrain ) . yP = argl[2] out = _generic_fit ( fqdn , result , classify_predict , yP , *argl , **argd ) return out": 6193,
 "def thai_to_eng ( text : str ) -> str : return \" \" . join ( [TH_EN_KEYB_PAIRS[ch] if ( ch in TH_EN_KEYB_PAIRS ) else ch for ch in text] ) ": 6194,
 "def months_ago ( date , nb_months = 1 ) : nb_years = nb_months // 12 nb_months = nb_months % 12 month_diff = date . month - nb_months if month_diff > 0 : new_month = month_diff else : new_month = 12 + month_diff nb_years + = 1 return date . replace ( day = 1 , month = new_month , year = date . year - nb_years ) ": 6195,
 "def exists ( self ) : limit = self . limit_ result = self . limit ( 1 ) . count ( ) > 0 self . limit ( limit ) return result": 6196,
 "def normalize_pattern ( pattern ) : if not ( pattern . startswith ( ' RE : ' ) or pattern . startswith ( ' !RE : ' ) ) : pattern = _slashes . sub ( ' / ' , pattern ) if len ( pattern ) > 1 : pattern = pattern . rstrip ( ' / ' ) return pattern": 6197,
 "def _collection_literal_to_py_ast ( ctx : GeneratorContext , form : Iterable[LispForm] ) -> Iterable[GeneratedPyAST] : yield from map ( partial ( _const_val_to_py_ast , ctx ) , form ) ": 6198,
 "def segment_intersection ( start0 , end0 , start1 , end1 ) : r delta0 = end0 - start0 delta1 = end1 - start1 cross_d0_d1 = _helpers . cross_product ( delta0 , delta1 ) if cross_d0_d1 = = 0 . 0 : return None , None , False else : start_delta = start1 - start0 s = _helpers . cross_product ( start_delta , delta1 ) / cross_d0_d1 t = _helpers . cross_product ( start_delta , delta0 ) / cross_d0_d1 return s , t , True": 6199,
 "def kernel ( self , spread = 1 ) : # TODO : use self . kernel_type to choose function def gaussian ( data , pixel ) : return mvn . pdf ( data , mean = pixel , cov = spread ) return gaussian": 6200,
 "def getPiLambert ( n ) : mypi = piGenLambert ( ) result = [] if n > 0 : result + = [next ( mypi ) for i in range ( n ) ] mypi . close ( ) return result": 6201,
 "def _get_latest_version ( ) : url = ' https : //api . github . com/repos/{}/releases/latest ' . format ( constants . DUSTY_GITHUB_PATH ) conn = urllib . urlopen ( url ) if conn . getcode ( ) > = 300 : raise RuntimeError ( ' GitHub api returned code {}; can\\ ' t determine latest version . Aborting ' . format ( conn . getcode ( ) ) ) json_data = conn . read ( ) return json . loads ( json_data ) [ ' tag_name ' ]": 6202,
 "def shift ( self , m : Union[float , pd . Series] ) -> Union[int , pd . Series] : out = m % 1 * self . TEN_DIGIT_MODULUS // 1 if isinstance ( out , pd . Series ) : return out . astype ( int ) return int ( out ) ": 6203,
 "def kdot ( x , y , K = 2 ) : xx = x . reshape ( -1 , x . shape[-1] ) yy = y . reshape ( y . shape[0] , -1 ) xx = numpy . ascontiguousarray ( xx ) yy = numpy . ascontiguousarray ( yy ) r = _accupy . kdot_helper ( xx , yy ) . reshape ( ( -1 , ) + x . shape[ : -1] + y . shape[1 : ] ) return ksum ( r , K - 1 ) ": 6204,
 "def pad ( a , desiredlength ) : if len ( a ) > = desiredlength : return a islist = isinstance ( a , list ) a = np . array ( a ) diff = desiredlength - len ( a ) shape = list ( a . shape ) shape[0] = diff padded = np . concatenate ( [a , np . zeros ( shape , dtype = a . dtype ) ] ) return padded . tolist ( ) if islist else padded": 6205,
 "def _darwin_current_arch ( self ) : if sys . platform = = \" darwin \" : if sys . maxsize > 2 ** 32 : # 64bits . return platform . mac_ver ( ) [2] # Both Darwin and Python are 64bits . else : # Python 32 bits return platform . processor ( ) ": 6206,
 "def usetz_now ( ) : USE_TZ = getattr ( settings , ' USE_TZ ' , False ) if USE_TZ and DJANGO_VERSION > = ' 1 . 4 ' : return now ( ) else : return datetime . utcnow ( ) ": 6207,
 "def get_codes ( s : Union[str , ' ChainedBase ' ] ) -> List[str] : return codegrabpat . findall ( str ( s ) ) ": 6208,
 "def setdefault ( self , name : str , default : Any = None ) -> Any : return self . __dict__ . setdefault ( name , default ) ": 6209,
 "def decode ( string , base ) : base = int ( base ) code_string = get_code_string ( base ) result = 0 if base = = 16 : string = string . lower ( ) while len ( string ) > 0 : result * = base result + = code_string . find ( string[0] ) string = string[1 : ] return result": 6210,
 "def enrich_complexes ( graph : BELGraph ) -> None : nodes = list ( get_nodes_by_function ( graph , COMPLEX ) ) for u in nodes : for v in u . members : graph . add_has_component ( u , v ) ": 6211,
 "def layer_with ( self , sample : np . ndarray , value : int ) -> np . ndarray : b = np . full ( ( 2 , len ( sample ) ) , value , dtype = float ) b[0] = sample return b": 6212,
 "def input_validate_str ( string , name , max_len = None , exact_len = None ) : if type ( string ) is not str : raise pyhsm . exception . YHSM_WrongInputType ( name , str , type ( string ) ) if max_len ! = None and len ( string ) > max_len : raise pyhsm . exception . YHSM_InputTooLong ( name , max_len , len ( string ) ) if exact_len ! = None and len ( string ) ! = exact_len : raise pyhsm . exception . YHSM_WrongInputSize ( name , exact_len , len ( string ) ) return string": 6213,
 "def index ( self , item ) : for i , x in enumerate ( self . iter ( ) ) : if x = = item : return i return None": 6214,
 "def _get_tuple ( self , fields ) : v1 = ' ' v2 = ' ' if len ( fields ) > 0 : v1 = fields[0] if len ( fields ) > 1 : v2 = fields[1] return v1 , v2": 6215,
 "def autoreload ( self , parameter_s = ' ' ) : r if parameter_s = = ' ' : self . _reloader . check ( True ) elif parameter_s = = ' 0 ' : self . _reloader . enabled = False elif parameter_s = = ' 1 ' : self . _reloader . check_all = False self . _reloader . enabled = True elif parameter_s = = ' 2 ' : self . _reloader . check_all = True self . _reloader . enabled = True": 6216,
 "def _centroids ( n_clusters : int , points : List[List[float]] ) -> List[List[float]] : k_means = KMeans ( n_clusters = n_clusters ) k_means . fit ( points ) closest , _ = pairwise_distances_argmin_min ( k_means . cluster_centers_ , points ) return list ( map ( list , np . array ( points ) [closest . tolist ( ) ] ) ) ": 6217,
 "def inner ( tensor0 : BKTensor , tensor1 : BKTensor ) -> BKTensor : # Note : Relying on fact that vdot flattens arrays return np . vdot ( tensor0 , tensor1 ) ": 6218,
 "def get_unique_links ( self ) : page_url = self . get_current_url ( ) soup = self . get_beautiful_soup ( self . get_page_source ( ) ) links = page_utils . _get_unique_links ( page_url , soup ) return links": 6219,
 "def identify_request ( request : RequestType ) -> bool : # noinspection PyBroadException try : data = json . loads ( decode_if_bytes ( request . body ) ) if \" @context \" in data : return True except Exception : pass return False": 6220,
 "def get_all_args ( fn ) -> list : sig = inspect . signature ( fn ) return list ( sig . parameters ) ": 6221,
 "def enumerate_chunks ( phrase , spacy_nlp ) : if ( len ( phrase ) > 1 ) : found = False text = \" \" . join ( [rl . text for rl in phrase] ) doc = spacy_nlp ( text . strip ( ) , parse = True ) for np in doc . noun_chunks : if np . text ! = text : found = True yield np . text , find_chunk ( phrase , np . text . split ( \" \" ) ) if not found and all ( [rl . pos[0] ! = \" v \" for rl in phrase] ) : yield text , phrase": 6222,
 "def convert_column ( self , values ) : assert all ( values > = 0 ) , ' Cannot normalize a column with negatives ' total = sum ( values ) if total > 0 : return values / total else : return values": 6223,
 "def uniqued ( iterable ) : seen = set ( ) add = seen . add return [i for i in iterable if i not in seen and not add ( i ) ]": 6224,
 "def run_web ( self , flask , host = ' 127 . 0 . 0 . 1 ' , port = 5000 , **options ) : # type : ( Zsl , str , int , **Any ) ->None return flask . run ( host = flask . config . get ( ' FLASK_HOST ' , host ) , port = flask . config . get ( ' FLASK_PORT ' , port ) , debug = flask . config . get ( ' DEBUG ' , False ) , **options ) ": 6225,
 "def _is_video ( filepath ) -> bool : if os . path . exists ( filepath ) : # Could be broken symlink extension = os . path . splitext ( filepath ) [1] return extension in ( ' . mkv ' , ' . mp4 ' , ' . avi ' ) else : return False": 6226,
 "def combine_pdf_as_bytes ( pdfs : List[BytesIO] ) -> bytes : writer = PdfWriter ( ) for pdf in pdfs : writer . addpages ( PdfReader ( pdf ) . pages ) bio = BytesIO ( ) writer . write ( bio ) bio . seek ( 0 ) output = bio . read ( ) bio . close ( ) return output": 6227,
 "def session_expired ( self ) : if not self . _login_time or ( datetime . datetime . now ( ) -self . _login_time ) . total_seconds ( ) > 12000 : return True": 6228,
 "def repl_complete ( text : str , state : int ) -> Optional[str] : # Can ' t complete Keywords , Numerals if __NOT_COMPLETEABLE . match ( text ) : return None elif text . startswith ( \" : \" ) : completions = kw . complete ( text ) else : ns = get_current_ns ( ) completions = ns . complete ( text ) return list ( completions ) [state] if completions is not None else None": 6229,
 "def ranges_to_set ( lst ) : return set ( itertools . chain ( * ( range ( x[0] , x[1]+1 ) for x in lst ) ) ) ": 6230,
 "def supports_py3 ( project_name ) : log = logging . getLogger ( \" ciu \" ) log . info ( \" Checking {} . . . \" . format ( project_name ) ) request = requests . get ( \" https : //pypi . org/pypi/{}/json \" . format ( project_name ) ) if request . status_code > = 400 : log = logging . getLogger ( \" ciu \" ) log . warning ( \" problem fetching {} , assuming ported ( {} ) \" . format ( project_name , request . status_code ) ) return True response = request . json ( ) return any ( c . startswith ( \" Programming Language : : Python : : 3 \" ) for c in response[ \" info \" ][ \" classifiers \" ] ) ": 6231,
 "def get_triangles ( graph : DiGraph ) -> SetOfNodeTriples : return { tuple ( sorted ( [a , b , c] , key = str ) ) for a , b in graph . edges ( ) for c in graph . successors ( b ) if graph . has_edge ( c , a ) }": 6232,
 "def assert_in ( first , second , msg_fmt = \" {msg} \" ) : if first not in second : msg = \" {!r} not in {!r} \" . format ( first , second ) fail ( msg_fmt . format ( msg = msg , first = first , second = second ) ) ": 6233,
 "def dictfetchall ( cursor : Cursor ) -> List[Dict[str , Any]] : columns = get_fieldnames_from_cursor ( cursor ) return [ OrderedDict ( zip ( columns , row ) ) for row in cursor . fetchall ( ) ]": 6234,
 "def backspace ( self ) : if self . _cx + self . _cw > = 0 : self . erase ( ) self . _cx - = self . _cw self . flush ( ) ": 6235,
 "def to_json ( self ) -> Mapping : return {str ( x ) : str ( y ) for x , y in self . items ( ) }": 6236,
 "def remove_leading ( needle , haystack ) : if haystack[ : len ( needle ) ] = = needle : return haystack[len ( needle ) : ] return haystack": 6237,
 "def CheckDisjointCalendars ( self ) : # TODO : Do an exact check here . a_service_periods = self . feed_merger . a_schedule . GetServicePeriodList ( ) b_service_periods = self . feed_merger . b_schedule . GetServicePeriodList ( ) for a_service_period in a_service_periods : a_start , a_end = a_service_period . GetDateRange ( ) for b_service_period in b_service_periods : b_start , b_end = b_service_period . GetDateRange ( ) overlap_start = max ( a_start , b_start ) overlap_end = min ( a_end , b_end ) if overlap_end > = overlap_start : return False return True": 6238,
 "def toHdlConversion ( self , top , topName : str , saveTo : str ) -> List[str] : raise NotImplementedError ( \" Implement this function for your type of your top module \" ) ": 6239,
 "def titleize ( text ) : if len ( text ) = = 0 : # if empty string , return it return text else : text = text . lower ( ) # lower all char # delete redundant empty space chunks = [chunk[0] . upper ( ) + chunk[1 : ] for chunk in text . split ( \" \" ) if len ( chunk ) > = 1] return \" \" . join ( chunks ) ": 6240,
 "def set_int ( bytearray_ , byte_index , _int ) : # make sure were dealing with an int _int = int ( _int ) _bytes = struct . unpack ( ' 2B ' , struct . pack ( ' >h ' , _int ) ) bytearray_[byte_index : byte_index + 2] = _bytes return bytearray_": 6241,
 "def dfromdm ( dm ) : if np . size ( dm ) >1 : dm = np . atleast_1d ( dm ) return 10** ( 1+dm/5 ) ": 6242,
 "def spanning_tree_count ( graph : nx . Graph ) -> int : laplacian = nx . laplacian_matrix ( graph ) . toarray ( ) comatrix = laplacian[ : -1 , : -1] det = np . linalg . det ( comatrix ) count = int ( round ( det ) ) return count": 6243,
 "def define_struct ( defn ) : struct = parse_type ( defn ) ALL_TYPES[struct . name] = struct return struct": 6244,
 "def get_current_item ( self ) : l = self . selectedIndexes ( ) if len ( l ) > 0 : return self . model ( ) . get_item ( l[0] ) ": 6245,
 "def median ( data ) : if len ( data ) = = 0 : return None data = sorted ( data ) return float ( ( data[len ( data ) // 2] + data[ ( len ( data ) - 1 ) // 2] ) / 2 . ) ": 6246,
 "def get_input_nodes ( G : nx . DiGraph ) -> List[str] : return [n for n , d in G . in_degree ( ) if d = = 0]": 6247,
 "def attr_names ( cls ) -> List[str] : return [k for k , v in cls . attr_types ( ) . items ( ) ]": 6248,
 "def is_blankspace ( self , char ) : if len ( char ) > 1 : raise TypeError ( \" Expected a char . \" ) if char in self . blankspaces : return True return False": 6249,
 "def consistent_shuffle ( *lists ) : perm = list ( range ( len ( lists[0] ) ) ) random . shuffle ( perm ) lists = tuple ( [sublist[index] for index in perm] for sublist in lists ) return lists": 6250,
 "def compatible_staticpath ( path ) : if VERSION > = ( 1 , 10 ) : # Since Django 1 . 10 , forms . Media automatically invoke static # lazily on the path if it is relative . return path try : # > = 1 . 4 from django . templatetags . static import static return static ( path ) except ImportError : pass try : # > = 1 . 3 return ' %s/%s ' % ( settings . STATIC_URL . rstrip ( ' / ' ) , path ) except AttributeError : pass try : return ' %s/%s ' % ( settings . PAGEDOWN_URL . rstrip ( ' / ' ) , path ) except AttributeError : pass return ' %s/%s ' % ( settings . MEDIA_URL . rstrip ( ' / ' ) , path ) ": 6251,
 "def simple_moving_average ( x , n = 10 ) : if x . ndim > 1 and len ( x[0] ) > 1 : x = np . average ( x , axis = 1 ) a = np . ones ( n ) / float ( n ) return np . convolve ( x , a , ' valid ' ) ": 6252,
 "def mostLikely ( self , pred ) : if len ( pred ) = = 1 : return pred . keys ( ) [0] mostLikelyOutcome = None maxProbability = 0 for prediction , probability in pred . items ( ) : if probability > maxProbability : mostLikelyOutcome = prediction maxProbability = probability return mostLikelyOutcome": 6253,
 "def has_obstory_metadata ( self , status_id ) : self . con . execute ( ' SELECT 1 FROM archive_metadata WHERE publicId = %s; ' , ( status_id , ) ) return len ( self . con . fetchall ( ) ) > 0": 6254,
 "def require ( executable : str , explanation : str = \" \" ) -> None : assert shutil . which ( executable ) , \" Need {!r} on the PATH . {} \" . format ( executable , \" \\n \" + explanation if explanation else \" \" ) ": 6255,
 "def without ( seq1 , seq2 ) : r if isSet ( seq2 ) : d2 = seq2 else : d2 = set ( seq2 ) return [elt for elt in seq1 if elt not in d2]": 6256,
 "def _check_stream_timeout ( started , timeout ) : if timeout : elapsed = datetime . datetime . utcnow ( ) - started if elapsed . seconds > timeout : raise StopIteration": 6257,
 "def trim_decimals ( s , precision = -3 ) : encoded = s . encode ( ' ascii ' , ' ignore ' ) str_val = \" \" if six . PY3 : str_val = str ( encoded , encoding = ' ascii ' , errors = ' ignore ' ) [ : precision] else : # If precision is 0 , this must be handled seperately if precision = = 0 : str_val = str ( encoded ) else : str_val = str ( encoded ) [ : precision] if len ( str_val ) > 0 : return float ( str_val ) else : return 0": 6258,
 "def test_string ( self , string : str ) -> bool : if self . input . startswith ( string , self . offset ) : self . offset + = len ( string ) return True return False": 6259,
 "def capture_stdout ( ) : stdout = sys . stdout sys . stdout = six . moves . cStringIO ( ) try : yield sys . stdout finally : sys . stdout = stdout": 6260,
 "def get_valid_filename ( s ) : s = s . strip ( ) . replace ( \" \" , \" _ \" ) return re . sub ( r \" ( ?u ) [^-\\w . ] \" , \" \" , s ) ": 6261,
 "def _is_numeric ( self , values ) : if len ( values ) > 0 : assert isinstance ( values[0] , ( float , int ) ) , \\ \" values must be numbers to perform math operations . Got {} \" . format ( type ( values[0] ) ) return True": 6262,
 "def copen ( filepath , flag = ' r ' , encoding = None ) : if encoding is None : encoding = locale . getdefaultlocale ( ) [1] return codecs . open ( filepath , flag , encoding ) ": 6263,
 "def create_opengl_object ( gl_gen_function , n = 1 ) : handle = gl . GLuint ( 1 ) gl_gen_function ( n , byref ( handle ) ) # Create n Empty Objects if n > 1 : return [handle . value + el for el in range ( n ) ] # Return list of handle values else : return handle . value": 6264,
 "def text_to_bool ( value : str ) -> bool : try : return bool ( strtobool ( value ) ) except ( ValueError , AttributeError ) : return value is not None": 6265,
 "def _check_env_var ( envvar : str ) -> bool : if os . getenv ( envvar ) is None : raise KeyError ( \" Required ENVVAR : {0} is not set \" . format ( envvar ) ) if not os . getenv ( envvar ) : # test if env var is empty raise KeyError ( \" Required ENVVAR : {0} is empty \" . format ( envvar ) ) return True": 6266
}